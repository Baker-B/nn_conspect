{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_hat\n",
      "[[0.83237553]\n",
      " [0.89655717]\n",
      " [0.87337397]\n",
      " [0.92904704]]\n",
      "y\n",
      "[[0.21]\n",
      " [0.83]\n",
      " [0.87]\n",
      " [0.75]]\n",
      "mse(y, y_hat)\n",
      "0.1059625955371147\n",
      "loss before training is 0.1059625955371147 -- epoch number 1\n",
      "\n",
      "\n",
      "loss before training is 0.10585968196673604 -- epoch number 2\n",
      "\n",
      "\n",
      "loss before training is 0.10575657334190687 -- epoch number 3\n",
      "\n",
      "\n",
      "loss before training is 0.10565326961304952 -- epoch number 4\n",
      "\n",
      "\n",
      "loss before training is 0.10554977073417839 -- epoch number 5\n",
      "\n",
      "\n",
      "loss before training is 0.10544607666292939 -- epoch number 6\n",
      "\n",
      "\n",
      "loss before training is 0.10534218736058998 -- epoch number 7\n",
      "\n",
      "\n",
      "loss before training is 0.10523810279212893 -- epoch number 8\n",
      "\n",
      "\n",
      "loss before training is 0.10513382292622661 -- epoch number 9\n",
      "\n",
      "\n",
      "loss before training is 0.10502934773530453 -- epoch number 10\n",
      "\n",
      "\n",
      "loss before training is 0.10492467719555569 -- epoch number 11\n",
      "\n",
      "\n",
      "loss before training is 0.10481981128697457 -- epoch number 12\n",
      "\n",
      "\n",
      "loss before training is 0.10471474999338735 -- epoch number 13\n",
      "\n",
      "\n",
      "loss before training is 0.10460949330248223 -- epoch number 14\n",
      "\n",
      "\n",
      "loss before training is 0.10450404120583942 -- epoch number 15\n",
      "\n",
      "\n",
      "loss before training is 0.10439839369896174 -- epoch number 16\n",
      "\n",
      "\n",
      "loss before training is 0.10429255078130464 -- epoch number 17\n",
      "\n",
      "\n",
      "loss before training is 0.10418651245630704 -- epoch number 18\n",
      "\n",
      "\n",
      "loss before training is 0.10408027873142128 -- epoch number 19\n",
      "\n",
      "\n",
      "loss before training is 0.10397384961814393 -- epoch number 20\n",
      "\n",
      "\n",
      "loss before training is 0.10386722513204605 -- epoch number 21\n",
      "\n",
      "\n",
      "loss before training is 0.10376040529280385 -- epoch number 22\n",
      "\n",
      "\n",
      "loss before training is 0.1036533901242293 -- epoch number 23\n",
      "\n",
      "\n",
      "loss before training is 0.1035461796543005 -- epoch number 24\n",
      "\n",
      "\n",
      "loss before training is 0.10343877391519246 -- epoch number 25\n",
      "\n",
      "\n",
      "loss before training is 0.10333117294330767 -- epoch number 26\n",
      "\n",
      "\n",
      "loss before training is 0.10322337677930671 -- epoch number 27\n",
      "\n",
      "\n",
      "loss before training is 0.10311538546813886 -- epoch number 28\n",
      "\n",
      "\n",
      "loss before training is 0.10300719905907292 -- epoch number 29\n",
      "\n",
      "\n",
      "loss before training is 0.1028988176057278 -- epoch number 30\n",
      "\n",
      "\n",
      "loss before training is 0.10279024116610308 -- epoch number 31\n",
      "\n",
      "\n",
      "loss before training is 0.10268146980261 -- epoch number 32\n",
      "\n",
      "\n",
      "loss before training is 0.10257250358210172 -- epoch number 33\n",
      "\n",
      "\n",
      "loss before training is 0.10246334257590442 -- epoch number 34\n",
      "\n",
      "\n",
      "loss before training is 0.10235398685984769 -- epoch number 35\n",
      "\n",
      "\n",
      "loss before training is 0.10224443651429546 -- epoch number 36\n",
      "\n",
      "\n",
      "loss before training is 0.10213469162417632 -- epoch number 37\n",
      "\n",
      "\n",
      "loss before training is 0.10202475227901439 -- epoch number 38\n",
      "\n",
      "\n",
      "loss before training is 0.1019146185729601 -- epoch number 39\n",
      "\n",
      "\n",
      "loss before training is 0.10180429060482034 -- epoch number 40\n",
      "\n",
      "\n",
      "loss before training is 0.10169376847808943 -- epoch number 41\n",
      "\n",
      "\n",
      "loss before training is 0.10158305230097972 -- epoch number 42\n",
      "\n",
      "\n",
      "loss before training is 0.10147214218645165 -- epoch number 43\n",
      "\n",
      "\n",
      "loss before training is 0.10136103825224474 -- epoch number 44\n",
      "\n",
      "\n",
      "loss before training is 0.10124974062090783 -- epoch number 45\n",
      "\n",
      "\n",
      "loss before training is 0.10113824941982952 -- epoch number 46\n",
      "\n",
      "\n",
      "loss before training is 0.1010265647812686 -- epoch number 47\n",
      "\n",
      "\n",
      "loss before training is 0.10091468684238415 -- epoch number 48\n",
      "\n",
      "\n",
      "loss before training is 0.10080261574526615 -- epoch number 49\n",
      "\n",
      "\n",
      "loss before training is 0.10069035163696553 -- epoch number 50\n",
      "\n",
      "\n",
      "loss before training is 0.10057789466952428 -- epoch number 51\n",
      "\n",
      "\n",
      "loss before training is 0.10046524500000567 -- epoch number 52\n",
      "\n",
      "\n",
      "loss before training is 0.10035240279052422 -- epoch number 53\n",
      "\n",
      "\n",
      "loss before training is 0.10023936820827575 -- epoch number 54\n",
      "\n",
      "\n",
      "loss before training is 0.1001261414255671 -- epoch number 55\n",
      "\n",
      "\n",
      "loss before training is 0.1000127226198462 -- epoch number 56\n",
      "\n",
      "\n",
      "loss before training is 0.09989911197373147 -- epoch number 57\n",
      "\n",
      "\n",
      "loss before training is 0.09978530967504207 -- epoch number 58\n",
      "\n",
      "\n",
      "loss before training is 0.09967131591682678 -- epoch number 59\n",
      "\n",
      "\n",
      "loss before training is 0.0995571308973938 -- epoch number 60\n",
      "\n",
      "\n",
      "loss before training is 0.09944275482034046 -- epoch number 61\n",
      "\n",
      "\n",
      "loss before training is 0.09932818789458177 -- epoch number 62\n",
      "\n",
      "\n",
      "loss before training is 0.09921343033438026 -- epoch number 63\n",
      "\n",
      "\n",
      "loss before training is 0.0990984823593748 -- epoch number 64\n",
      "\n",
      "\n",
      "loss before training is 0.0989833441946095 -- epoch number 65\n",
      "\n",
      "\n",
      "loss before training is 0.09886801607056275 -- epoch number 66\n",
      "\n",
      "\n",
      "loss before training is 0.09875249822317576 -- epoch number 67\n",
      "\n",
      "\n",
      "loss before training is 0.09863679089388125 -- epoch number 68\n",
      "\n",
      "\n",
      "loss before training is 0.09852089432963207 -- epoch number 69\n",
      "\n",
      "\n",
      "loss before training is 0.09840480878292919 -- epoch number 70\n",
      "\n",
      "\n",
      "loss before training is 0.09828853451185039 -- epoch number 71\n",
      "\n",
      "\n",
      "loss before training is 0.0981720717800779 -- epoch number 72\n",
      "\n",
      "\n",
      "loss before training is 0.09805542085692658 -- epoch number 73\n",
      "\n",
      "\n",
      "loss before training is 0.09793858201737163 -- epoch number 74\n",
      "\n",
      "\n",
      "loss before training is 0.09782155554207624 -- epoch number 75\n",
      "\n",
      "\n",
      "loss before training is 0.09770434171741896 -- epoch number 76\n",
      "\n",
      "\n",
      "loss before training is 0.09758694083552112 -- epoch number 77\n",
      "\n",
      "\n",
      "loss before training is 0.09746935319427394 -- epoch number 78\n",
      "\n",
      "\n",
      "loss before training is 0.0973515790973655 -- epoch number 79\n",
      "\n",
      "\n",
      "loss before training is 0.09723361885430742 -- epoch number 80\n",
      "\n",
      "\n",
      "loss before training is 0.0971154727804617 -- epoch number 81\n",
      "\n",
      "\n",
      "loss before training is 0.09699714119706694 -- epoch number 82\n",
      "\n",
      "\n",
      "loss before training is 0.09687862443126465 -- epoch number 83\n",
      "\n",
      "\n",
      "loss before training is 0.09675992281612526 -- epoch number 84\n",
      "\n",
      "\n",
      "loss before training is 0.09664103669067402 -- epoch number 85\n",
      "\n",
      "\n",
      "loss before training is 0.0965219663999167 -- epoch number 86\n",
      "\n",
      "\n",
      "loss before training is 0.09640271229486476 -- epoch number 87\n",
      "\n",
      "\n",
      "loss before training is 0.09628327473256097 -- epoch number 88\n",
      "\n",
      "\n",
      "loss before training is 0.09616365407610385 -- epoch number 89\n",
      "\n",
      "\n",
      "loss before training is 0.09604385069467307 -- epoch number 90\n",
      "\n",
      "\n",
      "loss before training is 0.09592386496355357 -- epoch number 91\n",
      "\n",
      "\n",
      "loss before training is 0.09580369726416013 -- epoch number 92\n",
      "\n",
      "\n",
      "loss before training is 0.09568334798406113 -- epoch number 93\n",
      "\n",
      "\n",
      "loss before training is 0.09556281751700269 -- epoch number 94\n",
      "\n",
      "\n",
      "loss before training is 0.09544210626293229 -- epoch number 95\n",
      "\n",
      "\n",
      "loss before training is 0.09532121462802172 -- epoch number 96\n",
      "\n",
      "\n",
      "loss before training is 0.09520014302469061 -- epoch number 97\n",
      "\n",
      "\n",
      "loss before training is 0.09507889187162895 -- epoch number 98\n",
      "\n",
      "\n",
      "loss before training is 0.09495746159381972 -- epoch number 99\n",
      "\n",
      "\n",
      "loss before training is 0.0948358526225613 -- epoch number 100\n",
      "\n",
      "\n",
      "loss before training is 0.09471406539548931 -- epoch number 101\n",
      "\n",
      "\n",
      "loss before training is 0.09459210035659837 -- epoch number 102\n",
      "\n",
      "\n",
      "loss before training is 0.09446995795626355 -- epoch number 103\n",
      "\n",
      "\n",
      "loss before training is 0.09434763865126145 -- epoch number 104\n",
      "\n",
      "\n",
      "loss before training is 0.0942251429047912 -- epoch number 105\n",
      "\n",
      "\n",
      "loss before training is 0.09410247118649481 -- epoch number 106\n",
      "\n",
      "\n",
      "loss before training is 0.09397962397247751 -- epoch number 107\n",
      "\n",
      "\n",
      "loss before training is 0.09385660174532766 -- epoch number 108\n",
      "\n",
      "\n",
      "loss before training is 0.09373340499413635 -- epoch number 109\n",
      "\n",
      "\n",
      "loss before training is 0.09361003421451662 -- epoch number 110\n",
      "\n",
      "\n",
      "loss before training is 0.09348648990862247 -- epoch number 111\n",
      "\n",
      "\n",
      "loss before training is 0.09336277258516747 -- epoch number 112\n",
      "\n",
      "\n",
      "loss before training is 0.09323888275944295 -- epoch number 113\n",
      "\n",
      "\n",
      "loss before training is 0.09311482095333626 -- epoch number 114\n",
      "\n",
      "\n",
      "loss before training is 0.09299058769534777 -- epoch number 115\n",
      "\n",
      "\n",
      "loss before training is 0.09286618352060858 -- epoch number 116\n",
      "\n",
      "\n",
      "loss before training is 0.09274160897089731 -- epoch number 117\n",
      "\n",
      "\n",
      "loss before training is 0.09261686459465653 -- epoch number 118\n",
      "\n",
      "\n",
      "loss before training is 0.0924919509470088 -- epoch number 119\n",
      "\n",
      "\n",
      "loss before training is 0.09236686858977258 -- epoch number 120\n",
      "\n",
      "\n",
      "loss before training is 0.0922416180914776 -- epoch number 121\n",
      "\n",
      "\n",
      "loss before training is 0.09211620002737987 -- epoch number 122\n",
      "\n",
      "\n",
      "loss before training is 0.09199061497947615 -- epoch number 123\n",
      "\n",
      "\n",
      "loss before training is 0.09186486353651825 -- epoch number 124\n",
      "\n",
      "\n",
      "loss before training is 0.09173894629402683 -- epoch number 125\n",
      "\n",
      "\n",
      "loss before training is 0.09161286385430499 -- epoch number 126\n",
      "\n",
      "\n",
      "loss before training is 0.0914866168264508 -- epoch number 127\n",
      "\n",
      "\n",
      "loss before training is 0.09136020582637028 -- epoch number 128\n",
      "\n",
      "\n",
      "loss before training is 0.09123363147678948 -- epoch number 129\n",
      "\n",
      "\n",
      "loss before training is 0.09110689440726603 -- epoch number 130\n",
      "\n",
      "\n",
      "loss before training is 0.09097999525420065 -- epoch number 131\n",
      "\n",
      "\n",
      "loss before training is 0.0908529346608478 -- epoch number 132\n",
      "\n",
      "\n",
      "loss before training is 0.09072571327732636 -- epoch number 133\n",
      "\n",
      "\n",
      "loss before training is 0.09059833176062922 -- epoch number 134\n",
      "\n",
      "\n",
      "loss before training is 0.09047079077463324 -- epoch number 135\n",
      "\n",
      "\n",
      "loss before training is 0.09034309099010787 -- epoch number 136\n",
      "\n",
      "\n",
      "loss before training is 0.09021523308472408 -- epoch number 137\n",
      "\n",
      "\n",
      "loss before training is 0.09008721774306225 -- epoch number 138\n",
      "\n",
      "\n",
      "loss before training is 0.08995904565662007 -- epoch number 139\n",
      "\n",
      "\n",
      "loss before training is 0.08983071752381944 -- epoch number 140\n",
      "\n",
      "\n",
      "loss before training is 0.08970223405001337 -- epoch number 141\n",
      "\n",
      "\n",
      "loss before training is 0.08957359594749206 -- epoch number 142\n",
      "\n",
      "\n",
      "loss before training is 0.08944480393548879 -- epoch number 143\n",
      "\n",
      "\n",
      "loss before training is 0.08931585874018487 -- epoch number 144\n",
      "\n",
      "\n",
      "loss before training is 0.08918676109471455 -- epoch number 145\n",
      "\n",
      "\n",
      "loss before training is 0.0890575117391692 -- epoch number 146\n",
      "\n",
      "\n",
      "loss before training is 0.088928111420601 -- epoch number 147\n",
      "\n",
      "\n",
      "loss before training is 0.08879856089302597 -- epoch number 148\n",
      "\n",
      "\n",
      "loss before training is 0.088668860917427 -- epoch number 149\n",
      "\n",
      "\n",
      "loss before training is 0.08853901226175549 -- epoch number 150\n",
      "\n",
      "\n",
      "loss before training is 0.08840901570093346 -- epoch number 151\n",
      "\n",
      "\n",
      "loss before training is 0.08827887201685414 -- epoch number 152\n",
      "\n",
      "\n",
      "loss before training is 0.08814858199838292 -- epoch number 153\n",
      "\n",
      "\n",
      "loss before training is 0.0880181464413569 -- epoch number 154\n",
      "\n",
      "\n",
      "loss before training is 0.08788756614858494 -- epoch number 155\n",
      "\n",
      "\n",
      "loss before training is 0.08775684192984567 -- epoch number 156\n",
      "\n",
      "\n",
      "loss before training is 0.08762597460188683 -- epoch number 157\n",
      "\n",
      "\n",
      "loss before training is 0.08749496498842219 -- epoch number 158\n",
      "\n",
      "\n",
      "loss before training is 0.08736381392012914 -- epoch number 159\n",
      "\n",
      "\n",
      "loss before training is 0.08723252223464535 -- epoch number 160\n",
      "\n",
      "\n",
      "loss before training is 0.08710109077656457 -- epoch number 161\n",
      "\n",
      "\n",
      "loss before training is 0.08696952039743255 -- epoch number 162\n",
      "\n",
      "\n",
      "loss before training is 0.08683781195574128 -- epoch number 163\n",
      "\n",
      "\n",
      "loss before training is 0.08670596631692401 -- epoch number 164\n",
      "\n",
      "\n",
      "loss before training is 0.08657398435334832 -- epoch number 165\n",
      "\n",
      "\n",
      "loss before training is 0.08644186694430979 -- epoch number 166\n",
      "\n",
      "\n",
      "loss before training is 0.0863096149760241 -- epoch number 167\n",
      "\n",
      "\n",
      "loss before training is 0.08617722934161923 -- epoch number 168\n",
      "\n",
      "\n",
      "loss before training is 0.08604471094112666 -- epoch number 169\n",
      "\n",
      "\n",
      "loss before training is 0.08591206068147203 -- epoch number 170\n",
      "\n",
      "\n",
      "loss before training is 0.08577927947646538 -- epoch number 171\n",
      "\n",
      "\n",
      "loss before training is 0.08564636824679055 -- epoch number 172\n",
      "\n",
      "\n",
      "loss before training is 0.08551332791999383 -- epoch number 173\n",
      "\n",
      "\n",
      "loss before training is 0.08538015943047253 -- epoch number 174\n",
      "\n",
      "\n",
      "loss before training is 0.0852468637194626 -- epoch number 175\n",
      "\n",
      "\n",
      "loss before training is 0.08511344173502515 -- epoch number 176\n",
      "\n",
      "\n",
      "loss before training is 0.08497989443203331 -- epoch number 177\n",
      "\n",
      "\n",
      "loss before training is 0.08484622277215756 -- epoch number 178\n",
      "\n",
      "\n",
      "loss before training is 0.08471242772385117 -- epoch number 179\n",
      "\n",
      "\n",
      "loss before training is 0.0845785102623342 -- epoch number 180\n",
      "\n",
      "\n",
      "loss before training is 0.0844444713695776 -- epoch number 181\n",
      "\n",
      "\n",
      "loss before training is 0.08431031203428632 -- epoch number 182\n",
      "\n",
      "\n",
      "loss before training is 0.08417603325188153 -- epoch number 183\n",
      "\n",
      "\n",
      "loss before training is 0.08404163602448278 -- epoch number 184\n",
      "\n",
      "\n",
      "loss before training is 0.083907121360889 -- epoch number 185\n",
      "\n",
      "\n",
      "loss before training is 0.08377249027655898 -- epoch number 186\n",
      "\n",
      "\n",
      "loss before training is 0.08363774379359142 -- epoch number 187\n",
      "\n",
      "\n",
      "loss before training is 0.08350288294070386 -- epoch number 188\n",
      "\n",
      "\n",
      "loss before training is 0.08336790875321144 -- epoch number 189\n",
      "\n",
      "\n",
      "loss before training is 0.08323282227300466 -- epoch number 190\n",
      "\n",
      "\n",
      "loss before training is 0.08309762454852651 -- epoch number 191\n",
      "\n",
      "\n",
      "loss before training is 0.08296231663474923 -- epoch number 192\n",
      "\n",
      "\n",
      "loss before training is 0.08282689959314976 -- epoch number 193\n",
      "\n",
      "\n",
      "loss before training is 0.08269137449168538 -- epoch number 194\n",
      "\n",
      "\n",
      "loss before training is 0.08255574240476787 -- epoch number 195\n",
      "\n",
      "\n",
      "loss before training is 0.08242000441323745 -- epoch number 196\n",
      "\n",
      "\n",
      "loss before training is 0.08228416160433599 -- epoch number 197\n",
      "\n",
      "\n",
      "loss before training is 0.0821482150716794 -- epoch number 198\n",
      "\n",
      "\n",
      "loss before training is 0.08201216591522939 -- epoch number 199\n",
      "\n",
      "\n",
      "loss before training is 0.08187601524126467 -- epoch number 200\n",
      "\n",
      "\n",
      "loss before training is 0.08173976416235122 -- epoch number 201\n",
      "\n",
      "\n",
      "loss before training is 0.08160341379731226 -- epoch number 202\n",
      "\n",
      "\n",
      "loss before training is 0.08146696527119707 -- epoch number 203\n",
      "\n",
      "\n",
      "loss before training is 0.08133041971524944 -- epoch number 204\n",
      "\n",
      "\n",
      "loss before training is 0.08119377826687546 -- epoch number 205\n",
      "\n",
      "\n",
      "loss before training is 0.08105704206961027 -- epoch number 206\n",
      "\n",
      "\n",
      "loss before training is 0.08092021227308469 -- epoch number 207\n",
      "\n",
      "\n",
      "loss before training is 0.08078329003299055 -- epoch number 208\n",
      "\n",
      "\n",
      "loss before training is 0.08064627651104579 -- epoch number 209\n",
      "\n",
      "\n",
      "loss before training is 0.08050917287495869 -- epoch number 210\n",
      "\n",
      "\n",
      "loss before training is 0.0803719802983913 -- epoch number 211\n",
      "\n",
      "\n",
      "loss before training is 0.0802346999609226 -- epoch number 212\n",
      "\n",
      "\n",
      "loss before training is 0.08009733304801028 -- epoch number 213\n",
      "\n",
      "\n",
      "loss before training is 0.07995988075095284 -- epoch number 214\n",
      "\n",
      "\n",
      "loss before training is 0.07982234426684963 -- epoch number 215\n",
      "\n",
      "\n",
      "loss before training is 0.07968472479856173 -- epoch number 216\n",
      "\n",
      "\n",
      "loss before training is 0.0795470235546709 -- epoch number 217\n",
      "\n",
      "\n",
      "loss before training is 0.07940924174943872 -- epoch number 218\n",
      "\n",
      "\n",
      "loss before training is 0.0792713806027643 -- epoch number 219\n",
      "\n",
      "\n",
      "loss before training is 0.07913344134014198 -- epoch number 220\n",
      "\n",
      "\n",
      "loss before training is 0.07899542519261804 -- epoch number 221\n",
      "\n",
      "\n",
      "loss before training is 0.07885733339674662 -- epoch number 222\n",
      "\n",
      "\n",
      "loss before training is 0.07871916719454512 -- epoch number 223\n",
      "\n",
      "\n",
      "loss before training is 0.07858092783344911 -- epoch number 224\n",
      "\n",
      "\n",
      "loss before training is 0.0784426165662661 -- epoch number 225\n",
      "\n",
      "\n",
      "loss before training is 0.07830423465112904 -- epoch number 226\n",
      "\n",
      "\n",
      "loss before training is 0.07816578335144907 -- epoch number 227\n",
      "\n",
      "\n",
      "loss before training is 0.0780272639358675 -- epoch number 228\n",
      "\n",
      "\n",
      "loss before training is 0.07788867767820708 -- epoch number 229\n",
      "\n",
      "\n",
      "loss before training is 0.07775002585742288 -- epoch number 230\n",
      "\n",
      "\n",
      "loss before training is 0.07761130975755232 -- epoch number 231\n",
      "\n",
      "\n",
      "loss before training is 0.07747253066766437 -- epoch number 232\n",
      "\n",
      "\n",
      "loss before training is 0.07733368988180872 -- epoch number 233\n",
      "\n",
      "\n",
      "loss before training is 0.07719478869896325 -- epoch number 234\n",
      "\n",
      "\n",
      "loss before training is 0.0770558284229823 -- epoch number 235\n",
      "\n",
      "\n",
      "loss before training is 0.07691681036254261 -- epoch number 236\n",
      "\n",
      "\n",
      "loss before training is 0.0767777358310902 -- epoch number 237\n",
      "\n",
      "\n",
      "loss before training is 0.07663860614678548 -- epoch number 238\n",
      "\n",
      "\n",
      "loss before training is 0.07649942263244842 -- epoch number 239\n",
      "\n",
      "\n",
      "loss before training is 0.07636018661550263 -- epoch number 240\n",
      "\n",
      "\n",
      "loss before training is 0.07622089942791906 -- epoch number 241\n",
      "\n",
      "\n",
      "loss before training is 0.07608156240615928 -- epoch number 242\n",
      "\n",
      "\n",
      "loss before training is 0.07594217689111739 -- epoch number 243\n",
      "\n",
      "\n",
      "loss before training is 0.07580274422806246 -- epoch number 244\n",
      "\n",
      "\n",
      "loss before training is 0.07566326576657915 -- epoch number 245\n",
      "\n",
      "\n",
      "loss before training is 0.07552374286050878 -- epoch number 246\n",
      "\n",
      "\n",
      "loss before training is 0.07538417686788902 -- epoch number 247\n",
      "\n",
      "\n",
      "loss before training is 0.07524456915089338 -- epoch number 248\n",
      "\n",
      "\n",
      "loss before training is 0.07510492107577016 -- epoch number 249\n",
      "\n",
      "\n",
      "loss before training is 0.07496523401278052 -- epoch number 250\n",
      "\n",
      "\n",
      "loss before training is 0.07482550933613634 -- epoch number 251\n",
      "\n",
      "\n",
      "loss before training is 0.07468574842393702 -- epoch number 252\n",
      "\n",
      "\n",
      "loss before training is 0.07454595265810643 -- epoch number 253\n",
      "\n",
      "\n",
      "loss before training is 0.07440612342432841 -- epoch number 254\n",
      "\n",
      "\n",
      "loss before training is 0.07426626211198258 -- epoch number 255\n",
      "\n",
      "\n",
      "loss before training is 0.07412637011407898 -- epoch number 256\n",
      "\n",
      "\n",
      "loss before training is 0.07398644882719242 -- epoch number 257\n",
      "\n",
      "\n",
      "loss before training is 0.07384649965139636 -- epoch number 258\n",
      "\n",
      "\n",
      "loss before training is 0.07370652399019613 -- epoch number 259\n",
      "\n",
      "\n",
      "loss before training is 0.07356652325046151 -- epoch number 260\n",
      "\n",
      "\n",
      "loss before training is 0.07342649884235933 -- epoch number 261\n",
      "\n",
      "\n",
      "loss before training is 0.07328645217928466 -- epoch number 262\n",
      "\n",
      "\n",
      "loss before training is 0.07314638467779247 -- epoch number 263\n",
      "\n",
      "\n",
      "loss before training is 0.07300629775752804 -- epoch number 264\n",
      "\n",
      "\n",
      "loss before training is 0.07286619284115742 -- epoch number 265\n",
      "\n",
      "\n",
      "loss before training is 0.07272607135429679 -- epoch number 266\n",
      "\n",
      "\n",
      "loss before training is 0.07258593472544228 -- epoch number 267\n",
      "\n",
      "\n",
      "loss before training is 0.07244578438589812 -- epoch number 268\n",
      "\n",
      "\n",
      "loss before training is 0.07230562176970554 -- epoch number 269\n",
      "\n",
      "\n",
      "loss before training is 0.0721654483135702 -- epoch number 270\n",
      "\n",
      "\n",
      "loss before training is 0.07202526545679003 -- epoch number 271\n",
      "\n",
      "\n",
      "loss before training is 0.07188507464118188 -- epoch number 272\n",
      "\n",
      "\n",
      "loss before training is 0.07174487731100813 -- epoch number 273\n",
      "\n",
      "\n",
      "loss before training is 0.07160467491290322 -- epoch number 274\n",
      "\n",
      "\n",
      "loss before training is 0.07146446889579879 -- epoch number 275\n",
      "\n",
      "\n",
      "loss before training is 0.07132426071084948 -- epoch number 276\n",
      "\n",
      "\n",
      "loss before training is 0.07118405181135765 -- epoch number 277\n",
      "\n",
      "\n",
      "loss before training is 0.0710438436526979 -- epoch number 278\n",
      "\n",
      "\n",
      "loss before training is 0.07090363769224138 -- epoch number 279\n",
      "\n",
      "\n",
      "loss before training is 0.0707634353892794 -- epoch number 280\n",
      "\n",
      "\n",
      "loss before training is 0.07062323820494709 -- epoch number 281\n",
      "\n",
      "\n",
      "loss before training is 0.07048304760214624 -- epoch number 282\n",
      "\n",
      "\n",
      "loss before training is 0.0703428650454681 -- epoch number 283\n",
      "\n",
      "\n",
      "loss before training is 0.07020269200111585 -- epoch number 284\n",
      "\n",
      "\n",
      "loss before training is 0.0700625299368267 -- epoch number 285\n",
      "\n",
      "\n",
      "loss before training is 0.06992238032179353 -- epoch number 286\n",
      "\n",
      "\n",
      "loss before training is 0.0697822446265863 -- epoch number 287\n",
      "\n",
      "\n",
      "loss before training is 0.06964212432307335 -- epoch number 288\n",
      "\n",
      "\n",
      "loss before training is 0.06950202088434229 -- epoch number 289\n",
      "\n",
      "\n",
      "loss before training is 0.06936193578462035 -- epoch number 290\n",
      "\n",
      "\n",
      "loss before training is 0.06922187049919484 -- epoch number 291\n",
      "\n",
      "\n",
      "loss before training is 0.06908182650433328 -- epoch number 292\n",
      "\n",
      "\n",
      "loss before training is 0.06894180527720298 -- epoch number 293\n",
      "\n",
      "\n",
      "loss before training is 0.06880180829579083 -- epoch number 294\n",
      "\n",
      "\n",
      "loss before training is 0.06866183703882249 -- epoch number 295\n",
      "\n",
      "\n",
      "loss before training is 0.06852189298568162 -- epoch number 296\n",
      "\n",
      "\n",
      "loss before training is 0.06838197761632867 -- epoch number 297\n",
      "\n",
      "\n",
      "loss before training is 0.06824209241121952 -- epoch number 298\n",
      "\n",
      "\n",
      "loss before training is 0.06810223885122427 -- epoch number 299\n",
      "\n",
      "\n",
      "loss before training is 0.06796241841754531 -- epoch number 300\n",
      "\n",
      "\n",
      "loss before training is 0.0678226325916356 -- epoch number 301\n",
      "\n",
      "\n",
      "loss before training is 0.06768288285511666 -- epoch number 302\n",
      "\n",
      "\n",
      "loss before training is 0.06754317068969636 -- epoch number 303\n",
      "\n",
      "\n",
      "loss before training is 0.06740349757708682 -- epoch number 304\n",
      "\n",
      "\n",
      "loss before training is 0.06726386499892176 -- epoch number 305\n",
      "\n",
      "\n",
      "loss before training is 0.06712427443667426 -- epoch number 306\n",
      "\n",
      "\n",
      "loss before training is 0.06698472737157378 -- epoch number 307\n",
      "\n",
      "\n",
      "loss before training is 0.06684522528452384 -- epoch number 308\n",
      "\n",
      "\n",
      "loss before training is 0.0667057696560189 -- epoch number 309\n",
      "\n",
      "\n",
      "loss before training is 0.06656636196606151 -- epoch number 310\n",
      "\n",
      "\n",
      "loss before training is 0.06642700369407961 -- epoch number 311\n",
      "\n",
      "\n",
      "loss before training is 0.06628769631884335 -- epoch number 312\n",
      "\n",
      "\n",
      "loss before training is 0.06614844131838188 -- epoch number 313\n",
      "\n",
      "\n",
      "loss before training is 0.06600924016990069 -- epoch number 314\n",
      "\n",
      "\n",
      "loss before training is 0.06587009434969816 -- epoch number 315\n",
      "\n",
      "\n",
      "loss before training is 0.06573100533308268 -- epoch number 316\n",
      "\n",
      "\n",
      "loss before training is 0.06559197459428948 -- epoch number 317\n",
      "\n",
      "\n",
      "loss before training is 0.06545300360639754 -- epoch number 318\n",
      "\n",
      "\n",
      "loss before training is 0.0653140938412466 -- epoch number 319\n",
      "\n",
      "\n",
      "loss before training is 0.06517524676935404 -- epoch number 320\n",
      "\n",
      "\n",
      "loss before training is 0.06503646385983196 -- epoch number 321\n",
      "\n",
      "\n",
      "loss before training is 0.06489774658030434 -- epoch number 322\n",
      "\n",
      "\n",
      "loss before training is 0.06475909639682405 -- epoch number 323\n",
      "\n",
      "\n",
      "loss before training is 0.06462051477379019 -- epoch number 324\n",
      "\n",
      "\n",
      "loss before training is 0.06448200317386532 -- epoch number 325\n",
      "\n",
      "\n",
      "loss before training is 0.06434356305789309 -- epoch number 326\n",
      "\n",
      "\n",
      "loss before training is 0.0642051958848154 -- epoch number 327\n",
      "\n",
      "\n",
      "loss before training is 0.0640669031115905 -- epoch number 328\n",
      "\n",
      "\n",
      "loss before training is 0.06392868619311047 -- epoch number 329\n",
      "\n",
      "\n",
      "loss before training is 0.06379054658211931 -- epoch number 330\n",
      "\n",
      "\n",
      "loss before training is 0.06365248572913104 -- epoch number 331\n",
      "\n",
      "\n",
      "loss before training is 0.06351450508234772 -- epoch number 332\n",
      "\n",
      "\n",
      "loss before training is 0.06337660608757842 -- epoch number 333\n",
      "\n",
      "\n",
      "loss before training is 0.06323879018815722 -- epoch number 334\n",
      "\n",
      "\n",
      "loss before training is 0.06310105882486254 -- epoch number 335\n",
      "\n",
      "\n",
      "loss before training is 0.06296341343583596 -- epoch number 336\n",
      "\n",
      "\n",
      "loss before training is 0.06282585545650143 -- epoch number 337\n",
      "\n",
      "\n",
      "loss before training is 0.062688386319485 -- epoch number 338\n",
      "\n",
      "\n",
      "loss before training is 0.06255100745453435 -- epoch number 339\n",
      "\n",
      "\n",
      "loss before training is 0.06241372028843878 -- epoch number 340\n",
      "\n",
      "\n",
      "loss before training is 0.06227652624494969 -- epoch number 341\n",
      "\n",
      "\n",
      "loss before training is 0.06213942674470092 -- epoch number 342\n",
      "\n",
      "\n",
      "loss before training is 0.0620024232051295 -- epoch number 343\n",
      "\n",
      "\n",
      "loss before training is 0.061865517040397014 -- epoch number 344\n",
      "\n",
      "\n",
      "loss before training is 0.06172870966131095 -- epoch number 345\n",
      "\n",
      "\n",
      "loss before training is 0.061592002475246176 -- epoch number 346\n",
      "\n",
      "\n",
      "loss before training is 0.06145539688606747 -- epoch number 347\n",
      "\n",
      "\n",
      "loss before training is 0.06131889429405138 -- epoch number 348\n",
      "\n",
      "\n",
      "loss before training is 0.06118249609580953 -- epoch number 349\n",
      "\n",
      "\n",
      "loss before training is 0.06104620368421134 -- epoch number 350\n",
      "\n",
      "\n",
      "loss before training is 0.060910018448307596 -- epoch number 351\n",
      "\n",
      "\n",
      "loss before training is 0.06077394177325448 -- epoch number 352\n",
      "\n",
      "\n",
      "loss before training is 0.06063797504023748 -- epoch number 353\n",
      "\n",
      "\n",
      "loss before training is 0.06050211962639645 -- epoch number 354\n",
      "\n",
      "\n",
      "loss before training is 0.06036637690475021 -- epoch number 355\n",
      "\n",
      "\n",
      "loss before training is 0.06023074824412244 -- epoch number 356\n",
      "\n",
      "\n",
      "loss before training is 0.0600952350090672 -- epoch number 357\n",
      "\n",
      "\n",
      "loss before training is 0.05995983855979556 -- epoch number 358\n",
      "\n",
      "\n",
      "loss before training is 0.05982456025210218 -- epoch number 359\n",
      "\n",
      "\n",
      "loss before training is 0.05968940143729258 -- epoch number 360\n",
      "\n",
      "\n",
      "loss before training is 0.059554363462110946 -- epoch number 361\n",
      "\n",
      "\n",
      "loss before training is 0.05941944766866813 -- epoch number 362\n",
      "\n",
      "\n",
      "loss before training is 0.059284655394370424 -- epoch number 363\n",
      "\n",
      "\n",
      "loss before training is 0.059149987971848686 -- epoch number 364\n",
      "\n",
      "\n",
      "loss before training is 0.05901544672888786 -- epoch number 365\n",
      "\n",
      "\n",
      "loss before training is 0.05888103298835738 -- epoch number 366\n",
      "\n",
      "\n",
      "loss before training is 0.05874674806814146 -- epoch number 367\n",
      "\n",
      "\n",
      "loss before training is 0.05861259328107081 -- epoch number 368\n",
      "\n",
      "\n",
      "loss before training is 0.05847856993485384 -- epoch number 369\n",
      "\n",
      "\n",
      "loss before training is 0.05834467933200917 -- epoch number 370\n",
      "\n",
      "\n",
      "loss before training is 0.058210922769798626 -- epoch number 371\n",
      "\n",
      "\n",
      "loss before training is 0.0580773015401603 -- epoch number 372\n",
      "\n",
      "\n",
      "loss before training is 0.05794381692964273 -- epoch number 373\n",
      "\n",
      "\n",
      "loss before training is 0.05781047021933934 -- epoch number 374\n",
      "\n",
      "\n",
      "loss before training is 0.057677262684823476 -- epoch number 375\n",
      "\n",
      "\n",
      "loss before training is 0.05754419559608436 -- epoch number 376\n",
      "\n",
      "\n",
      "loss before training is 0.05741127021746307 -- epoch number 377\n",
      "\n",
      "\n",
      "loss before training is 0.05727848780758973 -- epoch number 378\n",
      "\n",
      "\n",
      "loss before training is 0.057145849619320836 -- epoch number 379\n",
      "\n",
      "\n",
      "loss before training is 0.05701335689967747 -- epoch number 380\n",
      "\n",
      "\n",
      "loss before training is 0.05688101088978411 -- epoch number 381\n",
      "\n",
      "\n",
      "loss before training is 0.05674881282480789 -- epoch number 382\n",
      "\n",
      "\n",
      "loss before training is 0.05661676393389886 -- epoch number 383\n",
      "\n",
      "\n",
      "loss before training is 0.05648486544013051 -- epoch number 384\n",
      "\n",
      "\n",
      "loss before training is 0.056353118560441055 -- epoch number 385\n",
      "\n",
      "\n",
      "loss before training is 0.056221524505575715 -- epoch number 386\n",
      "\n",
      "\n",
      "loss before training is 0.05609008448002915 -- epoch number 387\n",
      "\n",
      "\n",
      "loss before training is 0.05595879968198882 -- epoch number 388\n",
      "\n",
      "\n",
      "loss before training is 0.05582767130327913 -- epoch number 389\n",
      "\n",
      "\n",
      "loss before training is 0.05569670052930602 -- epoch number 390\n",
      "\n",
      "\n",
      "loss before training is 0.05556588853900248 -- epoch number 391\n",
      "\n",
      "\n",
      "loss before training is 0.05543523650477453 -- epoch number 392\n",
      "\n",
      "\n",
      "loss before training is 0.05530474559244807 -- epoch number 393\n",
      "\n",
      "\n",
      "loss before training is 0.055174416961216374 -- epoch number 394\n",
      "\n",
      "\n",
      "loss before training is 0.05504425176358839 -- epoch number 395\n",
      "\n",
      "\n",
      "loss before training is 0.054914251145337455 -- epoch number 396\n",
      "\n",
      "\n",
      "loss before training is 0.05478441624545121 -- epoch number 397\n",
      "\n",
      "\n",
      "loss before training is 0.05465474819608183 -- epoch number 398\n",
      "\n",
      "\n",
      "loss before training is 0.054525248122497115 -- epoch number 399\n",
      "\n",
      "\n",
      "loss before training is 0.05439591714303235 -- epoch number 400\n",
      "\n",
      "\n",
      "loss before training is 0.054266756369043045 -- epoch number 401\n",
      "\n",
      "\n",
      "loss before training is 0.05413776690485808 -- epoch number 402\n",
      "\n",
      "\n",
      "loss before training is 0.05400894984773378 -- epoch number 403\n",
      "\n",
      "\n",
      "loss before training is 0.053880306287808905 -- epoch number 404\n",
      "\n",
      "\n",
      "loss before training is 0.053751837308060074 -- epoch number 405\n",
      "\n",
      "\n",
      "loss before training is 0.053623543984258185 -- epoch number 406\n",
      "\n",
      "\n",
      "loss before training is 0.05349542738492552 -- epoch number 407\n",
      "\n",
      "\n",
      "loss before training is 0.053367488571293496 -- epoch number 408\n",
      "\n",
      "\n",
      "loss before training is 0.053239728597261525 -- epoch number 409\n",
      "\n",
      "\n",
      "loss before training is 0.05311214850935628 -- epoch number 410\n",
      "\n",
      "\n",
      "loss before training is 0.052984749346691784 -- epoch number 411\n",
      "\n",
      "\n",
      "loss before training is 0.05285753214093063 -- epoch number 412\n",
      "\n",
      "\n",
      "loss before training is 0.05273049791624542 -- epoch number 413\n",
      "\n",
      "\n",
      "loss before training is 0.05260364768928154 -- epoch number 414\n",
      "\n",
      "\n",
      "loss before training is 0.05247698246912034 -- epoch number 415\n",
      "\n",
      "\n",
      "loss before training is 0.05235050325724313 -- epoch number 416\n",
      "\n",
      "\n",
      "loss before training is 0.05222421104749633 -- epoch number 417\n",
      "\n",
      "\n",
      "loss before training is 0.05209810682605687 -- epoch number 418\n",
      "\n",
      "\n",
      "loss before training is 0.05197219157139871 -- epoch number 419\n",
      "\n",
      "\n",
      "loss before training is 0.051846466254260225 -- epoch number 420\n",
      "\n",
      "\n",
      "loss before training is 0.05172093183761206 -- epoch number 421\n",
      "\n",
      "\n",
      "loss before training is 0.05159558927662608 -- epoch number 422\n",
      "\n",
      "\n",
      "loss before training is 0.05147043951864497 -- epoch number 423\n",
      "\n",
      "\n",
      "loss before training is 0.051345483503152684 -- epoch number 424\n",
      "\n",
      "\n",
      "loss before training is 0.051220722161745606 -- epoch number 425\n",
      "\n",
      "\n",
      "loss before training is 0.05109615641810461 -- epoch number 426\n",
      "\n",
      "\n",
      "loss before training is 0.05097178718796797 -- epoch number 427\n",
      "\n",
      "\n",
      "loss before training is 0.050847615379104864 -- epoch number 428\n",
      "\n",
      "\n",
      "loss before training is 0.05072364189128972 -- epoch number 429\n",
      "\n",
      "\n",
      "loss before training is 0.050599867616277744 -- epoch number 430\n",
      "\n",
      "\n",
      "loss before training is 0.050476293437780505 -- epoch number 431\n",
      "\n",
      "\n",
      "loss before training is 0.05035292023144315 -- epoch number 432\n",
      "\n",
      "\n",
      "loss before training is 0.05022974886482176 -- epoch number 433\n",
      "\n",
      "\n",
      "loss before training is 0.05010678019736183 -- epoch number 434\n",
      "\n",
      "\n",
      "loss before training is 0.049984015080377524 -- epoch number 435\n",
      "\n",
      "\n",
      "loss before training is 0.04986145435703151 -- epoch number 436\n",
      "\n",
      "\n",
      "loss before training is 0.04973909886231605 -- epoch number 437\n",
      "\n",
      "\n",
      "loss before training is 0.04961694942303427 -- epoch number 438\n",
      "\n",
      "\n",
      "loss before training is 0.049495006857782714 -- epoch number 439\n",
      "\n",
      "\n",
      "loss before training is 0.049373271976934495 -- epoch number 440\n",
      "\n",
      "\n",
      "loss before training is 0.0492517455826232 -- epoch number 441\n",
      "\n",
      "\n",
      "loss before training is 0.04913042846872772 -- epoch number 442\n",
      "\n",
      "\n",
      "loss before training is 0.049009321420857725 -- epoch number 443\n",
      "\n",
      "\n",
      "loss before training is 0.04888842521633989 -- epoch number 444\n",
      "\n",
      "\n",
      "loss before training is 0.04876774062420522 -- epoch number 445\n",
      "\n",
      "\n",
      "loss before training is 0.04864726840517673 -- epoch number 446\n",
      "\n",
      "\n",
      "loss before training is 0.04852700931165814 -- epoch number 447\n",
      "\n",
      "\n",
      "loss before training is 0.04840696408772337 -- epoch number 448\n",
      "\n",
      "\n",
      "loss before training is 0.048287133469106694 -- epoch number 449\n",
      "\n",
      "\n",
      "loss before training is 0.048167518183193675 -- epoch number 450\n",
      "\n",
      "\n",
      "loss before training is 0.04804811894901295 -- epoch number 451\n",
      "\n",
      "\n",
      "loss before training is 0.047928936477228755 -- epoch number 452\n",
      "\n",
      "\n",
      "loss before training is 0.04780997147013412 -- epoch number 453\n",
      "\n",
      "\n",
      "loss before training is 0.04769122462164495 -- epoch number 454\n",
      "\n",
      "\n",
      "loss before training is 0.04757269661729467 -- epoch number 455\n",
      "\n",
      "\n",
      "loss before training is 0.04745438813422998 -- epoch number 456\n",
      "\n",
      "\n",
      "loss before training is 0.047336299841206915 -- epoch number 457\n",
      "\n",
      "\n",
      "loss before training is 0.047218432398587924 -- epoch number 458\n",
      "\n",
      "\n",
      "loss before training is 0.047100786458339705 -- epoch number 459\n",
      "\n",
      "\n",
      "loss before training is 0.04698336266403159 -- epoch number 460\n",
      "\n",
      "\n",
      "loss before training is 0.04686616165083486 -- epoch number 461\n",
      "\n",
      "\n",
      "loss before training is 0.046749184045522515 -- epoch number 462\n",
      "\n",
      "\n",
      "loss before training is 0.04663243046647032 -- epoch number 463\n",
      "\n",
      "\n",
      "loss before training is 0.04651590152365777 -- epoch number 464\n",
      "\n",
      "\n",
      "loss before training is 0.046399597818670514 -- epoch number 465\n",
      "\n",
      "\n",
      "loss before training is 0.04628351994470309 -- epoch number 466\n",
      "\n",
      "\n",
      "loss before training is 0.04616766848656238 -- epoch number 467\n",
      "\n",
      "\n",
      "loss before training is 0.04605204402067193 -- epoch number 468\n",
      "\n",
      "\n",
      "loss before training is 0.0459366471150769 -- epoch number 469\n",
      "\n",
      "\n",
      "loss before training is 0.045821478329449654 -- epoch number 470\n",
      "\n",
      "\n",
      "loss before training is 0.04570653821509604 -- epoch number 471\n",
      "\n",
      "\n",
      "loss before training is 0.0455918273149625 -- epoch number 472\n",
      "\n",
      "\n",
      "loss before training is 0.0454773461636436 -- epoch number 473\n",
      "\n",
      "\n",
      "loss before training is 0.04536309528739047 -- epoch number 474\n",
      "\n",
      "\n",
      "loss before training is 0.04524907520411985 -- epoch number 475\n",
      "\n",
      "\n",
      "loss before training is 0.04513528642342369 -- epoch number 476\n",
      "\n",
      "\n",
      "loss before training is 0.045021729446579534 -- epoch number 477\n",
      "\n",
      "\n",
      "loss before training is 0.04490840476656155 -- epoch number 478\n",
      "\n",
      "\n",
      "loss before training is 0.04479531286805205 -- epoch number 479\n",
      "\n",
      "\n",
      "loss before training is 0.04468245422745392 -- epoch number 480\n",
      "\n",
      "\n",
      "loss before training is 0.04456982931290333 -- epoch number 481\n",
      "\n",
      "\n",
      "loss before training is 0.04445743858428354 -- epoch number 482\n",
      "\n",
      "\n",
      "loss before training is 0.04434528249323884 -- epoch number 483\n",
      "\n",
      "\n",
      "loss before training is 0.044233361483189404 -- epoch number 484\n",
      "\n",
      "\n",
      "loss before training is 0.04412167598934681 -- epoch number 485\n",
      "\n",
      "\n",
      "loss before training is 0.04401022643872985 -- epoch number 486\n",
      "\n",
      "\n",
      "loss before training is 0.04389901325018127 -- epoch number 487\n",
      "\n",
      "\n",
      "loss before training is 0.04378803683438486 -- epoch number 488\n",
      "\n",
      "\n",
      "loss before training is 0.04367729759388336 -- epoch number 489\n",
      "\n",
      "\n",
      "loss before training is 0.04356679592309678 -- epoch number 490\n",
      "\n",
      "\n",
      "loss before training is 0.04345653220834124 -- epoch number 491\n",
      "\n",
      "\n",
      "loss before training is 0.04334650682784869 -- epoch number 492\n",
      "\n",
      "\n",
      "loss before training is 0.043236720151786825 -- epoch number 493\n",
      "\n",
      "\n",
      "loss before training is 0.04312717254227971 -- epoch number 494\n",
      "\n",
      "\n",
      "loss before training is 0.04301786435342918 -- epoch number 495\n",
      "\n",
      "\n",
      "loss before training is 0.042908795931336216 -- epoch number 496\n",
      "\n",
      "\n",
      "loss before training is 0.04279996761412353 -- epoch number 497\n",
      "\n",
      "\n",
      "loss before training is 0.04269137973195822 -- epoch number 498\n",
      "\n",
      "\n",
      "loss before training is 0.04258303260707501 -- epoch number 499\n",
      "\n",
      "\n",
      "loss before training is 0.042474926553800314 -- epoch number 500\n",
      "\n",
      "\n",
      "loss before training is 0.04236706187857639 -- epoch number 501\n",
      "\n",
      "\n",
      "loss before training is 0.04225943887998623 -- epoch number 502\n",
      "\n",
      "\n",
      "loss before training is 0.042152057848779054 -- epoch number 503\n",
      "\n",
      "\n",
      "loss before training is 0.042044919067895876 -- epoch number 504\n",
      "\n",
      "\n",
      "loss before training is 0.04193802281249617 -- epoch number 505\n",
      "\n",
      "\n",
      "loss before training is 0.041831369349984375 -- epoch number 506\n",
      "\n",
      "\n",
      "loss before training is 0.0417249589400373 -- epoch number 507\n",
      "\n",
      "\n",
      "loss before training is 0.041618791834632 -- epoch number 508\n",
      "\n",
      "\n",
      "loss before training is 0.041512868278073704 -- epoch number 509\n",
      "\n",
      "\n",
      "loss before training is 0.04140718850702461 -- epoch number 510\n",
      "\n",
      "\n",
      "loss before training is 0.041301752750533036 -- epoch number 511\n",
      "\n",
      "\n",
      "loss before training is 0.041196561230062795 -- epoch number 512\n",
      "\n",
      "\n",
      "loss before training is 0.04109161415952328 -- epoch number 513\n",
      "\n",
      "\n",
      "loss before training is 0.04098691174529981 -- epoch number 514\n",
      "\n",
      "\n",
      "loss before training is 0.04088245418628441 -- epoch number 515\n",
      "\n",
      "\n",
      "loss before training is 0.04077824167390699 -- epoch number 516\n",
      "\n",
      "\n",
      "loss before training is 0.040674274392167 -- epoch number 517\n",
      "\n",
      "\n",
      "loss before training is 0.040570552517665476 -- epoch number 518\n",
      "\n",
      "\n",
      "loss before training is 0.04046707621963731 -- epoch number 519\n",
      "\n",
      "\n",
      "loss before training is 0.04036384565998416 -- epoch number 520\n",
      "\n",
      "\n",
      "loss before training is 0.040260860993307446 -- epoch number 521\n",
      "\n",
      "\n",
      "loss before training is 0.04015812236694205 -- epoch number 522\n",
      "\n",
      "\n",
      "loss before training is 0.04005562992099003 -- epoch number 523\n",
      "\n",
      "\n",
      "loss before training is 0.039953383788354974 -- epoch number 524\n",
      "\n",
      "\n",
      "loss before training is 0.03985138409477641 -- epoch number 525\n",
      "\n",
      "\n",
      "loss before training is 0.039749630958865 -- epoch number 526\n",
      "\n",
      "\n",
      "loss before training is 0.03964812449213744 -- epoch number 527\n",
      "\n",
      "\n",
      "loss before training is 0.03954686479905236 -- epoch number 528\n",
      "\n",
      "\n",
      "loss before training is 0.03944585197704603 -- epoch number 529\n",
      "\n",
      "\n",
      "loss before training is 0.03934508611656863 -- epoch number 530\n",
      "\n",
      "\n",
      "loss before training is 0.039244567301120734 -- epoch number 531\n",
      "\n",
      "\n",
      "loss before training is 0.03914429560729018 -- epoch number 532\n",
      "\n",
      "\n",
      "loss before training is 0.039044271104789106 -- epoch number 533\n",
      "\n",
      "\n",
      "loss before training is 0.038944493856491416 -- epoch number 534\n",
      "\n",
      "\n",
      "loss before training is 0.03884496391847035 -- epoch number 535\n",
      "\n",
      "\n",
      "loss before training is 0.03874568134003652 -- epoch number 536\n",
      "\n",
      "\n",
      "loss before training is 0.038646646163776076 -- epoch number 537\n",
      "\n",
      "\n",
      "loss before training is 0.03854785842558922 -- epoch number 538\n",
      "\n",
      "\n",
      "loss before training is 0.038449318154728705 -- epoch number 539\n",
      "\n",
      "\n",
      "loss before training is 0.038351025373839207 -- epoch number 540\n",
      "\n",
      "\n",
      "loss before training is 0.03825298009899606 -- epoch number 541\n",
      "\n",
      "\n",
      "loss before training is 0.038155182339745075 -- epoch number 542\n",
      "\n",
      "\n",
      "loss before training is 0.03805763209914194 -- epoch number 543\n",
      "\n",
      "\n",
      "loss before training is 0.037960329373792165 -- epoch number 544\n",
      "\n",
      "\n",
      "loss before training is 0.03786327415389128 -- epoch number 545\n",
      "\n",
      "\n",
      "loss before training is 0.03776646642326494 -- epoch number 546\n",
      "\n",
      "\n",
      "loss before training is 0.03766990615940953 -- epoch number 547\n",
      "\n",
      "\n",
      "loss before training is 0.037573593333532905 -- epoch number 548\n",
      "\n",
      "\n",
      "loss before training is 0.03747752791059507 -- epoch number 549\n",
      "\n",
      "\n",
      "loss before training is 0.037381709849349444 -- epoch number 550\n",
      "\n",
      "\n",
      "loss before training is 0.037286139102383875 -- epoch number 551\n",
      "\n",
      "\n",
      "loss before training is 0.0371908156161623 -- epoch number 552\n",
      "\n",
      "\n",
      "loss before training is 0.037095739331065934 -- epoch number 553\n",
      "\n",
      "\n",
      "loss before training is 0.03700091018143536 -- epoch number 554\n",
      "\n",
      "\n",
      "loss before training is 0.03690632809561208 -- epoch number 555\n",
      "\n",
      "\n",
      "loss before training is 0.03681199299598077 -- epoch number 556\n",
      "\n",
      "\n",
      "loss before training is 0.03671790479901113 -- epoch number 557\n",
      "\n",
      "\n",
      "loss before training is 0.03662406341530044 -- epoch number 558\n",
      "\n",
      "\n",
      "loss before training is 0.03653046874961572 -- epoch number 559\n",
      "\n",
      "\n",
      "loss before training is 0.03643712070093639 -- epoch number 560\n",
      "\n",
      "\n",
      "loss before training is 0.03634401916249685 -- epoch number 561\n",
      "\n",
      "\n",
      "loss before training is 0.03625116402182915 -- epoch number 562\n",
      "\n",
      "\n",
      "loss before training is 0.0361585551608059 -- epoch number 563\n",
      "\n",
      "\n",
      "loss before training is 0.03606619245568314 -- epoch number 564\n",
      "\n",
      "\n",
      "loss before training is 0.03597407577714341 -- epoch number 565\n",
      "\n",
      "\n",
      "loss before training is 0.03588220499033874 -- epoch number 566\n",
      "\n",
      "\n",
      "loss before training is 0.035790579954934044 -- epoch number 567\n",
      "\n",
      "\n",
      "loss before training is 0.03569920052515012 -- epoch number 568\n",
      "\n",
      "\n",
      "loss before training is 0.03560806654980707 -- epoch number 569\n",
      "\n",
      "\n",
      "loss before training is 0.03551717787236775 -- epoch number 570\n",
      "\n",
      "\n",
      "loss before training is 0.03542653433098112 -- epoch number 571\n",
      "\n",
      "\n",
      "loss before training is 0.03533613575852573 -- epoch number 572\n",
      "\n",
      "\n",
      "loss before training is 0.035245981982653295 -- epoch number 573\n",
      "\n",
      "\n",
      "loss before training is 0.035156072825832246 -- epoch number 574\n",
      "\n",
      "\n",
      "loss before training is 0.03506640810539132 -- epoch number 575\n",
      "\n",
      "\n",
      "loss before training is 0.034976987633563286 -- epoch number 576\n",
      "\n",
      "\n",
      "loss before training is 0.034887811217528396 -- epoch number 577\n",
      "\n",
      "\n",
      "loss before training is 0.03479887865945835 -- epoch number 578\n",
      "\n",
      "\n",
      "loss before training is 0.034710189756559776 -- epoch number 579\n",
      "\n",
      "\n",
      "loss before training is 0.03462174430111804 -- epoch number 580\n",
      "\n",
      "\n",
      "loss before training is 0.0345335420805409 -- epoch number 581\n",
      "\n",
      "\n",
      "loss before training is 0.03444558287740226 -- epoch number 582\n",
      "\n",
      "\n",
      "loss before training is 0.03435786646948588 -- epoch number 583\n",
      "\n",
      "\n",
      "loss before training is 0.034270392629829026 -- epoch number 584\n",
      "\n",
      "\n",
      "loss before training is 0.034183161126766254 -- epoch number 585\n",
      "\n",
      "\n",
      "loss before training is 0.034096171723972835 -- epoch number 586\n",
      "\n",
      "\n",
      "loss before training is 0.03400942418050882 -- epoch number 587\n",
      "\n",
      "\n",
      "loss before training is 0.03392291825086216 -- epoch number 588\n",
      "\n",
      "\n",
      "loss before training is 0.033836653684992675 -- epoch number 589\n",
      "\n",
      "\n",
      "loss before training is 0.03375063022837539 -- epoch number 590\n",
      "\n",
      "\n",
      "loss before training is 0.03366484762204413 -- epoch number 591\n",
      "\n",
      "\n",
      "loss before training is 0.033579305602634904 -- epoch number 592\n",
      "\n",
      "\n",
      "loss before training is 0.033494003902429376 -- epoch number 593\n",
      "\n",
      "\n",
      "loss before training is 0.0334089422493982 -- epoch number 594\n",
      "\n",
      "\n",
      "loss before training is 0.03332412036724436 -- epoch number 595\n",
      "\n",
      "\n",
      "loss before training is 0.03323953797544629 -- epoch number 596\n",
      "\n",
      "\n",
      "loss before training is 0.03315519478930114 -- epoch number 597\n",
      "\n",
      "\n",
      "loss before training is 0.033071090519967844 -- epoch number 598\n",
      "\n",
      "\n",
      "loss before training is 0.03298722487451017 -- epoch number 599\n",
      "\n",
      "\n",
      "loss before training is 0.03290359755593967 -- epoch number 600\n",
      "\n",
      "\n",
      "loss before training is 0.032820208263258446 -- epoch number 601\n",
      "\n",
      "\n",
      "loss before training is 0.032737056691502044 -- epoch number 602\n",
      "\n",
      "\n",
      "loss before training is 0.0326541425317822 -- epoch number 603\n",
      "\n",
      "\n",
      "loss before training is 0.03257146547132918 -- epoch number 604\n",
      "\n",
      "\n",
      "loss before training is 0.03248902519353462 -- epoch number 605\n",
      "\n",
      "\n",
      "loss before training is 0.032406821377993666 -- epoch number 606\n",
      "\n",
      "\n",
      "loss before training is 0.032324853700547405 -- epoch number 607\n",
      "\n",
      "\n",
      "loss before training is 0.03224312183332505 -- epoch number 608\n",
      "\n",
      "\n",
      "loss before training is 0.032161625444786 -- epoch number 609\n",
      "\n",
      "\n",
      "loss before training is 0.03208036419976176 -- epoch number 610\n",
      "\n",
      "\n",
      "loss before training is 0.03199933775949794 -- epoch number 611\n",
      "\n",
      "\n",
      "loss before training is 0.03191854578169588 -- epoch number 612\n",
      "\n",
      "\n",
      "loss before training is 0.03183798792055426 -- epoch number 613\n",
      "\n",
      "\n",
      "loss before training is 0.03175766382681069 -- epoch number 614\n",
      "\n",
      "\n",
      "loss before training is 0.03167757314778294 -- epoch number 615\n",
      "\n",
      "\n",
      "loss before training is 0.03159771552741027 -- epoch number 616\n",
      "\n",
      "\n",
      "loss before training is 0.031518090606294465 -- epoch number 617\n",
      "\n",
      "\n",
      "loss before training is 0.03143869802174086 -- epoch number 618\n",
      "\n",
      "\n",
      "loss before training is 0.0313595374077991 -- epoch number 619\n",
      "\n",
      "\n",
      "loss before training is 0.0312806083953038 -- epoch number 620\n",
      "\n",
      "\n",
      "loss before training is 0.031201910611915136 -- epoch number 621\n",
      "\n",
      "\n",
      "loss before training is 0.03112344368215921 -- epoch number 622\n",
      "\n",
      "\n",
      "loss before training is 0.03104520722746827 -- epoch number 623\n",
      "\n",
      "\n",
      "loss before training is 0.03096720086622078 -- epoch number 624\n",
      "\n",
      "\n",
      "loss before training is 0.030889424213781314 -- epoch number 625\n",
      "\n",
      "\n",
      "loss before training is 0.030811876882540494 -- epoch number 626\n",
      "\n",
      "\n",
      "loss before training is 0.030734558481954312 -- epoch number 627\n",
      "\n",
      "\n",
      "loss before training is 0.030657468618583823 -- epoch number 628\n",
      "\n",
      "\n",
      "loss before training is 0.0305806068961343 -- epoch number 629\n",
      "\n",
      "\n",
      "loss before training is 0.030503972915494355 -- epoch number 630\n",
      "\n",
      "\n",
      "loss before training is 0.030427566274774966 -- epoch number 631\n",
      "\n",
      "\n",
      "loss before training is 0.03035138656934811 -- epoch number 632\n",
      "\n",
      "\n",
      "loss before training is 0.03027543339188546 -- epoch number 633\n",
      "\n",
      "\n",
      "loss before training is 0.03019970633239681 -- epoch number 634\n",
      "\n",
      "\n",
      "loss before training is 0.030124204978268246 -- epoch number 635\n",
      "\n",
      "\n",
      "loss before training is 0.030048928914300325 -- epoch number 636\n",
      "\n",
      "\n",
      "loss before training is 0.02997387772274584 -- epoch number 637\n",
      "\n",
      "\n",
      "loss before training is 0.029899050983347605 -- epoch number 638\n",
      "\n",
      "\n",
      "loss before training is 0.02982444827337591 -- epoch number 639\n",
      "\n",
      "\n",
      "loss before training is 0.02975006916766598 -- epoch number 640\n",
      "\n",
      "\n",
      "loss before training is 0.029675913238654948 -- epoch number 641\n",
      "\n",
      "\n",
      "loss before training is 0.029601980056418942 -- epoch number 642\n",
      "\n",
      "\n",
      "loss before training is 0.02952826918870982 -- epoch number 643\n",
      "\n",
      "\n",
      "loss before training is 0.029454780200991616 -- epoch number 644\n",
      "\n",
      "\n",
      "loss before training is 0.02938151265647721 -- epoch number 645\n",
      "\n",
      "\n",
      "loss before training is 0.029308466116164188 -- epoch number 646\n",
      "\n",
      "\n",
      "loss before training is 0.02923564013887099 -- epoch number 647\n",
      "\n",
      "\n",
      "loss before training is 0.02916303428127271 -- epoch number 648\n",
      "\n",
      "\n",
      "loss before training is 0.029090648097936656 -- epoch number 649\n",
      "\n",
      "\n",
      "loss before training is 0.029018481141357674 -- epoch number 650\n",
      "\n",
      "\n",
      "loss before training is 0.028946532961993454 -- epoch number 651\n",
      "\n",
      "\n",
      "loss before training is 0.02887480310829945 -- epoch number 652\n",
      "\n",
      "\n",
      "loss before training is 0.028803291126763615 -- epoch number 653\n",
      "\n",
      "\n",
      "loss before training is 0.028731996561941028 -- epoch number 654\n",
      "\n",
      "\n",
      "loss before training is 0.028660918956488302 -- epoch number 655\n",
      "\n",
      "\n",
      "loss before training is 0.028590057851197614 -- epoch number 656\n",
      "\n",
      "\n",
      "loss before training is 0.028519412785030847 -- epoch number 657\n",
      "\n",
      "\n",
      "loss before training is 0.02844898329515313 -- epoch number 658\n",
      "\n",
      "\n",
      "loss before training is 0.0283787689169665 -- epoch number 659\n",
      "\n",
      "\n",
      "loss before training is 0.02830876918414315 -- epoch number 660\n",
      "\n",
      "\n",
      "loss before training is 0.02823898362865866 -- epoch number 661\n",
      "\n",
      "\n",
      "loss before training is 0.028169411780824733 -- epoch number 662\n",
      "\n",
      "\n",
      "loss before training is 0.028100053169322015 -- epoch number 663\n",
      "\n",
      "\n",
      "loss before training is 0.02803090732123245 -- epoch number 664\n",
      "\n",
      "\n",
      "loss before training is 0.027961973762071643 -- epoch number 665\n",
      "\n",
      "\n",
      "loss before training is 0.027893252015820845 -- epoch number 666\n",
      "\n",
      "\n",
      "loss before training is 0.027824741604958753 -- epoch number 667\n",
      "\n",
      "\n",
      "loss before training is 0.02775644205049321 -- epoch number 668\n",
      "\n",
      "\n",
      "loss before training is 0.027688352871992544 -- epoch number 669\n",
      "\n",
      "\n",
      "loss before training is 0.02762047358761669 -- epoch number 670\n",
      "\n",
      "\n",
      "loss before training is 0.02755280371414823 -- epoch number 671\n",
      "\n",
      "\n",
      "loss before training is 0.02748534276702308 -- epoch number 672\n",
      "\n",
      "\n",
      "loss before training is 0.027418090260361114 -- epoch number 673\n",
      "\n",
      "\n",
      "loss before training is 0.027351045706996313 -- epoch number 674\n",
      "\n",
      "\n",
      "loss before training is 0.027284208618506965 -- epoch number 675\n",
      "\n",
      "\n",
      "loss before training is 0.027217578505245477 -- epoch number 676\n",
      "\n",
      "\n",
      "loss before training is 0.027151154876368065 -- epoch number 677\n",
      "\n",
      "\n",
      "loss before training is 0.02708493723986411 -- epoch number 678\n",
      "\n",
      "\n",
      "loss before training is 0.027018925102585422 -- epoch number 679\n",
      "\n",
      "\n",
      "loss before training is 0.02695311797027525 -- epoch number 680\n",
      "\n",
      "\n",
      "loss before training is 0.026887515347596976 -- epoch number 681\n",
      "\n",
      "\n",
      "loss before training is 0.026822116738162708 -- epoch number 682\n",
      "\n",
      "\n",
      "loss before training is 0.02675692164456158 -- epoch number 683\n",
      "\n",
      "\n",
      "loss before training is 0.026691929568387868 -- epoch number 684\n",
      "\n",
      "\n",
      "loss before training is 0.02662714001026895 -- epoch number 685\n",
      "\n",
      "\n",
      "loss before training is 0.02656255246989286 -- epoch number 686\n",
      "\n",
      "\n",
      "loss before training is 0.026498166446035695 -- epoch number 687\n",
      "\n",
      "\n",
      "loss before training is 0.026433981436589066 -- epoch number 688\n",
      "\n",
      "\n",
      "loss before training is 0.026369996938586923 -- epoch number 689\n",
      "\n",
      "\n",
      "loss before training is 0.02630621244823229 -- epoch number 690\n",
      "\n",
      "\n",
      "loss before training is 0.026242627460924033 -- epoch number 691\n",
      "\n",
      "\n",
      "loss before training is 0.02617924147128302 -- epoch number 692\n",
      "\n",
      "\n",
      "loss before training is 0.02611605397317837 -- epoch number 693\n",
      "\n",
      "\n",
      "loss before training is 0.02605306445975332 -- epoch number 694\n",
      "\n",
      "\n",
      "loss before training is 0.025990272423450877 -- epoch number 695\n",
      "\n",
      "\n",
      "loss before training is 0.025927677356039375 -- epoch number 696\n",
      "\n",
      "\n",
      "loss before training is 0.02586527874863761 -- epoch number 697\n",
      "\n",
      "\n",
      "loss before training is 0.025803076091740037 -- epoch number 698\n",
      "\n",
      "\n",
      "loss before training is 0.025741068875241427 -- epoch number 699\n",
      "\n",
      "\n",
      "loss before training is 0.025679256588461593 -- epoch number 700\n",
      "\n",
      "\n",
      "loss before training is 0.02561763872016969 -- epoch number 701\n",
      "\n",
      "\n",
      "loss before training is 0.025556214758608416 -- epoch number 702\n",
      "\n",
      "\n",
      "loss before training is 0.025494984191517987 -- epoch number 703\n",
      "\n",
      "\n",
      "loss before training is 0.02543394650615985 -- epoch number 704\n",
      "\n",
      "\n",
      "loss before training is 0.025373101189340254 -- epoch number 705\n",
      "\n",
      "\n",
      "loss before training is 0.025312447727433414 -- epoch number 706\n",
      "\n",
      "\n",
      "loss before training is 0.025251985606404834 -- epoch number 707\n",
      "\n",
      "\n",
      "loss before training is 0.025191714311833986 -- epoch number 708\n",
      "\n",
      "\n",
      "loss before training is 0.0251316333289371 -- epoch number 709\n",
      "\n",
      "\n",
      "loss before training is 0.025071742142589556 -- epoch number 710\n",
      "\n",
      "\n",
      "loss before training is 0.025012040237348175 -- epoch number 711\n",
      "\n",
      "\n",
      "loss before training is 0.024952527097473268 -- epoch number 712\n",
      "\n",
      "\n",
      "loss before training is 0.024893202206950325 -- epoch number 713\n",
      "\n",
      "\n",
      "loss before training is 0.024834065049511876 -- epoch number 714\n",
      "\n",
      "\n",
      "loss before training is 0.02477511510865866 -- epoch number 715\n",
      "\n",
      "\n",
      "loss before training is 0.024716351867680928 -- epoch number 716\n",
      "\n",
      "\n",
      "loss before training is 0.02465777480967949 -- epoch number 717\n",
      "\n",
      "\n",
      "loss before training is 0.02459938341758637 -- epoch number 718\n",
      "\n",
      "\n",
      "loss before training is 0.024541177174185465 -- epoch number 719\n",
      "\n",
      "\n",
      "loss before training is 0.024483155562132937 -- epoch number 720\n",
      "\n",
      "\n",
      "loss before training is 0.02442531806397733 -- epoch number 721\n",
      "\n",
      "\n",
      "loss before training is 0.024367664162179514 -- epoch number 722\n",
      "\n",
      "\n",
      "loss before training is 0.024310193339132546 -- epoch number 723\n",
      "\n",
      "\n",
      "loss before training is 0.02425290507718109 -- epoch number 724\n",
      "\n",
      "\n",
      "loss before training is 0.02419579885864093 -- epoch number 725\n",
      "\n",
      "\n",
      "loss before training is 0.024138874165818006 -- epoch number 726\n",
      "\n",
      "\n",
      "loss before training is 0.024082130481027413 -- epoch number 727\n",
      "\n",
      "\n",
      "loss before training is 0.024025567286612204 -- epoch number 728\n",
      "\n",
      "\n",
      "loss before training is 0.023969184064961794 -- epoch number 729\n",
      "\n",
      "\n",
      "loss before training is 0.02391298029853052 -- epoch number 730\n",
      "\n",
      "\n",
      "loss before training is 0.023856955469855712 -- epoch number 731\n",
      "\n",
      "\n",
      "loss before training is 0.023801109061575655 -- epoch number 732\n",
      "\n",
      "\n",
      "loss before training is 0.0237454405564474 -- epoch number 733\n",
      "\n",
      "\n",
      "loss before training is 0.02368994943736428 -- epoch number 734\n",
      "\n",
      "\n",
      "loss before training is 0.023634635187373396 -- epoch number 735\n",
      "\n",
      "\n",
      "loss before training is 0.023579497289692764 -- epoch number 736\n",
      "\n",
      "\n",
      "loss before training is 0.02352453522772826 -- epoch number 737\n",
      "\n",
      "\n",
      "loss before training is 0.023469748485090557 -- epoch number 738\n",
      "\n",
      "\n",
      "loss before training is 0.02341513654561169 -- epoch number 739\n",
      "\n",
      "\n",
      "loss before training is 0.023360698893361443 -- epoch number 740\n",
      "\n",
      "\n",
      "loss before training is 0.023306435012663777 -- epoch number 741\n",
      "\n",
      "\n",
      "loss before training is 0.023252344388112627 -- epoch number 742\n",
      "\n",
      "\n",
      "loss before training is 0.02319842650458803 -- epoch number 743\n",
      "\n",
      "\n",
      "loss before training is 0.0231446808472717 -- epoch number 744\n",
      "\n",
      "\n",
      "loss before training is 0.023091106901662578 -- epoch number 745\n",
      "\n",
      "\n",
      "loss before training is 0.023037704153592114 -- epoch number 746\n",
      "\n",
      "\n",
      "loss before training is 0.02298447208923948 -- epoch number 747\n",
      "\n",
      "\n",
      "loss before training is 0.02293141019514654 -- epoch number 748\n",
      "\n",
      "\n",
      "loss before training is 0.022878517958232526 -- epoch number 749\n",
      "\n",
      "\n",
      "loss before training is 0.022825794865808838 -- epoch number 750\n",
      "\n",
      "\n",
      "loss before training is 0.022773240405593358 -- epoch number 751\n",
      "\n",
      "\n",
      "loss before training is 0.022720854065724643 -- epoch number 752\n",
      "\n",
      "\n",
      "loss before training is 0.022668635334776244 -- epoch number 753\n",
      "\n",
      "\n",
      "loss before training is 0.02261658370177033 -- epoch number 754\n",
      "\n",
      "\n",
      "loss before training is 0.022564698656191675 -- epoch number 755\n",
      "\n",
      "\n",
      "loss before training is 0.02251297968800103 -- epoch number 756\n",
      "\n",
      "\n",
      "loss before training is 0.02246142628764867 -- epoch number 757\n",
      "\n",
      "\n",
      "loss before training is 0.02241003794608752 -- epoch number 758\n",
      "\n",
      "\n",
      "loss before training is 0.02235881415478623 -- epoch number 759\n",
      "\n",
      "\n",
      "loss before training is 0.02230775440574212 -- epoch number 760\n",
      "\n",
      "\n",
      "loss before training is 0.022256858191493797 -- epoch number 761\n",
      "\n",
      "\n",
      "loss before training is 0.0222061250051338 -- epoch number 762\n",
      "\n",
      "\n",
      "loss before training is 0.022155554340321022 -- epoch number 763\n",
      "\n",
      "\n",
      "loss before training is 0.02210514569129279 -- epoch number 764\n",
      "\n",
      "\n",
      "loss before training is 0.022054898552877074 -- epoch number 765\n",
      "\n",
      "\n",
      "loss before training is 0.022004812420504317 -- epoch number 766\n",
      "\n",
      "\n",
      "loss before training is 0.02195488679021926 -- epoch number 767\n",
      "\n",
      "\n",
      "loss before training is 0.02190512115869241 -- epoch number 768\n",
      "\n",
      "\n",
      "loss before training is 0.021855515023231575 -- epoch number 769\n",
      "\n",
      "\n",
      "loss before training is 0.021806067881793047 -- epoch number 770\n",
      "\n",
      "\n",
      "loss before training is 0.02175677923299282 -- epoch number 771\n",
      "\n",
      "\n",
      "loss before training is 0.021707648576117473 -- epoch number 772\n",
      "\n",
      "\n",
      "loss before training is 0.02165867541113498 -- epoch number 773\n",
      "\n",
      "\n",
      "loss before training is 0.021609859238705405 -- epoch number 774\n",
      "\n",
      "\n",
      "loss before training is 0.021561199560191396 -- epoch number 775\n",
      "\n",
      "\n",
      "loss before training is 0.021512695877668523 -- epoch number 776\n",
      "\n",
      "\n",
      "loss before training is 0.021464347693935452 -- epoch number 777\n",
      "\n",
      "\n",
      "loss before training is 0.021416154512524106 -- epoch number 778\n",
      "\n",
      "\n",
      "loss before training is 0.02136811583770944 -- epoch number 779\n",
      "\n",
      "\n",
      "loss before training is 0.021320231174519335 -- epoch number 780\n",
      "\n",
      "\n",
      "loss before training is 0.021272500028744104 -- epoch number 781\n",
      "\n",
      "\n",
      "loss before training is 0.02122492190694601 -- epoch number 782\n",
      "\n",
      "\n",
      "loss before training is 0.0211774963164687 -- epoch number 783\n",
      "\n",
      "\n",
      "loss before training is 0.021130222765446134 -- epoch number 784\n",
      "\n",
      "\n",
      "loss before training is 0.021083100762811967 -- epoch number 785\n",
      "\n",
      "\n",
      "loss before training is 0.021036129818308193 -- epoch number 786\n",
      "\n",
      "\n",
      "loss before training is 0.020989309442494077 -- epoch number 787\n",
      "\n",
      "\n",
      "loss before training is 0.020942639146754705 -- epoch number 788\n",
      "\n",
      "\n",
      "loss before training is 0.02089611844330952 -- epoch number 789\n",
      "\n",
      "\n",
      "loss before training is 0.020849746845220667 -- epoch number 790\n",
      "\n",
      "\n",
      "loss before training is 0.02080352386640127 -- epoch number 791\n",
      "\n",
      "\n",
      "loss before training is 0.020757449021623485 -- epoch number 792\n",
      "\n",
      "\n",
      "loss before training is 0.02071152182652644 -- epoch number 793\n",
      "\n",
      "\n",
      "loss before training is 0.02066574179762417 -- epoch number 794\n",
      "\n",
      "\n",
      "loss before training is 0.02062010845231322 -- epoch number 795\n",
      "\n",
      "\n",
      "loss before training is 0.020574621308880277 -- epoch number 796\n",
      "\n",
      "\n",
      "loss before training is 0.020529279886509617 -- epoch number 797\n",
      "\n",
      "\n",
      "loss before training is 0.02048408370529041 -- epoch number 798\n",
      "\n",
      "\n",
      "loss before training is 0.020439032286223922 -- epoch number 799\n",
      "\n",
      "\n",
      "loss before training is 0.020394125151230603 -- epoch number 800\n",
      "\n",
      "\n",
      "loss before training is 0.020349361823157015 -- epoch number 801\n",
      "\n",
      "\n",
      "loss before training is 0.020304741825782683 -- epoch number 802\n",
      "\n",
      "\n",
      "loss before training is 0.02026026468382683 -- epoch number 803\n",
      "\n",
      "\n",
      "loss before training is 0.02021592992295486 -- epoch number 804\n",
      "\n",
      "\n",
      "loss before training is 0.02017173706978494 -- epoch number 805\n",
      "\n",
      "\n",
      "loss before training is 0.02012768565189431 -- epoch number 806\n",
      "\n",
      "\n",
      "loss before training is 0.02008377519782547 -- epoch number 807\n",
      "\n",
      "\n",
      "loss before training is 0.020040005237092404 -- epoch number 808\n",
      "\n",
      "\n",
      "loss before training is 0.019996375300186466 -- epoch number 809\n",
      "\n",
      "\n",
      "loss before training is 0.019952884918582298 -- epoch number 810\n",
      "\n",
      "\n",
      "loss before training is 0.019909533624743736 -- epoch number 811\n",
      "\n",
      "\n",
      "loss before training is 0.01986632095212924 -- epoch number 812\n",
      "\n",
      "\n",
      "loss before training is 0.019823246435197665 -- epoch number 813\n",
      "\n",
      "\n",
      "loss before training is 0.019780309609413575 -- epoch number 814\n",
      "\n",
      "\n",
      "loss before training is 0.01973751001125262 -- epoch number 815\n",
      "\n",
      "\n",
      "loss before training is 0.019694847178206767 -- epoch number 816\n",
      "\n",
      "\n",
      "loss before training is 0.019652320648789436 -- epoch number 817\n",
      "\n",
      "\n",
      "loss before training is 0.01960992996254043 -- epoch number 818\n",
      "\n",
      "\n",
      "loss before training is 0.019567674660030978 -- epoch number 819\n",
      "\n",
      "\n",
      "loss before training is 0.019525554282868438 -- epoch number 820\n",
      "\n",
      "\n",
      "loss before training is 0.01948356837370102 -- epoch number 821\n",
      "\n",
      "\n",
      "loss before training is 0.01944171647622243 -- epoch number 822\n",
      "\n",
      "\n",
      "loss before training is 0.019399998135176295 -- epoch number 823\n",
      "\n",
      "\n",
      "loss before training is 0.019358412896360686 -- epoch number 824\n",
      "\n",
      "\n",
      "loss before training is 0.019316960306632287 -- epoch number 825\n",
      "\n",
      "\n",
      "loss before training is 0.019275639913910646 -- epoch number 826\n",
      "\n",
      "\n",
      "loss before training is 0.019234451267182335 -- epoch number 827\n",
      "\n",
      "\n",
      "loss before training is 0.019193393916504892 -- epoch number 828\n",
      "\n",
      "\n",
      "loss before training is 0.019152467413010767 -- epoch number 829\n",
      "\n",
      "\n",
      "loss before training is 0.01911167130891115 -- epoch number 830\n",
      "\n",
      "\n",
      "loss before training is 0.01907100515749967 -- epoch number 831\n",
      "\n",
      "\n",
      "loss before training is 0.01903046851315604 -- epoch number 832\n",
      "\n",
      "\n",
      "loss before training is 0.018990060931349674 -- epoch number 833\n",
      "\n",
      "\n",
      "loss before training is 0.018949781968642988 -- epoch number 834\n",
      "\n",
      "\n",
      "loss before training is 0.018909631182694956 -- epoch number 835\n",
      "\n",
      "\n",
      "loss before training is 0.018869608132264182 -- epoch number 836\n",
      "\n",
      "\n",
      "loss before training is 0.01882971237721228 -- epoch number 837\n",
      "\n",
      "\n",
      "loss before training is 0.01878994347850685 -- epoch number 838\n",
      "\n",
      "\n",
      "loss before training is 0.018750300998224518 -- epoch number 839\n",
      "\n",
      "\n",
      "loss before training is 0.018710784499553917 -- epoch number 840\n",
      "\n",
      "\n",
      "loss before training is 0.018671393546798483 -- epoch number 841\n",
      "\n",
      "\n",
      "loss before training is 0.01863212770537924 -- epoch number 842\n",
      "\n",
      "\n",
      "loss before training is 0.018592986541837456 -- epoch number 843\n",
      "\n",
      "\n",
      "loss before training is 0.018553969623837284 -- epoch number 844\n",
      "\n",
      "\n",
      "loss before training is 0.018515076520168258 -- epoch number 845\n",
      "\n",
      "\n",
      "loss before training is 0.018476306800747744 -- epoch number 846\n",
      "\n",
      "\n",
      "loss before training is 0.018437660036623227 -- epoch number 847\n",
      "\n",
      "\n",
      "loss before training is 0.018399135799974754 -- epoch number 848\n",
      "\n",
      "\n",
      "loss before training is 0.018360733664116998 -- epoch number 849\n",
      "\n",
      "\n",
      "loss before training is 0.018322453203501395 -- epoch number 850\n",
      "\n",
      "\n",
      "loss before training is 0.01828429399371829 -- epoch number 851\n",
      "\n",
      "\n",
      "loss before training is 0.018246255611498848 -- epoch number 852\n",
      "\n",
      "\n",
      "loss before training is 0.01820833763471695 -- epoch number 853\n",
      "\n",
      "\n",
      "loss before training is 0.018170539642391043 -- epoch number 854\n",
      "\n",
      "\n",
      "loss before training is 0.018132861214685946 -- epoch number 855\n",
      "\n",
      "\n",
      "loss before training is 0.018095301932914455 -- epoch number 856\n",
      "\n",
      "\n",
      "loss before training is 0.018057861379539023 -- epoch number 857\n",
      "\n",
      "\n",
      "loss before training is 0.018020539138173246 -- epoch number 858\n",
      "\n",
      "\n",
      "loss before training is 0.01798333479358343 -- epoch number 859\n",
      "\n",
      "\n",
      "loss before training is 0.01794624793168994 -- epoch number 860\n",
      "\n",
      "\n",
      "loss before training is 0.01790927813956853 -- epoch number 861\n",
      "\n",
      "\n",
      "loss before training is 0.01787242500545166 -- epoch number 862\n",
      "\n",
      "\n",
      "loss before training is 0.01783568811872973 -- epoch number 863\n",
      "\n",
      "\n",
      "loss before training is 0.017799067069952105 -- epoch number 864\n",
      "\n",
      "\n",
      "loss before training is 0.017762561450828336 -- epoch number 865\n",
      "\n",
      "\n",
      "loss before training is 0.017726170854229124 -- epoch number 866\n",
      "\n",
      "\n",
      "loss before training is 0.01768989487418724 -- epoch number 867\n",
      "\n",
      "\n",
      "loss before training is 0.017653733105898465 -- epoch number 868\n",
      "\n",
      "\n",
      "loss before training is 0.017617685145722387 -- epoch number 869\n",
      "\n",
      "\n",
      "loss before training is 0.0175817505911832 -- epoch number 870\n",
      "\n",
      "\n",
      "loss before training is 0.017545929040970396 -- epoch number 871\n",
      "\n",
      "\n",
      "loss before training is 0.017510220094939393 -- epoch number 872\n",
      "\n",
      "\n",
      "loss before training is 0.017474623354112227 -- epoch number 873\n",
      "\n",
      "\n",
      "loss before training is 0.017439138420677944 -- epoch number 874\n",
      "\n",
      "\n",
      "loss before training is 0.01740376489799319 -- epoch number 875\n",
      "\n",
      "\n",
      "loss before training is 0.01736850239058256 -- epoch number 876\n",
      "\n",
      "\n",
      "loss before training is 0.017333350504139016 -- epoch number 877\n",
      "\n",
      "\n",
      "loss before training is 0.017298308845524187 -- epoch number 878\n",
      "\n",
      "\n",
      "loss before training is 0.017263377022768568 -- epoch number 879\n",
      "\n",
      "\n",
      "loss before training is 0.017228554645071822 -- epoch number 880\n",
      "\n",
      "\n",
      "loss before training is 0.01719384132280283 -- epoch number 881\n",
      "\n",
      "\n",
      "loss before training is 0.01715923666749987 -- epoch number 882\n",
      "\n",
      "\n",
      "loss before training is 0.017124740291870603 -- epoch number 883\n",
      "\n",
      "\n",
      "loss before training is 0.017090351809792112 -- epoch number 884\n",
      "\n",
      "\n",
      "loss before training is 0.017056070836310812 -- epoch number 885\n",
      "\n",
      "\n",
      "loss before training is 0.01702189698764233 -- epoch number 886\n",
      "\n",
      "\n",
      "loss before training is 0.016987829881171465 -- epoch number 887\n",
      "\n",
      "\n",
      "loss before training is 0.01695386913545181 -- epoch number 888\n",
      "\n",
      "\n",
      "loss before training is 0.016920014370205613 -- epoch number 889\n",
      "\n",
      "\n",
      "loss before training is 0.01688626520632349 -- epoch number 890\n",
      "\n",
      "\n",
      "loss before training is 0.016852621265864044 -- epoch number 891\n",
      "\n",
      "\n",
      "loss before training is 0.016819082172053423 -- epoch number 892\n",
      "\n",
      "\n",
      "loss before training is 0.016785647549284997 -- epoch number 893\n",
      "\n",
      "\n",
      "loss before training is 0.016752317023118805 -- epoch number 894\n",
      "\n",
      "\n",
      "loss before training is 0.016719090220281042 -- epoch number 895\n",
      "\n",
      "\n",
      "loss before training is 0.01668596676866349 -- epoch number 896\n",
      "\n",
      "\n",
      "loss before training is 0.01665294629732291 -- epoch number 897\n",
      "\n",
      "\n",
      "loss before training is 0.01662002843648044 -- epoch number 898\n",
      "\n",
      "\n",
      "loss before training is 0.016587212817520784 -- epoch number 899\n",
      "\n",
      "\n",
      "loss before training is 0.016554499072991606 -- epoch number 900\n",
      "\n",
      "\n",
      "loss before training is 0.016521886836602634 -- epoch number 901\n",
      "\n",
      "\n",
      "loss before training is 0.01648937574322494 -- epoch number 902\n",
      "\n",
      "\n",
      "loss before training is 0.016456965428890063 -- epoch number 903\n",
      "\n",
      "\n",
      "loss before training is 0.016424655530789034 -- epoch number 904\n",
      "\n",
      "\n",
      "loss before training is 0.016392445687271565 -- epoch number 905\n",
      "\n",
      "\n",
      "loss before training is 0.016360335537845015 -- epoch number 906\n",
      "\n",
      "\n",
      "loss before training is 0.016328324723173332 -- epoch number 907\n",
      "\n",
      "\n",
      "loss before training is 0.01629641288507611 -- epoch number 908\n",
      "\n",
      "\n",
      "loss before training is 0.01626459966652748 -- epoch number 909\n",
      "\n",
      "\n",
      "loss before training is 0.016232884711654905 -- epoch number 910\n",
      "\n",
      "\n",
      "loss before training is 0.01620126766573815 -- epoch number 911\n",
      "\n",
      "\n",
      "loss before training is 0.01616974817520802 -- epoch number 912\n",
      "\n",
      "\n",
      "loss before training is 0.016138325887645136 -- epoch number 913\n",
      "\n",
      "\n",
      "loss before training is 0.016107000451778774 -- epoch number 914\n",
      "\n",
      "\n",
      "loss before training is 0.016075771517485446 -- epoch number 915\n",
      "\n",
      "\n",
      "loss before training is 0.016044638735787646 -- epoch number 916\n",
      "\n",
      "\n",
      "loss before training is 0.01601360175885255 -- epoch number 917\n",
      "\n",
      "\n",
      "loss before training is 0.01598266023999048 -- epoch number 918\n",
      "\n",
      "\n",
      "loss before training is 0.015951813833653676 -- epoch number 919\n",
      "\n",
      "\n",
      "loss before training is 0.015921062195434717 -- epoch number 920\n",
      "\n",
      "\n",
      "loss before training is 0.01589040498206507 -- epoch number 921\n",
      "\n",
      "\n",
      "loss before training is 0.015859841851413647 -- epoch number 922\n",
      "\n",
      "\n",
      "loss before training is 0.015829372462485173 -- epoch number 923\n",
      "\n",
      "\n",
      "loss before training is 0.015798996475418717 -- epoch number 924\n",
      "\n",
      "\n",
      "loss before training is 0.015768713551486038 -- epoch number 925\n",
      "\n",
      "\n",
      "loss before training is 0.015738523353089985 -- epoch number 926\n",
      "\n",
      "\n",
      "loss before training is 0.015708425543762828 -- epoch number 927\n",
      "\n",
      "\n",
      "loss before training is 0.01567841978816463 -- epoch number 928\n",
      "\n",
      "\n",
      "loss before training is 0.01564850575208149 -- epoch number 929\n",
      "\n",
      "\n",
      "loss before training is 0.01561868310242387 -- epoch number 930\n",
      "\n",
      "\n",
      "loss before training is 0.015588951507224853 -- epoch number 931\n",
      "\n",
      "\n",
      "loss before training is 0.015559310635638222 -- epoch number 932\n",
      "\n",
      "\n",
      "loss before training is 0.01552976015793688 -- epoch number 933\n",
      "\n",
      "\n",
      "loss before training is 0.01550029974551082 -- epoch number 934\n",
      "\n",
      "\n",
      "loss before training is 0.015470929070865398 -- epoch number 935\n",
      "\n",
      "\n",
      "loss before training is 0.01544164780761944 -- epoch number 936\n",
      "\n",
      "\n",
      "loss before training is 0.015412455630503273 -- epoch number 937\n",
      "\n",
      "\n",
      "loss before training is 0.015383352215356909 -- epoch number 938\n",
      "\n",
      "\n",
      "loss before training is 0.015354337239127977 -- epoch number 939\n",
      "\n",
      "\n",
      "loss before training is 0.015325410379869918 -- epoch number 940\n",
      "\n",
      "\n",
      "loss before training is 0.015296571316739834 -- epoch number 941\n",
      "\n",
      "\n",
      "loss before training is 0.015267819729996586 -- epoch number 942\n",
      "\n",
      "\n",
      "loss before training is 0.01523915530099874 -- epoch number 943\n",
      "\n",
      "\n",
      "loss before training is 0.015210577712202474 -- epoch number 944\n",
      "\n",
      "\n",
      "loss before training is 0.015182086647159577 -- epoch number 945\n",
      "\n",
      "\n",
      "loss before training is 0.015153681790515332 -- epoch number 946\n",
      "\n",
      "\n",
      "loss before training is 0.015125362828006372 -- epoch number 947\n",
      "\n",
      "\n",
      "loss before training is 0.015097129446458607 -- epoch number 948\n",
      "\n",
      "\n",
      "loss before training is 0.015068981333785036 -- epoch number 949\n",
      "\n",
      "\n",
      "loss before training is 0.015040918178983611 -- epoch number 950\n",
      "\n",
      "\n",
      "loss before training is 0.015012939672135059 -- epoch number 951\n",
      "\n",
      "\n",
      "loss before training is 0.014985045504400616 -- epoch number 952\n",
      "\n",
      "\n",
      "loss before training is 0.014957235368019902 -- epoch number 953\n",
      "\n",
      "\n",
      "loss before training is 0.014929508956308627 -- epoch number 954\n",
      "\n",
      "\n",
      "loss before training is 0.014901865963656386 -- epoch number 955\n",
      "\n",
      "\n",
      "loss before training is 0.014874306085524298 -- epoch number 956\n",
      "\n",
      "\n",
      "loss before training is 0.014846829018442878 -- epoch number 957\n",
      "\n",
      "\n",
      "loss before training is 0.014819434460009565 -- epoch number 958\n",
      "\n",
      "\n",
      "loss before training is 0.014792122108886512 -- epoch number 959\n",
      "\n",
      "\n",
      "loss before training is 0.014764891664798278 -- epoch number 960\n",
      "\n",
      "\n",
      "loss before training is 0.014737742828529398 -- epoch number 961\n",
      "\n",
      "\n",
      "loss before training is 0.014710675301922105 -- epoch number 962\n",
      "\n",
      "\n",
      "loss before training is 0.014683688787873884 -- epoch number 963\n",
      "\n",
      "\n",
      "loss before training is 0.014656782990335144 -- epoch number 964\n",
      "\n",
      "\n",
      "loss before training is 0.014629957614306816 -- epoch number 965\n",
      "\n",
      "\n",
      "loss before training is 0.014603212365837923 -- epoch number 966\n",
      "\n",
      "\n",
      "loss before training is 0.014576546952023116 -- epoch number 967\n",
      "\n",
      "\n",
      "loss before training is 0.014549961081000342 -- epoch number 968\n",
      "\n",
      "\n",
      "loss before training is 0.01452345446194828 -- epoch number 969\n",
      "\n",
      "\n",
      "loss before training is 0.014497026805083954 -- epoch number 970\n",
      "\n",
      "\n",
      "loss before training is 0.014470677821660248 -- epoch number 971\n",
      "\n",
      "\n",
      "loss before training is 0.014444407223963385 -- epoch number 972\n",
      "\n",
      "\n",
      "loss before training is 0.014418214725310451 -- epoch number 973\n",
      "\n",
      "\n",
      "loss before training is 0.014392100040046948 -- epoch number 974\n",
      "\n",
      "\n",
      "loss before training is 0.014366062883544126 -- epoch number 975\n",
      "\n",
      "\n",
      "loss before training is 0.014340102972196674 -- epoch number 976\n",
      "\n",
      "\n",
      "loss before training is 0.014314220023419963 -- epoch number 977\n",
      "\n",
      "\n",
      "loss before training is 0.014288413755647628 -- epoch number 978\n",
      "\n",
      "\n",
      "loss before training is 0.01426268388832899 -- epoch number 979\n",
      "\n",
      "\n",
      "loss before training is 0.014237030141926463 -- epoch number 980\n",
      "\n",
      "\n",
      "loss before training is 0.014211452237913022 -- epoch number 981\n",
      "\n",
      "\n",
      "loss before training is 0.014185949898769565 -- epoch number 982\n",
      "\n",
      "\n",
      "loss before training is 0.014160522847982339 -- epoch number 983\n",
      "\n",
      "\n",
      "loss before training is 0.014135170810040374 -- epoch number 984\n",
      "\n",
      "\n",
      "loss before training is 0.014109893510432889 -- epoch number 985\n",
      "\n",
      "\n",
      "loss before training is 0.014084690675646536 -- epoch number 986\n",
      "\n",
      "\n",
      "loss before training is 0.014059562033162946 -- epoch number 987\n",
      "\n",
      "\n",
      "loss before training is 0.014034507311455991 -- epoch number 988\n",
      "\n",
      "\n",
      "loss before training is 0.014009526239989224 -- epoch number 989\n",
      "\n",
      "\n",
      "loss before training is 0.013984618549213158 -- epoch number 990\n",
      "\n",
      "\n",
      "loss before training is 0.013959783970562635 -- epoch number 991\n",
      "\n",
      "\n",
      "loss before training is 0.013935022236454212 -- epoch number 992\n",
      "\n",
      "\n",
      "loss before training is 0.013910333080283435 -- epoch number 993\n",
      "\n",
      "\n",
      "loss before training is 0.013885716236422208 -- epoch number 994\n",
      "\n",
      "\n",
      "loss before training is 0.013861171440216119 -- epoch number 995\n",
      "\n",
      "\n",
      "loss before training is 0.013836698427981697 -- epoch number 996\n",
      "\n",
      "\n",
      "loss before training is 0.013812296937003827 -- epoch number 997\n",
      "\n",
      "\n",
      "loss before training is 0.013787966705532957 -- epoch number 998\n",
      "\n",
      "\n",
      "loss before training is 0.013763707472782428 -- epoch number 999\n",
      "\n",
      "\n",
      "loss before training is 0.013739518978925856 -- epoch number 1000\n",
      "\n",
      "\n",
      "loss before training is 0.013715400965094274 -- epoch number 1001\n",
      "\n",
      "\n",
      "loss before training is 0.01369135317337359 -- epoch number 1002\n",
      "\n",
      "\n",
      "loss before training is 0.01366737534680166 -- epoch number 1003\n",
      "\n",
      "\n",
      "loss before training is 0.01364346722936579 -- epoch number 1004\n",
      "\n",
      "\n",
      "loss before training is 0.01361962856599987 -- epoch number 1005\n",
      "\n",
      "\n",
      "loss before training is 0.013595859102581712 -- epoch number 1006\n",
      "\n",
      "\n",
      "loss before training is 0.01357215858593024 -- epoch number 1007\n",
      "\n",
      "\n",
      "loss before training is 0.013548526763802866 -- epoch number 1008\n",
      "\n",
      "\n",
      "loss before training is 0.013524963384892685 -- epoch number 1009\n",
      "\n",
      "\n",
      "loss before training is 0.013501468198825724 -- epoch number 1010\n",
      "\n",
      "\n",
      "loss before training is 0.013478040956158236 -- epoch number 1011\n",
      "\n",
      "\n",
      "loss before training is 0.013454681408373928 -- epoch number 1012\n",
      "\n",
      "\n",
      "loss before training is 0.013431389307881228 -- epoch number 1013\n",
      "\n",
      "\n",
      "loss before training is 0.01340816440801053 -- epoch number 1014\n",
      "\n",
      "\n",
      "loss before training is 0.013385006463011441 -- epoch number 1015\n",
      "\n",
      "\n",
      "loss before training is 0.013361915228050001 -- epoch number 1016\n",
      "\n",
      "\n",
      "loss before training is 0.01333889045920603 -- epoch number 1017\n",
      "\n",
      "\n",
      "loss before training is 0.013315931913470186 -- epoch number 1018\n",
      "\n",
      "\n",
      "loss before training is 0.013293039348741372 -- epoch number 1019\n",
      "\n",
      "\n",
      "loss before training is 0.013270212523823896 -- epoch number 1020\n",
      "\n",
      "\n",
      "loss before training is 0.013247451198424737 -- epoch number 1021\n",
      "\n",
      "\n",
      "loss before training is 0.013224755133150745 -- epoch number 1022\n",
      "\n",
      "\n",
      "loss before training is 0.013202124089505947 -- epoch number 1023\n",
      "\n",
      "\n",
      "loss before training is 0.01317955782988869 -- epoch number 1024\n",
      "\n",
      "\n",
      "loss before training is 0.013157056117588937 -- epoch number 1025\n",
      "\n",
      "\n",
      "loss before training is 0.01313461871678551 -- epoch number 1026\n",
      "\n",
      "\n",
      "loss before training is 0.013112245392543274 -- epoch number 1027\n",
      "\n",
      "\n",
      "loss before training is 0.013089935910810393 -- epoch number 1028\n",
      "\n",
      "\n",
      "loss before training is 0.013067690038415623 -- epoch number 1029\n",
      "\n",
      "\n",
      "loss before training is 0.0130455075430654 -- epoch number 1030\n",
      "\n",
      "\n",
      "loss before training is 0.013023388193341243 -- epoch number 1031\n",
      "\n",
      "\n",
      "loss before training is 0.013001331758696867 -- epoch number 1032\n",
      "\n",
      "\n",
      "loss before training is 0.012979338009455471 -- epoch number 1033\n",
      "\n",
      "\n",
      "loss before training is 0.012957406716806966 -- epoch number 1034\n",
      "\n",
      "\n",
      "loss before training is 0.012935537652805178 -- epoch number 1035\n",
      "\n",
      "\n",
      "loss before training is 0.012913730590365158 -- epoch number 1036\n",
      "\n",
      "\n",
      "loss before training is 0.012891985303260366 -- epoch number 1037\n",
      "\n",
      "\n",
      "loss before training is 0.01287030156611988 -- epoch number 1038\n",
      "\n",
      "\n",
      "loss before training is 0.012848679154425714 -- epoch number 1039\n",
      "\n",
      "\n",
      "loss before training is 0.012827117844509994 -- epoch number 1040\n",
      "\n",
      "\n",
      "loss before training is 0.012805617413552264 -- epoch number 1041\n",
      "\n",
      "\n",
      "loss before training is 0.012784177639576639 -- epoch number 1042\n",
      "\n",
      "\n",
      "loss before training is 0.012762798301449144 -- epoch number 1043\n",
      "\n",
      "\n",
      "loss before training is 0.012741479178874925 -- epoch number 1044\n",
      "\n",
      "\n",
      "loss before training is 0.012720220052395436 -- epoch number 1045\n",
      "\n",
      "\n",
      "loss before training is 0.012699020703385843 -- epoch number 1046\n",
      "\n",
      "\n",
      "loss before training is 0.012677880914052085 -- epoch number 1047\n",
      "\n",
      "\n",
      "loss before training is 0.012656800467428323 -- epoch number 1048\n",
      "\n",
      "\n",
      "loss before training is 0.012635779147374022 -- epoch number 1049\n",
      "\n",
      "\n",
      "loss before training is 0.01261481673857134 -- epoch number 1050\n",
      "\n",
      "\n",
      "loss before training is 0.012593913026522349 -- epoch number 1051\n",
      "\n",
      "\n",
      "loss before training is 0.012573067797546227 -- epoch number 1052\n",
      "\n",
      "\n",
      "loss before training is 0.012552280838776686 -- epoch number 1053\n",
      "\n",
      "\n",
      "loss before training is 0.012531551938159087 -- epoch number 1054\n",
      "\n",
      "\n",
      "loss before training is 0.012510880884447788 -- epoch number 1055\n",
      "\n",
      "\n",
      "loss before training is 0.012490267467203432 -- epoch number 1056\n",
      "\n",
      "\n",
      "loss before training is 0.01246971147679015 -- epoch number 1057\n",
      "\n",
      "\n",
      "loss before training is 0.012449212704372953 -- epoch number 1058\n",
      "\n",
      "\n",
      "loss before training is 0.01242877094191493 -- epoch number 1059\n",
      "\n",
      "\n",
      "loss before training is 0.012408385982174586 -- epoch number 1060\n",
      "\n",
      "\n",
      "loss before training is 0.01238805761870309 -- epoch number 1061\n",
      "\n",
      "\n",
      "loss before training is 0.012367785645841595 -- epoch number 1062\n",
      "\n",
      "\n",
      "loss before training is 0.012347569858718578 -- epoch number 1063\n",
      "\n",
      "\n",
      "loss before training is 0.012327410053247057 -- epoch number 1064\n",
      "\n",
      "\n",
      "loss before training is 0.01230730602612199 -- epoch number 1065\n",
      "\n",
      "\n",
      "loss before training is 0.012287257574817474 -- epoch number 1066\n",
      "\n",
      "\n",
      "loss before training is 0.012267264497584184 -- epoch number 1067\n",
      "\n",
      "\n",
      "loss before training is 0.012247326593446604 -- epoch number 1068\n",
      "\n",
      "\n",
      "loss before training is 0.012227443662200351 -- epoch number 1069\n",
      "\n",
      "\n",
      "loss before training is 0.012207615504409597 -- epoch number 1070\n",
      "\n",
      "\n",
      "loss before training is 0.012187841921404232 -- epoch number 1071\n",
      "\n",
      "\n",
      "loss before training is 0.012168122715277369 -- epoch number 1072\n",
      "\n",
      "\n",
      "loss before training is 0.012148457688882574 -- epoch number 1073\n",
      "\n",
      "\n",
      "loss before training is 0.01212884664583123 -- epoch number 1074\n",
      "\n",
      "\n",
      "loss before training is 0.012109289390489898 -- epoch number 1075\n",
      "\n",
      "\n",
      "loss before training is 0.012089785727977701 -- epoch number 1076\n",
      "\n",
      "\n",
      "loss before training is 0.012070335464163605 -- epoch number 1077\n",
      "\n",
      "\n",
      "loss before training is 0.012050938405663819 -- epoch number 1078\n",
      "\n",
      "\n",
      "loss before training is 0.012031594359839177 -- epoch number 1079\n",
      "\n",
      "\n",
      "loss before training is 0.012012303134792464 -- epoch number 1080\n",
      "\n",
      "\n",
      "loss before training is 0.011993064539365848 -- epoch number 1081\n",
      "\n",
      "\n",
      "loss before training is 0.011973878383138202 -- epoch number 1082\n",
      "\n",
      "\n",
      "loss before training is 0.01195474447642253 -- epoch number 1083\n",
      "\n",
      "\n",
      "loss before training is 0.011935662630263334 -- epoch number 1084\n",
      "\n",
      "\n",
      "loss before training is 0.011916632656433994 -- epoch number 1085\n",
      "\n",
      "\n",
      "loss before training is 0.011897654367434205 -- epoch number 1086\n",
      "\n",
      "\n",
      "loss before training is 0.011878727576487367 -- epoch number 1087\n",
      "\n",
      "\n",
      "loss before training is 0.011859852097537978 -- epoch number 1088\n",
      "\n",
      "\n",
      "loss before training is 0.011841027745249057 -- epoch number 1089\n",
      "\n",
      "\n",
      "loss before training is 0.01182225433499957 -- epoch number 1090\n",
      "\n",
      "\n",
      "loss before training is 0.011803531682881856 -- epoch number 1091\n",
      "\n",
      "\n",
      "loss before training is 0.01178485960569903 -- epoch number 1092\n",
      "\n",
      "\n",
      "loss before training is 0.011766237920962482 -- epoch number 1093\n",
      "\n",
      "\n",
      "loss before training is 0.01174766644688923 -- epoch number 1094\n",
      "\n",
      "\n",
      "loss before training is 0.011729145002399428 -- epoch number 1095\n",
      "\n",
      "\n",
      "loss before training is 0.011710673407113795 -- epoch number 1096\n",
      "\n",
      "\n",
      "loss before training is 0.011692251481351092 -- epoch number 1097\n",
      "\n",
      "\n",
      "loss before training is 0.011673879046125574 -- epoch number 1098\n",
      "\n",
      "\n",
      "loss before training is 0.01165555592314443 -- epoch number 1099\n",
      "\n",
      "\n",
      "loss before training is 0.011637281934805309 -- epoch number 1100\n",
      "\n",
      "\n",
      "loss before training is 0.011619056904193733 -- epoch number 1101\n",
      "\n",
      "\n",
      "loss before training is 0.011600880655080683 -- epoch number 1102\n",
      "\n",
      "\n",
      "loss before training is 0.01158275301191998 -- epoch number 1103\n",
      "\n",
      "\n",
      "loss before training is 0.011564673799845833 -- epoch number 1104\n",
      "\n",
      "\n",
      "loss before training is 0.011546642844670354 -- epoch number 1105\n",
      "\n",
      "\n",
      "loss before training is 0.011528659972881085 -- epoch number 1106\n",
      "\n",
      "\n",
      "loss before training is 0.011510725011638412 -- epoch number 1107\n",
      "\n",
      "\n",
      "loss before training is 0.01149283778877319 -- epoch number 1108\n",
      "\n",
      "\n",
      "loss before training is 0.011474998132784232 -- epoch number 1109\n",
      "\n",
      "\n",
      "loss before training is 0.011457205872835833 -- epoch number 1110\n",
      "\n",
      "\n",
      "loss before training is 0.011439460838755347 -- epoch number 1111\n",
      "\n",
      "\n",
      "loss before training is 0.01142176286103064 -- epoch number 1112\n",
      "\n",
      "\n",
      "loss before training is 0.011404111770807756 -- epoch number 1113\n",
      "\n",
      "\n",
      "loss before training is 0.011386507399888415 -- epoch number 1114\n",
      "\n",
      "\n",
      "loss before training is 0.011368949580727521 -- epoch number 1115\n",
      "\n",
      "\n",
      "loss before training is 0.011351438146430883 -- epoch number 1116\n",
      "\n",
      "\n",
      "loss before training is 0.01133397293075265 -- epoch number 1117\n",
      "\n",
      "\n",
      "loss before training is 0.011316553768092921 -- epoch number 1118\n",
      "\n",
      "\n",
      "loss before training is 0.011299180493495351 -- epoch number 1119\n",
      "\n",
      "\n",
      "loss before training is 0.011281852942644797 -- epoch number 1120\n",
      "\n",
      "\n",
      "loss before training is 0.011264570951864847 -- epoch number 1121\n",
      "\n",
      "\n",
      "loss before training is 0.01124733435811539 -- epoch number 1122\n",
      "\n",
      "\n",
      "loss before training is 0.011230142998990347 -- epoch number 1123\n",
      "\n",
      "\n",
      "loss before training is 0.011212996712715199 -- epoch number 1124\n",
      "\n",
      "\n",
      "loss before training is 0.011195895338144657 -- epoch number 1125\n",
      "\n",
      "\n",
      "loss before training is 0.011178838714760265 -- epoch number 1126\n",
      "\n",
      "\n",
      "loss before training is 0.011161826682668043 -- epoch number 1127\n",
      "\n",
      "\n",
      "loss before training is 0.011144859082596149 -- epoch number 1128\n",
      "\n",
      "\n",
      "loss before training is 0.011127935755892535 -- epoch number 1129\n",
      "\n",
      "\n",
      "loss before training is 0.011111056544522577 -- epoch number 1130\n",
      "\n",
      "\n",
      "loss before training is 0.011094221291066745 -- epoch number 1131\n",
      "\n",
      "\n",
      "loss before training is 0.011077429838718279 -- epoch number 1132\n",
      "\n",
      "\n",
      "loss before training is 0.011060682031280888 -- epoch number 1133\n",
      "\n",
      "\n",
      "loss before training is 0.011043977713166413 -- epoch number 1134\n",
      "\n",
      "\n",
      "loss before training is 0.01102731672939248 -- epoch number 1135\n",
      "\n",
      "\n",
      "loss before training is 0.011010698925580282 -- epoch number 1136\n",
      "\n",
      "\n",
      "loss before training is 0.010994124147952214 -- epoch number 1137\n",
      "\n",
      "\n",
      "loss before training is 0.010977592243329604 -- epoch number 1138\n",
      "\n",
      "\n",
      "loss before training is 0.010961103059130424 -- epoch number 1139\n",
      "\n",
      "\n",
      "loss before training is 0.010944656443367031 -- epoch number 1140\n",
      "\n",
      "\n",
      "loss before training is 0.010928252244643874 -- epoch number 1141\n",
      "\n",
      "\n",
      "loss before training is 0.010911890312155254 -- epoch number 1142\n",
      "\n",
      "\n",
      "loss before training is 0.010895570495683026 -- epoch number 1143\n",
      "\n",
      "\n",
      "loss before training is 0.010879292645594413 -- epoch number 1144\n",
      "\n",
      "\n",
      "loss before training is 0.010863056612839712 -- epoch number 1145\n",
      "\n",
      "\n",
      "loss before training is 0.010846862248950047 -- epoch number 1146\n",
      "\n",
      "\n",
      "loss before training is 0.010830709406035206 -- epoch number 1147\n",
      "\n",
      "\n",
      "loss before training is 0.010814597936781353 -- epoch number 1148\n",
      "\n",
      "\n",
      "loss before training is 0.010798527694448815 -- epoch number 1149\n",
      "\n",
      "\n",
      "loss before training is 0.010782498532869911 -- epoch number 1150\n",
      "\n",
      "\n",
      "loss before training is 0.01076651030644672 -- epoch number 1151\n",
      "\n",
      "\n",
      "loss before training is 0.010750562870148913 -- epoch number 1152\n",
      "\n",
      "\n",
      "loss before training is 0.01073465607951149 -- epoch number 1153\n",
      "\n",
      "\n",
      "loss before training is 0.010718789790632708 -- epoch number 1154\n",
      "\n",
      "\n",
      "loss before training is 0.010702963860171786 -- epoch number 1155\n",
      "\n",
      "\n",
      "loss before training is 0.010687178145346848 -- epoch number 1156\n",
      "\n",
      "\n",
      "loss before training is 0.010671432503932658 -- epoch number 1157\n",
      "\n",
      "\n",
      "loss before training is 0.01065572679425858 -- epoch number 1158\n",
      "\n",
      "\n",
      "loss before training is 0.010640060875206263 -- epoch number 1159\n",
      "\n",
      "\n",
      "loss before training is 0.010624434606207666 -- epoch number 1160\n",
      "\n",
      "\n",
      "loss before training is 0.010608847847242853 -- epoch number 1161\n",
      "\n",
      "\n",
      "loss before training is 0.010593300458837815 -- epoch number 1162\n",
      "\n",
      "\n",
      "loss before training is 0.010577792302062433 -- epoch number 1163\n",
      "\n",
      "\n",
      "loss before training is 0.010562323238528296 -- epoch number 1164\n",
      "\n",
      "\n",
      "loss before training is 0.010546893130386665 -- epoch number 1165\n",
      "\n",
      "\n",
      "loss before training is 0.01053150184032628 -- epoch number 1166\n",
      "\n",
      "\n",
      "loss before training is 0.01051614923157133 -- epoch number 1167\n",
      "\n",
      "\n",
      "loss before training is 0.010500835167879346 -- epoch number 1168\n",
      "\n",
      "\n",
      "loss before training is 0.010485559513539112 -- epoch number 1169\n",
      "\n",
      "\n",
      "loss before training is 0.010470322133368612 -- epoch number 1170\n",
      "\n",
      "\n",
      "loss before training is 0.0104551228927129 -- epoch number 1171\n",
      "\n",
      "\n",
      "loss before training is 0.010439961657442163 -- epoch number 1172\n",
      "\n",
      "\n",
      "loss before training is 0.010424838293949523 -- epoch number 1173\n",
      "\n",
      "\n",
      "loss before training is 0.010409752669149053 -- epoch number 1174\n",
      "\n",
      "\n",
      "loss before training is 0.010394704650473787 -- epoch number 1175\n",
      "\n",
      "\n",
      "loss before training is 0.010379694105873574 -- epoch number 1176\n",
      "\n",
      "\n",
      "loss before training is 0.010364720903813178 -- epoch number 1177\n",
      "\n",
      "\n",
      "loss before training is 0.010349784913270127 -- epoch number 1178\n",
      "\n",
      "\n",
      "loss before training is 0.01033488600373281 -- epoch number 1179\n",
      "\n",
      "\n",
      "loss before training is 0.010320024045198377 -- epoch number 1180\n",
      "\n",
      "\n",
      "loss before training is 0.010305198908170835 -- epoch number 1181\n",
      "\n",
      "\n",
      "loss before training is 0.010290410463658955 -- epoch number 1182\n",
      "\n",
      "\n",
      "loss before training is 0.010275658583174337 -- epoch number 1183\n",
      "\n",
      "\n",
      "loss before training is 0.01026094313872948 -- epoch number 1184\n",
      "\n",
      "\n",
      "loss before training is 0.010246264002835667 -- epoch number 1185\n",
      "\n",
      "\n",
      "loss before training is 0.01023162104850115 -- epoch number 1186\n",
      "\n",
      "\n",
      "loss before training is 0.010217014149229112 -- epoch number 1187\n",
      "\n",
      "\n",
      "loss before training is 0.010202443179015672 -- epoch number 1188\n",
      "\n",
      "\n",
      "loss before training is 0.01018790801234807 -- epoch number 1189\n",
      "\n",
      "\n",
      "loss before training is 0.01017340852420259 -- epoch number 1190\n",
      "\n",
      "\n",
      "loss before training is 0.010158944590042691 -- epoch number 1191\n",
      "\n",
      "\n",
      "loss before training is 0.010144516085817113 -- epoch number 1192\n",
      "\n",
      "\n",
      "loss before training is 0.010130122887957855 -- epoch number 1193\n",
      "\n",
      "\n",
      "loss before training is 0.010115764873378376 -- epoch number 1194\n",
      "\n",
      "\n",
      "loss before training is 0.010101441919471606 -- epoch number 1195\n",
      "\n",
      "\n",
      "loss before training is 0.010087153904108085 -- epoch number 1196\n",
      "\n",
      "\n",
      "loss before training is 0.010072900705634054 -- epoch number 1197\n",
      "\n",
      "\n",
      "loss before training is 0.010058682202869578 -- epoch number 1198\n",
      "\n",
      "\n",
      "loss before training is 0.010044498275106666 -- epoch number 1199\n",
      "\n",
      "\n",
      "loss before training is 0.010030348802107368 -- epoch number 1200\n",
      "\n",
      "\n",
      "loss before training is 0.01001623366410196 -- epoch number 1201\n",
      "\n",
      "\n",
      "loss before training is 0.01000215274178705 -- epoch number 1202\n",
      "\n",
      "\n",
      "loss before training is 0.009988105916323719 -- epoch number 1203\n",
      "\n",
      "\n",
      "loss before training is 0.00997409306933569 -- epoch number 1204\n",
      "\n",
      "\n",
      "loss before training is 0.009960114082907479 -- epoch number 1205\n",
      "\n",
      "\n",
      "loss before training is 0.00994616883958257 -- epoch number 1206\n",
      "\n",
      "\n",
      "loss before training is 0.009932257222361594 -- epoch number 1207\n",
      "\n",
      "\n",
      "loss before training is 0.00991837911470045 -- epoch number 1208\n",
      "\n",
      "\n",
      "loss before training is 0.009904534400508598 -- epoch number 1209\n",
      "\n",
      "\n",
      "loss before training is 0.009890722964147121 -- epoch number 1210\n",
      "\n",
      "\n",
      "loss before training is 0.009876944690427027 -- epoch number 1211\n",
      "\n",
      "\n",
      "loss before training is 0.009863199464607428 -- epoch number 1212\n",
      "\n",
      "\n",
      "loss before training is 0.009849487172393718 -- epoch number 1213\n",
      "\n",
      "\n",
      "loss before training is 0.00983580769993583 -- epoch number 1214\n",
      "\n",
      "\n",
      "loss before training is 0.00982216093382645 -- epoch number 1215\n",
      "\n",
      "\n",
      "loss before training is 0.009808546761099197 -- epoch number 1216\n",
      "\n",
      "\n",
      "loss before training is 0.009794965069226946 -- epoch number 1217\n",
      "\n",
      "\n",
      "loss before training is 0.009781415746120035 -- epoch number 1218\n",
      "\n",
      "\n",
      "loss before training is 0.009767898680124513 -- epoch number 1219\n",
      "\n",
      "\n",
      "loss before training is 0.00975441376002036 -- epoch number 1220\n",
      "\n",
      "\n",
      "loss before training is 0.009740960875019793 -- epoch number 1221\n",
      "\n",
      "\n",
      "loss before training is 0.009727539914765566 -- epoch number 1222\n",
      "\n",
      "\n",
      "loss before training is 0.009714150769329175 -- epoch number 1223\n",
      "\n",
      "\n",
      "loss before training is 0.009700793329209166 -- epoch number 1224\n",
      "\n",
      "\n",
      "loss before training is 0.009687467485329459 -- epoch number 1225\n",
      "\n",
      "\n",
      "loss before training is 0.009674173129037573 -- epoch number 1226\n",
      "\n",
      "\n",
      "loss before training is 0.009660910152103026 -- epoch number 1227\n",
      "\n",
      "\n",
      "loss before training is 0.009647678446715512 -- epoch number 1228\n",
      "\n",
      "\n",
      "loss before training is 0.009634477905483323 -- epoch number 1229\n",
      "\n",
      "\n",
      "loss before training is 0.009621308421431652 -- epoch number 1230\n",
      "\n",
      "\n",
      "loss before training is 0.009608169888000853 -- epoch number 1231\n",
      "\n",
      "\n",
      "loss before training is 0.009595062199044858 -- epoch number 1232\n",
      "\n",
      "\n",
      "loss before training is 0.009581985248829455 -- epoch number 1233\n",
      "\n",
      "\n",
      "loss before training is 0.009568938932030667 -- epoch number 1234\n",
      "\n",
      "\n",
      "loss before training is 0.009555923143733078 -- epoch number 1235\n",
      "\n",
      "\n",
      "loss before training is 0.009542937779428228 -- epoch number 1236\n",
      "\n",
      "\n",
      "loss before training is 0.009529982735012911 -- epoch number 1237\n",
      "\n",
      "\n",
      "loss before training is 0.009517057906787627 -- epoch number 1238\n",
      "\n",
      "\n",
      "loss before training is 0.009504163191454893 -- epoch number 1239\n",
      "\n",
      "\n",
      "loss before training is 0.009491298486117659 -- epoch number 1240\n",
      "\n",
      "\n",
      "loss before training is 0.009478463688277691 -- epoch number 1241\n",
      "\n",
      "\n",
      "loss before training is 0.009465658695833917 -- epoch number 1242\n",
      "\n",
      "\n",
      "loss before training is 0.009452883407080927 -- epoch number 1243\n",
      "\n",
      "\n",
      "loss before training is 0.009440137720707311 -- epoch number 1244\n",
      "\n",
      "\n",
      "loss before training is 0.009427421535794032 -- epoch number 1245\n",
      "\n",
      "\n",
      "loss before training is 0.009414734751812951 -- epoch number 1246\n",
      "\n",
      "\n",
      "loss before training is 0.009402077268625169 -- epoch number 1247\n",
      "\n",
      "\n",
      "loss before training is 0.0093894489864795 -- epoch number 1248\n",
      "\n",
      "\n",
      "loss before training is 0.009376849806010884 -- epoch number 1249\n",
      "\n",
      "\n",
      "loss before training is 0.009364279628238822 -- epoch number 1250\n",
      "\n",
      "\n",
      "loss before training is 0.009351738354565852 -- epoch number 1251\n",
      "\n",
      "\n",
      "loss before training is 0.009339225886776 -- epoch number 1252\n",
      "\n",
      "\n",
      "loss before training is 0.009326742127033197 -- epoch number 1253\n",
      "\n",
      "\n",
      "loss before training is 0.009314286977879838 -- epoch number 1254\n",
      "\n",
      "\n",
      "loss before training is 0.009301860342235131 -- epoch number 1255\n",
      "\n",
      "\n",
      "loss before training is 0.009289462123393686 -- epoch number 1256\n",
      "\n",
      "\n",
      "loss before training is 0.00927709222502393 -- epoch number 1257\n",
      "\n",
      "\n",
      "loss before training is 0.00926475055116661 -- epoch number 1258\n",
      "\n",
      "\n",
      "loss before training is 0.009252437006233346 -- epoch number 1259\n",
      "\n",
      "\n",
      "loss before training is 0.009240151495005025 -- epoch number 1260\n",
      "\n",
      "\n",
      "loss before training is 0.0092278939226304 -- epoch number 1261\n",
      "\n",
      "\n",
      "loss before training is 0.009215664194624546 -- epoch number 1262\n",
      "\n",
      "\n",
      "loss before training is 0.009203462216867464 -- epoch number 1263\n",
      "\n",
      "\n",
      "loss before training is 0.009191287895602474 -- epoch number 1264\n",
      "\n",
      "\n",
      "loss before training is 0.009179141137434841 -- epoch number 1265\n",
      "\n",
      "\n",
      "loss before training is 0.009167021849330319 -- epoch number 1266\n",
      "\n",
      "\n",
      "loss before training is 0.00915492993861361 -- epoch number 1267\n",
      "\n",
      "\n",
      "loss before training is 0.009142865312966991 -- epoch number 1268\n",
      "\n",
      "\n",
      "loss before training is 0.009130827880428828 -- epoch number 1269\n",
      "\n",
      "\n",
      "loss before training is 0.009118817549392165 -- epoch number 1270\n",
      "\n",
      "\n",
      "loss before training is 0.009106834228603252 -- epoch number 1271\n",
      "\n",
      "\n",
      "loss before training is 0.009094877827160145 -- epoch number 1272\n",
      "\n",
      "\n",
      "loss before training is 0.00908294825451124 -- epoch number 1273\n",
      "\n",
      "\n",
      "loss before training is 0.0090710454204539 -- epoch number 1274\n",
      "\n",
      "\n",
      "loss before training is 0.009059169235133044 -- epoch number 1275\n",
      "\n",
      "\n",
      "loss before training is 0.009047319609039711 -- epoch number 1276\n",
      "\n",
      "\n",
      "loss before training is 0.009035496453009634 -- epoch number 1277\n",
      "\n",
      "\n",
      "loss before training is 0.009023699678221938 -- epoch number 1278\n",
      "\n",
      "\n",
      "loss before training is 0.009011929196197647 -- epoch number 1279\n",
      "\n",
      "\n",
      "loss before training is 0.00900018491879834 -- epoch number 1280\n",
      "\n",
      "\n",
      "loss before training is 0.008988466758224801 -- epoch number 1281\n",
      "\n",
      "\n",
      "loss before training is 0.008976774627015589 -- epoch number 1282\n",
      "\n",
      "\n",
      "loss before training is 0.008965108438045714 -- epoch number 1283\n",
      "\n",
      "\n",
      "loss before training is 0.008953468104525223 -- epoch number 1284\n",
      "\n",
      "\n",
      "loss before training is 0.00894185353999791 -- epoch number 1285\n",
      "\n",
      "\n",
      "loss before training is 0.008930264658339926 -- epoch number 1286\n",
      "\n",
      "\n",
      "loss before training is 0.008918701373758418 -- epoch number 1287\n",
      "\n",
      "\n",
      "loss before training is 0.008907163600790188 -- epoch number 1288\n",
      "\n",
      "\n",
      "loss before training is 0.008895651254300398 -- epoch number 1289\n",
      "\n",
      "\n",
      "loss before training is 0.008884164249481215 -- epoch number 1290\n",
      "\n",
      "\n",
      "loss before training is 0.008872702501850458 -- epoch number 1291\n",
      "\n",
      "\n",
      "loss before training is 0.008861265927250308 -- epoch number 1292\n",
      "\n",
      "\n",
      "loss before training is 0.00884985444184599 -- epoch number 1293\n",
      "\n",
      "\n",
      "loss before training is 0.008838467962124473 -- epoch number 1294\n",
      "\n",
      "\n",
      "loss before training is 0.008827106404893138 -- epoch number 1295\n",
      "\n",
      "\n",
      "loss before training is 0.008815769687278449 -- epoch number 1296\n",
      "\n",
      "\n",
      "loss before training is 0.008804457726724797 -- epoch number 1297\n",
      "\n",
      "\n",
      "loss before training is 0.008793170440993012 -- epoch number 1298\n",
      "\n",
      "\n",
      "loss before training is 0.008781907748159273 -- epoch number 1299\n",
      "\n",
      "\n",
      "loss before training is 0.00877066956661366 -- epoch number 1300\n",
      "\n",
      "\n",
      "loss before training is 0.00875945581505901 -- epoch number 1301\n",
      "\n",
      "\n",
      "loss before training is 0.008748266412509574 -- epoch number 1302\n",
      "\n",
      "\n",
      "loss before training is 0.008737101278289791 -- epoch number 1303\n",
      "\n",
      "\n",
      "loss before training is 0.008725960332032993 -- epoch number 1304\n",
      "\n",
      "\n",
      "loss before training is 0.00871484349368019 -- epoch number 1305\n",
      "\n",
      "\n",
      "loss before training is 0.008703750683478822 -- epoch number 1306\n",
      "\n",
      "\n",
      "loss before training is 0.008692681821981452 -- epoch number 1307\n",
      "\n",
      "\n",
      "loss before training is 0.008681636830044625 -- epoch number 1308\n",
      "\n",
      "\n",
      "loss before training is 0.00867061562882755 -- epoch number 1309\n",
      "\n",
      "\n",
      "loss before training is 0.008659618139790938 -- epoch number 1310\n",
      "\n",
      "\n",
      "loss before training is 0.00864864428469572 -- epoch number 1311\n",
      "\n",
      "\n",
      "loss before training is 0.008637693985601873 -- epoch number 1312\n",
      "\n",
      "\n",
      "loss before training is 0.008626767164867197 -- epoch number 1313\n",
      "\n",
      "\n",
      "loss before training is 0.00861586374514606 -- epoch number 1314\n",
      "\n",
      "\n",
      "loss before training is 0.008604983649388307 -- epoch number 1315\n",
      "\n",
      "\n",
      "loss before training is 0.008594126800837907 -- epoch number 1316\n",
      "\n",
      "\n",
      "loss before training is 0.008583293123031917 -- epoch number 1317\n",
      "\n",
      "\n",
      "loss before training is 0.008572482539799166 -- epoch number 1318\n",
      "\n",
      "\n",
      "loss before training is 0.008561694975259139 -- epoch number 1319\n",
      "\n",
      "\n",
      "loss before training is 0.008550930353820811 -- epoch number 1320\n",
      "\n",
      "\n",
      "loss before training is 0.008540188600181377 -- epoch number 1321\n",
      "\n",
      "\n",
      "loss before training is 0.008529469639325224 -- epoch number 1322\n",
      "\n",
      "\n",
      "loss before training is 0.008518773396522654 -- epoch number 1323\n",
      "\n",
      "\n",
      "loss before training is 0.00850809979732874 -- epoch number 1324\n",
      "\n",
      "\n",
      "loss before training is 0.008497448767582245 -- epoch number 1325\n",
      "\n",
      "\n",
      "loss before training is 0.008486820233404389 -- epoch number 1326\n",
      "\n",
      "\n",
      "loss before training is 0.008476214121197733 -- epoch number 1327\n",
      "\n",
      "\n",
      "loss before training is 0.008465630357645056 -- epoch number 1328\n",
      "\n",
      "\n",
      "loss before training is 0.008455068869708149 -- epoch number 1329\n",
      "\n",
      "\n",
      "loss before training is 0.008444529584626818 -- epoch number 1330\n",
      "\n",
      "\n",
      "loss before training is 0.008434012429917596 -- epoch number 1331\n",
      "\n",
      "\n",
      "loss before training is 0.008423517333372751 -- epoch number 1332\n",
      "\n",
      "\n",
      "loss before training is 0.008413044223059092 -- epoch number 1333\n",
      "\n",
      "\n",
      "loss before training is 0.008402593027316899 -- epoch number 1334\n",
      "\n",
      "\n",
      "loss before training is 0.008392163674758736 -- epoch number 1335\n",
      "\n",
      "\n",
      "loss before training is 0.008381756094268483 -- epoch number 1336\n",
      "\n",
      "\n",
      "loss before training is 0.008371370215000121 -- epoch number 1337\n",
      "\n",
      "\n",
      "loss before training is 0.008361005966376673 -- epoch number 1338\n",
      "\n",
      "\n",
      "loss before training is 0.008350663278089098 -- epoch number 1339\n",
      "\n",
      "\n",
      "loss before training is 0.008340342080095283 -- epoch number 1340\n",
      "\n",
      "\n",
      "loss before training is 0.008330042302618842 -- epoch number 1341\n",
      "\n",
      "\n",
      "loss before training is 0.008319763876148108 -- epoch number 1342\n",
      "\n",
      "\n",
      "loss before training is 0.008309506731435075 -- epoch number 1343\n",
      "\n",
      "\n",
      "loss before training is 0.008299270799494263 -- epoch number 1344\n",
      "\n",
      "\n",
      "loss before training is 0.008289056011601742 -- epoch number 1345\n",
      "\n",
      "\n",
      "loss before training is 0.008278862299293975 -- epoch number 1346\n",
      "\n",
      "\n",
      "loss before training is 0.008268689594366859 -- epoch number 1347\n",
      "\n",
      "\n",
      "loss before training is 0.008258537828874622 -- epoch number 1348\n",
      "\n",
      "\n",
      "loss before training is 0.00824840693512876 -- epoch number 1349\n",
      "\n",
      "\n",
      "loss before training is 0.008238296845697015 -- epoch number 1350\n",
      "\n",
      "\n",
      "loss before training is 0.008228207493402365 -- epoch number 1351\n",
      "\n",
      "\n",
      "loss before training is 0.008218138811321966 -- epoch number 1352\n",
      "\n",
      "\n",
      "loss before training is 0.008208090732786099 -- epoch number 1353\n",
      "\n",
      "\n",
      "loss before training is 0.008198063191377194 -- epoch number 1354\n",
      "\n",
      "\n",
      "loss before training is 0.008188056120928773 -- epoch number 1355\n",
      "\n",
      "\n",
      "loss before training is 0.008178069455524415 -- epoch number 1356\n",
      "\n",
      "\n",
      "loss before training is 0.00816810312949684 -- epoch number 1357\n",
      "\n",
      "\n",
      "loss before training is 0.008158157077426786 -- epoch number 1358\n",
      "\n",
      "\n",
      "loss before training is 0.008148231234142066 -- epoch number 1359\n",
      "\n",
      "\n",
      "loss before training is 0.008138325534716542 -- epoch number 1360\n",
      "\n",
      "\n",
      "loss before training is 0.008128439914469168 -- epoch number 1361\n",
      "\n",
      "\n",
      "loss before training is 0.00811857430896296 -- epoch number 1362\n",
      "\n",
      "\n",
      "loss before training is 0.008108728654004005 -- epoch number 1363\n",
      "\n",
      "\n",
      "loss before training is 0.008098902885640538 -- epoch number 1364\n",
      "\n",
      "\n",
      "loss before training is 0.008089096940161886 -- epoch number 1365\n",
      "\n",
      "\n",
      "loss before training is 0.008079310754097553 -- epoch number 1366\n",
      "\n",
      "\n",
      "loss before training is 0.00806954426421618 -- epoch number 1367\n",
      "\n",
      "\n",
      "loss before training is 0.008059797407524643 -- epoch number 1368\n",
      "\n",
      "\n",
      "loss before training is 0.00805007012126711 -- epoch number 1369\n",
      "\n",
      "\n",
      "loss before training is 0.008040362342923987 -- epoch number 1370\n",
      "\n",
      "\n",
      "loss before training is 0.008030674010211033 -- epoch number 1371\n",
      "\n",
      "\n",
      "loss before training is 0.008021005061078397 -- epoch number 1372\n",
      "\n",
      "\n",
      "loss before training is 0.008011355433709656 -- epoch number 1373\n",
      "\n",
      "\n",
      "loss before training is 0.008001725066520877 -- epoch number 1374\n",
      "\n",
      "\n",
      "loss before training is 0.007992113898159733 -- epoch number 1375\n",
      "\n",
      "\n",
      "loss before training is 0.007982521867504441 -- epoch number 1376\n",
      "\n",
      "\n",
      "loss before training is 0.00797294891366299 -- epoch number 1377\n",
      "\n",
      "\n",
      "loss before training is 0.007963394975972052 -- epoch number 1378\n",
      "\n",
      "\n",
      "loss before training is 0.007953859993996207 -- epoch number 1379\n",
      "\n",
      "\n",
      "loss before training is 0.007944343907526899 -- epoch number 1380\n",
      "\n",
      "\n",
      "loss before training is 0.00793484665658162 -- epoch number 1381\n",
      "\n",
      "\n",
      "loss before training is 0.007925368181402931 -- epoch number 1382\n",
      "\n",
      "\n",
      "loss before training is 0.007915908422457582 -- epoch number 1383\n",
      "\n",
      "\n",
      "loss before training is 0.007906467320435597 -- epoch number 1384\n",
      "\n",
      "\n",
      "loss before training is 0.007897044816249374 -- epoch number 1385\n",
      "\n",
      "\n",
      "loss before training is 0.007887640851032817 -- epoch number 1386\n",
      "\n",
      "\n",
      "loss before training is 0.007878255366140412 -- epoch number 1387\n",
      "\n",
      "\n",
      "loss before training is 0.007868888303146304 -- epoch number 1388\n",
      "\n",
      "\n",
      "loss before training is 0.007859539603843519 -- epoch number 1389\n",
      "\n",
      "\n",
      "loss before training is 0.007850209210242954 -- epoch number 1390\n",
      "\n",
      "\n",
      "loss before training is 0.007840897064572604 -- epoch number 1391\n",
      "\n",
      "\n",
      "loss before training is 0.007831603109276618 -- epoch number 1392\n",
      "\n",
      "\n",
      "loss before training is 0.007822327287014475 -- epoch number 1393\n",
      "\n",
      "\n",
      "loss before training is 0.00781306954066005 -- epoch number 1394\n",
      "\n",
      "\n",
      "loss before training is 0.007803829813300871 -- epoch number 1395\n",
      "\n",
      "\n",
      "loss before training is 0.0077946080482371 -- epoch number 1396\n",
      "\n",
      "\n",
      "loss before training is 0.007785404188980815 -- epoch number 1397\n",
      "\n",
      "\n",
      "loss before training is 0.007776218179255094 -- epoch number 1398\n",
      "\n",
      "\n",
      "loss before training is 0.007767049962993166 -- epoch number 1399\n",
      "\n",
      "\n",
      "loss before training is 0.007757899484337581 -- epoch number 1400\n",
      "\n",
      "\n",
      "loss before training is 0.0077487666876393324 -- epoch number 1401\n",
      "\n",
      "\n",
      "loss before training is 0.007739651517457107 -- epoch number 1402\n",
      "\n",
      "\n",
      "loss before training is 0.00773055391855632 -- epoch number 1403\n",
      "\n",
      "\n",
      "loss before training is 0.007721473835908406 -- epoch number 1404\n",
      "\n",
      "\n",
      "loss before training is 0.007712411214689914 -- epoch number 1405\n",
      "\n",
      "\n",
      "loss before training is 0.0077033660002817144 -- epoch number 1406\n",
      "\n",
      "\n",
      "loss before training is 0.007694338138268184 -- epoch number 1407\n",
      "\n",
      "\n",
      "loss before training is 0.0076853275744363115 -- epoch number 1408\n",
      "\n",
      "\n",
      "loss before training is 0.0076763342547750335 -- epoch number 1409\n",
      "\n",
      "\n",
      "loss before training is 0.007667358125474286 -- epoch number 1410\n",
      "\n",
      "\n",
      "loss before training is 0.007658399132924278 -- epoch number 1411\n",
      "\n",
      "\n",
      "loss before training is 0.007649457223714608 -- epoch number 1412\n",
      "\n",
      "\n",
      "loss before training is 0.007640532344633566 -- epoch number 1413\n",
      "\n",
      "\n",
      "loss before training is 0.00763162444266726 -- epoch number 1414\n",
      "\n",
      "\n",
      "loss before training is 0.007622733464998846 -- epoch number 1415\n",
      "\n",
      "\n",
      "loss before training is 0.00761385935900774 -- epoch number 1416\n",
      "\n",
      "\n",
      "loss before training is 0.007605002072268812 -- epoch number 1417\n",
      "\n",
      "\n",
      "loss before training is 0.007596161552551645 -- epoch number 1418\n",
      "\n",
      "\n",
      "loss before training is 0.007587337747819712 -- epoch number 1419\n",
      "\n",
      "\n",
      "loss before training is 0.007578530606229616 -- epoch number 1420\n",
      "\n",
      "\n",
      "loss before training is 0.007569740076130303 -- epoch number 1421\n",
      "\n",
      "\n",
      "loss before training is 0.007560966106062313 -- epoch number 1422\n",
      "\n",
      "\n",
      "loss before training is 0.007552208644757006 -- epoch number 1423\n",
      "\n",
      "\n",
      "loss before training is 0.00754346764113579 -- epoch number 1424\n",
      "\n",
      "\n",
      "loss before training is 0.007534743044309353 -- epoch number 1425\n",
      "\n",
      "\n",
      "loss before training is 0.007526034803576923 -- epoch number 1426\n",
      "\n",
      "\n",
      "loss before training is 0.007517342868425499 -- epoch number 1427\n",
      "\n",
      "\n",
      "loss before training is 0.0075086671885291265 -- epoch number 1428\n",
      "\n",
      "\n",
      "loss before training is 0.0075000077137480775 -- epoch number 1429\n",
      "\n",
      "\n",
      "loss before training is 0.007491364394128238 -- epoch number 1430\n",
      "\n",
      "\n",
      "loss before training is 0.007482737179900204 -- epoch number 1431\n",
      "\n",
      "\n",
      "loss before training is 0.007474126021478662 -- epoch number 1432\n",
      "\n",
      "\n",
      "loss before training is 0.007465530869461607 -- epoch number 1433\n",
      "\n",
      "\n",
      "loss before training is 0.007456951674629624 -- epoch number 1434\n",
      "\n",
      "\n",
      "loss before training is 0.007448388387945136 -- epoch number 1435\n",
      "\n",
      "\n",
      "loss before training is 0.007439840960551708 -- epoch number 1436\n",
      "\n",
      "\n",
      "loss before training is 0.007431309343773285 -- epoch number 1437\n",
      "\n",
      "\n",
      "loss before training is 0.00742279348911353 -- epoch number 1438\n",
      "\n",
      "\n",
      "loss before training is 0.007414293348255013 -- epoch number 1439\n",
      "\n",
      "\n",
      "loss before training is 0.007405808873058627 -- epoch number 1440\n",
      "\n",
      "\n",
      "loss before training is 0.007397340015562755 -- epoch number 1441\n",
      "\n",
      "\n",
      "loss before training is 0.007388886727982616 -- epoch number 1442\n",
      "\n",
      "\n",
      "loss before training is 0.0073804489627095635 -- epoch number 1443\n",
      "\n",
      "\n",
      "loss before training is 0.007372026672310385 -- epoch number 1444\n",
      "\n",
      "\n",
      "loss before training is 0.007363619809526552 -- epoch number 1445\n",
      "\n",
      "\n",
      "loss before training is 0.007355228327273606 -- epoch number 1446\n",
      "\n",
      "\n",
      "loss before training is 0.007346852178640407 -- epoch number 1447\n",
      "\n",
      "\n",
      "loss before training is 0.007338491316888431 -- epoch number 1448\n",
      "\n",
      "\n",
      "loss before training is 0.007330145695451159 -- epoch number 1449\n",
      "\n",
      "\n",
      "loss before training is 0.007321815267933291 -- epoch number 1450\n",
      "\n",
      "\n",
      "loss before training is 0.007313499988110154 -- epoch number 1451\n",
      "\n",
      "\n",
      "loss before training is 0.007305199809926952 -- epoch number 1452\n",
      "\n",
      "\n",
      "loss before training is 0.007296914687498134 -- epoch number 1453\n",
      "\n",
      "\n",
      "loss before training is 0.007288644575106742 -- epoch number 1454\n",
      "\n",
      "\n",
      "loss before training is 0.007280389427203641 -- epoch number 1455\n",
      "\n",
      "\n",
      "loss before training is 0.007272149198406956 -- epoch number 1456\n",
      "\n",
      "\n",
      "loss before training is 0.007263923843501354 -- epoch number 1457\n",
      "\n",
      "\n",
      "loss before training is 0.007255713317437443 -- epoch number 1458\n",
      "\n",
      "\n",
      "loss before training is 0.007247517575330972 -- epoch number 1459\n",
      "\n",
      "\n",
      "loss before training is 0.0072393365724623595 -- epoch number 1460\n",
      "\n",
      "\n",
      "loss before training is 0.007231170264275884 -- epoch number 1461\n",
      "\n",
      "\n",
      "loss before training is 0.007223018606379138 -- epoch number 1462\n",
      "\n",
      "\n",
      "loss before training is 0.007214881554542315 -- epoch number 1463\n",
      "\n",
      "\n",
      "loss before training is 0.007206759064697604 -- epoch number 1464\n",
      "\n",
      "\n",
      "loss before training is 0.007198651092938505 -- epoch number 1465\n",
      "\n",
      "\n",
      "loss before training is 0.0071905575955192496 -- epoch number 1466\n",
      "\n",
      "\n",
      "loss before training is 0.00718247852885409 -- epoch number 1467\n",
      "\n",
      "\n",
      "loss before training is 0.007174413849516725 -- epoch number 1468\n",
      "\n",
      "\n",
      "loss before training is 0.007166363514239658 -- epoch number 1469\n",
      "\n",
      "\n",
      "loss before training is 0.007158327479913518 -- epoch number 1470\n",
      "\n",
      "\n",
      "loss before training is 0.007150305703586504 -- epoch number 1471\n",
      "\n",
      "\n",
      "loss before training is 0.007142298142463701 -- epoch number 1472\n",
      "\n",
      "\n",
      "loss before training is 0.007134304753906498 -- epoch number 1473\n",
      "\n",
      "\n",
      "loss before training is 0.0071263254954319535 -- epoch number 1474\n",
      "\n",
      "\n",
      "loss before training is 0.00711836032471218 -- epoch number 1475\n",
      "\n",
      "\n",
      "loss before training is 0.007110409199573731 -- epoch number 1476\n",
      "\n",
      "\n",
      "loss before training is 0.0071024720779970085 -- epoch number 1477\n",
      "\n",
      "\n",
      "loss before training is 0.007094548918115592 -- epoch number 1478\n",
      "\n",
      "\n",
      "loss before training is 0.0070866396782157046 -- epoch number 1479\n",
      "\n",
      "\n",
      "loss before training is 0.007078744316735602 -- epoch number 1480\n",
      "\n",
      "\n",
      "loss before training is 0.007070862792264923 -- epoch number 1481\n",
      "\n",
      "\n",
      "loss before training is 0.007062995063544116 -- epoch number 1482\n",
      "\n",
      "\n",
      "loss before training is 0.007055141089463873 -- epoch number 1483\n",
      "\n",
      "\n",
      "loss before training is 0.00704730082906449 -- epoch number 1484\n",
      "\n",
      "\n",
      "loss before training is 0.007039474241535296 -- epoch number 1485\n",
      "\n",
      "\n",
      "loss before training is 0.007031661286214082 -- epoch number 1486\n",
      "\n",
      "\n",
      "loss before training is 0.007023861922586472 -- epoch number 1487\n",
      "\n",
      "\n",
      "loss before training is 0.0070160761102853976 -- epoch number 1488\n",
      "\n",
      "\n",
      "loss before training is 0.0070083038090904826 -- epoch number 1489\n",
      "\n",
      "\n",
      "loss before training is 0.0070005449789274175 -- epoch number 1490\n",
      "\n",
      "\n",
      "loss before training is 0.006992799579867511 -- epoch number 1491\n",
      "\n",
      "\n",
      "loss before training is 0.006985067572126975 -- epoch number 1492\n",
      "\n",
      "\n",
      "loss before training is 0.006977348916066458 -- epoch number 1493\n",
      "\n",
      "\n",
      "loss before training is 0.006969643572190412 -- epoch number 1494\n",
      "\n",
      "\n",
      "loss before training is 0.006961951501146545 -- epoch number 1495\n",
      "\n",
      "\n",
      "loss before training is 0.0069542726637253005 -- epoch number 1496\n",
      "\n",
      "\n",
      "loss before training is 0.006946607020859214 -- epoch number 1497\n",
      "\n",
      "\n",
      "loss before training is 0.006938954533622434 -- epoch number 1498\n",
      "\n",
      "\n",
      "loss before training is 0.006931315163230085 -- epoch number 1499\n",
      "\n",
      "\n",
      "loss before training is 0.006923688871037796 -- epoch number 1500\n",
      "\n",
      "\n",
      "loss before training is 0.006916075618541093 -- epoch number 1501\n",
      "\n",
      "\n",
      "loss before training is 0.006908475367374875 -- epoch number 1502\n",
      "\n",
      "\n",
      "loss before training is 0.006900888079312823 -- epoch number 1503\n",
      "\n",
      "\n",
      "loss before training is 0.006893313716266928 -- epoch number 1504\n",
      "\n",
      "\n",
      "loss before training is 0.006885752240286883 -- epoch number 1505\n",
      "\n",
      "\n",
      "loss before training is 0.006878203613559576 -- epoch number 1506\n",
      "\n",
      "\n",
      "loss before training is 0.006870667798408545 -- epoch number 1507\n",
      "\n",
      "\n",
      "loss before training is 0.006863144757293436 -- epoch number 1508\n",
      "\n",
      "\n",
      "loss before training is 0.006855634452809473 -- epoch number 1509\n",
      "\n",
      "\n",
      "loss before training is 0.006848136847686918 -- epoch number 1510\n",
      "\n",
      "\n",
      "loss before training is 0.00684065190479056 -- epoch number 1511\n",
      "\n",
      "\n",
      "loss before training is 0.006833179587119179 -- epoch number 1512\n",
      "\n",
      "\n",
      "loss before training is 0.006825719857805024 -- epoch number 1513\n",
      "\n",
      "\n",
      "loss before training is 0.006818272680113266 -- epoch number 1514\n",
      "\n",
      "\n",
      "loss before training is 0.006810838017441509 -- epoch number 1515\n",
      "\n",
      "\n",
      "loss before training is 0.006803415833319242 -- epoch number 1516\n",
      "\n",
      "\n",
      "loss before training is 0.006796006091407385 -- epoch number 1517\n",
      "\n",
      "\n",
      "loss before training is 0.006788608755497694 -- epoch number 1518\n",
      "\n",
      "\n",
      "loss before training is 0.006781223789512273 -- epoch number 1519\n",
      "\n",
      "\n",
      "loss before training is 0.006773851157503117 -- epoch number 1520\n",
      "\n",
      "\n",
      "loss before training is 0.006766490823651548 -- epoch number 1521\n",
      "\n",
      "\n",
      "loss before training is 0.006759142752267681 -- epoch number 1522\n",
      "\n",
      "\n",
      "loss before training is 0.006751806907790049 -- epoch number 1523\n",
      "\n",
      "\n",
      "loss before training is 0.0067444832547849725 -- epoch number 1524\n",
      "\n",
      "\n",
      "loss before training is 0.006737171757946081 -- epoch number 1525\n",
      "\n",
      "\n",
      "loss before training is 0.006729872382093893 -- epoch number 1526\n",
      "\n",
      "\n",
      "loss before training is 0.006722585092175221 -- epoch number 1527\n",
      "\n",
      "\n",
      "loss before training is 0.006715309853262777 -- epoch number 1528\n",
      "\n",
      "\n",
      "loss before training is 0.006708046630554574 -- epoch number 1529\n",
      "\n",
      "\n",
      "loss before training is 0.006700795389373536 -- epoch number 1530\n",
      "\n",
      "\n",
      "loss before training is 0.006693556095166949 -- epoch number 1531\n",
      "\n",
      "\n",
      "loss before training is 0.006686328713506011 -- epoch number 1532\n",
      "\n",
      "\n",
      "loss before training is 0.006679113210085319 -- epoch number 1533\n",
      "\n",
      "\n",
      "loss before training is 0.0066719095507224374 -- epoch number 1534\n",
      "\n",
      "\n",
      "loss before training is 0.0066647177013573426 -- epoch number 1535\n",
      "\n",
      "\n",
      "loss before training is 0.006657537628052022 -- epoch number 1536\n",
      "\n",
      "\n",
      "loss before training is 0.006650369296989942 -- epoch number 1537\n",
      "\n",
      "\n",
      "loss before training is 0.006643212674475627 -- epoch number 1538\n",
      "\n",
      "\n",
      "loss before training is 0.006636067726934155 -- epoch number 1539\n",
      "\n",
      "\n",
      "loss before training is 0.0066289344209106826 -- epoch number 1540\n",
      "\n",
      "\n",
      "loss before training is 0.006621812723070022 -- epoch number 1541\n",
      "\n",
      "\n",
      "loss before training is 0.006614702600196112 -- epoch number 1542\n",
      "\n",
      "\n",
      "loss before training is 0.006607604019191615 -- epoch number 1543\n",
      "\n",
      "\n",
      "loss before training is 0.006600516947077421 -- epoch number 1544\n",
      "\n",
      "\n",
      "loss before training is 0.006593441350992194 -- epoch number 1545\n",
      "\n",
      "\n",
      "loss before training is 0.006586377198191941 -- epoch number 1546\n",
      "\n",
      "\n",
      "loss before training is 0.006579324456049512 -- epoch number 1547\n",
      "\n",
      "\n",
      "loss before training is 0.0065722830920541715 -- epoch number 1548\n",
      "\n",
      "\n",
      "loss before training is 0.006565253073811158 -- epoch number 1549\n",
      "\n",
      "\n",
      "loss before training is 0.00655823436904122 -- epoch number 1550\n",
      "\n",
      "\n",
      "loss before training is 0.006551226945580177 -- epoch number 1551\n",
      "\n",
      "\n",
      "loss before training is 0.006544230771378461 -- epoch number 1552\n",
      "\n",
      "\n",
      "loss before training is 0.0065372458145006584 -- epoch number 1553\n",
      "\n",
      "\n",
      "loss before training is 0.006530272043125123 -- epoch number 1554\n",
      "\n",
      "\n",
      "loss before training is 0.006523309425543494 -- epoch number 1555\n",
      "\n",
      "\n",
      "loss before training is 0.006516357930160249 -- epoch number 1556\n",
      "\n",
      "\n",
      "loss before training is 0.006509417525492303 -- epoch number 1557\n",
      "\n",
      "\n",
      "loss before training is 0.006502488180168529 -- epoch number 1558\n",
      "\n",
      "\n",
      "loss before training is 0.006495569862929395 -- epoch number 1559\n",
      "\n",
      "\n",
      "loss before training is 0.006488662542626462 -- epoch number 1560\n",
      "\n",
      "\n",
      "loss before training is 0.00648176618822197 -- epoch number 1561\n",
      "\n",
      "\n",
      "loss before training is 0.0064748807687884345 -- epoch number 1562\n",
      "\n",
      "\n",
      "loss before training is 0.0064680062535082215 -- epoch number 1563\n",
      "\n",
      "\n",
      "loss before training is 0.0064611426116731015 -- epoch number 1564\n",
      "\n",
      "\n",
      "loss before training is 0.0064542898126838215 -- epoch number 1565\n",
      "\n",
      "\n",
      "loss before training is 0.006447447826049714 -- epoch number 1566\n",
      "\n",
      "\n",
      "loss before training is 0.006440616621388286 -- epoch number 1567\n",
      "\n",
      "\n",
      "loss before training is 0.0064337961684247415 -- epoch number 1568\n",
      "\n",
      "\n",
      "loss before training is 0.006426986436991624 -- epoch number 1569\n",
      "\n",
      "\n",
      "loss before training is 0.00642018739702839 -- epoch number 1570\n",
      "\n",
      "\n",
      "loss before training is 0.0064133990185809685 -- epoch number 1571\n",
      "\n",
      "\n",
      "loss before training is 0.006406621271801409 -- epoch number 1572\n",
      "\n",
      "\n",
      "loss before training is 0.006399854126947406 -- epoch number 1573\n",
      "\n",
      "\n",
      "loss before training is 0.006393097554381963 -- epoch number 1574\n",
      "\n",
      "\n",
      "loss before training is 0.006386351524572889 -- epoch number 1575\n",
      "\n",
      "\n",
      "loss before training is 0.006379616008092525 -- epoch number 1576\n",
      "\n",
      "\n",
      "loss before training is 0.006372890975617227 -- epoch number 1577\n",
      "\n",
      "\n",
      "loss before training is 0.006366176397927028 -- epoch number 1578\n",
      "\n",
      "\n",
      "loss before training is 0.006359472245905235 -- epoch number 1579\n",
      "\n",
      "\n",
      "loss before training is 0.006352778490537987 -- epoch number 1580\n",
      "\n",
      "\n",
      "loss before training is 0.0063460951029139494 -- epoch number 1581\n",
      "\n",
      "\n",
      "loss before training is 0.006339422054223816 -- epoch number 1582\n",
      "\n",
      "\n",
      "loss before training is 0.006332759315759986 -- epoch number 1583\n",
      "\n",
      "\n",
      "loss before training is 0.006326106858916158 -- epoch number 1584\n",
      "\n",
      "\n",
      "loss before training is 0.006319464655186951 -- epoch number 1585\n",
      "\n",
      "\n",
      "loss before training is 0.0063128326761674874 -- epoch number 1586\n",
      "\n",
      "\n",
      "loss before training is 0.0063062108935530315 -- epoch number 1587\n",
      "\n",
      "\n",
      "loss before training is 0.006299599279138597 -- epoch number 1588\n",
      "\n",
      "\n",
      "loss before training is 0.006292997804818588 -- epoch number 1589\n",
      "\n",
      "\n",
      "loss before training is 0.006286406442586379 -- epoch number 1590\n",
      "\n",
      "\n",
      "loss before training is 0.006279825164533959 -- epoch number 1591\n",
      "\n",
      "\n",
      "loss before training is 0.0062732539428515715 -- epoch number 1592\n",
      "\n",
      "\n",
      "loss before training is 0.006266692749827299 -- epoch number 1593\n",
      "\n",
      "\n",
      "loss before training is 0.00626014155784671 -- epoch number 1594\n",
      "\n",
      "\n",
      "loss before training is 0.006253600339392505 -- epoch number 1595\n",
      "\n",
      "\n",
      "loss before training is 0.00624706906704409 -- epoch number 1596\n",
      "\n",
      "\n",
      "loss before training is 0.006240547713477278 -- epoch number 1597\n",
      "\n",
      "\n",
      "loss before training is 0.006234036251463893 -- epoch number 1598\n",
      "\n",
      "\n",
      "loss before training is 0.006227534653871358 -- epoch number 1599\n",
      "\n",
      "\n",
      "loss before training is 0.006221042893662386 -- epoch number 1600\n",
      "\n",
      "\n",
      "loss before training is 0.0062145609438946 -- epoch number 1601\n",
      "\n",
      "\n",
      "loss before training is 0.006208088777720197 -- epoch number 1602\n",
      "\n",
      "\n",
      "loss before training is 0.006201626368385515 -- epoch number 1603\n",
      "\n",
      "\n",
      "loss before training is 0.00619517368923075 -- epoch number 1604\n",
      "\n",
      "\n",
      "loss before training is 0.0061887307136895605 -- epoch number 1605\n",
      "\n",
      "\n",
      "loss before training is 0.006182297415288722 -- epoch number 1606\n",
      "\n",
      "\n",
      "loss before training is 0.006175873767647774 -- epoch number 1607\n",
      "\n",
      "\n",
      "loss before training is 0.006169459744478656 -- epoch number 1608\n",
      "\n",
      "\n",
      "loss before training is 0.006163055319585362 -- epoch number 1609\n",
      "\n",
      "\n",
      "loss before training is 0.006156660466863595 -- epoch number 1610\n",
      "\n",
      "\n",
      "loss before training is 0.006150275160300435 -- epoch number 1611\n",
      "\n",
      "\n",
      "loss before training is 0.006143899373973925 -- epoch number 1612\n",
      "\n",
      "\n",
      "loss before training is 0.006137533082052806 -- epoch number 1613\n",
      "\n",
      "\n",
      "loss before training is 0.006131176258796157 -- epoch number 1614\n",
      "\n",
      "\n",
      "loss before training is 0.006124828878552976 -- epoch number 1615\n",
      "\n",
      "\n",
      "loss before training is 0.006118490915761955 -- epoch number 1616\n",
      "\n",
      "\n",
      "loss before training is 0.006112162344951025 -- epoch number 1617\n",
      "\n",
      "\n",
      "loss before training is 0.006105843140737135 -- epoch number 1618\n",
      "\n",
      "\n",
      "loss before training is 0.006099533277825812 -- epoch number 1619\n",
      "\n",
      "\n",
      "loss before training is 0.00609323273101086 -- epoch number 1620\n",
      "\n",
      "\n",
      "loss before training is 0.006086941475174051 -- epoch number 1621\n",
      "\n",
      "\n",
      "loss before training is 0.006080659485284786 -- epoch number 1622\n",
      "\n",
      "\n",
      "loss before training is 0.006074386736399722 -- epoch number 1623\n",
      "\n",
      "\n",
      "loss before training is 0.006068123203662469 -- epoch number 1624\n",
      "\n",
      "\n",
      "loss before training is 0.006061868862303252 -- epoch number 1625\n",
      "\n",
      "\n",
      "loss before training is 0.0060556236876386504 -- epoch number 1626\n",
      "\n",
      "\n",
      "loss before training is 0.006049387655071146 -- epoch number 1627\n",
      "\n",
      "\n",
      "loss before training is 0.006043160740088892 -- epoch number 1628\n",
      "\n",
      "\n",
      "loss before training is 0.006036942918265364 -- epoch number 1629\n",
      "\n",
      "\n",
      "loss before training is 0.006030734165259048 -- epoch number 1630\n",
      "\n",
      "\n",
      "loss before training is 0.006024534456813056 -- epoch number 1631\n",
      "\n",
      "\n",
      "loss before training is 0.00601834376875492 -- epoch number 1632\n",
      "\n",
      "\n",
      "loss before training is 0.00601216207699619 -- epoch number 1633\n",
      "\n",
      "\n",
      "loss before training is 0.006005989357532114 -- epoch number 1634\n",
      "\n",
      "\n",
      "loss before training is 0.00599982558644137 -- epoch number 1635\n",
      "\n",
      "\n",
      "loss before training is 0.0059936707398857356 -- epoch number 1636\n",
      "\n",
      "\n",
      "loss before training is 0.005987524794109723 -- epoch number 1637\n",
      "\n",
      "\n",
      "loss before training is 0.005981387725440371 -- epoch number 1638\n",
      "\n",
      "\n",
      "loss before training is 0.005975259510286827 -- epoch number 1639\n",
      "\n",
      "\n",
      "loss before training is 0.005969140125140104 -- epoch number 1640\n",
      "\n",
      "\n",
      "loss before training is 0.005963029546572754 -- epoch number 1641\n",
      "\n",
      "\n",
      "loss before training is 0.0059569277512385495 -- epoch number 1642\n",
      "\n",
      "\n",
      "loss before training is 0.005950834715872197 -- epoch number 1643\n",
      "\n",
      "\n",
      "loss before training is 0.005944750417289028 -- epoch number 1644\n",
      "\n",
      "\n",
      "loss before training is 0.005938674832384659 -- epoch number 1645\n",
      "\n",
      "\n",
      "loss before training is 0.005932607938134783 -- epoch number 1646\n",
      "\n",
      "\n",
      "loss before training is 0.005926549711594755 -- epoch number 1647\n",
      "\n",
      "\n",
      "loss before training is 0.005920500129899359 -- epoch number 1648\n",
      "\n",
      "\n",
      "loss before training is 0.005914459170262511 -- epoch number 1649\n",
      "\n",
      "\n",
      "loss before training is 0.005908426809976933 -- epoch number 1650\n",
      "\n",
      "\n",
      "loss before training is 0.005902403026413898 -- epoch number 1651\n",
      "\n",
      "\n",
      "loss before training is 0.00589638779702286 -- epoch number 1652\n",
      "\n",
      "\n",
      "loss before training is 0.005890381099331234 -- epoch number 1653\n",
      "\n",
      "\n",
      "loss before training is 0.005884382910944106 -- epoch number 1654\n",
      "\n",
      "\n",
      "loss before training is 0.005878393209543875 -- epoch number 1655\n",
      "\n",
      "\n",
      "loss before training is 0.005872411972890037 -- epoch number 1656\n",
      "\n",
      "\n",
      "loss before training is 0.005866439178818821 -- epoch number 1657\n",
      "\n",
      "\n",
      "loss before training is 0.005860474805242993 -- epoch number 1658\n",
      "\n",
      "\n",
      "loss before training is 0.0058545188301515 -- epoch number 1659\n",
      "\n",
      "\n",
      "loss before training is 0.005848571231609163 -- epoch number 1660\n",
      "\n",
      "\n",
      "loss before training is 0.005842631987756515 -- epoch number 1661\n",
      "\n",
      "\n",
      "loss before training is 0.005836701076809379 -- epoch number 1662\n",
      "\n",
      "\n",
      "loss before training is 0.005830778477058648 -- epoch number 1663\n",
      "\n",
      "\n",
      "loss before training is 0.005824864166870052 -- epoch number 1664\n",
      "\n",
      "\n",
      "loss before training is 0.005818958124683766 -- epoch number 1665\n",
      "\n",
      "\n",
      "loss before training is 0.005813060329014223 -- epoch number 1666\n",
      "\n",
      "\n",
      "loss before training is 0.005807170758449824 -- epoch number 1667\n",
      "\n",
      "\n",
      "loss before training is 0.005801289391652611 -- epoch number 1668\n",
      "\n",
      "\n",
      "loss before training is 0.005795416207358066 -- epoch number 1669\n",
      "\n",
      "\n",
      "loss before training is 0.00578955118437475 -- epoch number 1670\n",
      "\n",
      "\n",
      "loss before training is 0.00578369430158413 -- epoch number 1671\n",
      "\n",
      "\n",
      "loss before training is 0.005777845537940237 -- epoch number 1672\n",
      "\n",
      "\n",
      "loss before training is 0.005772004872469401 -- epoch number 1673\n",
      "\n",
      "\n",
      "loss before training is 0.005766172284269991 -- epoch number 1674\n",
      "\n",
      "\n",
      "loss before training is 0.0057603477525122095 -- epoch number 1675\n",
      "\n",
      "\n",
      "loss before training is 0.005754531256437688 -- epoch number 1676\n",
      "\n",
      "\n",
      "loss before training is 0.005748722775359344 -- epoch number 1677\n",
      "\n",
      "\n",
      "loss before training is 0.0057429222886610665 -- epoch number 1678\n",
      "\n",
      "\n",
      "loss before training is 0.0057371297757974745 -- epoch number 1679\n",
      "\n",
      "\n",
      "loss before training is 0.005731345216293579 -- epoch number 1680\n",
      "\n",
      "\n",
      "loss before training is 0.005725568589744665 -- epoch number 1681\n",
      "\n",
      "\n",
      "loss before training is 0.005719799875815863 -- epoch number 1682\n",
      "\n",
      "\n",
      "loss before training is 0.0057140390542420386 -- epoch number 1683\n",
      "\n",
      "\n",
      "loss before training is 0.0057082861048274 -- epoch number 1684\n",
      "\n",
      "\n",
      "loss before training is 0.005702541007445385 -- epoch number 1685\n",
      "\n",
      "\n",
      "loss before training is 0.005696803742038253 -- epoch number 1686\n",
      "\n",
      "\n",
      "loss before training is 0.005691074288616948 -- epoch number 1687\n",
      "\n",
      "\n",
      "loss before training is 0.005685352627260788 -- epoch number 1688\n",
      "\n",
      "\n",
      "loss before training is 0.005679638738117212 -- epoch number 1689\n",
      "\n",
      "\n",
      "loss before training is 0.005673932601401569 -- epoch number 1690\n",
      "\n",
      "\n",
      "loss before training is 0.0056682341973967945 -- epoch number 1691\n",
      "\n",
      "\n",
      "loss before training is 0.0056625435064532196 -- epoch number 1692\n",
      "\n",
      "\n",
      "loss before training is 0.005656860508988323 -- epoch number 1693\n",
      "\n",
      "\n",
      "loss before training is 0.005651185185486438 -- epoch number 1694\n",
      "\n",
      "\n",
      "loss before training is 0.005645517516498524 -- epoch number 1695\n",
      "\n",
      "\n",
      "loss before training is 0.0056398574826419575 -- epoch number 1696\n",
      "\n",
      "\n",
      "loss before training is 0.005634205064600234 -- epoch number 1697\n",
      "\n",
      "\n",
      "loss before training is 0.005628560243122735 -- epoch number 1698\n",
      "\n",
      "\n",
      "loss before training is 0.005622922999024522 -- epoch number 1699\n",
      "\n",
      "\n",
      "loss before training is 0.005617293313186055 -- epoch number 1700\n",
      "\n",
      "\n",
      "loss before training is 0.005611671166552961 -- epoch number 1701\n",
      "\n",
      "\n",
      "loss before training is 0.005606056540135784 -- epoch number 1702\n",
      "\n",
      "\n",
      "loss before training is 0.005600449415009762 -- epoch number 1703\n",
      "\n",
      "\n",
      "loss before training is 0.00559484977231461 -- epoch number 1704\n",
      "\n",
      "\n",
      "loss before training is 0.005589257593254218 -- epoch number 1705\n",
      "\n",
      "\n",
      "loss before training is 0.005583672859096471 -- epoch number 1706\n",
      "\n",
      "\n",
      "loss before training is 0.005578095551172996 -- epoch number 1707\n",
      "\n",
      "\n",
      "loss before training is 0.005572525650878895 -- epoch number 1708\n",
      "\n",
      "\n",
      "loss before training is 0.005566963139672602 -- epoch number 1709\n",
      "\n",
      "\n",
      "loss before training is 0.0055614079990755245 -- epoch number 1710\n",
      "\n",
      "\n",
      "loss before training is 0.005555860210671906 -- epoch number 1711\n",
      "\n",
      "\n",
      "loss before training is 0.005550319756108576 -- epoch number 1712\n",
      "\n",
      "\n",
      "loss before training is 0.005544786617094682 -- epoch number 1713\n",
      "\n",
      "\n",
      "loss before training is 0.005539260775401523 -- epoch number 1714\n",
      "\n",
      "\n",
      "loss before training is 0.005533742212862238 -- epoch number 1715\n",
      "\n",
      "\n",
      "loss before training is 0.005528230911371675 -- epoch number 1716\n",
      "\n",
      "\n",
      "loss before training is 0.005522726852886086 -- epoch number 1717\n",
      "\n",
      "\n",
      "loss before training is 0.005517230019422933 -- epoch number 1718\n",
      "\n",
      "\n",
      "loss before training is 0.005511740393060668 -- epoch number 1719\n",
      "\n",
      "\n",
      "loss before training is 0.005506257955938521 -- epoch number 1720\n",
      "\n",
      "\n",
      "loss before training is 0.005500782690256211 -- epoch number 1721\n",
      "\n",
      "\n",
      "loss before training is 0.005495314578273834 -- epoch number 1722\n",
      "\n",
      "\n",
      "loss before training is 0.0054898536023115195 -- epoch number 1723\n",
      "\n",
      "\n",
      "loss before training is 0.005484399744749305 -- epoch number 1724\n",
      "\n",
      "\n",
      "loss before training is 0.005478952988026873 -- epoch number 1725\n",
      "\n",
      "\n",
      "loss before training is 0.005473513314643366 -- epoch number 1726\n",
      "\n",
      "\n",
      "loss before training is 0.0054680807071571 -- epoch number 1727\n",
      "\n",
      "\n",
      "loss before training is 0.005462655148185422 -- epoch number 1728\n",
      "\n",
      "\n",
      "loss before training is 0.0054572366204044594 -- epoch number 1729\n",
      "\n",
      "\n",
      "loss before training is 0.005451825106548906 -- epoch number 1730\n",
      "\n",
      "\n",
      "loss before training is 0.005446420589411821 -- epoch number 1731\n",
      "\n",
      "\n",
      "loss before training is 0.005441023051844407 -- epoch number 1732\n",
      "\n",
      "\n",
      "loss before training is 0.005435632476755766 -- epoch number 1733\n",
      "\n",
      "\n",
      "loss before training is 0.005430248847112773 -- epoch number 1734\n",
      "\n",
      "\n",
      "loss before training is 0.0054248721459397705 -- epoch number 1735\n",
      "\n",
      "\n",
      "loss before training is 0.005419502356318399 -- epoch number 1736\n",
      "\n",
      "\n",
      "loss before training is 0.005414139461387433 -- epoch number 1737\n",
      "\n",
      "\n",
      "loss before training is 0.0054087834443424685 -- epoch number 1738\n",
      "\n",
      "\n",
      "loss before training is 0.0054034342884358095 -- epoch number 1739\n",
      "\n",
      "\n",
      "loss before training is 0.005398091976976229 -- epoch number 1740\n",
      "\n",
      "\n",
      "loss before training is 0.005392756493328731 -- epoch number 1741\n",
      "\n",
      "\n",
      "loss before training is 0.005387427820914437 -- epoch number 1742\n",
      "\n",
      "\n",
      "loss before training is 0.005382105943210236 -- epoch number 1743\n",
      "\n",
      "\n",
      "loss before training is 0.005376790843748758 -- epoch number 1744\n",
      "\n",
      "\n",
      "loss before training is 0.005371482506117983 -- epoch number 1745\n",
      "\n",
      "\n",
      "loss before training is 0.0053661809139612104 -- epoch number 1746\n",
      "\n",
      "\n",
      "loss before training is 0.005360886050976753 -- epoch number 1747\n",
      "\n",
      "\n",
      "loss before training is 0.005355597900917768 -- epoch number 1748\n",
      "\n",
      "\n",
      "loss before training is 0.005350316447592067 -- epoch number 1749\n",
      "\n",
      "\n",
      "loss before training is 0.00534504167486189 -- epoch number 1750\n",
      "\n",
      "\n",
      "loss before training is 0.005339773566643736 -- epoch number 1751\n",
      "\n",
      "\n",
      "loss before training is 0.005334512106908155 -- epoch number 1752\n",
      "\n",
      "\n",
      "loss before training is 0.00532925727967955 -- epoch number 1753\n",
      "\n",
      "\n",
      "loss before training is 0.005324009069035971 -- epoch number 1754\n",
      "\n",
      "\n",
      "loss before training is 0.005318767459108951 -- epoch number 1755\n",
      "\n",
      "\n",
      "loss before training is 0.005313532434083277 -- epoch number 1756\n",
      "\n",
      "\n",
      "loss before training is 0.005308303978196823 -- epoch number 1757\n",
      "\n",
      "\n",
      "loss before training is 0.005303082075740357 -- epoch number 1758\n",
      "\n",
      "\n",
      "loss before training is 0.005297866711057305 -- epoch number 1759\n",
      "\n",
      "\n",
      "loss before training is 0.005292657868543641 -- epoch number 1760\n",
      "\n",
      "\n",
      "loss before training is 0.005287455532647615 -- epoch number 1761\n",
      "\n",
      "\n",
      "loss before training is 0.0052822596878696025 -- epoch number 1762\n",
      "\n",
      "\n",
      "loss before training is 0.005277070318761947 -- epoch number 1763\n",
      "\n",
      "\n",
      "loss before training is 0.0052718874099287015 -- epoch number 1764\n",
      "\n",
      "\n",
      "loss before training is 0.005266710946025474 -- epoch number 1765\n",
      "\n",
      "\n",
      "loss before training is 0.005261540911759283 -- epoch number 1766\n",
      "\n",
      "\n",
      "loss before training is 0.005256377291888303 -- epoch number 1767\n",
      "\n",
      "\n",
      "loss before training is 0.005251220071221728 -- epoch number 1768\n",
      "\n",
      "\n",
      "loss before training is 0.005246069234619537 -- epoch number 1769\n",
      "\n",
      "\n",
      "loss before training is 0.005240924766992386 -- epoch number 1770\n",
      "\n",
      "\n",
      "loss before training is 0.005235786653301355 -- epoch number 1771\n",
      "\n",
      "\n",
      "loss before training is 0.005230654878557807 -- epoch number 1772\n",
      "\n",
      "\n",
      "loss before training is 0.005225529427823165 -- epoch number 1773\n",
      "\n",
      "\n",
      "loss before training is 0.005220410286208812 -- epoch number 1774\n",
      "\n",
      "\n",
      "loss before training is 0.005215297438875782 -- epoch number 1775\n",
      "\n",
      "\n",
      "loss before training is 0.005210190871034746 -- epoch number 1776\n",
      "\n",
      "\n",
      "loss before training is 0.005205090567945671 -- epoch number 1777\n",
      "\n",
      "\n",
      "loss before training is 0.005199996514917746 -- epoch number 1778\n",
      "\n",
      "\n",
      "loss before training is 0.005194908697309179 -- epoch number 1779\n",
      "\n",
      "\n",
      "loss before training is 0.005189827100527014 -- epoch number 1780\n",
      "\n",
      "\n",
      "loss before training is 0.005184751710026932 -- epoch number 1781\n",
      "\n",
      "\n",
      "loss before training is 0.0051796825113131365 -- epoch number 1782\n",
      "\n",
      "\n",
      "loss before training is 0.005174619489938107 -- epoch number 1783\n",
      "\n",
      "\n",
      "loss before training is 0.005169562631502499 -- epoch number 1784\n",
      "\n",
      "\n",
      "loss before training is 0.005164511921654916 -- epoch number 1785\n",
      "\n",
      "\n",
      "loss before training is 0.005159467346091752 -- epoch number 1786\n",
      "\n",
      "\n",
      "loss before training is 0.005154428890557019 -- epoch number 1787\n",
      "\n",
      "\n",
      "loss before training is 0.005149396540842201 -- epoch number 1788\n",
      "\n",
      "\n",
      "loss before training is 0.005144370282786038 -- epoch number 1789\n",
      "\n",
      "\n",
      "loss before training is 0.0051393501022743895 -- epoch number 1790\n",
      "\n",
      "\n",
      "loss before training is 0.005134335985240057 -- epoch number 1791\n",
      "\n",
      "\n",
      "loss before training is 0.005129327917662631 -- epoch number 1792\n",
      "\n",
      "\n",
      "loss before training is 0.005124325885568262 -- epoch number 1793\n",
      "\n",
      "\n",
      "loss before training is 0.005119329875029608 -- epoch number 1794\n",
      "\n",
      "\n",
      "loss before training is 0.005114339872165525 -- epoch number 1795\n",
      "\n",
      "\n",
      "loss before training is 0.0051093558631410295 -- epoch number 1796\n",
      "\n",
      "\n",
      "loss before training is 0.005104377834167046 -- epoch number 1797\n",
      "\n",
      "\n",
      "loss before training is 0.0050994057715002955 -- epoch number 1798\n",
      "\n",
      "\n",
      "loss before training is 0.00509443966144312 -- epoch number 1799\n",
      "\n",
      "\n",
      "loss before training is 0.005089479490343269 -- epoch number 1800\n",
      "\n",
      "\n",
      "loss before training is 0.005084525244593841 -- epoch number 1801\n",
      "\n",
      "\n",
      "loss before training is 0.005079576910632984 -- epoch number 1802\n",
      "\n",
      "\n",
      "loss before training is 0.005074634474943865 -- epoch number 1803\n",
      "\n",
      "\n",
      "loss before training is 0.005069697924054456 -- epoch number 1804\n",
      "\n",
      "\n",
      "loss before training is 0.0050647672445373335 -- epoch number 1805\n",
      "\n",
      "\n",
      "loss before training is 0.005059842423009585 -- epoch number 1806\n",
      "\n",
      "\n",
      "loss before training is 0.0050549234461326285 -- epoch number 1807\n",
      "\n",
      "\n",
      "loss before training is 0.005050010300612029 -- epoch number 1808\n",
      "\n",
      "\n",
      "loss before training is 0.0050451029731973475 -- epoch number 1809\n",
      "\n",
      "\n",
      "loss before training is 0.005040201450682023 -- epoch number 1810\n",
      "\n",
      "\n",
      "loss before training is 0.005035305719903206 -- epoch number 1811\n",
      "\n",
      "\n",
      "loss before training is 0.005030415767741545 -- epoch number 1812\n",
      "\n",
      "\n",
      "loss before training is 0.005025531581121088 -- epoch number 1813\n",
      "\n",
      "\n",
      "loss before training is 0.0050206531470091175 -- epoch number 1814\n",
      "\n",
      "\n",
      "loss before training is 0.005015780452416006 -- epoch number 1815\n",
      "\n",
      "\n",
      "loss before training is 0.0050109134843950125 -- epoch number 1816\n",
      "\n",
      "\n",
      "loss before training is 0.005006052230042185 -- epoch number 1817\n",
      "\n",
      "\n",
      "loss before training is 0.0050011966764961936 -- epoch number 1818\n",
      "\n",
      "\n",
      "loss before training is 0.004996346810938173 -- epoch number 1819\n",
      "\n",
      "\n",
      "loss before training is 0.004991502620591553 -- epoch number 1820\n",
      "\n",
      "\n",
      "loss before training is 0.004986664092721954 -- epoch number 1821\n",
      "\n",
      "\n",
      "loss before training is 0.004981831214637001 -- epoch number 1822\n",
      "\n",
      "\n",
      "loss before training is 0.004977003973686173 -- epoch number 1823\n",
      "\n",
      "\n",
      "loss before training is 0.004972182357260673 -- epoch number 1824\n",
      "\n",
      "\n",
      "loss before training is 0.004967366352793297 -- epoch number 1825\n",
      "\n",
      "\n",
      "loss before training is 0.00496255594775819 -- epoch number 1826\n",
      "\n",
      "\n",
      "loss before training is 0.00495775112967085 -- epoch number 1827\n",
      "\n",
      "\n",
      "loss before training is 0.004952951886087863 -- epoch number 1828\n",
      "\n",
      "\n",
      "loss before training is 0.004948158204606791 -- epoch number 1829\n",
      "\n",
      "\n",
      "loss before training is 0.004943370072866059 -- epoch number 1830\n",
      "\n",
      "\n",
      "loss before training is 0.004938587478544742 -- epoch number 1831\n",
      "\n",
      "\n",
      "loss before training is 0.004933810409362503 -- epoch number 1832\n",
      "\n",
      "\n",
      "loss before training is 0.004929038853079378 -- epoch number 1833\n",
      "\n",
      "\n",
      "loss before training is 0.004924272797495682 -- epoch number 1834\n",
      "\n",
      "\n",
      "loss before training is 0.004919512230451836 -- epoch number 1835\n",
      "\n",
      "\n",
      "loss before training is 0.004914757139828238 -- epoch number 1836\n",
      "\n",
      "\n",
      "loss before training is 0.00491000751354511 -- epoch number 1837\n",
      "\n",
      "\n",
      "loss before training is 0.004905263339562377 -- epoch number 1838\n",
      "\n",
      "\n",
      "loss before training is 0.004900524605879536 -- epoch number 1839\n",
      "\n",
      "\n",
      "loss before training is 0.004895791300535457 -- epoch number 1840\n",
      "\n",
      "\n",
      "loss before training is 0.0048910634116083075 -- epoch number 1841\n",
      "\n",
      "\n",
      "loss before training is 0.004886340927215371 -- epoch number 1842\n",
      "\n",
      "\n",
      "loss before training is 0.004881623835512959 -- epoch number 1843\n",
      "\n",
      "\n",
      "loss before training is 0.004876912124696202 -- epoch number 1844\n",
      "\n",
      "\n",
      "loss before training is 0.0048722057829989835 -- epoch number 1845\n",
      "\n",
      "\n",
      "loss before training is 0.004867504798693728 -- epoch number 1846\n",
      "\n",
      "\n",
      "loss before training is 0.004862809160091362 -- epoch number 1847\n",
      "\n",
      "\n",
      "loss before training is 0.004858118855541099 -- epoch number 1848\n",
      "\n",
      "\n",
      "loss before training is 0.004853433873430313 -- epoch number 1849\n",
      "\n",
      "\n",
      "loss before training is 0.004848754202184452 -- epoch number 1850\n",
      "\n",
      "\n",
      "loss before training is 0.004844079830266829 -- epoch number 1851\n",
      "\n",
      "\n",
      "loss before training is 0.004839410746178593 -- epoch number 1852\n",
      "\n",
      "\n",
      "loss before training is 0.004834746938458465 -- epoch number 1853\n",
      "\n",
      "\n",
      "loss before training is 0.004830088395682744 -- epoch number 1854\n",
      "\n",
      "\n",
      "loss before training is 0.004825435106465031 -- epoch number 1855\n",
      "\n",
      "\n",
      "loss before training is 0.004820787059456233 -- epoch number 1856\n",
      "\n",
      "\n",
      "loss before training is 0.004816144243344365 -- epoch number 1857\n",
      "\n",
      "\n",
      "loss before training is 0.00481150664685438 -- epoch number 1858\n",
      "\n",
      "\n",
      "loss before training is 0.00480687425874813 -- epoch number 1859\n",
      "\n",
      "\n",
      "loss before training is 0.004802247067824171 -- epoch number 1860\n",
      "\n",
      "\n",
      "loss before training is 0.004797625062917656 -- epoch number 1861\n",
      "\n",
      "\n",
      "loss before training is 0.004793008232900199 -- epoch number 1862\n",
      "\n",
      "\n",
      "loss before training is 0.004788396566679771 -- epoch number 1863\n",
      "\n",
      "\n",
      "loss before training is 0.004783790053200529 -- epoch number 1864\n",
      "\n",
      "\n",
      "loss before training is 0.0047791886814427245 -- epoch number 1865\n",
      "\n",
      "\n",
      "loss before training is 0.004774592440422553 -- epoch number 1866\n",
      "\n",
      "\n",
      "loss before training is 0.00477000131919207 -- epoch number 1867\n",
      "\n",
      "\n",
      "loss before training is 0.004765415306839005 -- epoch number 1868\n",
      "\n",
      "\n",
      "loss before training is 0.0047608343924866615 -- epoch number 1869\n",
      "\n",
      "\n",
      "loss before training is 0.004756258565293836 -- epoch number 1870\n",
      "\n",
      "\n",
      "loss before training is 0.004751687814454614 -- epoch number 1871\n",
      "\n",
      "\n",
      "loss before training is 0.004747122129198309 -- epoch number 1872\n",
      "\n",
      "\n",
      "loss before training is 0.004742561498789313 -- epoch number 1873\n",
      "\n",
      "\n",
      "loss before training is 0.004738005912526955 -- epoch number 1874\n",
      "\n",
      "\n",
      "loss before training is 0.00473345535974545 -- epoch number 1875\n",
      "\n",
      "\n",
      "loss before training is 0.0047289098298136725 -- epoch number 1876\n",
      "\n",
      "\n",
      "loss before training is 0.004724369312135144 -- epoch number 1877\n",
      "\n",
      "\n",
      "loss before training is 0.004719833796147807 -- epoch number 1878\n",
      "\n",
      "\n",
      "loss before training is 0.004715303271323987 -- epoch number 1879\n",
      "\n",
      "\n",
      "loss before training is 0.004710777727170239 -- epoch number 1880\n",
      "\n",
      "\n",
      "loss before training is 0.004706257153227219 -- epoch number 1881\n",
      "\n",
      "\n",
      "loss before training is 0.004701741539069583 -- epoch number 1882\n",
      "\n",
      "\n",
      "loss before training is 0.0046972308743058536 -- epoch number 1883\n",
      "\n",
      "\n",
      "loss before training is 0.004692725148578321 -- epoch number 1884\n",
      "\n",
      "\n",
      "loss before training is 0.004688224351562888 -- epoch number 1885\n",
      "\n",
      "\n",
      "loss before training is 0.004683728472969001 -- epoch number 1886\n",
      "\n",
      "\n",
      "loss before training is 0.004679237502539517 -- epoch number 1887\n",
      "\n",
      "\n",
      "loss before training is 0.0046747514300505486 -- epoch number 1888\n",
      "\n",
      "\n",
      "loss before training is 0.0046702702453113995 -- epoch number 1889\n",
      "\n",
      "\n",
      "loss before training is 0.00466579393816441 -- epoch number 1890\n",
      "\n",
      "\n",
      "loss before training is 0.004661322498484884 -- epoch number 1891\n",
      "\n",
      "\n",
      "loss before training is 0.00465685591618094 -- epoch number 1892\n",
      "\n",
      "\n",
      "loss before training is 0.004652394181193384 -- epoch number 1893\n",
      "\n",
      "\n",
      "loss before training is 0.004647937283495645 -- epoch number 1894\n",
      "\n",
      "\n",
      "loss before training is 0.0046434852130936306 -- epoch number 1895\n",
      "\n",
      "\n",
      "loss before training is 0.00463903796002559 -- epoch number 1896\n",
      "\n",
      "\n",
      "loss before training is 0.004634595514362067 -- epoch number 1897\n",
      "\n",
      "\n",
      "loss before training is 0.0046301578662057315 -- epoch number 1898\n",
      "\n",
      "\n",
      "loss before training is 0.004625725005691271 -- epoch number 1899\n",
      "\n",
      "\n",
      "loss before training is 0.00462129692298531 -- epoch number 1900\n",
      "\n",
      "\n",
      "loss before training is 0.004616873608286292 -- epoch number 1901\n",
      "\n",
      "\n",
      "loss before training is 0.00461245505182432 -- epoch number 1902\n",
      "\n",
      "\n",
      "loss before training is 0.004608041243861131 -- epoch number 1903\n",
      "\n",
      "\n",
      "loss before training is 0.004603632174689907 -- epoch number 1904\n",
      "\n",
      "\n",
      "loss before training is 0.004599227834635216 -- epoch number 1905\n",
      "\n",
      "\n",
      "loss before training is 0.0045948282140528835 -- epoch number 1906\n",
      "\n",
      "\n",
      "loss before training is 0.004590433303329876 -- epoch number 1907\n",
      "\n",
      "\n",
      "loss before training is 0.004586043092884208 -- epoch number 1908\n",
      "\n",
      "\n",
      "loss before training is 0.004581657573164855 -- epoch number 1909\n",
      "\n",
      "\n",
      "loss before training is 0.004577276734651555 -- epoch number 1910\n",
      "\n",
      "\n",
      "loss before training is 0.0045729005678548425 -- epoch number 1911\n",
      "\n",
      "\n",
      "loss before training is 0.004568529063315821 -- epoch number 1912\n",
      "\n",
      "\n",
      "loss before training is 0.004564162211606107 -- epoch number 1913\n",
      "\n",
      "\n",
      "loss before training is 0.004559800003327723 -- epoch number 1914\n",
      "\n",
      "\n",
      "loss before training is 0.004555442429112993 -- epoch number 1915\n",
      "\n",
      "\n",
      "loss before training is 0.004551089479624433 -- epoch number 1916\n",
      "\n",
      "\n",
      "loss before training is 0.00454674114555462 -- epoch number 1917\n",
      "\n",
      "\n",
      "loss before training is 0.004542397417626169 -- epoch number 1918\n",
      "\n",
      "\n",
      "loss before training is 0.004538058286591513 -- epoch number 1919\n",
      "\n",
      "\n",
      "loss before training is 0.004533723743232881 -- epoch number 1920\n",
      "\n",
      "\n",
      "loss before training is 0.00452939377836219 -- epoch number 1921\n",
      "\n",
      "\n",
      "loss before training is 0.00452506838282093 -- epoch number 1922\n",
      "\n",
      "\n",
      "loss before training is 0.00452074754748001 -- epoch number 1923\n",
      "\n",
      "\n",
      "loss before training is 0.004516431263239766 -- epoch number 1924\n",
      "\n",
      "\n",
      "loss before training is 0.0045121195210297525 -- epoch number 1925\n",
      "\n",
      "\n",
      "loss before training is 0.004507812311808702 -- epoch number 1926\n",
      "\n",
      "\n",
      "loss before training is 0.004503509626564401 -- epoch number 1927\n",
      "\n",
      "\n",
      "loss before training is 0.00449921145631363 -- epoch number 1928\n",
      "\n",
      "\n",
      "loss before training is 0.004494917792101961 -- epoch number 1929\n",
      "\n",
      "\n",
      "loss before training is 0.004490628625003804 -- epoch number 1930\n",
      "\n",
      "\n",
      "loss before training is 0.0044863439461221765 -- epoch number 1931\n",
      "\n",
      "\n",
      "loss before training is 0.004482063746588678 -- epoch number 1932\n",
      "\n",
      "\n",
      "loss before training is 0.0044777880175633665 -- epoch number 1933\n",
      "\n",
      "\n",
      "loss before training is 0.004473516750234684 -- epoch number 1934\n",
      "\n",
      "\n",
      "loss before training is 0.004469249935819306 -- epoch number 1935\n",
      "\n",
      "\n",
      "loss before training is 0.00446498756556212 -- epoch number 1936\n",
      "\n",
      "\n",
      "loss before training is 0.004460729630736037 -- epoch number 1937\n",
      "\n",
      "\n",
      "loss before training is 0.0044564761226419895 -- epoch number 1938\n",
      "\n",
      "\n",
      "loss before training is 0.004452227032608752 -- epoch number 1939\n",
      "\n",
      "\n",
      "loss before training is 0.004447982351992911 -- epoch number 1940\n",
      "\n",
      "\n",
      "loss before training is 0.00444374207217873 -- epoch number 1941\n",
      "\n",
      "\n",
      "loss before training is 0.004439506184578051 -- epoch number 1942\n",
      "\n",
      "\n",
      "loss before training is 0.004435274680630236 -- epoch number 1943\n",
      "\n",
      "\n",
      "loss before training is 0.0044310475518020195 -- epoch number 1944\n",
      "\n",
      "\n",
      "loss before training is 0.004426824789587487 -- epoch number 1945\n",
      "\n",
      "\n",
      "loss before training is 0.004422606385507892 -- epoch number 1946\n",
      "\n",
      "\n",
      "loss before training is 0.004418392331111642 -- epoch number 1947\n",
      "\n",
      "\n",
      "loss before training is 0.004414182617974147 -- epoch number 1948\n",
      "\n",
      "\n",
      "loss before training is 0.0044099772376977615 -- epoch number 1949\n",
      "\n",
      "\n",
      "loss before training is 0.004405776181911693 -- epoch number 1950\n",
      "\n",
      "\n",
      "loss before training is 0.004401579442271864 -- epoch number 1951\n",
      "\n",
      "\n",
      "loss before training is 0.004397387010460879 -- epoch number 1952\n",
      "\n",
      "\n",
      "loss before training is 0.0043931988781879035 -- epoch number 1953\n",
      "\n",
      "\n",
      "loss before training is 0.004389015037188587 -- epoch number 1954\n",
      "\n",
      "\n",
      "loss before training is 0.004384835479224926 -- epoch number 1955\n",
      "\n",
      "\n",
      "loss before training is 0.004380660196085248 -- epoch number 1956\n",
      "\n",
      "\n",
      "loss before training is 0.004376489179584036 -- epoch number 1957\n",
      "\n",
      "\n",
      "loss before training is 0.004372322421561959 -- epoch number 1958\n",
      "\n",
      "\n",
      "loss before training is 0.004368159913885623 -- epoch number 1959\n",
      "\n",
      "\n",
      "loss before training is 0.004364001648447637 -- epoch number 1960\n",
      "\n",
      "\n",
      "loss before training is 0.004359847617166388 -- epoch number 1961\n",
      "\n",
      "\n",
      "loss before training is 0.0043556978119860725 -- epoch number 1962\n",
      "\n",
      "\n",
      "loss before training is 0.004351552224876518 -- epoch number 1963\n",
      "\n",
      "\n",
      "loss before training is 0.004347410847833157 -- epoch number 1964\n",
      "\n",
      "\n",
      "loss before training is 0.004343273672876883 -- epoch number 1965\n",
      "\n",
      "\n",
      "loss before training is 0.004339140692054016 -- epoch number 1966\n",
      "\n",
      "\n",
      "loss before training is 0.004335011897436184 -- epoch number 1967\n",
      "\n",
      "\n",
      "loss before training is 0.0043308872811202385 -- epoch number 1968\n",
      "\n",
      "\n",
      "loss before training is 0.00432676683522818 -- epoch number 1969\n",
      "\n",
      "\n",
      "loss before training is 0.004322650551907058 -- epoch number 1970\n",
      "\n",
      "\n",
      "loss before training is 0.0043185384233288965 -- epoch number 1971\n",
      "\n",
      "\n",
      "loss before training is 0.004314430441690622 -- epoch number 1972\n",
      "\n",
      "\n",
      "loss before training is 0.004310326599213919 -- epoch number 1973\n",
      "\n",
      "\n",
      "loss before training is 0.004306226888145222 -- epoch number 1974\n",
      "\n",
      "\n",
      "loss before training is 0.004302131300755588 -- epoch number 1975\n",
      "\n",
      "\n",
      "loss before training is 0.004298039829340598 -- epoch number 1976\n",
      "\n",
      "\n",
      "loss before training is 0.004293952466220342 -- epoch number 1977\n",
      "\n",
      "\n",
      "loss before training is 0.004289869203739228 -- epoch number 1978\n",
      "\n",
      "\n",
      "loss before training is 0.004285790034266009 -- epoch number 1979\n",
      "\n",
      "\n",
      "loss before training is 0.004281714950193619 -- epoch number 1980\n",
      "\n",
      "\n",
      "loss before training is 0.004277643943939122 -- epoch number 1981\n",
      "\n",
      "\n",
      "loss before training is 0.004273577007943661 -- epoch number 1982\n",
      "\n",
      "\n",
      "loss before training is 0.004269514134672288 -- epoch number 1983\n",
      "\n",
      "\n",
      "loss before training is 0.004265455316613992 -- epoch number 1984\n",
      "\n",
      "\n",
      "loss before training is 0.004261400546281518 -- epoch number 1985\n",
      "\n",
      "\n",
      "loss before training is 0.004257349816211358 -- epoch number 1986\n",
      "\n",
      "\n",
      "loss before training is 0.004253303118963629 -- epoch number 1987\n",
      "\n",
      "\n",
      "loss before training is 0.004249260447122003 -- epoch number 1988\n",
      "\n",
      "\n",
      "loss before training is 0.004245221793293653 -- epoch number 1989\n",
      "\n",
      "\n",
      "loss before training is 0.004241187150109111 -- epoch number 1990\n",
      "\n",
      "\n",
      "loss before training is 0.004237156510222256 -- epoch number 1991\n",
      "\n",
      "\n",
      "loss before training is 0.004233129866310178 -- epoch number 1992\n",
      "\n",
      "\n",
      "loss before training is 0.004229107211073142 -- epoch number 1993\n",
      "\n",
      "\n",
      "loss before training is 0.004225088537234498 -- epoch number 1994\n",
      "\n",
      "\n",
      "loss before training is 0.004221073837540576 -- epoch number 1995\n",
      "\n",
      "\n",
      "loss before training is 0.004217063104760631 -- epoch number 1996\n",
      "\n",
      "\n",
      "loss before training is 0.004213056331686791 -- epoch number 1997\n",
      "\n",
      "\n",
      "loss before training is 0.004209053511133905 -- epoch number 1998\n",
      "\n",
      "\n",
      "loss before training is 0.004205054635939533 -- epoch number 1999\n",
      "\n",
      "\n",
      "loss before training is 0.004201059698963846 -- epoch number 2000\n",
      "\n",
      "\n",
      "loss before training is 0.004197068693089545 -- epoch number 2001\n",
      "\n",
      "\n",
      "loss before training is 0.004193081611221783 -- epoch number 2002\n",
      "\n",
      "\n",
      "loss before training is 0.004189098446288092 -- epoch number 2003\n",
      "\n",
      "\n",
      "loss before training is 0.004185119191238325 -- epoch number 2004\n",
      "\n",
      "\n",
      "loss before training is 0.004181143839044547 -- epoch number 2005\n",
      "\n",
      "\n",
      "loss before training is 0.00417717238270097 -- epoch number 2006\n",
      "\n",
      "\n",
      "loss before training is 0.004173204815223909 -- epoch number 2007\n",
      "\n",
      "\n",
      "loss before training is 0.004169241129651628 -- epoch number 2008\n",
      "\n",
      "\n",
      "loss before training is 0.0041652813190443784 -- epoch number 2009\n",
      "\n",
      "\n",
      "loss before training is 0.00416132537648424 -- epoch number 2010\n",
      "\n",
      "\n",
      "loss before training is 0.004157373295075048 -- epoch number 2011\n",
      "\n",
      "\n",
      "loss before training is 0.0041534250679423675 -- epoch number 2012\n",
      "\n",
      "\n",
      "loss before training is 0.004149480688233383 -- epoch number 2013\n",
      "\n",
      "\n",
      "loss before training is 0.004145540149116842 -- epoch number 2014\n",
      "\n",
      "\n",
      "loss before training is 0.004141603443782964 -- epoch number 2015\n",
      "\n",
      "\n",
      "loss before training is 0.004137670565443379 -- epoch number 2016\n",
      "\n",
      "\n",
      "loss before training is 0.004133741507331071 -- epoch number 2017\n",
      "\n",
      "\n",
      "loss before training is 0.004129816262700271 -- epoch number 2018\n",
      "\n",
      "\n",
      "loss before training is 0.004125894824826398 -- epoch number 2019\n",
      "\n",
      "\n",
      "loss before training is 0.004121977187006008 -- epoch number 2020\n",
      "\n",
      "\n",
      "loss before training is 0.0041180633425566895 -- epoch number 2021\n",
      "\n",
      "\n",
      "loss before training is 0.004114153284817012 -- epoch number 2022\n",
      "\n",
      "\n",
      "loss before training is 0.004110247007146464 -- epoch number 2023\n",
      "\n",
      "\n",
      "loss before training is 0.004106344502925356 -- epoch number 2024\n",
      "\n",
      "\n",
      "loss before training is 0.004102445765554762 -- epoch number 2025\n",
      "\n",
      "\n",
      "loss before training is 0.004098550788456438 -- epoch number 2026\n",
      "\n",
      "\n",
      "loss before training is 0.0040946595650727955 -- epoch number 2027\n",
      "\n",
      "\n",
      "loss before training is 0.004090772088866764 -- epoch number 2028\n",
      "\n",
      "\n",
      "loss before training is 0.0040868883533217715 -- epoch number 2029\n",
      "\n",
      "\n",
      "loss before training is 0.004083008351941659 -- epoch number 2030\n",
      "\n",
      "\n",
      "loss before training is 0.004079132078250613 -- epoch number 2031\n",
      "\n",
      "\n",
      "loss before training is 0.004075259525793095 -- epoch number 2032\n",
      "\n",
      "\n",
      "loss before training is 0.004071390688133774 -- epoch number 2033\n",
      "\n",
      "\n",
      "loss before training is 0.004067525558857445 -- epoch number 2034\n",
      "\n",
      "\n",
      "loss before training is 0.004063664131568987 -- epoch number 2035\n",
      "\n",
      "\n",
      "loss before training is 0.00405980639989328 -- epoch number 2036\n",
      "\n",
      "\n",
      "loss before training is 0.004055952357475124 -- epoch number 2037\n",
      "\n",
      "\n",
      "loss before training is 0.004052101997979191 -- epoch number 2038\n",
      "\n",
      "\n",
      "loss before training is 0.004048255315089977 -- epoch number 2039\n",
      "\n",
      "\n",
      "loss before training is 0.004044412302511669 -- epoch number 2040\n",
      "\n",
      "\n",
      "loss before training is 0.004040572953968145 -- epoch number 2041\n",
      "\n",
      "\n",
      "loss before training is 0.004036737263202861 -- epoch number 2042\n",
      "\n",
      "\n",
      "loss before training is 0.0040329052239788405 -- epoch number 2043\n",
      "\n",
      "\n",
      "loss before training is 0.004029076830078525 -- epoch number 2044\n",
      "\n",
      "\n",
      "loss before training is 0.004025252075303793 -- epoch number 2045\n",
      "\n",
      "\n",
      "loss before training is 0.00402143095347585 -- epoch number 2046\n",
      "\n",
      "\n",
      "loss before training is 0.004017613458435154 -- epoch number 2047\n",
      "\n",
      "\n",
      "loss before training is 0.004013799584041371 -- epoch number 2048\n",
      "\n",
      "\n",
      "loss before training is 0.004009989324173336 -- epoch number 2049\n",
      "\n",
      "\n",
      "loss before training is 0.004006182672728904 -- epoch number 2050\n",
      "\n",
      "\n",
      "loss before training is 0.004002379623624968 -- epoch number 2051\n",
      "\n",
      "\n",
      "loss before training is 0.003998580170797392 -- epoch number 2052\n",
      "\n",
      "\n",
      "loss before training is 0.0039947843082008645 -- epoch number 2053\n",
      "\n",
      "\n",
      "loss before training is 0.0039909920298089405 -- epoch number 2054\n",
      "\n",
      "\n",
      "loss before training is 0.003987203329613884 -- epoch number 2055\n",
      "\n",
      "\n",
      "loss before training is 0.00398341820162669 -- epoch number 2056\n",
      "\n",
      "\n",
      "loss before training is 0.0039796366398769465 -- epoch number 2057\n",
      "\n",
      "\n",
      "loss before training is 0.003975858638412829 -- epoch number 2058\n",
      "\n",
      "\n",
      "loss before training is 0.00397208419130099 -- epoch number 2059\n",
      "\n",
      "\n",
      "loss before training is 0.003968313292626549 -- epoch number 2060\n",
      "\n",
      "\n",
      "loss before training is 0.003964545936492972 -- epoch number 2061\n",
      "\n",
      "\n",
      "loss before training is 0.003960782117022067 -- epoch number 2062\n",
      "\n",
      "\n",
      "loss before training is 0.003957021828353856 -- epoch number 2063\n",
      "\n",
      "\n",
      "loss before training is 0.003953265064646583 -- epoch number 2064\n",
      "\n",
      "\n",
      "loss before training is 0.003949511820076608 -- epoch number 2065\n",
      "\n",
      "\n",
      "loss before training is 0.003945762088838369 -- epoch number 2066\n",
      "\n",
      "\n",
      "loss before training is 0.003942015865144292 -- epoch number 2067\n",
      "\n",
      "\n",
      "loss before training is 0.003938273143224761 -- epoch number 2068\n",
      "\n",
      "\n",
      "loss before training is 0.00393453391732803 -- epoch number 2069\n",
      "\n",
      "\n",
      "loss before training is 0.003930798181720205 -- epoch number 2070\n",
      "\n",
      "\n",
      "loss before training is 0.00392706593068512 -- epoch number 2071\n",
      "\n",
      "\n",
      "loss before training is 0.003923337158524339 -- epoch number 2072\n",
      "\n",
      "\n",
      "loss before training is 0.003919611859557069 -- epoch number 2073\n",
      "\n",
      "\n",
      "loss before training is 0.003915890028120076 -- epoch number 2074\n",
      "\n",
      "\n",
      "loss before training is 0.003912171658567693 -- epoch number 2075\n",
      "\n",
      "\n",
      "loss before training is 0.003908456745271687 -- epoch number 2076\n",
      "\n",
      "\n",
      "loss before training is 0.0039047452826212366 -- epoch number 2077\n",
      "\n",
      "\n",
      "loss before training is 0.0039010372650228665 -- epoch number 2078\n",
      "\n",
      "\n",
      "loss before training is 0.003897332686900414 -- epoch number 2079\n",
      "\n",
      "\n",
      "loss before training is 0.003893631542694925 -- epoch number 2080\n",
      "\n",
      "\n",
      "loss before training is 0.0038899338268646093 -- epoch number 2081\n",
      "\n",
      "\n",
      "loss before training is 0.0038862395338848275 -- epoch number 2082\n",
      "\n",
      "\n",
      "loss before training is 0.003882548658247977 -- epoch number 2083\n",
      "\n",
      "\n",
      "loss before training is 0.0038788611944634336 -- epoch number 2084\n",
      "\n",
      "\n",
      "loss before training is 0.0038751771370575563 -- epoch number 2085\n",
      "\n",
      "\n",
      "loss before training is 0.00387149648057357 -- epoch number 2086\n",
      "\n",
      "\n",
      "loss before training is 0.0038678192195715174 -- epoch number 2087\n",
      "\n",
      "\n",
      "loss before training is 0.003864145348628236 -- epoch number 2088\n",
      "\n",
      "\n",
      "loss before training is 0.003860474862337252 -- epoch number 2089\n",
      "\n",
      "\n",
      "loss before training is 0.003856807755308771 -- epoch number 2090\n",
      "\n",
      "\n",
      "loss before training is 0.003853144022169601 -- epoch number 2091\n",
      "\n",
      "\n",
      "loss before training is 0.003849483657563081 -- epoch number 2092\n",
      "\n",
      "\n",
      "loss before training is 0.003845826656149065 -- epoch number 2093\n",
      "\n",
      "\n",
      "loss before training is 0.0038421730126038 -- epoch number 2094\n",
      "\n",
      "\n",
      "loss before training is 0.0038385227216199552 -- epoch number 2095\n",
      "\n",
      "\n",
      "loss before training is 0.0038348757779065124 -- epoch number 2096\n",
      "\n",
      "\n",
      "loss before training is 0.00383123217618871 -- epoch number 2097\n",
      "\n",
      "\n",
      "loss before training is 0.003827591911208011 -- epoch number 2098\n",
      "\n",
      "\n",
      "loss before training is 0.0038239549777220353 -- epoch number 2099\n",
      "\n",
      "\n",
      "loss before training is 0.003820321370504522 -- epoch number 2100\n",
      "\n",
      "\n",
      "loss before training is 0.0038166910843452436 -- epoch number 2101\n",
      "\n",
      "\n",
      "loss before training is 0.0038130641140499684 -- epoch number 2102\n",
      "\n",
      "\n",
      "loss before training is 0.003809440454440412 -- epoch number 2103\n",
      "\n",
      "\n",
      "loss before training is 0.003805820100354194 -- epoch number 2104\n",
      "\n",
      "\n",
      "loss before training is 0.0038022030466447567 -- epoch number 2105\n",
      "\n",
      "\n",
      "loss before training is 0.00379858928818132 -- epoch number 2106\n",
      "\n",
      "\n",
      "loss before training is 0.0037949788198488495 -- epoch number 2107\n",
      "\n",
      "\n",
      "loss before training is 0.0037913716365479645 -- epoch number 2108\n",
      "\n",
      "\n",
      "loss before training is 0.0037877677331949206 -- epoch number 2109\n",
      "\n",
      "\n",
      "loss before training is 0.0037841671047215636 -- epoch number 2110\n",
      "\n",
      "\n",
      "loss before training is 0.0037805697460752113 -- epoch number 2111\n",
      "\n",
      "\n",
      "loss before training is 0.003776975652218697 -- epoch number 2112\n",
      "\n",
      "\n",
      "loss before training is 0.003773384818130232 -- epoch number 2113\n",
      "\n",
      "\n",
      "loss before training is 0.0037697972388034116 -- epoch number 2114\n",
      "\n",
      "\n",
      "loss before training is 0.0037662129092471196 -- epoch number 2115\n",
      "\n",
      "\n",
      "loss before training is 0.0037626318244855365 -- epoch number 2116\n",
      "\n",
      "\n",
      "loss before training is 0.0037590539795580064 -- epoch number 2117\n",
      "\n",
      "\n",
      "loss before training is 0.003755479369519061 -- epoch number 2118\n",
      "\n",
      "\n",
      "loss before training is 0.0037519079894383165 -- epoch number 2119\n",
      "\n",
      "\n",
      "loss before training is 0.003748339834400466 -- epoch number 2120\n",
      "\n",
      "\n",
      "loss before training is 0.0037447748995051763 -- epoch number 2121\n",
      "\n",
      "\n",
      "loss before training is 0.0037412131798670993 -- epoch number 2122\n",
      "\n",
      "\n",
      "loss before training is 0.0037376546706157578 -- epoch number 2123\n",
      "\n",
      "\n",
      "loss before training is 0.003734099366895556 -- epoch number 2124\n",
      "\n",
      "\n",
      "loss before training is 0.0037305472638656896 -- epoch number 2125\n",
      "\n",
      "\n",
      "loss before training is 0.003726998356700093 -- epoch number 2126\n",
      "\n",
      "\n",
      "loss before training is 0.0037234526405874307 -- epoch number 2127\n",
      "\n",
      "\n",
      "loss before training is 0.00371991011073101 -- epoch number 2128\n",
      "\n",
      "\n",
      "loss before training is 0.003716370762348713 -- epoch number 2129\n",
      "\n",
      "\n",
      "loss before training is 0.0037128345906730286 -- epoch number 2130\n",
      "\n",
      "\n",
      "loss before training is 0.0037093015909509157 -- epoch number 2131\n",
      "\n",
      "\n",
      "loss before training is 0.0037057717584438052 -- epoch number 2132\n",
      "\n",
      "\n",
      "loss before training is 0.0037022450884275386 -- epoch number 2133\n",
      "\n",
      "\n",
      "loss before training is 0.003698721576192296 -- epoch number 2134\n",
      "\n",
      "\n",
      "loss before training is 0.003695201217042588 -- epoch number 2135\n",
      "\n",
      "\n",
      "loss before training is 0.003691684006297188 -- epoch number 2136\n",
      "\n",
      "\n",
      "loss before training is 0.0036881699392890843 -- epoch number 2137\n",
      "\n",
      "\n",
      "loss before training is 0.0036846590113654262 -- epoch number 2138\n",
      "\n",
      "\n",
      "loss before training is 0.003681151217887488 -- epoch number 2139\n",
      "\n",
      "\n",
      "loss before training is 0.0036776465542306333 -- epoch number 2140\n",
      "\n",
      "\n",
      "loss before training is 0.0036741450157842066 -- epoch number 2141\n",
      "\n",
      "\n",
      "loss before training is 0.0036706465979515703 -- epoch number 2142\n",
      "\n",
      "\n",
      "loss before training is 0.003667151296150001 -- epoch number 2143\n",
      "\n",
      "\n",
      "loss before training is 0.0036636591058106694 -- epoch number 2144\n",
      "\n",
      "\n",
      "loss before training is 0.0036601700223785763 -- epoch number 2145\n",
      "\n",
      "\n",
      "loss before training is 0.0036566840413125063 -- epoch number 2146\n",
      "\n",
      "\n",
      "loss before training is 0.0036532011580849965 -- epoch number 2147\n",
      "\n",
      "\n",
      "loss before training is 0.003649721368182287 -- epoch number 2148\n",
      "\n",
      "\n",
      "loss before training is 0.003646244667104255 -- epoch number 2149\n",
      "\n",
      "\n",
      "loss before training is 0.0036427710503644 -- epoch number 2150\n",
      "\n",
      "\n",
      "loss before training is 0.003639300513489779 -- epoch number 2151\n",
      "\n",
      "\n",
      "loss before training is 0.0036358330520209494 -- epoch number 2152\n",
      "\n",
      "\n",
      "loss before training is 0.003632368661511942 -- epoch number 2153\n",
      "\n",
      "\n",
      "loss before training is 0.0036289073375302327 -- epoch number 2154\n",
      "\n",
      "\n",
      "loss before training is 0.0036254490756566504 -- epoch number 2155\n",
      "\n",
      "\n",
      "loss before training is 0.0036219938714853604 -- epoch number 2156\n",
      "\n",
      "\n",
      "loss before training is 0.0036185417206238313 -- epoch number 2157\n",
      "\n",
      "\n",
      "loss before training is 0.003615092618692762 -- epoch number 2158\n",
      "\n",
      "\n",
      "loss before training is 0.003611646561326052 -- epoch number 2159\n",
      "\n",
      "\n",
      "loss before training is 0.0036082035441707696 -- epoch number 2160\n",
      "\n",
      "\n",
      "loss before training is 0.003604763562887077 -- epoch number 2161\n",
      "\n",
      "\n",
      "loss before training is 0.0036013266131482043 -- epoch number 2162\n",
      "\n",
      "\n",
      "loss before training is 0.0035978926906404017 -- epoch number 2163\n",
      "\n",
      "\n",
      "loss before training is 0.0035944617910629354 -- epoch number 2164\n",
      "\n",
      "\n",
      "loss before training is 0.0035910339101279352 -- epoch number 2165\n",
      "\n",
      "\n",
      "loss before training is 0.003587609043560495 -- epoch number 2166\n",
      "\n",
      "\n",
      "loss before training is 0.003584187187098511 -- epoch number 2167\n",
      "\n",
      "\n",
      "loss before training is 0.003580768336492692 -- epoch number 2168\n",
      "\n",
      "\n",
      "loss before training is 0.0035773524875065267 -- epoch number 2169\n",
      "\n",
      "\n",
      "loss before training is 0.0035739396359161946 -- epoch number 2170\n",
      "\n",
      "\n",
      "loss before training is 0.003570529777510576 -- epoch number 2171\n",
      "\n",
      "\n",
      "loss before training is 0.0035671229080911724 -- epoch number 2172\n",
      "\n",
      "\n",
      "loss before training is 0.0035637190234720727 -- epoch number 2173\n",
      "\n",
      "\n",
      "loss before training is 0.003560318119479927 -- epoch number 2174\n",
      "\n",
      "\n",
      "loss before training is 0.0035569201919538815 -- epoch number 2175\n",
      "\n",
      "\n",
      "loss before training is 0.003553525236745539 -- epoch number 2176\n",
      "\n",
      "\n",
      "loss before training is 0.0035501332497189296 -- epoch number 2177\n",
      "\n",
      "\n",
      "loss before training is 0.0035467442267504822 -- epoch number 2178\n",
      "\n",
      "\n",
      "loss before training is 0.003543358163728936 -- epoch number 2179\n",
      "\n",
      "\n",
      "loss before training is 0.003539975056555343 -- epoch number 2180\n",
      "\n",
      "\n",
      "loss before training is 0.0035365949011430062 -- epoch number 2181\n",
      "\n",
      "\n",
      "loss before training is 0.0035332176934174337 -- epoch number 2182\n",
      "\n",
      "\n",
      "loss before training is 0.003529843429316337 -- epoch number 2183\n",
      "\n",
      "\n",
      "loss before training is 0.0035264721047895227 -- epoch number 2184\n",
      "\n",
      "\n",
      "loss before training is 0.0035231037157988964 -- epoch number 2185\n",
      "\n",
      "\n",
      "loss before training is 0.003519738258318433 -- epoch number 2186\n",
      "\n",
      "\n",
      "loss before training is 0.0035163757283341074 -- epoch number 2187\n",
      "\n",
      "\n",
      "loss before training is 0.0035130161218438465 -- epoch number 2188\n",
      "\n",
      "\n",
      "loss before training is 0.0035096594348575294 -- epoch number 2189\n",
      "\n",
      "\n",
      "loss before training is 0.0035063056633969163 -- epoch number 2190\n",
      "\n",
      "\n",
      "loss before training is 0.0035029548034956146 -- epoch number 2191\n",
      "\n",
      "\n",
      "loss before training is 0.003499606851199046 -- epoch number 2192\n",
      "\n",
      "\n",
      "loss before training is 0.0034962618025643796 -- epoch number 2193\n",
      "\n",
      "\n",
      "loss before training is 0.003492919653660539 -- epoch number 2194\n",
      "\n",
      "\n",
      "loss before training is 0.0034895804005681246 -- epoch number 2195\n",
      "\n",
      "\n",
      "loss before training is 0.0034862440393793968 -- epoch number 2196\n",
      "\n",
      "\n",
      "loss before training is 0.0034829105661982047 -- epoch number 2197\n",
      "\n",
      "\n",
      "loss before training is 0.003479579977140005 -- epoch number 2198\n",
      "\n",
      "\n",
      "loss before training is 0.0034762522683317422 -- epoch number 2199\n",
      "\n",
      "\n",
      "loss before training is 0.003472927435911913 -- epoch number 2200\n",
      "\n",
      "\n",
      "loss before training is 0.0034696054760304028 -- epoch number 2201\n",
      "\n",
      "\n",
      "loss before training is 0.003466286384848552 -- epoch number 2202\n",
      "\n",
      "\n",
      "loss before training is 0.0034629701585390943 -- epoch number 2203\n",
      "\n",
      "\n",
      "loss before training is 0.0034596567932860516 -- epoch number 2204\n",
      "\n",
      "\n",
      "loss before training is 0.0034563462852848018 -- epoch number 2205\n",
      "\n",
      "\n",
      "loss before training is 0.0034530386307419485 -- epoch number 2206\n",
      "\n",
      "\n",
      "loss before training is 0.0034497338258753286 -- epoch number 2207\n",
      "\n",
      "\n",
      "loss before training is 0.0034464318669139788 -- epoch number 2208\n",
      "\n",
      "\n",
      "loss before training is 0.0034431327500980802 -- epoch number 2209\n",
      "\n",
      "\n",
      "loss before training is 0.003439836471678912 -- epoch number 2210\n",
      "\n",
      "\n",
      "loss before training is 0.003436543027918854 -- epoch number 2211\n",
      "\n",
      "\n",
      "loss before training is 0.0034332524150912816 -- epoch number 2212\n",
      "\n",
      "\n",
      "loss before training is 0.0034299646294806245 -- epoch number 2213\n",
      "\n",
      "\n",
      "loss before training is 0.0034266796673822217 -- epoch number 2214\n",
      "\n",
      "\n",
      "loss before training is 0.0034233975251023833 -- epoch number 2215\n",
      "\n",
      "\n",
      "loss before training is 0.0034201181989582797 -- epoch number 2216\n",
      "\n",
      "\n",
      "loss before training is 0.0034168416852779276 -- epoch number 2217\n",
      "\n",
      "\n",
      "loss before training is 0.003413567980400198 -- epoch number 2218\n",
      "\n",
      "\n",
      "loss before training is 0.0034102970806746936 -- epoch number 2219\n",
      "\n",
      "\n",
      "loss before training is 0.0034070289824617798 -- epoch number 2220\n",
      "\n",
      "\n",
      "loss before training is 0.003403763682132539 -- epoch number 2221\n",
      "\n",
      "\n",
      "loss before training is 0.00340050117606872 -- epoch number 2222\n",
      "\n",
      "\n",
      "loss before training is 0.0033972414606626856 -- epoch number 2223\n",
      "\n",
      "\n",
      "loss before training is 0.0033939845323174007 -- epoch number 2224\n",
      "\n",
      "\n",
      "loss before training is 0.0033907303874464237 -- epoch number 2225\n",
      "\n",
      "\n",
      "loss before training is 0.0033874790224738102 -- epoch number 2226\n",
      "\n",
      "\n",
      "loss before training is 0.0033842304338341034 -- epoch number 2227\n",
      "\n",
      "\n",
      "loss before training is 0.0033809846179723114 -- epoch number 2228\n",
      "\n",
      "\n",
      "loss before training is 0.0033777415713438746 -- epoch number 2229\n",
      "\n",
      "\n",
      "loss before training is 0.0033745012904145967 -- epoch number 2230\n",
      "\n",
      "\n",
      "loss before training is 0.003371263771660641 -- epoch number 2231\n",
      "\n",
      "\n",
      "loss before training is 0.003368029011568489 -- epoch number 2232\n",
      "\n",
      "\n",
      "loss before training is 0.0033647970066348976 -- epoch number 2233\n",
      "\n",
      "\n",
      "loss before training is 0.0033615677533668595 -- epoch number 2234\n",
      "\n",
      "\n",
      "loss before training is 0.0033583412482815914 -- epoch number 2235\n",
      "\n",
      "\n",
      "loss before training is 0.003355117487906475 -- epoch number 2236\n",
      "\n",
      "\n",
      "loss before training is 0.003351896468779054 -- epoch number 2237\n",
      "\n",
      "\n",
      "loss before training is 0.003348678187446953 -- epoch number 2238\n",
      "\n",
      "\n",
      "loss before training is 0.003345462640467881 -- epoch number 2239\n",
      "\n",
      "\n",
      "loss before training is 0.003342249824409594 -- epoch number 2240\n",
      "\n",
      "\n",
      "loss before training is 0.0033390397358498227 -- epoch number 2241\n",
      "\n",
      "\n",
      "loss before training is 0.003335832371376313 -- epoch number 2242\n",
      "\n",
      "\n",
      "loss before training is 0.003332627727586702 -- epoch number 2243\n",
      "\n",
      "\n",
      "loss before training is 0.003329425801088564 -- epoch number 2244\n",
      "\n",
      "\n",
      "loss before training is 0.0033262265884993346 -- epoch number 2245\n",
      "\n",
      "\n",
      "loss before training is 0.0033230300864462827 -- epoch number 2246\n",
      "\n",
      "\n",
      "loss before training is 0.003319836291566465 -- epoch number 2247\n",
      "\n",
      "\n",
      "loss before training is 0.0033166452005067458 -- epoch number 2248\n",
      "\n",
      "\n",
      "loss before training is 0.003313456809923673 -- epoch number 2249\n",
      "\n",
      "\n",
      "loss before training is 0.003310271116483552 -- epoch number 2250\n",
      "\n",
      "\n",
      "loss before training is 0.0033070881168623277 -- epoch number 2251\n",
      "\n",
      "\n",
      "loss before training is 0.003303907807745576 -- epoch number 2252\n",
      "\n",
      "\n",
      "loss before training is 0.0033007301858285097 -- epoch number 2253\n",
      "\n",
      "\n",
      "loss before training is 0.003297555247815895 -- epoch number 2254\n",
      "\n",
      "\n",
      "loss before training is 0.0032943829904220354 -- epoch number 2255\n",
      "\n",
      "\n",
      "loss before training is 0.003291213410370744 -- epoch number 2256\n",
      "\n",
      "\n",
      "loss before training is 0.003288046504395311 -- epoch number 2257\n",
      "\n",
      "\n",
      "loss before training is 0.0032848822692384807 -- epoch number 2258\n",
      "\n",
      "\n",
      "loss before training is 0.0032817207016523787 -- epoch number 2259\n",
      "\n",
      "\n",
      "loss before training is 0.003278561798398539 -- epoch number 2260\n",
      "\n",
      "\n",
      "loss before training is 0.0032754055562478394 -- epoch number 2261\n",
      "\n",
      "\n",
      "loss before training is 0.003272251971980479 -- epoch number 2262\n",
      "\n",
      "\n",
      "loss before training is 0.0032691010423858908 -- epoch number 2263\n",
      "\n",
      "\n",
      "loss before training is 0.003265952764262838 -- epoch number 2264\n",
      "\n",
      "\n",
      "loss before training is 0.003262807134419251 -- epoch number 2265\n",
      "\n",
      "\n",
      "loss before training is 0.003259664149672257 -- epoch number 2266\n",
      "\n",
      "\n",
      "loss before training is 0.003256523806848156 -- epoch number 2267\n",
      "\n",
      "\n",
      "loss before training is 0.003253386102782375 -- epoch number 2268\n",
      "\n",
      "\n",
      "loss before training is 0.003250251034319423 -- epoch number 2269\n",
      "\n",
      "\n",
      "loss before training is 0.003247118598312875 -- epoch number 2270\n",
      "\n",
      "\n",
      "loss before training is 0.0032439887916253644 -- epoch number 2271\n",
      "\n",
      "\n",
      "loss before training is 0.003240861611128501 -- epoch number 2272\n",
      "\n",
      "\n",
      "loss before training is 0.003237737053702873 -- epoch number 2273\n",
      "\n",
      "\n",
      "loss before training is 0.003234615116238041 -- epoch number 2274\n",
      "\n",
      "\n",
      "loss before training is 0.0032314957956324263 -- epoch number 2275\n",
      "\n",
      "\n",
      "loss before training is 0.003228379088793367 -- epoch number 2276\n",
      "\n",
      "\n",
      "loss before training is 0.0032252649926370527 -- epoch number 2277\n",
      "\n",
      "\n",
      "loss before training is 0.003222153504088475 -- epoch number 2278\n",
      "\n",
      "\n",
      "loss before training is 0.003219044620081429 -- epoch number 2279\n",
      "\n",
      "\n",
      "loss before training is 0.0032159383375584788 -- epoch number 2280\n",
      "\n",
      "\n",
      "loss before training is 0.00321283465347091 -- epoch number 2281\n",
      "\n",
      "\n",
      "loss before training is 0.003209733564778708 -- epoch number 2282\n",
      "\n",
      "\n",
      "loss before training is 0.003206635068450522 -- epoch number 2283\n",
      "\n",
      "\n",
      "loss before training is 0.0032035391614636667 -- epoch number 2284\n",
      "\n",
      "\n",
      "loss before training is 0.003200445840804059 -- epoch number 2285\n",
      "\n",
      "\n",
      "loss before training is 0.0031973551034662024 -- epoch number 2286\n",
      "\n",
      "\n",
      "loss before training is 0.0031942669464531453 -- epoch number 2287\n",
      "\n",
      "\n",
      "loss before training is 0.0031911813667764594 -- epoch number 2288\n",
      "\n",
      "\n",
      "loss before training is 0.0031880983614562307 -- epoch number 2289\n",
      "\n",
      "\n",
      "loss before training is 0.0031850179275209993 -- epoch number 2290\n",
      "\n",
      "\n",
      "loss before training is 0.003181940062007741 -- epoch number 2291\n",
      "\n",
      "\n",
      "loss before training is 0.0031788647619618473 -- epoch number 2292\n",
      "\n",
      "\n",
      "loss before training is 0.00317579202443709 -- epoch number 2293\n",
      "\n",
      "\n",
      "loss before training is 0.0031727218464955883 -- epoch number 2294\n",
      "\n",
      "\n",
      "loss before training is 0.003169654225207792 -- epoch number 2295\n",
      "\n",
      "\n",
      "loss before training is 0.003166589157652432 -- epoch number 2296\n",
      "\n",
      "\n",
      "loss before training is 0.0031635266409165263 -- epoch number 2297\n",
      "\n",
      "\n",
      "loss before training is 0.0031604666720953063 -- epoch number 2298\n",
      "\n",
      "\n",
      "loss before training is 0.0031574092482922417 -- epoch number 2299\n",
      "\n",
      "\n",
      "loss before training is 0.0031543543666189603 -- epoch number 2300\n",
      "\n",
      "\n",
      "loss before training is 0.0031513020241952495 -- epoch number 2301\n",
      "\n",
      "\n",
      "loss before training is 0.003148252218149037 -- epoch number 2302\n",
      "\n",
      "\n",
      "loss before training is 0.003145204945616326 -- epoch number 2303\n",
      "\n",
      "\n",
      "loss before training is 0.0031421602037412107 -- epoch number 2304\n",
      "\n",
      "\n",
      "loss before training is 0.003139117989675818 -- epoch number 2305\n",
      "\n",
      "\n",
      "loss before training is 0.003136078300580292 -- epoch number 2306\n",
      "\n",
      "\n",
      "loss before training is 0.0031330411336227574 -- epoch number 2307\n",
      "\n",
      "\n",
      "loss before training is 0.0031300064859793157 -- epoch number 2308\n",
      "\n",
      "\n",
      "loss before training is 0.003126974354833979 -- epoch number 2309\n",
      "\n",
      "\n",
      "loss before training is 0.0031239447373786946 -- epoch number 2310\n",
      "\n",
      "\n",
      "loss before training is 0.003120917630813257 -- epoch number 2311\n",
      "\n",
      "\n",
      "loss before training is 0.0031178930323453283 -- epoch number 2312\n",
      "\n",
      "\n",
      "loss before training is 0.0031148709391904143 -- epoch number 2313\n",
      "\n",
      "\n",
      "loss before training is 0.0031118513485717835 -- epoch number 2314\n",
      "\n",
      "\n",
      "loss before training is 0.0031088342577204786 -- epoch number 2315\n",
      "\n",
      "\n",
      "loss before training is 0.003105819663875326 -- epoch number 2316\n",
      "\n",
      "\n",
      "loss before training is 0.003102807564282826 -- epoch number 2317\n",
      "\n",
      "\n",
      "loss before training is 0.0030997979561972 -- epoch number 2318\n",
      "\n",
      "\n",
      "loss before training is 0.0030967908368803028 -- epoch number 2319\n",
      "\n",
      "\n",
      "loss before training is 0.0030937862036016575 -- epoch number 2320\n",
      "\n",
      "\n",
      "loss before training is 0.0030907840536383967 -- epoch number 2321\n",
      "\n",
      "\n",
      "loss before training is 0.003087784384275218 -- epoch number 2322\n",
      "\n",
      "\n",
      "loss before training is 0.003084787192804397 -- epoch number 2323\n",
      "\n",
      "\n",
      "loss before training is 0.003081792476525745 -- epoch number 2324\n",
      "\n",
      "\n",
      "loss before training is 0.0030788002327465525 -- epoch number 2325\n",
      "\n",
      "\n",
      "loss before training is 0.003075810458781648 -- epoch number 2326\n",
      "\n",
      "\n",
      "loss before training is 0.003072823151953256 -- epoch number 2327\n",
      "\n",
      "\n",
      "loss before training is 0.0030698383095910647 -- epoch number 2328\n",
      "\n",
      "\n",
      "loss before training is 0.003066855929032171 -- epoch number 2329\n",
      "\n",
      "\n",
      "loss before training is 0.0030638760076210246 -- epoch number 2330\n",
      "\n",
      "\n",
      "loss before training is 0.0030608985427094566 -- epoch number 2331\n",
      "\n",
      "\n",
      "loss before training is 0.003057923531656617 -- epoch number 2332\n",
      "\n",
      "\n",
      "loss before training is 0.0030549509718289544 -- epoch number 2333\n",
      "\n",
      "\n",
      "loss before training is 0.0030519808606002084 -- epoch number 2334\n",
      "\n",
      "\n",
      "loss before training is 0.0030490131953513503 -- epoch number 2335\n",
      "\n",
      "\n",
      "loss before training is 0.0030460479734705963 -- epoch number 2336\n",
      "\n",
      "\n",
      "loss before training is 0.003043085192353371 -- epoch number 2337\n",
      "\n",
      "\n",
      "loss before training is 0.0030401248494022525 -- epoch number 2338\n",
      "\n",
      "\n",
      "loss before training is 0.0030371669420270076 -- epoch number 2339\n",
      "\n",
      "\n",
      "loss before training is 0.0030342114676444893 -- epoch number 2340\n",
      "\n",
      "\n",
      "loss before training is 0.003031258423678701 -- epoch number 2341\n",
      "\n",
      "\n",
      "loss before training is 0.003028307807560681 -- epoch number 2342\n",
      "\n",
      "\n",
      "loss before training is 0.003025359616728546 -- epoch number 2343\n",
      "\n",
      "\n",
      "loss before training is 0.0030224138486274546 -- epoch number 2344\n",
      "\n",
      "\n",
      "loss before training is 0.0030194705007095543 -- epoch number 2345\n",
      "\n",
      "\n",
      "loss before training is 0.0030165295704339613 -- epoch number 2346\n",
      "\n",
      "\n",
      "loss before training is 0.0030135910552667846 -- epoch number 2347\n",
      "\n",
      "\n",
      "loss before training is 0.0030106549526810376 -- epoch number 2348\n",
      "\n",
      "\n",
      "loss before training is 0.003007721260156654 -- epoch number 2349\n",
      "\n",
      "\n",
      "loss before training is 0.0030047899751804645 -- epoch number 2350\n",
      "\n",
      "\n",
      "loss before training is 0.0030018610952461428 -- epoch number 2351\n",
      "\n",
      "\n",
      "loss before training is 0.0029989346178542074 -- epoch number 2352\n",
      "\n",
      "\n",
      "loss before training is 0.0029960105405119853 -- epoch number 2353\n",
      "\n",
      "\n",
      "loss before training is 0.002993088860733614 -- epoch number 2354\n",
      "\n",
      "\n",
      "loss before training is 0.002990169576039981 -- epoch number 2355\n",
      "\n",
      "\n",
      "loss before training is 0.0029872526839587045 -- epoch number 2356\n",
      "\n",
      "\n",
      "loss before training is 0.0029843381820241614 -- epoch number 2357\n",
      "\n",
      "\n",
      "loss before training is 0.0029814260677773893 -- epoch number 2358\n",
      "\n",
      "\n",
      "loss before training is 0.0029785163387661155 -- epoch number 2359\n",
      "\n",
      "\n",
      "loss before training is 0.002975608992544719 -- epoch number 2360\n",
      "\n",
      "\n",
      "loss before training is 0.002972704026674191 -- epoch number 2361\n",
      "\n",
      "\n",
      "loss before training is 0.002969801438722148 -- epoch number 2362\n",
      "\n",
      "\n",
      "loss before training is 0.002966901226262771 -- epoch number 2363\n",
      "\n",
      "\n",
      "loss before training is 0.0029640033868768034 -- epoch number 2364\n",
      "\n",
      "\n",
      "loss before training is 0.0029611079181515315 -- epoch number 2365\n",
      "\n",
      "\n",
      "loss before training is 0.002958214817680739 -- epoch number 2366\n",
      "\n",
      "\n",
      "loss before training is 0.0029553240830647114 -- epoch number 2367\n",
      "\n",
      "\n",
      "loss before training is 0.0029524357119102055 -- epoch number 2368\n",
      "\n",
      "\n",
      "loss before training is 0.0029495497018304 -- epoch number 2369\n",
      "\n",
      "\n",
      "loss before training is 0.0029466660504449222 -- epoch number 2370\n",
      "\n",
      "\n",
      "loss before training is 0.0029437847553797822 -- epoch number 2371\n",
      "\n",
      "\n",
      "loss before training is 0.0029409058142673724 -- epoch number 2372\n",
      "\n",
      "\n",
      "loss before training is 0.002938029224746438 -- epoch number 2373\n",
      "\n",
      "\n",
      "loss before training is 0.002935154984462075 -- epoch number 2374\n",
      "\n",
      "\n",
      "loss before training is 0.0029322830910656476 -- epoch number 2375\n",
      "\n",
      "\n",
      "loss before training is 0.0029294135422148625 -- epoch number 2376\n",
      "\n",
      "\n",
      "loss before training is 0.0029265463355736447 -- epoch number 2377\n",
      "\n",
      "\n",
      "loss before training is 0.002923681468812199 -- epoch number 2378\n",
      "\n",
      "\n",
      "loss before training is 0.002920818939606933 -- epoch number 2379\n",
      "\n",
      "\n",
      "loss before training is 0.002917958745640457 -- epoch number 2380\n",
      "\n",
      "\n",
      "loss before training is 0.0029151008846015655 -- epoch number 2381\n",
      "\n",
      "\n",
      "loss before training is 0.002912245354185231 -- epoch number 2382\n",
      "\n",
      "\n",
      "loss before training is 0.002909392152092501 -- epoch number 2383\n",
      "\n",
      "\n",
      "loss before training is 0.002906541276030606 -- epoch number 2384\n",
      "\n",
      "\n",
      "loss before training is 0.0029036927237128377 -- epoch number 2385\n",
      "\n",
      "\n",
      "loss before training is 0.0029008464928585616 -- epoch number 2386\n",
      "\n",
      "\n",
      "loss before training is 0.002898002581193185 -- epoch number 2387\n",
      "\n",
      "\n",
      "loss before training is 0.0028951609864481657 -- epoch number 2388\n",
      "\n",
      "\n",
      "loss before training is 0.0028923217063609548 -- epoch number 2389\n",
      "\n",
      "\n",
      "loss before training is 0.002889484738674985 -- epoch number 2390\n",
      "\n",
      "\n",
      "loss before training is 0.0028866500811396607 -- epoch number 2391\n",
      "\n",
      "\n",
      "loss before training is 0.002883817731510355 -- epoch number 2392\n",
      "\n",
      "\n",
      "loss before training is 0.002880987687548319 -- epoch number 2393\n",
      "\n",
      "\n",
      "loss before training is 0.002878159947020752 -- epoch number 2394\n",
      "\n",
      "\n",
      "loss before training is 0.0028753345077006894 -- epoch number 2395\n",
      "\n",
      "\n",
      "loss before training is 0.0028725113673670703 -- epoch number 2396\n",
      "\n",
      "\n",
      "loss before training is 0.0028696905238046492 -- epoch number 2397\n",
      "\n",
      "\n",
      "loss before training is 0.002866871974804021 -- epoch number 2398\n",
      "\n",
      "\n",
      "loss before training is 0.002864055718161543 -- epoch number 2399\n",
      "\n",
      "\n",
      "loss before training is 0.002861241751679402 -- epoch number 2400\n",
      "\n",
      "\n",
      "loss before training is 0.0028584300731655113 -- epoch number 2401\n",
      "\n",
      "\n",
      "loss before training is 0.0028556206804335148 -- epoch number 2402\n",
      "\n",
      "\n",
      "loss before training is 0.002852813571302815 -- epoch number 2403\n",
      "\n",
      "\n",
      "loss before training is 0.002850008743598463 -- epoch number 2404\n",
      "\n",
      "\n",
      "loss before training is 0.002847206195151221 -- epoch number 2405\n",
      "\n",
      "\n",
      "loss before training is 0.002844405923797497 -- epoch number 2406\n",
      "\n",
      "\n",
      "loss before training is 0.002841607927379355 -- epoch number 2407\n",
      "\n",
      "\n",
      "loss before training is 0.0028388122037444428 -- epoch number 2408\n",
      "\n",
      "\n",
      "loss before training is 0.0028360187507460288 -- epoch number 2409\n",
      "\n",
      "\n",
      "loss before training is 0.002833227566242959 -- epoch number 2410\n",
      "\n",
      "\n",
      "loss before training is 0.002830438648099629 -- epoch number 2411\n",
      "\n",
      "\n",
      "loss before training is 0.0028276519941859775 -- epoch number 2412\n",
      "\n",
      "\n",
      "loss before training is 0.0028248676023774743 -- epoch number 2413\n",
      "\n",
      "\n",
      "loss before training is 0.0028220854705550647 -- epoch number 2414\n",
      "\n",
      "\n",
      "loss before training is 0.002819305596605179 -- epoch number 2415\n",
      "\n",
      "\n",
      "loss before training is 0.002816527978419728 -- epoch number 2416\n",
      "\n",
      "\n",
      "loss before training is 0.002813752613896048 -- epoch number 2417\n",
      "\n",
      "\n",
      "loss before training is 0.0028109795009368947 -- epoch number 2418\n",
      "\n",
      "\n",
      "loss before training is 0.002808208637450437 -- epoch number 2419\n",
      "\n",
      "\n",
      "loss before training is 0.002805440021350211 -- epoch number 2420\n",
      "\n",
      "\n",
      "loss before training is 0.0028026736505551413 -- epoch number 2421\n",
      "\n",
      "\n",
      "loss before training is 0.0027999095229894596 -- epoch number 2422\n",
      "\n",
      "\n",
      "loss before training is 0.0027971476365827703 -- epoch number 2423\n",
      "\n",
      "\n",
      "loss before training is 0.0027943879892699426 -- epoch number 2424\n",
      "\n",
      "\n",
      "loss before training is 0.002791630578991157 -- epoch number 2425\n",
      "\n",
      "\n",
      "loss before training is 0.002788875403691867 -- epoch number 2426\n",
      "\n",
      "\n",
      "loss before training is 0.002786122461322752 -- epoch number 2427\n",
      "\n",
      "\n",
      "loss before training is 0.0027833717498397478 -- epoch number 2428\n",
      "\n",
      "\n",
      "loss before training is 0.0027806232672039936 -- epoch number 2429\n",
      "\n",
      "\n",
      "loss before training is 0.002777877011381804 -- epoch number 2430\n",
      "\n",
      "\n",
      "loss before training is 0.0027751329803447186 -- epoch number 2431\n",
      "\n",
      "\n",
      "loss before training is 0.00277239117206938 -- epoch number 2432\n",
      "\n",
      "\n",
      "loss before training is 0.0027696515845376003 -- epoch number 2433\n",
      "\n",
      "\n",
      "loss before training is 0.0027669142157362983 -- epoch number 2434\n",
      "\n",
      "\n",
      "loss before training is 0.002764179063657505 -- epoch number 2435\n",
      "\n",
      "\n",
      "loss before training is 0.002761446126298344 -- epoch number 2436\n",
      "\n",
      "\n",
      "loss before training is 0.002758715401660972 -- epoch number 2437\n",
      "\n",
      "\n",
      "loss before training is 0.00275598688775261 -- epoch number 2438\n",
      "\n",
      "\n",
      "loss before training is 0.0027532605825855185 -- epoch number 2439\n",
      "\n",
      "\n",
      "loss before training is 0.0027505364841769802 -- epoch number 2440\n",
      "\n",
      "\n",
      "loss before training is 0.0027478145905492075 -- epoch number 2441\n",
      "\n",
      "\n",
      "loss before training is 0.0027450948997294676 -- epoch number 2442\n",
      "\n",
      "\n",
      "loss before training is 0.002742377409749935 -- epoch number 2443\n",
      "\n",
      "\n",
      "loss before training is 0.002739662118647752 -- epoch number 2444\n",
      "\n",
      "\n",
      "loss before training is 0.002736949024464946 -- epoch number 2445\n",
      "\n",
      "\n",
      "loss before training is 0.0027342381252484847 -- epoch number 2446\n",
      "\n",
      "\n",
      "loss before training is 0.0027315294190502146 -- epoch number 2447\n",
      "\n",
      "\n",
      "loss before training is 0.0027288229039268267 -- epoch number 2448\n",
      "\n",
      "\n",
      "loss before training is 0.0027261185779398913 -- epoch number 2449\n",
      "\n",
      "\n",
      "loss before training is 0.002723416439155811 -- epoch number 2450\n",
      "\n",
      "\n",
      "loss before training is 0.002720716485645783 -- epoch number 2451\n",
      "\n",
      "\n",
      "loss before training is 0.002718018715485822 -- epoch number 2452\n",
      "\n",
      "\n",
      "loss before training is 0.0027153231267567175 -- epoch number 2453\n",
      "\n",
      "\n",
      "loss before training is 0.0027126297175440158 -- epoch number 2454\n",
      "\n",
      "\n",
      "loss before training is 0.00270993848593803 -- epoch number 2455\n",
      "\n",
      "\n",
      "loss before training is 0.0027072494300337895 -- epoch number 2456\n",
      "\n",
      "\n",
      "loss before training is 0.0027045625479310336 -- epoch number 2457\n",
      "\n",
      "\n",
      "loss before training is 0.002701877837734219 -- epoch number 2458\n",
      "\n",
      "\n",
      "loss before training is 0.002699195297552435 -- epoch number 2459\n",
      "\n",
      "\n",
      "loss before training is 0.0026965149254994853 -- epoch number 2460\n",
      "\n",
      "\n",
      "loss before training is 0.0026938367196937775 -- epoch number 2461\n",
      "\n",
      "\n",
      "loss before training is 0.002691160678258375 -- epoch number 2462\n",
      "\n",
      "\n",
      "loss before training is 0.0026884867993209466 -- epoch number 2463\n",
      "\n",
      "\n",
      "loss before training is 0.0026858150810137402 -- epoch number 2464\n",
      "\n",
      "\n",
      "loss before training is 0.0026831455214735974 -- epoch number 2465\n",
      "\n",
      "\n",
      "loss before training is 0.0026804781188419203 -- epoch number 2466\n",
      "\n",
      "\n",
      "loss before training is 0.0026778128712646354 -- epoch number 2467\n",
      "\n",
      "\n",
      "loss before training is 0.0026751497768922224 -- epoch number 2468\n",
      "\n",
      "\n",
      "loss before training is 0.0026724888338796587 -- epoch number 2469\n",
      "\n",
      "\n",
      "loss before training is 0.002669830040386423 -- epoch number 2470\n",
      "\n",
      "\n",
      "loss before training is 0.002667173394576468 -- epoch number 2471\n",
      "\n",
      "\n",
      "loss before training is 0.0026645188946182105 -- epoch number 2472\n",
      "\n",
      "\n",
      "loss before training is 0.0026618665386845233 -- epoch number 2473\n",
      "\n",
      "\n",
      "loss before training is 0.002659216324952671 -- epoch number 2474\n",
      "\n",
      "\n",
      "loss before training is 0.0026565682516043903 -- epoch number 2475\n",
      "\n",
      "\n",
      "loss before training is 0.002653922316825762 -- epoch number 2476\n",
      "\n",
      "\n",
      "loss before training is 0.0026512785188072888 -- epoch number 2477\n",
      "\n",
      "\n",
      "loss before training is 0.002648636855743811 -- epoch number 2478\n",
      "\n",
      "\n",
      "loss before training is 0.002645997325834525 -- epoch number 2479\n",
      "\n",
      "\n",
      "loss before training is 0.0026433599272829736 -- epoch number 2480\n",
      "\n",
      "\n",
      "loss before training is 0.0026407246582969956 -- epoch number 2481\n",
      "\n",
      "\n",
      "loss before training is 0.002638091517088761 -- epoch number 2482\n",
      "\n",
      "\n",
      "loss before training is 0.002635460501874684 -- epoch number 2483\n",
      "\n",
      "\n",
      "loss before training is 0.0026328316108754912 -- epoch number 2484\n",
      "\n",
      "\n",
      "loss before training is 0.002630204842316144 -- epoch number 2485\n",
      "\n",
      "\n",
      "loss before training is 0.002627580194425829 -- epoch number 2486\n",
      "\n",
      "\n",
      "loss before training is 0.0026249576654379858 -- epoch number 2487\n",
      "\n",
      "\n",
      "loss before training is 0.0026223372535902484 -- epoch number 2488\n",
      "\n",
      "\n",
      "loss before training is 0.002619718957124434 -- epoch number 2489\n",
      "\n",
      "\n",
      "loss before training is 0.0026171027742865442 -- epoch number 2490\n",
      "\n",
      "\n",
      "loss before training is 0.002614488703326743 -- epoch number 2491\n",
      "\n",
      "\n",
      "loss before training is 0.0026118767424993515 -- epoch number 2492\n",
      "\n",
      "\n",
      "loss before training is 0.0026092668900627902 -- epoch number 2493\n",
      "\n",
      "\n",
      "loss before training is 0.002606659144279634 -- epoch number 2494\n",
      "\n",
      "\n",
      "loss before training is 0.0026040535034165214 -- epoch number 2495\n",
      "\n",
      "\n",
      "loss before training is 0.0026014499657442116 -- epoch number 2496\n",
      "\n",
      "\n",
      "loss before training is 0.0025988485295375 -- epoch number 2497\n",
      "\n",
      "\n",
      "loss before training is 0.00259624919307527 -- epoch number 2498\n",
      "\n",
      "\n",
      "loss before training is 0.002593651954640415 -- epoch number 2499\n",
      "\n",
      "\n",
      "loss before training is 0.002591056812519864 -- epoch number 2500\n",
      "\n",
      "\n",
      "loss before training is 0.0025884637650045684 -- epoch number 2501\n",
      "\n",
      "\n",
      "loss before training is 0.002585872810389467 -- epoch number 2502\n",
      "\n",
      "\n",
      "loss before training is 0.0025832839469734684 -- epoch number 2503\n",
      "\n",
      "\n",
      "loss before training is 0.002580697173059466 -- epoch number 2504\n",
      "\n",
      "\n",
      "loss before training is 0.002578112486954287 -- epoch number 2505\n",
      "\n",
      "\n",
      "loss before training is 0.0025755298869687008 -- epoch number 2506\n",
      "\n",
      "\n",
      "loss before training is 0.0025729493714174005 -- epoch number 2507\n",
      "\n",
      "\n",
      "loss before training is 0.0025703709386189965 -- epoch number 2508\n",
      "\n",
      "\n",
      "loss before training is 0.002567794586895963 -- epoch number 2509\n",
      "\n",
      "\n",
      "loss before training is 0.0025652203145746823 -- epoch number 2510\n",
      "\n",
      "\n",
      "loss before training is 0.002562648119985392 -- epoch number 2511\n",
      "\n",
      "\n",
      "loss before training is 0.0025600780014621563 -- epoch number 2512\n",
      "\n",
      "\n",
      "loss before training is 0.00255750995734291 -- epoch number 2513\n",
      "\n",
      "\n",
      "loss before training is 0.0025549439859693795 -- epoch number 2514\n",
      "\n",
      "\n",
      "loss before training is 0.0025523800856871097 -- epoch number 2515\n",
      "\n",
      "\n",
      "loss before training is 0.002549818254845443 -- epoch number 2516\n",
      "\n",
      "\n",
      "loss before training is 0.0025472584917974953 -- epoch number 2517\n",
      "\n",
      "\n",
      "loss before training is 0.0025447007949001284 -- epoch number 2518\n",
      "\n",
      "\n",
      "loss before training is 0.0025421451625139845 -- epoch number 2519\n",
      "\n",
      "\n",
      "loss before training is 0.0025395915930034214 -- epoch number 2520\n",
      "\n",
      "\n",
      "loss before training is 0.0025370400847365237 -- epoch number 2521\n",
      "\n",
      "\n",
      "loss before training is 0.002534490636085072 -- epoch number 2522\n",
      "\n",
      "\n",
      "loss before training is 0.0025319432454245644 -- epoch number 2523\n",
      "\n",
      "\n",
      "loss before training is 0.002529397911134157 -- epoch number 2524\n",
      "\n",
      "\n",
      "loss before training is 0.002526854631596687 -- epoch number 2525\n",
      "\n",
      "\n",
      "loss before training is 0.0025243134051986357 -- epoch number 2526\n",
      "\n",
      "\n",
      "loss before training is 0.002521774230330118 -- epoch number 2527\n",
      "\n",
      "\n",
      "loss before training is 0.0025192371053848793 -- epoch number 2528\n",
      "\n",
      "\n",
      "loss before training is 0.0025167020287602845 -- epoch number 2529\n",
      "\n",
      "\n",
      "loss before training is 0.002514168998857279 -- epoch number 2530\n",
      "\n",
      "\n",
      "loss before training is 0.0025116380140803997 -- epoch number 2531\n",
      "\n",
      "\n",
      "loss before training is 0.002509109072837753 -- epoch number 2532\n",
      "\n",
      "\n",
      "loss before training is 0.002506582173541015 -- epoch number 2533\n",
      "\n",
      "\n",
      "loss before training is 0.0025040573146053804 -- epoch number 2534\n",
      "\n",
      "\n",
      "loss before training is 0.0025015344944495895 -- epoch number 2535\n",
      "\n",
      "\n",
      "loss before training is 0.0024990137114958956 -- epoch number 2536\n",
      "\n",
      "\n",
      "loss before training is 0.002496494964170055 -- epoch number 2537\n",
      "\n",
      "\n",
      "loss before training is 0.0024939782509013175 -- epoch number 2538\n",
      "\n",
      "\n",
      "loss before training is 0.0024914635701224082 -- epoch number 2539\n",
      "\n",
      "\n",
      "loss before training is 0.0024889509202695157 -- epoch number 2540\n",
      "\n",
      "\n",
      "loss before training is 0.002486440299782263 -- epoch number 2541\n",
      "\n",
      "\n",
      "loss before training is 0.002483931707103741 -- epoch number 2542\n",
      "\n",
      "\n",
      "loss before training is 0.002481425140680429 -- epoch number 2543\n",
      "\n",
      "\n",
      "loss before training is 0.002478920598962266 -- epoch number 2544\n",
      "\n",
      "\n",
      "loss before training is 0.0024764180804025277 -- epoch number 2545\n",
      "\n",
      "\n",
      "loss before training is 0.00247391758345793 -- epoch number 2546\n",
      "\n",
      "\n",
      "loss before training is 0.0024714191065885235 -- epoch number 2547\n",
      "\n",
      "\n",
      "loss before training is 0.002468922648257742 -- epoch number 2548\n",
      "\n",
      "\n",
      "loss before training is 0.0024664282069323425 -- epoch number 2549\n",
      "\n",
      "\n",
      "loss before training is 0.002463935781082447 -- epoch number 2550\n",
      "\n",
      "\n",
      "loss before training is 0.0024614453691814715 -- epoch number 2551\n",
      "\n",
      "\n",
      "loss before training is 0.0024589569697061513 -- epoch number 2552\n",
      "\n",
      "\n",
      "loss before training is 0.0024564705811365092 -- epoch number 2553\n",
      "\n",
      "\n",
      "loss before training is 0.0024539862019558735 -- epoch number 2554\n",
      "\n",
      "\n",
      "loss before training is 0.0024515038306508158 -- epoch number 2555\n",
      "\n",
      "\n",
      "loss before training is 0.0024490234657111734 -- epoch number 2556\n",
      "\n",
      "\n",
      "loss before training is 0.002446545105630034 -- epoch number 2557\n",
      "\n",
      "\n",
      "loss before training is 0.00244406874890372 -- epoch number 2558\n",
      "\n",
      "\n",
      "loss before training is 0.0024415943940317777 -- epoch number 2559\n",
      "\n",
      "\n",
      "loss before training is 0.002439122039516931 -- epoch number 2560\n",
      "\n",
      "\n",
      "loss before training is 0.0024366516838651413 -- epoch number 2561\n",
      "\n",
      "\n",
      "loss before training is 0.0024341833255855324 -- epoch number 2562\n",
      "\n",
      "\n",
      "loss before training is 0.002431716963190397 -- epoch number 2563\n",
      "\n",
      "\n",
      "loss before training is 0.002429252595195189 -- epoch number 2564\n",
      "\n",
      "\n",
      "loss before training is 0.002426790220118522 -- epoch number 2565\n",
      "\n",
      "\n",
      "loss before training is 0.0024243298364821247 -- epoch number 2566\n",
      "\n",
      "\n",
      "loss before training is 0.0024218714428108487 -- epoch number 2567\n",
      "\n",
      "\n",
      "loss before training is 0.002419415037632682 -- epoch number 2568\n",
      "\n",
      "\n",
      "loss before training is 0.0024169606194786777 -- epoch number 2569\n",
      "\n",
      "\n",
      "loss before training is 0.002414508186882999 -- epoch number 2570\n",
      "\n",
      "\n",
      "loss before training is 0.0024120577383828653 -- epoch number 2571\n",
      "\n",
      "\n",
      "loss before training is 0.0024096092725185724 -- epoch number 2572\n",
      "\n",
      "\n",
      "loss before training is 0.0024071627878334673 -- epoch number 2573\n",
      "\n",
      "\n",
      "loss before training is 0.0024047182828739275 -- epoch number 2574\n",
      "\n",
      "\n",
      "loss before training is 0.002402275756189343 -- epoch number 2575\n",
      "\n",
      "\n",
      "loss before training is 0.0023998352063321466 -- epoch number 2576\n",
      "\n",
      "\n",
      "loss before training is 0.0023973966318577727 -- epoch number 2577\n",
      "\n",
      "\n",
      "loss before training is 0.0023949600313246245 -- epoch number 2578\n",
      "\n",
      "\n",
      "loss before training is 0.0023925254032940977 -- epoch number 2579\n",
      "\n",
      "\n",
      "loss before training is 0.0023900927463305624 -- epoch number 2580\n",
      "\n",
      "\n",
      "loss before training is 0.002387662059001343 -- epoch number 2581\n",
      "\n",
      "\n",
      "loss before training is 0.002385233339876695 -- epoch number 2582\n",
      "\n",
      "\n",
      "loss before training is 0.0023828065875298185 -- epoch number 2583\n",
      "\n",
      "\n",
      "loss before training is 0.002380381800536844 -- epoch number 2584\n",
      "\n",
      "\n",
      "loss before training is 0.0023779589774767925 -- epoch number 2585\n",
      "\n",
      "\n",
      "loss before training is 0.002375538116931605 -- epoch number 2586\n",
      "\n",
      "\n",
      "loss before training is 0.0023731192174860946 -- epoch number 2587\n",
      "\n",
      "\n",
      "loss before training is 0.0023707022777279584 -- epoch number 2588\n",
      "\n",
      "\n",
      "loss before training is 0.002368287296247755 -- epoch number 2589\n",
      "\n",
      "\n",
      "loss before training is 0.002365874271638907 -- epoch number 2590\n",
      "\n",
      "\n",
      "loss before training is 0.0023634632024976524 -- epoch number 2591\n",
      "\n",
      "\n",
      "loss before training is 0.0023610540874231018 -- epoch number 2592\n",
      "\n",
      "\n",
      "loss before training is 0.0023586469250171556 -- epoch number 2593\n",
      "\n",
      "\n",
      "loss before training is 0.0023562417138845246 -- epoch number 2594\n",
      "\n",
      "\n",
      "loss before training is 0.0023538384526327356 -- epoch number 2595\n",
      "\n",
      "\n",
      "loss before training is 0.002351437139872084 -- epoch number 2596\n",
      "\n",
      "\n",
      "loss before training is 0.0023490377742156543 -- epoch number 2597\n",
      "\n",
      "\n",
      "loss before training is 0.0023466403542792866 -- epoch number 2598\n",
      "\n",
      "\n",
      "loss before training is 0.00234424487868158 -- epoch number 2599\n",
      "\n",
      "\n",
      "loss before training is 0.002341851346043874 -- epoch number 2600\n",
      "\n",
      "\n",
      "loss before training is 0.0023394597549902395 -- epoch number 2601\n",
      "\n",
      "\n",
      "loss before training is 0.00233707010414749 -- epoch number 2602\n",
      "\n",
      "\n",
      "loss before training is 0.0023346823921451066 -- epoch number 2603\n",
      "\n",
      "\n",
      "loss before training is 0.002332296617615306 -- epoch number 2604\n",
      "\n",
      "\n",
      "loss before training is 0.002329912779192986 -- epoch number 2605\n",
      "\n",
      "\n",
      "loss before training is 0.002327530875515714 -- epoch number 2606\n",
      "\n",
      "\n",
      "loss before training is 0.0023251509052237287 -- epoch number 2607\n",
      "\n",
      "\n",
      "loss before training is 0.0023227728669599373 -- epoch number 2608\n",
      "\n",
      "\n",
      "loss before training is 0.002320396759369873 -- epoch number 2609\n",
      "\n",
      "\n",
      "loss before training is 0.0023180225811017183 -- epoch number 2610\n",
      "\n",
      "\n",
      "loss before training is 0.0023156503308062767 -- epoch number 2611\n",
      "\n",
      "\n",
      "loss before training is 0.002313280007136974 -- epoch number 2612\n",
      "\n",
      "\n",
      "loss before training is 0.0023109116087498298 -- epoch number 2613\n",
      "\n",
      "\n",
      "loss before training is 0.002308545134303477 -- epoch number 2614\n",
      "\n",
      "\n",
      "loss before training is 0.0023061805824590963 -- epoch number 2615\n",
      "\n",
      "\n",
      "loss before training is 0.002303817951880469 -- epoch number 2616\n",
      "\n",
      "\n",
      "loss before training is 0.0023014572412339337 -- epoch number 2617\n",
      "\n",
      "\n",
      "loss before training is 0.0022990984491883925 -- epoch number 2618\n",
      "\n",
      "\n",
      "loss before training is 0.0022967415744152564 -- epoch number 2619\n",
      "\n",
      "\n",
      "loss before training is 0.0022943866155885014 -- epoch number 2620\n",
      "\n",
      "\n",
      "loss before training is 0.0022920335713846134 -- epoch number 2621\n",
      "\n",
      "\n",
      "loss before training is 0.002289682440482589 -- epoch number 2622\n",
      "\n",
      "\n",
      "loss before training is 0.0022873332215639307 -- epoch number 2623\n",
      "\n",
      "\n",
      "loss before training is 0.00228498591331262 -- epoch number 2624\n",
      "\n",
      "\n",
      "loss before training is 0.002282640514415139 -- epoch number 2625\n",
      "\n",
      "\n",
      "loss before training is 0.002280297023560418 -- epoch number 2626\n",
      "\n",
      "\n",
      "loss before training is 0.0022779554394398768 -- epoch number 2627\n",
      "\n",
      "\n",
      "loss before training is 0.002275615760747359 -- epoch number 2628\n",
      "\n",
      "\n",
      "loss before training is 0.0022732779861791737 -- epoch number 2629\n",
      "\n",
      "\n",
      "loss before training is 0.0022709421144340393 -- epoch number 2630\n",
      "\n",
      "\n",
      "loss before training is 0.0022686081442131003 -- epoch number 2631\n",
      "\n",
      "\n",
      "loss before training is 0.002266276074219934 -- epoch number 2632\n",
      "\n",
      "\n",
      "loss before training is 0.0022639459031604824 -- epoch number 2633\n",
      "\n",
      "\n",
      "loss before training is 0.0022616176297431166 -- epoch number 2634\n",
      "\n",
      "\n",
      "loss before training is 0.0022592912526785704 -- epoch number 2635\n",
      "\n",
      "\n",
      "loss before training is 0.002256966770679948 -- epoch number 2636\n",
      "\n",
      "\n",
      "loss before training is 0.0022546441824627308 -- epoch number 2637\n",
      "\n",
      "\n",
      "loss before training is 0.0022523234867447405 -- epoch number 2638\n",
      "\n",
      "\n",
      "loss before training is 0.002250004682246136 -- epoch number 2639\n",
      "\n",
      "\n",
      "loss before training is 0.002247687767689439 -- epoch number 2640\n",
      "\n",
      "\n",
      "loss before training is 0.0022453727417994624 -- epoch number 2641\n",
      "\n",
      "\n",
      "loss before training is 0.0022430596033033608 -- epoch number 2642\n",
      "\n",
      "\n",
      "loss before training is 0.00224074835093057 -- epoch number 2643\n",
      "\n",
      "\n",
      "loss before training is 0.0022384389834128426 -- epoch number 2644\n",
      "\n",
      "\n",
      "loss before training is 0.0022361314994842124 -- epoch number 2645\n",
      "\n",
      "\n",
      "loss before training is 0.002233825897880963 -- epoch number 2646\n",
      "\n",
      "\n",
      "loss before training is 0.0022315221773416896 -- epoch number 2647\n",
      "\n",
      "\n",
      "loss before training is 0.0022292203366072265 -- epoch number 2648\n",
      "\n",
      "\n",
      "loss before training is 0.0022269203744206536 -- epoch number 2649\n",
      "\n",
      "\n",
      "loss before training is 0.0022246222895272753 -- epoch number 2650\n",
      "\n",
      "\n",
      "loss before training is 0.002222326080674661 -- epoch number 2651\n",
      "\n",
      "\n",
      "loss before training is 0.0022200317466125733 -- epoch number 2652\n",
      "\n",
      "\n",
      "loss before training is 0.0022177392860930085 -- epoch number 2653\n",
      "\n",
      "\n",
      "loss before training is 0.002215448697870146 -- epoch number 2654\n",
      "\n",
      "\n",
      "loss before training is 0.0022131599807003605 -- epoch number 2655\n",
      "\n",
      "\n",
      "loss before training is 0.002210873133342235 -- epoch number 2656\n",
      "\n",
      "\n",
      "loss before training is 0.002208588154556496 -- epoch number 2657\n",
      "\n",
      "\n",
      "loss before training is 0.002206305043106055 -- epoch number 2658\n",
      "\n",
      "\n",
      "loss before training is 0.002204023797755971 -- epoch number 2659\n",
      "\n",
      "\n",
      "loss before training is 0.002201744417273475 -- epoch number 2660\n",
      "\n",
      "\n",
      "loss before training is 0.0021994669004278913 -- epoch number 2661\n",
      "\n",
      "\n",
      "loss before training is 0.002197191245990724 -- epoch number 2662\n",
      "\n",
      "\n",
      "loss before training is 0.0021949174527355723 -- epoch number 2663\n",
      "\n",
      "\n",
      "loss before training is 0.0021926455194381427 -- epoch number 2664\n",
      "\n",
      "\n",
      "loss before training is 0.002190375444876278 -- epoch number 2665\n",
      "\n",
      "\n",
      "loss before training is 0.0021881072278298664 -- epoch number 2666\n",
      "\n",
      "\n",
      "loss before training is 0.002185840867080922 -- epoch number 2667\n",
      "\n",
      "\n",
      "loss before training is 0.002183576361413534 -- epoch number 2668\n",
      "\n",
      "\n",
      "loss before training is 0.0021813137096138246 -- epoch number 2669\n",
      "\n",
      "\n",
      "loss before training is 0.0021790529104700218 -- epoch number 2670\n",
      "\n",
      "\n",
      "loss before training is 0.002176793962772384 -- epoch number 2671\n",
      "\n",
      "\n",
      "loss before training is 0.0021745368653132017 -- epoch number 2672\n",
      "\n",
      "\n",
      "loss before training is 0.002172281616886809 -- epoch number 2673\n",
      "\n",
      "\n",
      "loss before training is 0.002170028216289579 -- epoch number 2674\n",
      "\n",
      "\n",
      "loss before training is 0.0021677766623198866 -- epoch number 2675\n",
      "\n",
      "\n",
      "loss before training is 0.002165526953778104 -- epoch number 2676\n",
      "\n",
      "\n",
      "loss before training is 0.0021632790894666296 -- epoch number 2677\n",
      "\n",
      "\n",
      "loss before training is 0.002161033068189834 -- epoch number 2678\n",
      "\n",
      "\n",
      "loss before training is 0.0021587888887540864 -- epoch number 2679\n",
      "\n",
      "\n",
      "loss before training is 0.002156546549967707 -- epoch number 2680\n",
      "\n",
      "\n",
      "loss before training is 0.002154306050640998 -- epoch number 2681\n",
      "\n",
      "\n",
      "loss before training is 0.0021520673895862263 -- epoch number 2682\n",
      "\n",
      "\n",
      "loss before training is 0.002149830565617592 -- epoch number 2683\n",
      "\n",
      "\n",
      "loss before training is 0.002147595577551248 -- epoch number 2684\n",
      "\n",
      "\n",
      "loss before training is 0.0021453624242052617 -- epoch number 2685\n",
      "\n",
      "\n",
      "loss before training is 0.0021431311043996525 -- epoch number 2686\n",
      "\n",
      "\n",
      "loss before training is 0.00214090161695633 -- epoch number 2687\n",
      "\n",
      "\n",
      "loss before training is 0.002138673960699141 -- epoch number 2688\n",
      "\n",
      "\n",
      "loss before training is 0.002136448134453785 -- epoch number 2689\n",
      "\n",
      "\n",
      "loss before training is 0.0021342241370479165 -- epoch number 2690\n",
      "\n",
      "\n",
      "loss before training is 0.0021320019673110174 -- epoch number 2691\n",
      "\n",
      "\n",
      "loss before training is 0.00212978162407447 -- epoch number 2692\n",
      "\n",
      "\n",
      "loss before training is 0.00212756310617152 -- epoch number 2693\n",
      "\n",
      "\n",
      "loss before training is 0.00212534641243728 -- epoch number 2694\n",
      "\n",
      "\n",
      "loss before training is 0.0021231315417087077 -- epoch number 2695\n",
      "\n",
      "\n",
      "loss before training is 0.0021209184928246 -- epoch number 2696\n",
      "\n",
      "\n",
      "loss before training is 0.00211870726462559 -- epoch number 2697\n",
      "\n",
      "\n",
      "loss before training is 0.002116497855954148 -- epoch number 2698\n",
      "\n",
      "\n",
      "loss before training is 0.0021142902656545457 -- epoch number 2699\n",
      "\n",
      "\n",
      "loss before training is 0.0021120844925728893 -- epoch number 2700\n",
      "\n",
      "\n",
      "loss before training is 0.0021098805355570702 -- epoch number 2701\n",
      "\n",
      "\n",
      "loss before training is 0.002107678393456789 -- epoch number 2702\n",
      "\n",
      "\n",
      "loss before training is 0.0021054780651235225 -- epoch number 2703\n",
      "\n",
      "\n",
      "loss before training is 0.0021032795494105305 -- epoch number 2704\n",
      "\n",
      "\n",
      "loss before training is 0.002101082845172855 -- epoch number 2705\n",
      "\n",
      "\n",
      "loss before training is 0.0020988879512672904 -- epoch number 2706\n",
      "\n",
      "\n",
      "loss before training is 0.00209669486655239 -- epoch number 2707\n",
      "\n",
      "\n",
      "loss before training is 0.002094503589888474 -- epoch number 2708\n",
      "\n",
      "\n",
      "loss before training is 0.0020923141201375783 -- epoch number 2709\n",
      "\n",
      "\n",
      "loss before training is 0.0020901264561634836 -- epoch number 2710\n",
      "\n",
      "\n",
      "loss before training is 0.00208794059683171 -- epoch number 2711\n",
      "\n",
      "\n",
      "loss before training is 0.0020857565410094805 -- epoch number 2712\n",
      "\n",
      "\n",
      "loss before training is 0.0020835742875657337 -- epoch number 2713\n",
      "\n",
      "\n",
      "loss before training is 0.002081393835371101 -- epoch number 2714\n",
      "\n",
      "\n",
      "loss before training is 0.002079215183297937 -- epoch number 2715\n",
      "\n",
      "\n",
      "loss before training is 0.002077038330220272 -- epoch number 2716\n",
      "\n",
      "\n",
      "loss before training is 0.0020748632750138 -- epoch number 2717\n",
      "\n",
      "\n",
      "loss before training is 0.002072690016555924 -- epoch number 2718\n",
      "\n",
      "\n",
      "loss before training is 0.002070518553725675 -- epoch number 2719\n",
      "\n",
      "\n",
      "loss before training is 0.002068348885403781 -- epoch number 2720\n",
      "\n",
      "\n",
      "loss before training is 0.002066181010472598 -- epoch number 2721\n",
      "\n",
      "\n",
      "loss before training is 0.0020640149278161224 -- epoch number 2722\n",
      "\n",
      "\n",
      "loss before training is 0.00206185063632001 -- epoch number 2723\n",
      "\n",
      "\n",
      "loss before training is 0.0020596881348715237 -- epoch number 2724\n",
      "\n",
      "\n",
      "loss before training is 0.0020575274223595644 -- epoch number 2725\n",
      "\n",
      "\n",
      "loss before training is 0.0020553684976746555 -- epoch number 2726\n",
      "\n",
      "\n",
      "loss before training is 0.002053211359708901 -- epoch number 2727\n",
      "\n",
      "\n",
      "loss before training is 0.002051056007356028 -- epoch number 2728\n",
      "\n",
      "\n",
      "loss before training is 0.002048902439511363 -- epoch number 2729\n",
      "\n",
      "\n",
      "loss before training is 0.002046750655071785 -- epoch number 2730\n",
      "\n",
      "\n",
      "loss before training is 0.0020446006529358 -- epoch number 2731\n",
      "\n",
      "\n",
      "loss before training is 0.002042452432003443 -- epoch number 2732\n",
      "\n",
      "\n",
      "loss before training is 0.002040305991176349 -- epoch number 2733\n",
      "\n",
      "\n",
      "loss before training is 0.0020381613293576906 -- epoch number 2734\n",
      "\n",
      "\n",
      "loss before training is 0.0020360184454521965 -- epoch number 2735\n",
      "\n",
      "\n",
      "loss before training is 0.002033877338366144 -- epoch number 2736\n",
      "\n",
      "\n",
      "loss before training is 0.0020317380070073512 -- epoch number 2737\n",
      "\n",
      "\n",
      "loss before training is 0.0020296004502851537 -- epoch number 2738\n",
      "\n",
      "\n",
      "loss before training is 0.002027464667110429 -- epoch number 2739\n",
      "\n",
      "\n",
      "loss before training is 0.0020253306563955418 -- epoch number 2740\n",
      "\n",
      "\n",
      "loss before training is 0.0020231984170544157 -- epoch number 2741\n",
      "\n",
      "\n",
      "loss before training is 0.0020210679480024175 -- epoch number 2742\n",
      "\n",
      "\n",
      "loss before training is 0.0020189392481564606 -- epoch number 2743\n",
      "\n",
      "\n",
      "loss before training is 0.002016812316434926 -- epoch number 2744\n",
      "\n",
      "\n",
      "loss before training is 0.0020146871517576718 -- epoch number 2745\n",
      "\n",
      "\n",
      "loss before training is 0.002012563753046044 -- epoch number 2746\n",
      "\n",
      "\n",
      "loss before training is 0.0020104421192228563 -- epoch number 2747\n",
      "\n",
      "\n",
      "loss before training is 0.0020083222492123893 -- epoch number 2748\n",
      "\n",
      "\n",
      "loss before training is 0.002006204141940362 -- epoch number 2749\n",
      "\n",
      "\n",
      "loss before training is 0.002004087796333955 -- epoch number 2750\n",
      "\n",
      "\n",
      "loss before training is 0.002001973211321788 -- epoch number 2751\n",
      "\n",
      "\n",
      "loss before training is 0.001999860385833931 -- epoch number 2752\n",
      "\n",
      "\n",
      "loss before training is 0.0019977493188018613 -- epoch number 2753\n",
      "\n",
      "\n",
      "loss before training is 0.0019956400091584925 -- epoch number 2754\n",
      "\n",
      "\n",
      "loss before training is 0.0019935324558381508 -- epoch number 2755\n",
      "\n",
      "\n",
      "loss before training is 0.0019914266577765673 -- epoch number 2756\n",
      "\n",
      "\n",
      "loss before training is 0.0019893226139108973 -- epoch number 2757\n",
      "\n",
      "\n",
      "loss before training is 0.001987220323179663 -- epoch number 2758\n",
      "\n",
      "\n",
      "loss before training is 0.0019851197845227983 -- epoch number 2759\n",
      "\n",
      "\n",
      "loss before training is 0.001983020996881608 -- epoch number 2760\n",
      "\n",
      "\n",
      "loss before training is 0.0019809239591987763 -- epoch number 2761\n",
      "\n",
      "\n",
      "loss before training is 0.001978828670418375 -- epoch number 2762\n",
      "\n",
      "\n",
      "loss before training is 0.0019767351294858308 -- epoch number 2763\n",
      "\n",
      "\n",
      "loss before training is 0.0019746433353479108 -- epoch number 2764\n",
      "\n",
      "\n",
      "loss before training is 0.0019725532869527516 -- epoch number 2765\n",
      "\n",
      "\n",
      "loss before training is 0.00197046498324985 -- epoch number 2766\n",
      "\n",
      "\n",
      "loss before training is 0.0019683784231900136 -- epoch number 2767\n",
      "\n",
      "\n",
      "loss before training is 0.0019662936057253987 -- epoch number 2768\n",
      "\n",
      "\n",
      "loss before training is 0.0019642105298094898 -- epoch number 2769\n",
      "\n",
      "\n",
      "loss before training is 0.00196212919439708 -- epoch number 2770\n",
      "\n",
      "\n",
      "loss before training is 0.0019600495984442826 -- epoch number 2771\n",
      "\n",
      "\n",
      "loss before training is 0.0019579717409085404 -- epoch number 2772\n",
      "\n",
      "\n",
      "loss before training is 0.001955895620748563 -- epoch number 2773\n",
      "\n",
      "\n",
      "loss before training is 0.001953821236924371 -- epoch number 2774\n",
      "\n",
      "\n",
      "loss before training is 0.001951748588397294 -- epoch number 2775\n",
      "\n",
      "\n",
      "loss before training is 0.0019496776741299224 -- epoch number 2776\n",
      "\n",
      "\n",
      "loss before training is 0.0019476084930861218 -- epoch number 2777\n",
      "\n",
      "\n",
      "loss before training is 0.0019455410442310445 -- epoch number 2778\n",
      "\n",
      "\n",
      "loss before training is 0.001943475326531109 -- epoch number 2779\n",
      "\n",
      "\n",
      "loss before training is 0.0019414113389539832 -- epoch number 2780\n",
      "\n",
      "\n",
      "loss before training is 0.0019393490804685924 -- epoch number 2781\n",
      "\n",
      "\n",
      "loss before training is 0.0019372885500451168 -- epoch number 2782\n",
      "\n",
      "\n",
      "loss before training is 0.0019352297466549676 -- epoch number 2783\n",
      "\n",
      "\n",
      "loss before training is 0.0019331726692708023 -- epoch number 2784\n",
      "\n",
      "\n",
      "loss before training is 0.001931117316866493 -- epoch number 2785\n",
      "\n",
      "\n",
      "loss before training is 0.0019290636884171535 -- epoch number 2786\n",
      "\n",
      "\n",
      "loss before training is 0.0019270117828991155 -- epoch number 2787\n",
      "\n",
      "\n",
      "loss before training is 0.001924961599289916 -- epoch number 2788\n",
      "\n",
      "\n",
      "loss before training is 0.0019229131365682886 -- epoch number 2789\n",
      "\n",
      "\n",
      "loss before training is 0.0019208663937141926 -- epoch number 2790\n",
      "\n",
      "\n",
      "loss before training is 0.0019188213697087658 -- epoch number 2791\n",
      "\n",
      "\n",
      "loss before training is 0.001916778063534337 -- epoch number 2792\n",
      "\n",
      "\n",
      "loss before training is 0.0019147364741744254 -- epoch number 2793\n",
      "\n",
      "\n",
      "loss before training is 0.0019126966006137187 -- epoch number 2794\n",
      "\n",
      "\n",
      "loss before training is 0.0019106584418380895 -- epoch number 2795\n",
      "\n",
      "\n",
      "loss before training is 0.001908621996834556 -- epoch number 2796\n",
      "\n",
      "\n",
      "loss before training is 0.0019065872645913364 -- epoch number 2797\n",
      "\n",
      "\n",
      "loss before training is 0.0019045542440977521 -- epoch number 2798\n",
      "\n",
      "\n",
      "loss before training is 0.00190252293434432 -- epoch number 2799\n",
      "\n",
      "\n",
      "loss before training is 0.001900493334322674 -- epoch number 2800\n",
      "\n",
      "\n",
      "loss before training is 0.001898465443025609 -- epoch number 2801\n",
      "\n",
      "\n",
      "loss before training is 0.001896439259447027 -- epoch number 2802\n",
      "\n",
      "\n",
      "loss before training is 0.0018944147825819798 -- epoch number 2803\n",
      "\n",
      "\n",
      "loss before training is 0.0018923920114266185 -- epoch number 2804\n",
      "\n",
      "\n",
      "loss before training is 0.001890370944978235 -- epoch number 2805\n",
      "\n",
      "\n",
      "loss before training is 0.0018883515822352313 -- epoch number 2806\n",
      "\n",
      "\n",
      "loss before training is 0.0018863339221970898 -- epoch number 2807\n",
      "\n",
      "\n",
      "loss before training is 0.001884317963864412 -- epoch number 2808\n",
      "\n",
      "\n",
      "loss before training is 0.0018823037062389082 -- epoch number 2809\n",
      "\n",
      "\n",
      "loss before training is 0.0018802911483233376 -- epoch number 2810\n",
      "\n",
      "\n",
      "loss before training is 0.0018782802891215858 -- epoch number 2811\n",
      "\n",
      "\n",
      "loss before training is 0.0018762711276385903 -- epoch number 2812\n",
      "\n",
      "\n",
      "loss before training is 0.0018742636628803766 -- epoch number 2813\n",
      "\n",
      "\n",
      "loss before training is 0.0018722578938540238 -- epoch number 2814\n",
      "\n",
      "\n",
      "loss before training is 0.0018702538195676968 -- epoch number 2815\n",
      "\n",
      "\n",
      "loss before training is 0.0018682514390305958 -- epoch number 2816\n",
      "\n",
      "\n",
      "loss before training is 0.0018662507512529737 -- epoch number 2817\n",
      "\n",
      "\n",
      "loss before training is 0.001864251755246159 -- epoch number 2818\n",
      "\n",
      "\n",
      "loss before training is 0.00186225445002249 -- epoch number 2819\n",
      "\n",
      "\n",
      "loss before training is 0.0018602588345953486 -- epoch number 2820\n",
      "\n",
      "\n",
      "loss before training is 0.0018582649079791622 -- epoch number 2821\n",
      "\n",
      "\n",
      "loss before training is 0.0018562726691893708 -- epoch number 2822\n",
      "\n",
      "\n",
      "loss before training is 0.0018542821172424424 -- epoch number 2823\n",
      "\n",
      "\n",
      "loss before training is 0.0018522932511558594 -- epoch number 2824\n",
      "\n",
      "\n",
      "loss before training is 0.0018503060699481167 -- epoch number 2825\n",
      "\n",
      "\n",
      "loss before training is 0.0018483205726387132 -- epoch number 2826\n",
      "\n",
      "\n",
      "loss before training is 0.001846336758248139 -- epoch number 2827\n",
      "\n",
      "\n",
      "loss before training is 0.001844354625797904 -- epoch number 2828\n",
      "\n",
      "\n",
      "loss before training is 0.0018423741743104933 -- epoch number 2829\n",
      "\n",
      "\n",
      "loss before training is 0.001840395402809376 -- epoch number 2830\n",
      "\n",
      "\n",
      "loss before training is 0.0018384183103189976 -- epoch number 2831\n",
      "\n",
      "\n",
      "loss before training is 0.0018364428958648031 -- epoch number 2832\n",
      "\n",
      "\n",
      "loss before training is 0.0018344691584731838 -- epoch number 2833\n",
      "\n",
      "\n",
      "loss before training is 0.001832497097171502 -- epoch number 2834\n",
      "\n",
      "\n",
      "loss before training is 0.001830526710988096 -- epoch number 2835\n",
      "\n",
      "\n",
      "loss before training is 0.0018285579989522518 -- epoch number 2836\n",
      "\n",
      "\n",
      "loss before training is 0.0018265909600941894 -- epoch number 2837\n",
      "\n",
      "\n",
      "loss before training is 0.0018246255934450959 -- epoch number 2838\n",
      "\n",
      "\n",
      "loss before training is 0.001822661898037097 -- epoch number 2839\n",
      "\n",
      "\n",
      "loss before training is 0.0018206998729032504 -- epoch number 2840\n",
      "\n",
      "\n",
      "loss before training is 0.0018187395170775444 -- epoch number 2841\n",
      "\n",
      "\n",
      "loss before training is 0.0018167808295949108 -- epoch number 2842\n",
      "\n",
      "\n",
      "loss before training is 0.0018148238094911721 -- epoch number 2843\n",
      "\n",
      "\n",
      "loss before training is 0.0018128684558030967 -- epoch number 2844\n",
      "\n",
      "\n",
      "loss before training is 0.0018109147675683614 -- epoch number 2845\n",
      "\n",
      "\n",
      "loss before training is 0.001808962743825536 -- epoch number 2846\n",
      "\n",
      "\n",
      "loss before training is 0.001807012383614107 -- epoch number 2847\n",
      "\n",
      "\n",
      "loss before training is 0.0018050636859744712 -- epoch number 2848\n",
      "\n",
      "\n",
      "loss before training is 0.0018031166499478785 -- epoch number 2849\n",
      "\n",
      "\n",
      "loss before training is 0.001801171274576523 -- epoch number 2850\n",
      "\n",
      "\n",
      "loss before training is 0.0017992275589034305 -- epoch number 2851\n",
      "\n",
      "\n",
      "loss before training is 0.0017972855019725469 -- epoch number 2852\n",
      "\n",
      "\n",
      "loss before training is 0.0017953451028286708 -- epoch number 2853\n",
      "\n",
      "\n",
      "loss before training is 0.0017934063605174841 -- epoch number 2854\n",
      "\n",
      "\n",
      "loss before training is 0.0017914692740855337 -- epoch number 2855\n",
      "\n",
      "\n",
      "loss before training is 0.0017895338425802216 -- epoch number 2856\n",
      "\n",
      "\n",
      "loss before training is 0.0017876000650498135 -- epoch number 2857\n",
      "\n",
      "\n",
      "loss before training is 0.0017856679405434284 -- epoch number 2858\n",
      "\n",
      "\n",
      "loss before training is 0.0017837374681110255 -- epoch number 2859\n",
      "\n",
      "\n",
      "loss before training is 0.001781808646803423 -- epoch number 2860\n",
      "\n",
      "\n",
      "loss before training is 0.0017798814756722569 -- epoch number 2861\n",
      "\n",
      "\n",
      "loss before training is 0.0017779559537700231 -- epoch number 2862\n",
      "\n",
      "\n",
      "loss before training is 0.0017760320801500265 -- epoch number 2863\n",
      "\n",
      "\n",
      "loss before training is 0.0017741098538664262 -- epoch number 2864\n",
      "\n",
      "\n",
      "loss before training is 0.001772189273974162 -- epoch number 2865\n",
      "\n",
      "\n",
      "loss before training is 0.0017702703395290286 -- epoch number 2866\n",
      "\n",
      "\n",
      "loss before training is 0.001768353049587603 -- epoch number 2867\n",
      "\n",
      "\n",
      "loss before training is 0.0017664374032073122 -- epoch number 2868\n",
      "\n",
      "\n",
      "loss before training is 0.0017645233994463517 -- epoch number 2869\n",
      "\n",
      "\n",
      "loss before training is 0.0017626110373637274 -- epoch number 2870\n",
      "\n",
      "\n",
      "loss before training is 0.0017607003160192314 -- epoch number 2871\n",
      "\n",
      "\n",
      "loss before training is 0.001758791234473479 -- epoch number 2872\n",
      "\n",
      "\n",
      "loss before training is 0.0017568837917878385 -- epoch number 2873\n",
      "\n",
      "\n",
      "loss before training is 0.001754977987024482 -- epoch number 2874\n",
      "\n",
      "\n",
      "loss before training is 0.0017530738192463521 -- epoch number 2875\n",
      "\n",
      "\n",
      "loss before training is 0.001751171287517165 -- epoch number 2876\n",
      "\n",
      "\n",
      "loss before training is 0.0017492703909014055 -- epoch number 2877\n",
      "\n",
      "\n",
      "loss before training is 0.0017473711284643396 -- epoch number 2878\n",
      "\n",
      "\n",
      "loss before training is 0.00174547349927198 -- epoch number 2879\n",
      "\n",
      "\n",
      "loss before training is 0.0017435775023911032 -- epoch number 2880\n",
      "\n",
      "\n",
      "loss before training is 0.001741683136889243 -- epoch number 2881\n",
      "\n",
      "\n",
      "loss before training is 0.001739790401834668 -- epoch number 2882\n",
      "\n",
      "\n",
      "loss before training is 0.001737899296296416 -- epoch number 2883\n",
      "\n",
      "\n",
      "loss before training is 0.001736009819344246 -- epoch number 2884\n",
      "\n",
      "\n",
      "loss before training is 0.001734121970048671 -- epoch number 2885\n",
      "\n",
      "\n",
      "loss before training is 0.001732235747480929 -- epoch number 2886\n",
      "\n",
      "\n",
      "loss before training is 0.001730351150712972 -- epoch number 2887\n",
      "\n",
      "\n",
      "loss before training is 0.0017284681788175128 -- epoch number 2888\n",
      "\n",
      "\n",
      "loss before training is 0.0017265868308679582 -- epoch number 2889\n",
      "\n",
      "\n",
      "loss before training is 0.0017247071059384449 -- epoch number 2890\n",
      "\n",
      "\n",
      "loss before training is 0.0017228290031038132 -- epoch number 2891\n",
      "\n",
      "\n",
      "loss before training is 0.0017209525214396215 -- epoch number 2892\n",
      "\n",
      "\n",
      "loss before training is 0.0017190776600221273 -- epoch number 2893\n",
      "\n",
      "\n",
      "loss before training is 0.0017172044179283035 -- epoch number 2894\n",
      "\n",
      "\n",
      "loss before training is 0.0017153327942358097 -- epoch number 2895\n",
      "\n",
      "\n",
      "loss before training is 0.0017134627880229982 -- epoch number 2896\n",
      "\n",
      "\n",
      "loss before training is 0.0017115943983689085 -- epoch number 2897\n",
      "\n",
      "\n",
      "loss before training is 0.001709727624353276 -- epoch number 2898\n",
      "\n",
      "\n",
      "loss before training is 0.0017078624650565194 -- epoch number 2899\n",
      "\n",
      "\n",
      "loss before training is 0.0017059989195597342 -- epoch number 2900\n",
      "\n",
      "\n",
      "loss before training is 0.0017041369869446777 -- epoch number 2901\n",
      "\n",
      "\n",
      "loss before training is 0.0017022766662937933 -- epoch number 2902\n",
      "\n",
      "\n",
      "loss before training is 0.0017004179566901929 -- epoch number 2903\n",
      "\n",
      "\n",
      "loss before training is 0.0016985608572176374 -- epoch number 2904\n",
      "\n",
      "\n",
      "loss before training is 0.0016967053669605567 -- epoch number 2905\n",
      "\n",
      "\n",
      "loss before training is 0.0016948514850040435 -- epoch number 2906\n",
      "\n",
      "\n",
      "loss before training is 0.0016929992104338279 -- epoch number 2907\n",
      "\n",
      "\n",
      "loss before training is 0.0016911485423362952 -- epoch number 2908\n",
      "\n",
      "\n",
      "loss before training is 0.0016892994797984826 -- epoch number 2909\n",
      "\n",
      "\n",
      "loss before training is 0.00168745202190806 -- epoch number 2910\n",
      "\n",
      "\n",
      "loss before training is 0.0016856061677533337 -- epoch number 2911\n",
      "\n",
      "\n",
      "loss before training is 0.0016837619164232526 -- epoch number 2912\n",
      "\n",
      "\n",
      "loss before training is 0.0016819192670073843 -- epoch number 2913\n",
      "\n",
      "\n",
      "loss before training is 0.001680078218595934 -- epoch number 2914\n",
      "\n",
      "\n",
      "loss before training is 0.0016782387702797314 -- epoch number 2915\n",
      "\n",
      "\n",
      "loss before training is 0.0016764009211502119 -- epoch number 2916\n",
      "\n",
      "\n",
      "loss before training is 0.0016745646702994313 -- epoch number 2917\n",
      "\n",
      "\n",
      "loss before training is 0.0016727300168200645 -- epoch number 2918\n",
      "\n",
      "\n",
      "loss before training is 0.0016708969598054004 -- epoch number 2919\n",
      "\n",
      "\n",
      "loss before training is 0.0016690654983493145 -- epoch number 2920\n",
      "\n",
      "\n",
      "loss before training is 0.0016672356315462996 -- epoch number 2921\n",
      "\n",
      "\n",
      "loss before training is 0.0016654073584914408 -- epoch number 2922\n",
      "\n",
      "\n",
      "loss before training is 0.0016635806782804138 -- epoch number 2923\n",
      "\n",
      "\n",
      "loss before training is 0.001661755590009498 -- epoch number 2924\n",
      "\n",
      "\n",
      "loss before training is 0.0016599320927755555 -- epoch number 2925\n",
      "\n",
      "\n",
      "loss before training is 0.0016581101856760136 -- epoch number 2926\n",
      "\n",
      "\n",
      "loss before training is 0.0016562898678089228 -- epoch number 2927\n",
      "\n",
      "\n",
      "loss before training is 0.0016544711382728708 -- epoch number 2928\n",
      "\n",
      "\n",
      "loss before training is 0.0016526539961670408 -- epoch number 2929\n",
      "\n",
      "\n",
      "loss before training is 0.001650838440591176 -- epoch number 2930\n",
      "\n",
      "\n",
      "loss before training is 0.0016490244706456013 -- epoch number 2931\n",
      "\n",
      "\n",
      "loss before training is 0.0016472120854311794 -- epoch number 2932\n",
      "\n",
      "\n",
      "loss before training is 0.0016454012840493738 -- epoch number 2933\n",
      "\n",
      "\n",
      "loss before training is 0.0016435920656021643 -- epoch number 2934\n",
      "\n",
      "\n",
      "loss before training is 0.0016417844291921214 -- epoch number 2935\n",
      "\n",
      "\n",
      "loss before training is 0.0016399783739223354 -- epoch number 2936\n",
      "\n",
      "\n",
      "loss before training is 0.001638173898896457 -- epoch number 2937\n",
      "\n",
      "\n",
      "loss before training is 0.0016363710032186933 -- epoch number 2938\n",
      "\n",
      "\n",
      "loss before training is 0.0016345696859937694 -- epoch number 2939\n",
      "\n",
      "\n",
      "loss before training is 0.0016327699463269663 -- epoch number 2940\n",
      "\n",
      "\n",
      "loss before training is 0.00163097178332409 -- epoch number 2941\n",
      "\n",
      "\n",
      "loss before training is 0.00162917519609148 -- epoch number 2942\n",
      "\n",
      "\n",
      "loss before training is 0.0016273801837360115 -- epoch number 2943\n",
      "\n",
      "\n",
      "loss before training is 0.0016255867453650746 -- epoch number 2944\n",
      "\n",
      "\n",
      "loss before training is 0.0016237948800865785 -- epoch number 2945\n",
      "\n",
      "\n",
      "loss before training is 0.001622004587008967 -- epoch number 2946\n",
      "\n",
      "\n",
      "loss before training is 0.0016202158652411887 -- epoch number 2947\n",
      "\n",
      "\n",
      "loss before training is 0.001618428713892707 -- epoch number 2948\n",
      "\n",
      "\n",
      "loss before training is 0.0016166431320734866 -- epoch number 2949\n",
      "\n",
      "\n",
      "loss before training is 0.0016148591188940085 -- epoch number 2950\n",
      "\n",
      "\n",
      "loss before training is 0.0016130766734652605 -- epoch number 2951\n",
      "\n",
      "\n",
      "loss before training is 0.00161129579489872 -- epoch number 2952\n",
      "\n",
      "\n",
      "loss before training is 0.0016095164823063629 -- epoch number 2953\n",
      "\n",
      "\n",
      "loss before training is 0.0016077387348006585 -- epoch number 2954\n",
      "\n",
      "\n",
      "loss before training is 0.001605962551494574 -- epoch number 2955\n",
      "\n",
      "\n",
      "loss before training is 0.0016041879315015551 -- epoch number 2956\n",
      "\n",
      "\n",
      "loss before training is 0.0016024148739355482 -- epoch number 2957\n",
      "\n",
      "\n",
      "loss before training is 0.0016006433779109648 -- epoch number 2958\n",
      "\n",
      "\n",
      "loss before training is 0.0015988734425427037 -- epoch number 2959\n",
      "\n",
      "\n",
      "loss before training is 0.0015971050669461287 -- epoch number 2960\n",
      "\n",
      "\n",
      "loss before training is 0.0015953382502370919 -- epoch number 2961\n",
      "\n",
      "\n",
      "loss before training is 0.0015935729915319097 -- epoch number 2962\n",
      "\n",
      "\n",
      "loss before training is 0.0015918092899473645 -- epoch number 2963\n",
      "\n",
      "\n",
      "loss before training is 0.001590047144600699 -- epoch number 2964\n",
      "\n",
      "\n",
      "loss before training is 0.0015882865546096223 -- epoch number 2965\n",
      "\n",
      "\n",
      "loss before training is 0.0015865275190923066 -- epoch number 2966\n",
      "\n",
      "\n",
      "loss before training is 0.0015847700371673702 -- epoch number 2967\n",
      "\n",
      "\n",
      "loss before training is 0.0015830141079538791 -- epoch number 2968\n",
      "\n",
      "\n",
      "loss before training is 0.0015812597305713725 -- epoch number 2969\n",
      "\n",
      "\n",
      "loss before training is 0.0015795069041398071 -- epoch number 2970\n",
      "\n",
      "\n",
      "loss before training is 0.0015777556277796017 -- epoch number 2971\n",
      "\n",
      "\n",
      "loss before training is 0.0015760059006116177 -- epoch number 2972\n",
      "\n",
      "\n",
      "loss before training is 0.0015742577217571492 -- epoch number 2973\n",
      "\n",
      "\n",
      "loss before training is 0.0015725110903379233 -- epoch number 2974\n",
      "\n",
      "\n",
      "loss before training is 0.0015707660054760982 -- epoch number 2975\n",
      "\n",
      "\n",
      "loss before training is 0.0015690224662942825 -- epoch number 2976\n",
      "\n",
      "\n",
      "loss before training is 0.0015672804719154862 -- epoch number 2977\n",
      "\n",
      "\n",
      "loss before training is 0.0015655400214631568 -- epoch number 2978\n",
      "\n",
      "\n",
      "loss before training is 0.0015638011140611627 -- epoch number 2979\n",
      "\n",
      "\n",
      "loss before training is 0.0015620637488337875 -- epoch number 2980\n",
      "\n",
      "\n",
      "loss before training is 0.001560327924905744 -- epoch number 2981\n",
      "\n",
      "\n",
      "loss before training is 0.0015585936414021318 -- epoch number 2982\n",
      "\n",
      "\n",
      "loss before training is 0.001556860897448499 -- epoch number 2983\n",
      "\n",
      "\n",
      "loss before training is 0.0015551296921707714 -- epoch number 2984\n",
      "\n",
      "\n",
      "loss before training is 0.0015534000246952887 -- epoch number 2985\n",
      "\n",
      "\n",
      "loss before training is 0.001551671894148803 -- epoch number 2986\n",
      "\n",
      "\n",
      "loss before training is 0.0015499452996584583 -- epoch number 2987\n",
      "\n",
      "\n",
      "loss before training is 0.0015482202403517987 -- epoch number 2988\n",
      "\n",
      "\n",
      "loss before training is 0.0015464967153567626 -- epoch number 2989\n",
      "\n",
      "\n",
      "loss before training is 0.0015447747238016812 -- epoch number 2990\n",
      "\n",
      "\n",
      "loss before training is 0.0015430542648152815 -- epoch number 2991\n",
      "\n",
      "\n",
      "loss before training is 0.001541335337526668 -- epoch number 2992\n",
      "\n",
      "\n",
      "loss before training is 0.0015396179410653366 -- epoch number 2993\n",
      "\n",
      "\n",
      "loss before training is 0.0015379020745611713 -- epoch number 2994\n",
      "\n",
      "\n",
      "loss before training is 0.0015361877371444144 -- epoch number 2995\n",
      "\n",
      "\n",
      "loss before training is 0.0015344749279457112 -- epoch number 2996\n",
      "\n",
      "\n",
      "loss before training is 0.0015327636460960787 -- epoch number 2997\n",
      "\n",
      "\n",
      "loss before training is 0.0015310538907268823 -- epoch number 2998\n",
      "\n",
      "\n",
      "loss before training is 0.0015293456609698814 -- epoch number 2999\n",
      "\n",
      "\n",
      "loss before training is 0.0015276389559571953 -- epoch number 3000\n",
      "\n",
      "\n",
      "loss before training is 0.0015259337748213142 -- epoch number 3001\n",
      "\n",
      "\n",
      "loss before training is 0.001524230116695074 -- epoch number 3002\n",
      "\n",
      "\n",
      "loss before training is 0.0015225279807116875 -- epoch number 3003\n",
      "\n",
      "\n",
      "loss before training is 0.001520827366004719 -- epoch number 3004\n",
      "\n",
      "\n",
      "loss before training is 0.0015191282717080844 -- epoch number 3005\n",
      "\n",
      "\n",
      "loss before training is 0.0015174306969560688 -- epoch number 3006\n",
      "\n",
      "\n",
      "loss before training is 0.0015157346408832808 -- epoch number 3007\n",
      "\n",
      "\n",
      "loss before training is 0.0015140401026246932 -- epoch number 3008\n",
      "\n",
      "\n",
      "loss before training is 0.0015123470813156333 -- epoch number 3009\n",
      "\n",
      "\n",
      "loss before training is 0.0015106555760917586 -- epoch number 3010\n",
      "\n",
      "\n",
      "loss before training is 0.0015089655860890637 -- epoch number 3011\n",
      "\n",
      "\n",
      "loss before training is 0.0015072771104438906 -- epoch number 3012\n",
      "\n",
      "\n",
      "loss before training is 0.0015055901482929179 -- epoch number 3013\n",
      "\n",
      "\n",
      "loss before training is 0.0015039046987731556 -- epoch number 3014\n",
      "\n",
      "\n",
      "loss before training is 0.0015022207610219428 -- epoch number 3015\n",
      "\n",
      "\n",
      "loss before training is 0.0015005383341769583 -- epoch number 3016\n",
      "\n",
      "\n",
      "loss before training is 0.0014988574173761921 -- epoch number 3017\n",
      "\n",
      "\n",
      "loss before training is 0.0014971780097579718 -- epoch number 3018\n",
      "\n",
      "\n",
      "loss before training is 0.0014955001104609486 -- epoch number 3019\n",
      "\n",
      "\n",
      "loss before training is 0.00149382371862408 -- epoch number 3020\n",
      "\n",
      "\n",
      "loss before training is 0.0014921488333866626 -- epoch number 3021\n",
      "\n",
      "\n",
      "loss before training is 0.0014904754538882744 -- epoch number 3022\n",
      "\n",
      "\n",
      "loss before training is 0.0014888035792688572 -- epoch number 3023\n",
      "\n",
      "\n",
      "loss before training is 0.001487133208668624 -- epoch number 3024\n",
      "\n",
      "\n",
      "loss before training is 0.001485464341228106 -- epoch number 3025\n",
      "\n",
      "\n",
      "loss before training is 0.0014837969760881531 -- epoch number 3026\n",
      "\n",
      "\n",
      "loss before training is 0.0014821311123899054 -- epoch number 3027\n",
      "\n",
      "\n",
      "loss before training is 0.0014804667492748242 -- epoch number 3028\n",
      "\n",
      "\n",
      "loss before training is 0.0014788038858846513 -- epoch number 3029\n",
      "\n",
      "\n",
      "loss before training is 0.0014771425213614472 -- epoch number 3030\n",
      "\n",
      "\n",
      "loss before training is 0.001475482654847534 -- epoch number 3031\n",
      "\n",
      "\n",
      "loss before training is 0.0014738242854855797 -- epoch number 3032\n",
      "\n",
      "\n",
      "loss before training is 0.0014721674124184949 -- epoch number 3033\n",
      "\n",
      "\n",
      "loss before training is 0.0014705120347895196 -- epoch number 3034\n",
      "\n",
      "\n",
      "loss before training is 0.0014688581517421587 -- epoch number 3035\n",
      "\n",
      "\n",
      "loss before training is 0.0014672057624202023 -- epoch number 3036\n",
      "\n",
      "\n",
      "loss before training is 0.0014655548659677367 -- epoch number 3037\n",
      "\n",
      "\n",
      "loss before training is 0.0014639054615291202 -- epoch number 3038\n",
      "\n",
      "\n",
      "loss before training is 0.0014622575482489985 -- epoch number 3039\n",
      "\n",
      "\n",
      "loss before training is 0.0014606111252722883 -- epoch number 3040\n",
      "\n",
      "\n",
      "loss before training is 0.0014589661917441949 -- epoch number 3041\n",
      "\n",
      "\n",
      "loss before training is 0.0014573227468101702 -- epoch number 3042\n",
      "\n",
      "\n",
      "loss before training is 0.0014556807896159718 -- epoch number 3043\n",
      "\n",
      "\n",
      "loss before training is 0.0014540403193076038 -- epoch number 3044\n",
      "\n",
      "\n",
      "loss before training is 0.001452401335031341 -- epoch number 3045\n",
      "\n",
      "\n",
      "loss before training is 0.0014507638359337334 -- epoch number 3046\n",
      "\n",
      "\n",
      "loss before training is 0.0014491278211615861 -- epoch number 3047\n",
      "\n",
      "\n",
      "loss before training is 0.001447493289861968 -- epoch number 3048\n",
      "\n",
      "\n",
      "loss before training is 0.001445860241182223 -- epoch number 3049\n",
      "\n",
      "\n",
      "loss before training is 0.0014442286742699219 -- epoch number 3050\n",
      "\n",
      "\n",
      "loss before training is 0.0014425985882729172 -- epoch number 3051\n",
      "\n",
      "\n",
      "loss before training is 0.0014409699823393057 -- epoch number 3052\n",
      "\n",
      "\n",
      "loss before training is 0.0014393428556174384 -- epoch number 3053\n",
      "\n",
      "\n",
      "loss before training is 0.0014377172072559197 -- epoch number 3054\n",
      "\n",
      "\n",
      "loss before training is 0.0014360930364035983 -- epoch number 3055\n",
      "\n",
      "\n",
      "loss before training is 0.0014344703422095682 -- epoch number 3056\n",
      "\n",
      "\n",
      "loss before training is 0.0014328491238231778 -- epoch number 3057\n",
      "\n",
      "\n",
      "loss before training is 0.001431229380394008 -- epoch number 3058\n",
      "\n",
      "\n",
      "loss before training is 0.0014296111110718769 -- epoch number 3059\n",
      "\n",
      "\n",
      "loss before training is 0.0014279943150068664 -- epoch number 3060\n",
      "\n",
      "\n",
      "loss before training is 0.001426378991349261 -- epoch number 3061\n",
      "\n",
      "\n",
      "loss before training is 0.0014247651392496152 -- epoch number 3062\n",
      "\n",
      "\n",
      "loss before training is 0.0014231527578586923 -- epoch number 3063\n",
      "\n",
      "\n",
      "loss before training is 0.001421541846327493 -- epoch number 3064\n",
      "\n",
      "\n",
      "loss before training is 0.0014199324038072663 -- epoch number 3065\n",
      "\n",
      "\n",
      "loss before training is 0.0014183244294494694 -- epoch number 3066\n",
      "\n",
      "\n",
      "loss before training is 0.0014167179224057922 -- epoch number 3067\n",
      "\n",
      "\n",
      "loss before training is 0.0014151128818281494 -- epoch number 3068\n",
      "\n",
      "\n",
      "loss before training is 0.0014135093068686805 -- epoch number 3069\n",
      "\n",
      "\n",
      "loss before training is 0.0014119071966797426 -- epoch number 3070\n",
      "\n",
      "\n",
      "loss before training is 0.0014103065504139215 -- epoch number 3071\n",
      "\n",
      "\n",
      "loss before training is 0.0014087073672240172 -- epoch number 3072\n",
      "\n",
      "\n",
      "loss before training is 0.0014071096462630482 -- epoch number 3073\n",
      "\n",
      "\n",
      "loss before training is 0.0014055133866842334 -- epoch number 3074\n",
      "\n",
      "\n",
      "loss before training is 0.0014039185876410206 -- epoch number 3075\n",
      "\n",
      "\n",
      "loss before training is 0.001402325248287071 -- epoch number 3076\n",
      "\n",
      "\n",
      "loss before training is 0.0014007333677762443 -- epoch number 3077\n",
      "\n",
      "\n",
      "loss before training is 0.0013991429452626211 -- epoch number 3078\n",
      "\n",
      "\n",
      "loss before training is 0.0013975539799004706 -- epoch number 3079\n",
      "\n",
      "\n",
      "loss before training is 0.001395966470844276 -- epoch number 3080\n",
      "\n",
      "\n",
      "loss before training is 0.0013943804172487377 -- epoch number 3081\n",
      "\n",
      "\n",
      "loss before training is 0.001392795818268733 -- epoch number 3082\n",
      "\n",
      "\n",
      "loss before training is 0.0013912126730593612 -- epoch number 3083\n",
      "\n",
      "\n",
      "loss before training is 0.0013896309807759 -- epoch number 3084\n",
      "\n",
      "\n",
      "loss before training is 0.0013880507405738438 -- epoch number 3085\n",
      "\n",
      "\n",
      "loss before training is 0.0013864719516088692 -- epoch number 3086\n",
      "\n",
      "\n",
      "loss before training is 0.00138489461303685 -- epoch number 3087\n",
      "\n",
      "\n",
      "loss before training is 0.0013833187240138555 -- epoch number 3088\n",
      "\n",
      "\n",
      "loss before training is 0.0013817442836961415 -- epoch number 3089\n",
      "\n",
      "\n",
      "loss before training is 0.0013801712912401463 -- epoch number 3090\n",
      "\n",
      "\n",
      "loss before training is 0.0013785997458025168 -- epoch number 3091\n",
      "\n",
      "\n",
      "loss before training is 0.0013770296465400655 -- epoch number 3092\n",
      "\n",
      "\n",
      "loss before training is 0.0013754609926097967 -- epoch number 3093\n",
      "\n",
      "\n",
      "loss before training is 0.0013738937831688964 -- epoch number 3094\n",
      "\n",
      "\n",
      "loss before training is 0.0013723280173747392 -- epoch number 3095\n",
      "\n",
      "\n",
      "loss before training is 0.0013707636943848635 -- epoch number 3096\n",
      "\n",
      "\n",
      "loss before training is 0.001369200813357015 -- epoch number 3097\n",
      "\n",
      "\n",
      "loss before training is 0.0013676393734490771 -- epoch number 3098\n",
      "\n",
      "\n",
      "loss before training is 0.001366079373819148 -- epoch number 3099\n",
      "\n",
      "\n",
      "loss before training is 0.0013645208136254703 -- epoch number 3100\n",
      "\n",
      "\n",
      "loss before training is 0.0013629636920264785 -- epoch number 3101\n",
      "\n",
      "\n",
      "loss before training is 0.001361408008180764 -- epoch number 3102\n",
      "\n",
      "\n",
      "loss before training is 0.001359853761247111 -- epoch number 3103\n",
      "\n",
      "\n",
      "loss before training is 0.0013583009503844393 -- epoch number 3104\n",
      "\n",
      "\n",
      "loss before training is 0.001356749574751861 -- epoch number 3105\n",
      "\n",
      "\n",
      "loss before training is 0.0013551996335086454 -- epoch number 3106\n",
      "\n",
      "\n",
      "loss before training is 0.0013536511258142323 -- epoch number 3107\n",
      "\n",
      "\n",
      "loss before training is 0.001352104050828206 -- epoch number 3108\n",
      "\n",
      "\n",
      "loss before training is 0.0013505584077103453 -- epoch number 3109\n",
      "\n",
      "\n",
      "loss before training is 0.0013490141956205444 -- epoch number 3110\n",
      "\n",
      "\n",
      "loss before training is 0.0013474714137189014 -- epoch number 3111\n",
      "\n",
      "\n",
      "loss before training is 0.0013459300611656437 -- epoch number 3112\n",
      "\n",
      "\n",
      "loss before training is 0.0013443901371211681 -- epoch number 3113\n",
      "\n",
      "\n",
      "loss before training is 0.0013428516407460163 -- epoch number 3114\n",
      "\n",
      "\n",
      "loss before training is 0.0013413145712008853 -- epoch number 3115\n",
      "\n",
      "\n",
      "loss before training is 0.0013397789276466377 -- epoch number 3116\n",
      "\n",
      "\n",
      "loss before training is 0.0013382447092442663 -- epoch number 3117\n",
      "\n",
      "\n",
      "loss before training is 0.001336711915154934 -- epoch number 3118\n",
      "\n",
      "\n",
      "loss before training is 0.0013351805445399323 -- epoch number 3119\n",
      "\n",
      "\n",
      "loss before training is 0.0013336505965607203 -- epoch number 3120\n",
      "\n",
      "\n",
      "loss before training is 0.0013321220703788848 -- epoch number 3121\n",
      "\n",
      "\n",
      "loss before training is 0.0013305949651561647 -- epoch number 3122\n",
      "\n",
      "\n",
      "loss before training is 0.0013290692800544436 -- epoch number 3123\n",
      "\n",
      "\n",
      "loss before training is 0.0013275450142357416 -- epoch number 3124\n",
      "\n",
      "\n",
      "loss before training is 0.001326022166862238 -- epoch number 3125\n",
      "\n",
      "\n",
      "loss before training is 0.0013245007370962152 -- epoch number 3126\n",
      "\n",
      "\n",
      "loss before training is 0.0013229807241001354 -- epoch number 3127\n",
      "\n",
      "\n",
      "loss before training is 0.0013214621270365653 -- epoch number 3128\n",
      "\n",
      "\n",
      "loss before training is 0.0013199449450682363 -- epoch number 3129\n",
      "\n",
      "\n",
      "loss before training is 0.00131842917735798 -- epoch number 3130\n",
      "\n",
      "\n",
      "loss before training is 0.0013169148230687913 -- epoch number 3131\n",
      "\n",
      "\n",
      "loss before training is 0.0013154018813637883 -- epoch number 3132\n",
      "\n",
      "\n",
      "loss before training is 0.001313890351406213 -- epoch number 3133\n",
      "\n",
      "\n",
      "loss before training is 0.0013123802323594508 -- epoch number 3134\n",
      "\n",
      "\n",
      "loss before training is 0.0013108715233870016 -- epoch number 3135\n",
      "\n",
      "\n",
      "loss before training is 0.0013093642236524994 -- epoch number 3136\n",
      "\n",
      "\n",
      "loss before training is 0.0013078583323197117 -- epoch number 3137\n",
      "\n",
      "\n",
      "loss before training is 0.001306353848552524 -- epoch number 3138\n",
      "\n",
      "\n",
      "loss before training is 0.0013048507715149433 -- epoch number 3139\n",
      "\n",
      "\n",
      "loss before training is 0.001303349100371105 -- epoch number 3140\n",
      "\n",
      "\n",
      "loss before training is 0.0013018488342852674 -- epoch number 3141\n",
      "\n",
      "\n",
      "loss before training is 0.0013003499724218073 -- epoch number 3142\n",
      "\n",
      "\n",
      "loss before training is 0.0012988525139452207 -- epoch number 3143\n",
      "\n",
      "\n",
      "loss before training is 0.0012973564580201274 -- epoch number 3144\n",
      "\n",
      "\n",
      "loss before training is 0.001295861803811256 -- epoch number 3145\n",
      "\n",
      "\n",
      "loss before training is 0.001294368550483463 -- epoch number 3146\n",
      "\n",
      "\n",
      "loss before training is 0.0012928766972017144 -- epoch number 3147\n",
      "\n",
      "\n",
      "loss before training is 0.0012913862431310828 -- epoch number 3148\n",
      "\n",
      "\n",
      "loss before training is 0.0012898971874367741 -- epoch number 3149\n",
      "\n",
      "\n",
      "loss before training is 0.0012884095292840898 -- epoch number 3150\n",
      "\n",
      "\n",
      "loss before training is 0.001286923267838444 -- epoch number 3151\n",
      "\n",
      "\n",
      "loss before training is 0.0012854384022653793 -- epoch number 3152\n",
      "\n",
      "\n",
      "loss before training is 0.0012839549317305236 -- epoch number 3153\n",
      "\n",
      "\n",
      "loss before training is 0.001282472855399623 -- epoch number 3154\n",
      "\n",
      "\n",
      "loss before training is 0.0012809921724385382 -- epoch number 3155\n",
      "\n",
      "\n",
      "loss before training is 0.0012795128820132285 -- epoch number 3156\n",
      "\n",
      "\n",
      "loss before training is 0.001278034983289761 -- epoch number 3157\n",
      "\n",
      "\n",
      "loss before training is 0.0012765584754343003 -- epoch number 3158\n",
      "\n",
      "\n",
      "loss before training is 0.0012750833576131268 -- epoch number 3159\n",
      "\n",
      "\n",
      "loss before training is 0.0012736096289926134 -- epoch number 3160\n",
      "\n",
      "\n",
      "loss before training is 0.0012721372887392432 -- epoch number 3161\n",
      "\n",
      "\n",
      "loss before training is 0.0012706663360195969 -- epoch number 3162\n",
      "\n",
      "\n",
      "loss before training is 0.001269196770000342 -- epoch number 3163\n",
      "\n",
      "\n",
      "loss before training is 0.0012677285898482708 -- epoch number 3164\n",
      "\n",
      "\n",
      "loss before training is 0.0012662617947302455 -- epoch number 3165\n",
      "\n",
      "\n",
      "loss before training is 0.0012647963838132504 -- epoch number 3166\n",
      "\n",
      "\n",
      "loss before training is 0.0012633323562643427 -- epoch number 3167\n",
      "\n",
      "\n",
      "loss before training is 0.0012618697112506958 -- epoch number 3168\n",
      "\n",
      "\n",
      "loss before training is 0.0012604084479395643 -- epoch number 3169\n",
      "\n",
      "\n",
      "loss before training is 0.0012589485654982962 -- epoch number 3170\n",
      "\n",
      "\n",
      "loss before training is 0.0012574900630943357 -- epoch number 3171\n",
      "\n",
      "\n",
      "loss before training is 0.0012560329398952287 -- epoch number 3172\n",
      "\n",
      "\n",
      "loss before training is 0.0012545771950685856 -- epoch number 3173\n",
      "\n",
      "\n",
      "loss before training is 0.0012531228277821273 -- epoch number 3174\n",
      "\n",
      "\n",
      "loss before training is 0.0012516698372036662 -- epoch number 3175\n",
      "\n",
      "\n",
      "loss before training is 0.0012502182225010827 -- epoch number 3176\n",
      "\n",
      "\n",
      "loss before training is 0.001248767982842364 -- epoch number 3177\n",
      "\n",
      "\n",
      "loss before training is 0.0012473191173955802 -- epoch number 3178\n",
      "\n",
      "\n",
      "loss before training is 0.0012458716253288772 -- epoch number 3179\n",
      "\n",
      "\n",
      "loss before training is 0.0012444255058104885 -- epoch number 3180\n",
      "\n",
      "\n",
      "loss before training is 0.0012429807580087457 -- epoch number 3181\n",
      "\n",
      "\n",
      "loss before training is 0.0012415373810920492 -- epoch number 3182\n",
      "\n",
      "\n",
      "loss before training is 0.0012400953742288826 -- epoch number 3183\n",
      "\n",
      "\n",
      "loss before training is 0.0012386547365878173 -- epoch number 3184\n",
      "\n",
      "\n",
      "loss before training is 0.0012372154673374969 -- epoch number 3185\n",
      "\n",
      "\n",
      "loss before training is 0.0012357775656466597 -- epoch number 3186\n",
      "\n",
      "\n",
      "loss before training is 0.0012343410306841082 -- epoch number 3187\n",
      "\n",
      "\n",
      "loss before training is 0.0012329058616187267 -- epoch number 3188\n",
      "\n",
      "\n",
      "loss before training is 0.0012314720576194883 -- epoch number 3189\n",
      "\n",
      "\n",
      "loss before training is 0.0012300396178554279 -- epoch number 3190\n",
      "\n",
      "\n",
      "loss before training is 0.0012286085414956636 -- epoch number 3191\n",
      "\n",
      "\n",
      "loss before training is 0.0012271788277093952 -- epoch number 3192\n",
      "\n",
      "\n",
      "loss before training is 0.0012257504756658776 -- epoch number 3193\n",
      "\n",
      "\n",
      "loss before training is 0.001224323484534469 -- epoch number 3194\n",
      "\n",
      "\n",
      "loss before training is 0.001222897853484576 -- epoch number 3195\n",
      "\n",
      "\n",
      "loss before training is 0.001221473581685682 -- epoch number 3196\n",
      "\n",
      "\n",
      "loss before training is 0.0012200506683073635 -- epoch number 3197\n",
      "\n",
      "\n",
      "loss before training is 0.001218629112519232 -- epoch number 3198\n",
      "\n",
      "\n",
      "loss before training is 0.0012172089134910057 -- epoch number 3199\n",
      "\n",
      "\n",
      "loss before training is 0.0012157900703924482 -- epoch number 3200\n",
      "\n",
      "\n",
      "loss before training is 0.001214372582393403 -- epoch number 3201\n",
      "\n",
      "\n",
      "loss before training is 0.0012129564486637713 -- epoch number 3202\n",
      "\n",
      "\n",
      "loss before training is 0.0012115416683735455 -- epoch number 3203\n",
      "\n",
      "\n",
      "loss before training is 0.0012101282406927546 -- epoch number 3204\n",
      "\n",
      "\n",
      "loss before training is 0.0012087161647915245 -- epoch number 3205\n",
      "\n",
      "\n",
      "loss before training is 0.0012073054398400187 -- epoch number 3206\n",
      "\n",
      "\n",
      "loss before training is 0.0012058960650084916 -- epoch number 3207\n",
      "\n",
      "\n",
      "loss before training is 0.001204488039467236 -- epoch number 3208\n",
      "\n",
      "\n",
      "loss before training is 0.0012030813623866246 -- epoch number 3209\n",
      "\n",
      "\n",
      "loss before training is 0.0012016760329371043 -- epoch number 3210\n",
      "\n",
      "\n",
      "loss before training is 0.0012002720502891607 -- epoch number 3211\n",
      "\n",
      "\n",
      "loss before training is 0.0011988694136133527 -- epoch number 3212\n",
      "\n",
      "\n",
      "loss before training is 0.0011974681220803065 -- epoch number 3213\n",
      "\n",
      "\n",
      "loss before training is 0.0011960681748606982 -- epoch number 3214\n",
      "\n",
      "\n",
      "loss before training is 0.001194669571125269 -- epoch number 3215\n",
      "\n",
      "\n",
      "loss before training is 0.0011932723100448195 -- epoch number 3216\n",
      "\n",
      "\n",
      "loss before training is 0.0011918763907902115 -- epoch number 3217\n",
      "\n",
      "\n",
      "loss before training is 0.0011904818125323658 -- epoch number 3218\n",
      "\n",
      "\n",
      "loss before training is 0.0011890885744422603 -- epoch number 3219\n",
      "\n",
      "\n",
      "loss before training is 0.0011876966756909258 -- epoch number 3220\n",
      "\n",
      "\n",
      "loss before training is 0.0011863061154494556 -- epoch number 3221\n",
      "\n",
      "\n",
      "loss before training is 0.001184916892888996 -- epoch number 3222\n",
      "\n",
      "\n",
      "loss before training is 0.0011835290071807495 -- epoch number 3223\n",
      "\n",
      "\n",
      "loss before training is 0.0011821424574959822 -- epoch number 3224\n",
      "\n",
      "\n",
      "loss before training is 0.0011807572430059914 -- epoch number 3225\n",
      "\n",
      "\n",
      "loss before training is 0.0011793733628821651 -- epoch number 3226\n",
      "\n",
      "\n",
      "loss before training is 0.0011779908162959105 -- epoch number 3227\n",
      "\n",
      "\n",
      "loss before training is 0.0011766096024187062 -- epoch number 3228\n",
      "\n",
      "\n",
      "loss before training is 0.0011752297204220836 -- epoch number 3229\n",
      "\n",
      "\n",
      "loss before training is 0.0011738511694776158 -- epoch number 3230\n",
      "\n",
      "\n",
      "loss before training is 0.00117247394875694 -- epoch number 3231\n",
      "\n",
      "\n",
      "loss before training is 0.0011710980574317366 -- epoch number 3232\n",
      "\n",
      "\n",
      "loss before training is 0.0011697234946737357 -- epoch number 3233\n",
      "\n",
      "\n",
      "loss before training is 0.0011683502596547238 -- epoch number 3234\n",
      "\n",
      "\n",
      "loss before training is 0.0011669783515465334 -- epoch number 3235\n",
      "\n",
      "\n",
      "loss before training is 0.0011656077695210462 -- epoch number 3236\n",
      "\n",
      "\n",
      "loss before training is 0.0011642385127501969 -- epoch number 3237\n",
      "\n",
      "\n",
      "loss before training is 0.0011628705804059625 -- epoch number 3238\n",
      "\n",
      "\n",
      "loss before training is 0.0011615039716603678 -- epoch number 3239\n",
      "\n",
      "\n",
      "loss before training is 0.0011601386856854973 -- epoch number 3240\n",
      "\n",
      "\n",
      "loss before training is 0.0011587747216534605 -- epoch number 3241\n",
      "\n",
      "\n",
      "loss before training is 0.0011574120787364393 -- epoch number 3242\n",
      "\n",
      "\n",
      "loss before training is 0.0011560507561066422 -- epoch number 3243\n",
      "\n",
      "\n",
      "loss before training is 0.0011546907529363312 -- epoch number 3244\n",
      "\n",
      "\n",
      "loss before training is 0.0011533320683978084 -- epoch number 3245\n",
      "\n",
      "\n",
      "loss before training is 0.0011519747016634305 -- epoch number 3246\n",
      "\n",
      "\n",
      "loss before training is 0.0011506186519055976 -- epoch number 3247\n",
      "\n",
      "\n",
      "loss before training is 0.0011492639182967435 -- epoch number 3248\n",
      "\n",
      "\n",
      "loss before training is 0.0011479105000093478 -- epoch number 3249\n",
      "\n",
      "\n",
      "loss before training is 0.0011465583962159463 -- epoch number 3250\n",
      "\n",
      "\n",
      "loss before training is 0.00114520760608911 -- epoch number 3251\n",
      "\n",
      "\n",
      "loss before training is 0.0011438581288014437 -- epoch number 3252\n",
      "\n",
      "\n",
      "loss before training is 0.001142509963525613 -- epoch number 3253\n",
      "\n",
      "\n",
      "loss before training is 0.0011411631094343027 -- epoch number 3254\n",
      "\n",
      "\n",
      "loss before training is 0.0011398175657002566 -- epoch number 3255\n",
      "\n",
      "\n",
      "loss before training is 0.0011384733314962602 -- epoch number 3256\n",
      "\n",
      "\n",
      "loss before training is 0.0011371304059951317 -- epoch number 3257\n",
      "\n",
      "\n",
      "loss before training is 0.0011357887883697228 -- epoch number 3258\n",
      "\n",
      "\n",
      "loss before training is 0.0011344484777929436 -- epoch number 3259\n",
      "\n",
      "\n",
      "loss before training is 0.0011331094734377406 -- epoch number 3260\n",
      "\n",
      "\n",
      "loss before training is 0.001131771774477086 -- epoch number 3261\n",
      "\n",
      "\n",
      "loss before training is 0.0011304353800839998 -- epoch number 3262\n",
      "\n",
      "\n",
      "loss before training is 0.0011291002894315456 -- epoch number 3263\n",
      "\n",
      "\n",
      "loss before training is 0.0011277665016928133 -- epoch number 3264\n",
      "\n",
      "\n",
      "loss before training is 0.0011264340160409391 -- epoch number 3265\n",
      "\n",
      "\n",
      "loss before training is 0.0011251028316491094 -- epoch number 3266\n",
      "\n",
      "\n",
      "loss before training is 0.001123772947690519 -- epoch number 3267\n",
      "\n",
      "\n",
      "loss before training is 0.0011224443633384284 -- epoch number 3268\n",
      "\n",
      "\n",
      "loss before training is 0.0011211170777661141 -- epoch number 3269\n",
      "\n",
      "\n",
      "loss before training is 0.001119791090146904 -- epoch number 3270\n",
      "\n",
      "\n",
      "loss before training is 0.0011184663996541546 -- epoch number 3271\n",
      "\n",
      "\n",
      "loss before training is 0.0011171430054612555 -- epoch number 3272\n",
      "\n",
      "\n",
      "loss before training is 0.001115820906741654 -- epoch number 3273\n",
      "\n",
      "\n",
      "loss before training is 0.0011145001026688043 -- epoch number 3274\n",
      "\n",
      "\n",
      "loss before training is 0.0011131805924162054 -- epoch number 3275\n",
      "\n",
      "\n",
      "loss before training is 0.0011118623751574018 -- epoch number 3276\n",
      "\n",
      "\n",
      "loss before training is 0.0011105454500659672 -- epoch number 3277\n",
      "\n",
      "\n",
      "loss before training is 0.001109229816315502 -- epoch number 3278\n",
      "\n",
      "\n",
      "loss before training is 0.0011079154730796556 -- epoch number 3279\n",
      "\n",
      "\n",
      "loss before training is 0.0011066024195320935 -- epoch number 3280\n",
      "\n",
      "\n",
      "loss before training is 0.0011052906548465378 -- epoch number 3281\n",
      "\n",
      "\n",
      "loss before training is 0.0011039801781967198 -- epoch number 3282\n",
      "\n",
      "\n",
      "loss before training is 0.0011026709887564227 -- epoch number 3283\n",
      "\n",
      "\n",
      "loss before training is 0.0011013630856994668 -- epoch number 3284\n",
      "\n",
      "\n",
      "loss before training is 0.0011000564681996762 -- epoch number 3285\n",
      "\n",
      "\n",
      "loss before training is 0.0010987511354309425 -- epoch number 3286\n",
      "\n",
      "\n",
      "loss before training is 0.0010974470865671685 -- epoch number 3287\n",
      "\n",
      "\n",
      "loss before training is 0.0010961443207822975 -- epoch number 3288\n",
      "\n",
      "\n",
      "loss before training is 0.001094842837250303 -- epoch number 3289\n",
      "\n",
      "\n",
      "loss before training is 0.0010935426351451967 -- epoch number 3290\n",
      "\n",
      "\n",
      "loss before training is 0.0010922437136410177 -- epoch number 3291\n",
      "\n",
      "\n",
      "loss before training is 0.001090946071911827 -- epoch number 3292\n",
      "\n",
      "\n",
      "loss before training is 0.0010896497091317362 -- epoch number 3293\n",
      "\n",
      "\n",
      "loss before training is 0.001088354624474876 -- epoch number 3294\n",
      "\n",
      "\n",
      "loss before training is 0.0010870608171154078 -- epoch number 3295\n",
      "\n",
      "\n",
      "loss before training is 0.0010857682862275328 -- epoch number 3296\n",
      "\n",
      "\n",
      "loss before training is 0.001084477030985474 -- epoch number 3297\n",
      "\n",
      "\n",
      "loss before training is 0.0010831870505635004 -- epoch number 3298\n",
      "\n",
      "\n",
      "loss before training is 0.0010818983441358908 -- epoch number 3299\n",
      "\n",
      "\n",
      "loss before training is 0.0010806109108769698 -- epoch number 3300\n",
      "\n",
      "\n",
      "loss before training is 0.0010793247499610824 -- epoch number 3301\n",
      "\n",
      "\n",
      "loss before training is 0.0010780398605626164 -- epoch number 3302\n",
      "\n",
      "\n",
      "loss before training is 0.001076756241855977 -- epoch number 3303\n",
      "\n",
      "\n",
      "loss before training is 0.0010754738930156104 -- epoch number 3304\n",
      "\n",
      "\n",
      "loss before training is 0.001074192813215982 -- epoch number 3305\n",
      "\n",
      "\n",
      "loss before training is 0.0010729130016315955 -- epoch number 3306\n",
      "\n",
      "\n",
      "loss before training is 0.0010716344574369886 -- epoch number 3307\n",
      "\n",
      "\n",
      "loss before training is 0.0010703571798067145 -- epoch number 3308\n",
      "\n",
      "\n",
      "loss before training is 0.0010690811679153595 -- epoch number 3309\n",
      "\n",
      "\n",
      "loss before training is 0.001067806420937551 -- epoch number 3310\n",
      "\n",
      "\n",
      "loss before training is 0.0010665329380479382 -- epoch number 3311\n",
      "\n",
      "\n",
      "loss before training is 0.0010652607184211968 -- epoch number 3312\n",
      "\n",
      "\n",
      "loss before training is 0.0010639897612320318 -- epoch number 3313\n",
      "\n",
      "\n",
      "loss before training is 0.0010627200656551867 -- epoch number 3314\n",
      "\n",
      "\n",
      "loss before training is 0.0010614516308654288 -- epoch number 3315\n",
      "\n",
      "\n",
      "loss before training is 0.0010601844560375426 -- epoch number 3316\n",
      "\n",
      "\n",
      "loss before training is 0.0010589185403463645 -- epoch number 3317\n",
      "\n",
      "\n",
      "loss before training is 0.0010576538829667461 -- epoch number 3318\n",
      "\n",
      "\n",
      "loss before training is 0.001056390483073558 -- epoch number 3319\n",
      "\n",
      "\n",
      "loss before training is 0.0010551283398417255 -- epoch number 3320\n",
      "\n",
      "\n",
      "loss before training is 0.0010538674524461784 -- epoch number 3321\n",
      "\n",
      "\n",
      "loss before training is 0.001052607820061896 -- epoch number 3322\n",
      "\n",
      "\n",
      "loss before training is 0.0010513494418638639 -- epoch number 3323\n",
      "\n",
      "\n",
      "loss before training is 0.0010500923170271158 -- epoch number 3324\n",
      "\n",
      "\n",
      "loss before training is 0.0010488364447267006 -- epoch number 3325\n",
      "\n",
      "\n",
      "loss before training is 0.0010475818241377135 -- epoch number 3326\n",
      "\n",
      "\n",
      "loss before training is 0.001046328454435254 -- epoch number 3327\n",
      "\n",
      "\n",
      "loss before training is 0.001045076334794467 -- epoch number 3328\n",
      "\n",
      "\n",
      "loss before training is 0.001043825464390525 -- epoch number 3329\n",
      "\n",
      "\n",
      "loss before training is 0.00104257584239862 -- epoch number 3330\n",
      "\n",
      "\n",
      "loss before training is 0.001041327467993983 -- epoch number 3331\n",
      "\n",
      "\n",
      "loss before training is 0.0010400803403518726 -- epoch number 3332\n",
      "\n",
      "\n",
      "loss before training is 0.0010388344586475624 -- epoch number 3333\n",
      "\n",
      "\n",
      "loss before training is 0.0010375898220563737 -- epoch number 3334\n",
      "\n",
      "\n",
      "loss before training is 0.001036346429753645 -- epoch number 3335\n",
      "\n",
      "\n",
      "loss before training is 0.0010351042809147427 -- epoch number 3336\n",
      "\n",
      "\n",
      "loss before training is 0.0010338633747150718 -- epoch number 3337\n",
      "\n",
      "\n",
      "loss before training is 0.0010326237103300572 -- epoch number 3338\n",
      "\n",
      "\n",
      "loss before training is 0.0010313852869351468 -- epoch number 3339\n",
      "\n",
      "\n",
      "loss before training is 0.0010301481037058378 -- epoch number 3340\n",
      "\n",
      "\n",
      "loss before training is 0.001028912159817633 -- epoch number 3341\n",
      "\n",
      "\n",
      "loss before training is 0.001027677454446082 -- epoch number 3342\n",
      "\n",
      "\n",
      "loss before training is 0.0010264439867667522 -- epoch number 3343\n",
      "\n",
      "\n",
      "loss before training is 0.0010252117559552422 -- epoch number 3344\n",
      "\n",
      "\n",
      "loss before training is 0.0010239807611871839 -- epoch number 3345\n",
      "\n",
      "\n",
      "loss before training is 0.0010227510016382335 -- epoch number 3346\n",
      "\n",
      "\n",
      "loss before training is 0.0010215224764840826 -- epoch number 3347\n",
      "\n",
      "\n",
      "loss before training is 0.001020295184900442 -- epoch number 3348\n",
      "\n",
      "\n",
      "loss before training is 0.0010190691260630593 -- epoch number 3349\n",
      "\n",
      "\n",
      "loss before training is 0.001017844299147709 -- epoch number 3350\n",
      "\n",
      "\n",
      "loss before training is 0.0010166207033301994 -- epoch number 3351\n",
      "\n",
      "\n",
      "loss before training is 0.0010153983377863523 -- epoch number 3352\n",
      "\n",
      "\n",
      "loss before training is 0.0010141772016920465 -- epoch number 3353\n",
      "\n",
      "\n",
      "loss before training is 0.0010129572942231691 -- epoch number 3354\n",
      "\n",
      "\n",
      "loss before training is 0.0010117386145556389 -- epoch number 3355\n",
      "\n",
      "\n",
      "loss before training is 0.001010521161865409 -- epoch number 3356\n",
      "\n",
      "\n",
      "loss before training is 0.0010093049353284626 -- epoch number 3357\n",
      "\n",
      "\n",
      "loss before training is 0.0010080899341208182 -- epoch number 3358\n",
      "\n",
      "\n",
      "loss before training is 0.0010068761574185047 -- epoch number 3359\n",
      "\n",
      "\n",
      "loss before training is 0.0010056636043976055 -- epoch number 3360\n",
      "\n",
      "\n",
      "loss before training is 0.001004452274234226 -- epoch number 3361\n",
      "\n",
      "\n",
      "loss before training is 0.001003242166104486 -- epoch number 3362\n",
      "\n",
      "\n",
      "loss before training is 0.0010020332791845646 -- epoch number 3363\n",
      "\n",
      "\n",
      "loss before training is 0.0010008256126506504 -- epoch number 3364\n",
      "\n",
      "\n",
      "loss before training is 0.0009996191656789632 -- epoch number 3365\n",
      "\n",
      "\n",
      "loss before training is 0.0009984139374457676 -- epoch number 3366\n",
      "\n",
      "\n",
      "loss before training is 0.0009972099271273478 -- epoch number 3367\n",
      "\n",
      "\n",
      "loss before training is 0.0009960071339000234 -- epoch number 3368\n",
      "\n",
      "\n",
      "loss before training is 0.000994805556940136 -- epoch number 3369\n",
      "\n",
      "\n",
      "loss before training is 0.0009936051954240858 -- epoch number 3370\n",
      "\n",
      "\n",
      "loss before training is 0.0009924060485282662 -- epoch number 3371\n",
      "\n",
      "\n",
      "loss before training is 0.0009912081154291336 -- epoch number 3372\n",
      "\n",
      "\n",
      "loss before training is 0.0009900113953031666 -- epoch number 3373\n",
      "\n",
      "\n",
      "loss before training is 0.0009888158873268655 -- epoch number 3374\n",
      "\n",
      "\n",
      "loss before training is 0.0009876215906767752 -- epoch number 3375\n",
      "\n",
      "\n",
      "loss before training is 0.000986428504529471 -- epoch number 3376\n",
      "\n",
      "\n",
      "loss before training is 0.0009852366280615622 -- epoch number 3377\n",
      "\n",
      "\n",
      "loss before training is 0.0009840459604496794 -- epoch number 3378\n",
      "\n",
      "\n",
      "loss before training is 0.000982856500870496 -- epoch number 3379\n",
      "\n",
      "\n",
      "loss before training is 0.000981668248500725 -- epoch number 3380\n",
      "\n",
      "\n",
      "loss before training is 0.0009804812025170947 -- epoch number 3381\n",
      "\n",
      "\n",
      "loss before training is 0.0009792953620963846 -- epoch number 3382\n",
      "\n",
      "\n",
      "loss before training is 0.0009781107264153982 -- epoch number 3383\n",
      "\n",
      "\n",
      "loss before training is 0.0009769272946509736 -- epoch number 3384\n",
      "\n",
      "\n",
      "loss before training is 0.0009757450659799772 -- epoch number 3385\n",
      "\n",
      "\n",
      "loss before training is 0.0009745640395793314 -- epoch number 3386\n",
      "\n",
      "\n",
      "loss before training is 0.0009733842146259695 -- epoch number 3387\n",
      "\n",
      "\n",
      "loss before training is 0.0009722055902968668 -- epoch number 3388\n",
      "\n",
      "\n",
      "loss before training is 0.0009710281657690384 -- epoch number 3389\n",
      "\n",
      "\n",
      "loss before training is 0.0009698519402195306 -- epoch number 3390\n",
      "\n",
      "\n",
      "loss before training is 0.0009686769128254256 -- epoch number 3391\n",
      "\n",
      "\n",
      "loss before training is 0.0009675030827638335 -- epoch number 3392\n",
      "\n",
      "\n",
      "loss before training is 0.0009663304492119186 -- epoch number 3393\n",
      "\n",
      "\n",
      "loss before training is 0.0009651590113468545 -- epoch number 3394\n",
      "\n",
      "\n",
      "loss before training is 0.0009639887683458824 -- epoch number 3395\n",
      "\n",
      "\n",
      "loss before training is 0.0009628197193862552 -- epoch number 3396\n",
      "\n",
      "\n",
      "loss before training is 0.000961651863645277 -- epoch number 3397\n",
      "\n",
      "\n",
      "loss before training is 0.0009604852003002708 -- epoch number 3398\n",
      "\n",
      "\n",
      "loss before training is 0.0009593197285286202 -- epoch number 3399\n",
      "\n",
      "\n",
      "loss before training is 0.0009581554475077254 -- epoch number 3400\n",
      "\n",
      "\n",
      "loss before training is 0.0009569923564150393 -- epoch number 3401\n",
      "\n",
      "\n",
      "loss before training is 0.0009558304544280463 -- epoch number 3402\n",
      "\n",
      "\n",
      "loss before training is 0.0009546697407242682 -- epoch number 3403\n",
      "\n",
      "\n",
      "loss before training is 0.0009535102144812561 -- epoch number 3404\n",
      "\n",
      "\n",
      "loss before training is 0.0009523518748766218 -- epoch number 3405\n",
      "\n",
      "\n",
      "loss before training is 0.0009511947210880025 -- epoch number 3406\n",
      "\n",
      "\n",
      "loss before training is 0.000950038752293067 -- epoch number 3407\n",
      "\n",
      "\n",
      "loss before training is 0.0009488839676695455 -- epoch number 3408\n",
      "\n",
      "\n",
      "loss before training is 0.0009477303663951748 -- epoch number 3409\n",
      "\n",
      "\n",
      "loss before training is 0.0009465779476477645 -- epoch number 3410\n",
      "\n",
      "\n",
      "loss before training is 0.0009454267106051485 -- epoch number 3411\n",
      "\n",
      "\n",
      "loss before training is 0.0009442766544452043 -- epoch number 3412\n",
      "\n",
      "\n",
      "loss before training is 0.0009431277783458463 -- epoch number 3413\n",
      "\n",
      "\n",
      "loss before training is 0.000941980081485031 -- epoch number 3414\n",
      "\n",
      "\n",
      "loss before training is 0.00094083356304076 -- epoch number 3415\n",
      "\n",
      "\n",
      "loss before training is 0.0009396882221910723 -- epoch number 3416\n",
      "\n",
      "\n",
      "loss before training is 0.0009385440581140567 -- epoch number 3417\n",
      "\n",
      "\n",
      "loss before training is 0.0009374010699878305 -- epoch number 3418\n",
      "\n",
      "\n",
      "loss before training is 0.0009362592569905621 -- epoch number 3419\n",
      "\n",
      "\n",
      "loss before training is 0.0009351186183004677 -- epoch number 3420\n",
      "\n",
      "\n",
      "loss before training is 0.0009339791530957927 -- epoch number 3421\n",
      "\n",
      "\n",
      "loss before training is 0.0009328408605548354 -- epoch number 3422\n",
      "\n",
      "\n",
      "loss before training is 0.000931703739855937 -- epoch number 3423\n",
      "\n",
      "\n",
      "loss before training is 0.0009305677901774765 -- epoch number 3424\n",
      "\n",
      "\n",
      "loss before training is 0.0009294330106978921 -- epoch number 3425\n",
      "\n",
      "\n",
      "loss before training is 0.0009282994005956435 -- epoch number 3426\n",
      "\n",
      "\n",
      "loss before training is 0.0009271669590492565 -- epoch number 3427\n",
      "\n",
      "\n",
      "loss before training is 0.0009260356852372914 -- epoch number 3428\n",
      "\n",
      "\n",
      "loss before training is 0.0009249055783383585 -- epoch number 3429\n",
      "\n",
      "\n",
      "loss before training is 0.0009237766375311006 -- epoch number 3430\n",
      "\n",
      "\n",
      "loss before training is 0.0009226488619942276 -- epoch number 3431\n",
      "\n",
      "\n",
      "loss before training is 0.0009215222509064849 -- epoch number 3432\n",
      "\n",
      "\n",
      "loss before training is 0.0009203968034466643 -- epoch number 3433\n",
      "\n",
      "\n",
      "loss before training is 0.0009192725187936035 -- epoch number 3434\n",
      "\n",
      "\n",
      "loss before training is 0.000918149396126189 -- epoch number 3435\n",
      "\n",
      "\n",
      "loss before training is 0.0009170274346233647 -- epoch number 3436\n",
      "\n",
      "\n",
      "loss before training is 0.0009159066334641019 -- epoch number 3437\n",
      "\n",
      "\n",
      "loss before training is 0.0009147869918274421 -- epoch number 3438\n",
      "\n",
      "\n",
      "loss before training is 0.0009136685088924598 -- epoch number 3439\n",
      "\n",
      "\n",
      "loss before training is 0.0009125511838382945 -- epoch number 3440\n",
      "\n",
      "\n",
      "loss before training is 0.0009114350158441147 -- epoch number 3441\n",
      "\n",
      "\n",
      "loss before training is 0.0009103200040891533 -- epoch number 3442\n",
      "\n",
      "\n",
      "loss before training is 0.0009092061477526908 -- epoch number 3443\n",
      "\n",
      "\n",
      "loss before training is 0.0009080934460140566 -- epoch number 3444\n",
      "\n",
      "\n",
      "loss before training is 0.0009069818980526284 -- epoch number 3445\n",
      "\n",
      "\n",
      "loss before training is 0.0009058715030478456 -- epoch number 3446\n",
      "\n",
      "\n",
      "loss before training is 0.0009047622601791917 -- epoch number 3447\n",
      "\n",
      "\n",
      "loss before training is 0.0009036541686261978 -- epoch number 3448\n",
      "\n",
      "\n",
      "loss before training is 0.0009025472275684531 -- epoch number 3449\n",
      "\n",
      "\n",
      "loss before training is 0.0009014414361856022 -- epoch number 3450\n",
      "\n",
      "\n",
      "loss before training is 0.0009003367936573308 -- epoch number 3451\n",
      "\n",
      "\n",
      "loss before training is 0.0008992332991633995 -- epoch number 3452\n",
      "\n",
      "\n",
      "loss before training is 0.0008981309518835993 -- epoch number 3453\n",
      "\n",
      "\n",
      "loss before training is 0.000897029750997796 -- epoch number 3454\n",
      "\n",
      "\n",
      "loss before training is 0.0008959296956858927 -- epoch number 3455\n",
      "\n",
      "\n",
      "loss before training is 0.0008948307851278583 -- epoch number 3456\n",
      "\n",
      "\n",
      "loss before training is 0.0008937330185037082 -- epoch number 3457\n",
      "\n",
      "\n",
      "loss before training is 0.0008926363949935285 -- epoch number 3458\n",
      "\n",
      "\n",
      "loss before training is 0.000891540913777445 -- epoch number 3459\n",
      "\n",
      "\n",
      "loss before training is 0.0008904465740356561 -- epoch number 3460\n",
      "\n",
      "\n",
      "loss before training is 0.0008893533749484027 -- epoch number 3461\n",
      "\n",
      "\n",
      "loss before training is 0.0008882613156959848 -- epoch number 3462\n",
      "\n",
      "\n",
      "loss before training is 0.0008871703954587745 -- epoch number 3463\n",
      "\n",
      "\n",
      "loss before training is 0.0008860806134171866 -- epoch number 3464\n",
      "\n",
      "\n",
      "loss before training is 0.0008849919687517052 -- epoch number 3465\n",
      "\n",
      "\n",
      "loss before training is 0.000883904460642856 -- epoch number 3466\n",
      "\n",
      "\n",
      "loss before training is 0.000882818088271248 -- epoch number 3467\n",
      "\n",
      "\n",
      "loss before training is 0.0008817328508175342 -- epoch number 3468\n",
      "\n",
      "\n",
      "loss before training is 0.0008806487474624329 -- epoch number 3469\n",
      "\n",
      "\n",
      "loss before training is 0.0008795657773867233 -- epoch number 3470\n",
      "\n",
      "\n",
      "loss before training is 0.0008784839397712441 -- epoch number 3471\n",
      "\n",
      "\n",
      "loss before training is 0.0008774032337968921 -- epoch number 3472\n",
      "\n",
      "\n",
      "loss before training is 0.0008763236586446355 -- epoch number 3473\n",
      "\n",
      "\n",
      "loss before training is 0.0008752452134955005 -- epoch number 3474\n",
      "\n",
      "\n",
      "loss before training is 0.0008741678975305721 -- epoch number 3475\n",
      "\n",
      "\n",
      "loss before training is 0.0008730917099309982 -- epoch number 3476\n",
      "\n",
      "\n",
      "loss before training is 0.0008720166498779981 -- epoch number 3477\n",
      "\n",
      "\n",
      "loss before training is 0.0008709427165528495 -- epoch number 3478\n",
      "\n",
      "\n",
      "loss before training is 0.0008698699091368967 -- epoch number 3479\n",
      "\n",
      "\n",
      "loss before training is 0.0008687982268115431 -- epoch number 3480\n",
      "\n",
      "\n",
      "loss before training is 0.000867727668758269 -- epoch number 3481\n",
      "\n",
      "\n",
      "loss before training is 0.0008666582341586111 -- epoch number 3482\n",
      "\n",
      "\n",
      "loss before training is 0.0008655899221941753 -- epoch number 3483\n",
      "\n",
      "\n",
      "loss before training is 0.0008645227320466381 -- epoch number 3484\n",
      "\n",
      "\n",
      "loss before training is 0.0008634566628977285 -- epoch number 3485\n",
      "\n",
      "\n",
      "loss before training is 0.0008623917139292616 -- epoch number 3486\n",
      "\n",
      "\n",
      "loss before training is 0.0008613278843231133 -- epoch number 3487\n",
      "\n",
      "\n",
      "loss before training is 0.0008602651732612257 -- epoch number 3488\n",
      "\n",
      "\n",
      "loss before training is 0.0008592035799256104 -- epoch number 3489\n",
      "\n",
      "\n",
      "loss before training is 0.0008581431034983525 -- epoch number 3490\n",
      "\n",
      "\n",
      "loss before training is 0.0008570837431616017 -- epoch number 3491\n",
      "\n",
      "\n",
      "loss before training is 0.0008560254980975805 -- epoch number 3492\n",
      "\n",
      "\n",
      "loss before training is 0.0008549683674885815 -- epoch number 3493\n",
      "\n",
      "\n",
      "loss before training is 0.0008539123505169714 -- epoch number 3494\n",
      "\n",
      "\n",
      "loss before training is 0.0008528574463651836 -- epoch number 3495\n",
      "\n",
      "\n",
      "loss before training is 0.0008518036542157327 -- epoch number 3496\n",
      "\n",
      "\n",
      "loss before training is 0.0008507509732511874 -- epoch number 3497\n",
      "\n",
      "\n",
      "loss before training is 0.0008496994026542127 -- epoch number 3498\n",
      "\n",
      "\n",
      "loss before training is 0.0008486489416075334 -- epoch number 3499\n",
      "\n",
      "\n",
      "loss before training is 0.0008475995892939503 -- epoch number 3500\n",
      "\n",
      "\n",
      "loss before training is 0.0008465513448963385 -- epoch number 3501\n",
      "\n",
      "\n",
      "loss before training is 0.0008455042075976528 -- epoch number 3502\n",
      "\n",
      "\n",
      "loss before training is 0.0008444581765809148 -- epoch number 3503\n",
      "\n",
      "\n",
      "loss before training is 0.0008434132510292303 -- epoch number 3504\n",
      "\n",
      "\n",
      "loss before training is 0.0008423694301257804 -- epoch number 3505\n",
      "\n",
      "\n",
      "loss before training is 0.0008413267130538193 -- epoch number 3506\n",
      "\n",
      "\n",
      "loss before training is 0.000840285098996677 -- epoch number 3507\n",
      "\n",
      "\n",
      "loss before training is 0.0008392445871377673 -- epoch number 3508\n",
      "\n",
      "\n",
      "loss before training is 0.0008382051766605881 -- epoch number 3509\n",
      "\n",
      "\n",
      "loss before training is 0.0008371668667486946 -- epoch number 3510\n",
      "\n",
      "\n",
      "loss before training is 0.000836129656585743 -- epoch number 3511\n",
      "\n",
      "\n",
      "loss before training is 0.00083509354535546 -- epoch number 3512\n",
      "\n",
      "\n",
      "loss before training is 0.0008340585322416527 -- epoch number 3513\n",
      "\n",
      "\n",
      "loss before training is 0.0008330246164282064 -- epoch number 3514\n",
      "\n",
      "\n",
      "loss before training is 0.0008319917970991016 -- epoch number 3515\n",
      "\n",
      "\n",
      "loss before training is 0.0008309600734383795 -- epoch number 3516\n",
      "\n",
      "\n",
      "loss before training is 0.0008299294446301834 -- epoch number 3517\n",
      "\n",
      "\n",
      "loss before training is 0.0008288999098587292 -- epoch number 3518\n",
      "\n",
      "\n",
      "loss before training is 0.0008278714683083115 -- epoch number 3519\n",
      "\n",
      "\n",
      "loss before training is 0.0008268441191633221 -- epoch number 3520\n",
      "\n",
      "\n",
      "loss before training is 0.0008258178616082248 -- epoch number 3521\n",
      "\n",
      "\n",
      "loss before training is 0.0008247926948275788 -- epoch number 3522\n",
      "\n",
      "\n",
      "loss before training is 0.0008237686180060204 -- epoch number 3523\n",
      "\n",
      "\n",
      "loss before training is 0.0008227456303282767 -- epoch number 3524\n",
      "\n",
      "\n",
      "loss before training is 0.0008217237309791573 -- epoch number 3525\n",
      "\n",
      "\n",
      "loss before training is 0.0008207029191435593 -- epoch number 3526\n",
      "\n",
      "\n",
      "loss before training is 0.0008196831940064713 -- epoch number 3527\n",
      "\n",
      "\n",
      "loss before training is 0.0008186645547529666 -- epoch number 3528\n",
      "\n",
      "\n",
      "loss before training is 0.0008176470005682118 -- epoch number 3529\n",
      "\n",
      "\n",
      "loss before training is 0.0008166305306374537 -- epoch number 3530\n",
      "\n",
      "\n",
      "loss before training is 0.0008156151441460307 -- epoch number 3531\n",
      "\n",
      "\n",
      "loss before training is 0.0008146008402793798 -- epoch number 3532\n",
      "\n",
      "\n",
      "loss before training is 0.0008135876182230163 -- epoch number 3533\n",
      "\n",
      "\n",
      "loss before training is 0.0008125754771625619 -- epoch number 3534\n",
      "\n",
      "\n",
      "loss before training is 0.0008115644162837104 -- epoch number 3535\n",
      "\n",
      "\n",
      "loss before training is 0.0008105544347722675 -- epoch number 3536\n",
      "\n",
      "\n",
      "loss before training is 0.000809545531814113 -- epoch number 3537\n",
      "\n",
      "\n",
      "loss before training is 0.0008085377065952355 -- epoch number 3538\n",
      "\n",
      "\n",
      "loss before training is 0.0008075309583017124 -- epoch number 3539\n",
      "\n",
      "\n",
      "loss before training is 0.0008065252861197095 -- epoch number 3540\n",
      "\n",
      "\n",
      "loss before training is 0.0008055206892354907 -- epoch number 3541\n",
      "\n",
      "\n",
      "loss before training is 0.0008045171668354194 -- epoch number 3542\n",
      "\n",
      "\n",
      "loss before training is 0.0008035147181059565 -- epoch number 3543\n",
      "\n",
      "\n",
      "loss before training is 0.0008025133422336455 -- epoch number 3544\n",
      "\n",
      "\n",
      "loss before training is 0.0008015130384051393 -- epoch number 3545\n",
      "\n",
      "\n",
      "loss before training is 0.0008005138058071882 -- epoch number 3546\n",
      "\n",
      "\n",
      "loss before training is 0.0007995156436266377 -- epoch number 3547\n",
      "\n",
      "\n",
      "loss before training is 0.0007985185510504251 -- epoch number 3548\n",
      "\n",
      "\n",
      "loss before training is 0.0007975225272655977 -- epoch number 3549\n",
      "\n",
      "\n",
      "loss before training is 0.0007965275714592985 -- epoch number 3550\n",
      "\n",
      "\n",
      "loss before training is 0.0007955336828187667 -- epoch number 3551\n",
      "\n",
      "\n",
      "loss before training is 0.00079454086053135 -- epoch number 3552\n",
      "\n",
      "\n",
      "loss before training is 0.0007935491037844898 -- epoch number 3553\n",
      "\n",
      "\n",
      "loss before training is 0.0007925584117657349 -- epoch number 3554\n",
      "\n",
      "\n",
      "loss before training is 0.0007915687836627358 -- epoch number 3555\n",
      "\n",
      "\n",
      "loss before training is 0.0007905802186632412 -- epoch number 3556\n",
      "\n",
      "\n",
      "loss before training is 0.0007895927159551084 -- epoch number 3557\n",
      "\n",
      "\n",
      "loss before training is 0.0007886062747262976 -- epoch number 3558\n",
      "\n",
      "\n",
      "loss before training is 0.0007876208941648667 -- epoch number 3559\n",
      "\n",
      "\n",
      "loss before training is 0.0007866365734589963 -- epoch number 3560\n",
      "\n",
      "\n",
      "loss before training is 0.000785653311796953 -- epoch number 3561\n",
      "\n",
      "\n",
      "loss before training is 0.0007846711083671224 -- epoch number 3562\n",
      "\n",
      "\n",
      "loss before training is 0.00078368996235799 -- epoch number 3563\n",
      "\n",
      "\n",
      "loss before training is 0.0007827098729581547 -- epoch number 3564\n",
      "\n",
      "\n",
      "loss before training is 0.0007817308393563196 -- epoch number 3565\n",
      "\n",
      "\n",
      "loss before training is 0.0007807528607412955 -- epoch number 3566\n",
      "\n",
      "\n",
      "loss before training is 0.0007797759363020102 -- epoch number 3567\n",
      "\n",
      "\n",
      "loss before training is 0.0007788000652274847 -- epoch number 3568\n",
      "\n",
      "\n",
      "loss before training is 0.0007778252467068619 -- epoch number 3569\n",
      "\n",
      "\n",
      "loss before training is 0.0007768514799294036 -- epoch number 3570\n",
      "\n",
      "\n",
      "loss before training is 0.0007758787640844614 -- epoch number 3571\n",
      "\n",
      "\n",
      "loss before training is 0.0007749070983615201 -- epoch number 3572\n",
      "\n",
      "\n",
      "loss before training is 0.0007739364819501645 -- epoch number 3573\n",
      "\n",
      "\n",
      "loss before training is 0.0007729669140400959 -- epoch number 3574\n",
      "\n",
      "\n",
      "loss before training is 0.0007719983938211286 -- epoch number 3575\n",
      "\n",
      "\n",
      "loss before training is 0.0007710309204831934 -- epoch number 3576\n",
      "\n",
      "\n",
      "loss before training is 0.0007700644932163294 -- epoch number 3577\n",
      "\n",
      "\n",
      "loss before training is 0.0007690991112107054 -- epoch number 3578\n",
      "\n",
      "\n",
      "loss before training is 0.0007681347736565902 -- epoch number 3579\n",
      "\n",
      "\n",
      "loss before training is 0.0007671714797443742 -- epoch number 3580\n",
      "\n",
      "\n",
      "loss before training is 0.0007662092286645709 -- epoch number 3581\n",
      "\n",
      "\n",
      "loss before training is 0.0007652480196078013 -- epoch number 3582\n",
      "\n",
      "\n",
      "loss before training is 0.0007642878517648151 -- epoch number 3583\n",
      "\n",
      "\n",
      "loss before training is 0.0007633287243264817 -- epoch number 3584\n",
      "\n",
      "\n",
      "loss before training is 0.0007623706364837737 -- epoch number 3585\n",
      "\n",
      "\n",
      "loss before training is 0.0007614135874278036 -- epoch number 3586\n",
      "\n",
      "\n",
      "loss before training is 0.000760457576349781 -- epoch number 3587\n",
      "\n",
      "\n",
      "loss before training is 0.0007595026024410695 -- epoch number 3588\n",
      "\n",
      "\n",
      "loss before training is 0.0007585486648931247 -- epoch number 3589\n",
      "\n",
      "\n",
      "loss before training is 0.0007575957628975412 -- epoch number 3590\n",
      "\n",
      "\n",
      "loss before training is 0.0007566438956460248 -- epoch number 3591\n",
      "\n",
      "\n",
      "loss before training is 0.0007556930623304257 -- epoch number 3592\n",
      "\n",
      "\n",
      "loss before training is 0.0007547432621426887 -- epoch number 3593\n",
      "\n",
      "\n",
      "loss before training is 0.0007537944942749017 -- epoch number 3594\n",
      "\n",
      "\n",
      "loss before training is 0.0007528467579192802 -- epoch number 3595\n",
      "\n",
      "\n",
      "loss before training is 0.0007519000522681627 -- epoch number 3596\n",
      "\n",
      "\n",
      "loss before training is 0.0007509543765140019 -- epoch number 3597\n",
      "\n",
      "\n",
      "loss before training is 0.0007500097298493922 -- epoch number 3598\n",
      "\n",
      "\n",
      "loss before training is 0.0007490661114670522 -- epoch number 3599\n",
      "\n",
      "\n",
      "loss before training is 0.0007481235205598266 -- epoch number 3600\n",
      "\n",
      "\n",
      "loss before training is 0.0007471819563206898 -- epoch number 3601\n",
      "\n",
      "\n",
      "loss before training is 0.0007462414179427483 -- epoch number 3602\n",
      "\n",
      "\n",
      "loss before training is 0.0007453019046192331 -- epoch number 3603\n",
      "\n",
      "\n",
      "loss before training is 0.0007443634155435085 -- epoch number 3604\n",
      "\n",
      "\n",
      "loss before training is 0.0007434259499090746 -- epoch number 3605\n",
      "\n",
      "\n",
      "loss before training is 0.0007424895069095532 -- epoch number 3606\n",
      "\n",
      "\n",
      "loss before training is 0.000741554085738713 -- epoch number 3607\n",
      "\n",
      "\n",
      "loss before training is 0.0007406196855904405 -- epoch number 3608\n",
      "\n",
      "\n",
      "loss before training is 0.0007396863056587659 -- epoch number 3609\n",
      "\n",
      "\n",
      "loss before training is 0.0007387539451378483 -- epoch number 3610\n",
      "\n",
      "\n",
      "loss before training is 0.0007378226032219908 -- epoch number 3611\n",
      "\n",
      "\n",
      "loss before training is 0.0007368922791056174 -- epoch number 3612\n",
      "\n",
      "\n",
      "loss before training is 0.0007359629719832967 -- epoch number 3613\n",
      "\n",
      "\n",
      "loss before training is 0.0007350346810497374 -- epoch number 3614\n",
      "\n",
      "\n",
      "loss before training is 0.0007341074054997801 -- epoch number 3615\n",
      "\n",
      "\n",
      "loss before training is 0.0007331811445283982 -- epoch number 3616\n",
      "\n",
      "\n",
      "loss before training is 0.0007322558973307211 -- epoch number 3617\n",
      "\n",
      "\n",
      "loss before training is 0.0007313316631019975 -- epoch number 3618\n",
      "\n",
      "\n",
      "loss before training is 0.0007304084410376284 -- epoch number 3619\n",
      "\n",
      "\n",
      "loss before training is 0.0007294862303331475 -- epoch number 3620\n",
      "\n",
      "\n",
      "loss before training is 0.0007285650301842421 -- epoch number 3621\n",
      "\n",
      "\n",
      "loss before training is 0.0007276448397867198 -- epoch number 3622\n",
      "\n",
      "\n",
      "loss before training is 0.0007267256583365543 -- epoch number 3623\n",
      "\n",
      "\n",
      "loss before training is 0.0007258074850298378 -- epoch number 3624\n",
      "\n",
      "\n",
      "loss before training is 0.0007248903190628252 -- epoch number 3625\n",
      "\n",
      "\n",
      "loss before training is 0.0007239741596319145 -- epoch number 3626\n",
      "\n",
      "\n",
      "loss before training is 0.000723059005933631 -- epoch number 3627\n",
      "\n",
      "\n",
      "loss before training is 0.0007221448571646667 -- epoch number 3628\n",
      "\n",
      "\n",
      "loss before training is 0.0007212317125218394 -- epoch number 3629\n",
      "\n",
      "\n",
      "loss before training is 0.00072031957120213 -- epoch number 3630\n",
      "\n",
      "\n",
      "loss before training is 0.0007194084324026519 -- epoch number 3631\n",
      "\n",
      "\n",
      "loss before training is 0.0007184982953206871 -- epoch number 3632\n",
      "\n",
      "\n",
      "loss before training is 0.0007175891591536447 -- epoch number 3633\n",
      "\n",
      "\n",
      "loss before training is 0.0007166810230990884 -- epoch number 3634\n",
      "\n",
      "\n",
      "loss before training is 0.0007157738863547339 -- epoch number 3635\n",
      "\n",
      "\n",
      "loss before training is 0.0007148677481184542 -- epoch number 3636\n",
      "\n",
      "\n",
      "loss before training is 0.0007139626075882612 -- epoch number 3637\n",
      "\n",
      "\n",
      "loss before training is 0.0007130584639623187 -- epoch number 3638\n",
      "\n",
      "\n",
      "loss before training is 0.0007121553164389526 -- epoch number 3639\n",
      "\n",
      "\n",
      "loss before training is 0.0007112531642166262 -- epoch number 3640\n",
      "\n",
      "\n",
      "loss before training is 0.0007103520064939773 -- epoch number 3641\n",
      "\n",
      "\n",
      "loss before training is 0.000709451842469773 -- epoch number 3642\n",
      "\n",
      "\n",
      "loss before training is 0.0007085526713429516 -- epoch number 3643\n",
      "\n",
      "\n",
      "loss before training is 0.0007076544923126059 -- epoch number 3644\n",
      "\n",
      "\n",
      "loss before training is 0.0007067573045779721 -- epoch number 3645\n",
      "\n",
      "\n",
      "loss before training is 0.0007058611073384594 -- epoch number 3646\n",
      "\n",
      "\n",
      "loss before training is 0.0007049658997936193 -- epoch number 3647\n",
      "\n",
      "\n",
      "loss before training is 0.0007040716811431687 -- epoch number 3648\n",
      "\n",
      "\n",
      "loss before training is 0.0007031784505869815 -- epoch number 3649\n",
      "\n",
      "\n",
      "loss before training is 0.0007022862073250862 -- epoch number 3650\n",
      "\n",
      "\n",
      "loss before training is 0.0007013949505576759 -- epoch number 3651\n",
      "\n",
      "\n",
      "loss before training is 0.0007005046794851075 -- epoch number 3652\n",
      "\n",
      "\n",
      "loss before training is 0.0006996153933078863 -- epoch number 3653\n",
      "\n",
      "\n",
      "loss before training is 0.0006987270912266883 -- epoch number 3654\n",
      "\n",
      "\n",
      "loss before training is 0.000697839772442344 -- epoch number 3655\n",
      "\n",
      "\n",
      "loss before training is 0.0006969534361558592 -- epoch number 3656\n",
      "\n",
      "\n",
      "loss before training is 0.000696068081568389 -- epoch number 3657\n",
      "\n",
      "\n",
      "loss before training is 0.0006951837078812604 -- epoch number 3658\n",
      "\n",
      "\n",
      "loss before training is 0.0006943003142959642 -- epoch number 3659\n",
      "\n",
      "\n",
      "loss before training is 0.0006934179000141472 -- epoch number 3660\n",
      "\n",
      "\n",
      "loss before training is 0.0006925364642376365 -- epoch number 3661\n",
      "\n",
      "\n",
      "loss before training is 0.0006916560061684144 -- epoch number 3662\n",
      "\n",
      "\n",
      "loss before training is 0.0006907765250086319 -- epoch number 3663\n",
      "\n",
      "\n",
      "loss before training is 0.0006898980199606117 -- epoch number 3664\n",
      "\n",
      "\n",
      "loss before training is 0.0006890204902268438 -- epoch number 3665\n",
      "\n",
      "\n",
      "loss before training is 0.0006881439350099806 -- epoch number 3666\n",
      "\n",
      "\n",
      "loss before training is 0.0006872683535128555 -- epoch number 3667\n",
      "\n",
      "\n",
      "loss before training is 0.0006863937449384536 -- epoch number 3668\n",
      "\n",
      "\n",
      "loss before training is 0.0006855201084899589 -- epoch number 3669\n",
      "\n",
      "\n",
      "loss before training is 0.0006846474433706932 -- epoch number 3670\n",
      "\n",
      "\n",
      "loss before training is 0.0006837757487841721 -- epoch number 3671\n",
      "\n",
      "\n",
      "loss before training is 0.000682905023934086 -- epoch number 3672\n",
      "\n",
      "\n",
      "loss before training is 0.0006820352680242832 -- epoch number 3673\n",
      "\n",
      "\n",
      "loss before training is 0.0006811664802587939 -- epoch number 3674\n",
      "\n",
      "\n",
      "loss before training is 0.000680298659841821 -- epoch number 3675\n",
      "\n",
      "\n",
      "loss before training is 0.0006794318059777519 -- epoch number 3676\n",
      "\n",
      "\n",
      "loss before training is 0.0006785659178711325 -- epoch number 3677\n",
      "\n",
      "\n",
      "loss before training is 0.0006777009947266985 -- epoch number 3678\n",
      "\n",
      "\n",
      "loss before training is 0.0006768370357493549 -- epoch number 3679\n",
      "\n",
      "\n",
      "loss before training is 0.0006759740401441862 -- epoch number 3680\n",
      "\n",
      "\n",
      "loss before training is 0.0006751120071164624 -- epoch number 3681\n",
      "\n",
      "\n",
      "loss before training is 0.0006742509358716199 -- epoch number 3682\n",
      "\n",
      "\n",
      "loss before training is 0.0006733908256152844 -- epoch number 3683\n",
      "\n",
      "\n",
      "loss before training is 0.0006725316755532563 -- epoch number 3684\n",
      "\n",
      "\n",
      "loss before training is 0.0006716734848915178 -- epoch number 3685\n",
      "\n",
      "\n",
      "loss before training is 0.0006708162528362326 -- epoch number 3686\n",
      "\n",
      "\n",
      "loss before training is 0.0006699599785937495 -- epoch number 3687\n",
      "\n",
      "\n",
      "loss before training is 0.0006691046613705914 -- epoch number 3688\n",
      "\n",
      "\n",
      "loss before training is 0.0006682503003734753 -- epoch number 3689\n",
      "\n",
      "\n",
      "loss before training is 0.000667396894809296 -- epoch number 3690\n",
      "\n",
      "\n",
      "loss before training is 0.0006665444438851328 -- epoch number 3691\n",
      "\n",
      "\n",
      "loss before training is 0.0006656929468082488 -- epoch number 3692\n",
      "\n",
      "\n",
      "loss before training is 0.0006648424027860968 -- epoch number 3693\n",
      "\n",
      "\n",
      "loss before training is 0.0006639928110263126 -- epoch number 3694\n",
      "\n",
      "\n",
      "loss before training is 0.0006631441707367216 -- epoch number 3695\n",
      "\n",
      "\n",
      "loss before training is 0.00066229648112534 -- epoch number 3696\n",
      "\n",
      "\n",
      "loss before training is 0.0006614497414003541 -- epoch number 3697\n",
      "\n",
      "\n",
      "loss before training is 0.0006606039507701669 -- epoch number 3698\n",
      "\n",
      "\n",
      "loss before training is 0.0006597591084433515 -- epoch number 3699\n",
      "\n",
      "\n",
      "loss before training is 0.0006589152136286722 -- epoch number 3700\n",
      "\n",
      "\n",
      "loss before training is 0.0006580722655350978 -- epoch number 3701\n",
      "\n",
      "\n",
      "loss before training is 0.0006572302633717712 -- epoch number 3702\n",
      "\n",
      "\n",
      "loss before training is 0.0006563892063480347 -- epoch number 3703\n",
      "\n",
      "\n",
      "loss before training is 0.0006555490936734287 -- epoch number 3704\n",
      "\n",
      "\n",
      "loss before training is 0.0006547099245576783 -- epoch number 3705\n",
      "\n",
      "\n",
      "loss before training is 0.0006538716982107044 -- epoch number 3706\n",
      "\n",
      "\n",
      "loss before training is 0.0006530344138426303 -- epoch number 3707\n",
      "\n",
      "\n",
      "loss before training is 0.0006521980706637647 -- epoch number 3708\n",
      "\n",
      "\n",
      "loss before training is 0.0006513626678846132 -- epoch number 3709\n",
      "\n",
      "\n",
      "loss before training is 0.0006505282047158808 -- epoch number 3710\n",
      "\n",
      "\n",
      "loss before training is 0.0006496946803684736 -- epoch number 3711\n",
      "\n",
      "\n",
      "loss before training is 0.0006488620940534858 -- epoch number 3712\n",
      "\n",
      "\n",
      "loss before training is 0.0006480304449822153 -- epoch number 3713\n",
      "\n",
      "\n",
      "loss before training is 0.0006471997323661545 -- epoch number 3714\n",
      "\n",
      "\n",
      "loss before training is 0.0006463699554170119 -- epoch number 3715\n",
      "\n",
      "\n",
      "loss before training is 0.0006455411133466762 -- epoch number 3716\n",
      "\n",
      "\n",
      "loss before training is 0.0006447132053672401 -- epoch number 3717\n",
      "\n",
      "\n",
      "loss before training is 0.0006438862306910098 -- epoch number 3718\n",
      "\n",
      "\n",
      "loss before training is 0.00064306018853048 -- epoch number 3719\n",
      "\n",
      "\n",
      "loss before training is 0.0006422350780983562 -- epoch number 3720\n",
      "\n",
      "\n",
      "loss before training is 0.0006414108986075432 -- epoch number 3721\n",
      "\n",
      "\n",
      "loss before training is 0.0006405876492711566 -- epoch number 3722\n",
      "\n",
      "\n",
      "loss before training is 0.000639765329302507 -- epoch number 3723\n",
      "\n",
      "\n",
      "loss before training is 0.0006389439379151133 -- epoch number 3724\n",
      "\n",
      "\n",
      "loss before training is 0.0006381234743227084 -- epoch number 3725\n",
      "\n",
      "\n",
      "loss before training is 0.0006373039377392211 -- epoch number 3726\n",
      "\n",
      "\n",
      "loss before training is 0.0006364853273787889 -- epoch number 3727\n",
      "\n",
      "\n",
      "loss before training is 0.0006356676424557628 -- epoch number 3728\n",
      "\n",
      "\n",
      "loss before training is 0.0006348508821846963 -- epoch number 3729\n",
      "\n",
      "\n",
      "loss before training is 0.0006340350457803613 -- epoch number 3730\n",
      "\n",
      "\n",
      "loss before training is 0.0006332201324577198 -- epoch number 3731\n",
      "\n",
      "\n",
      "loss before training is 0.0006324061414319672 -- epoch number 3732\n",
      "\n",
      "\n",
      "loss before training is 0.0006315930719184966 -- epoch number 3733\n",
      "\n",
      "\n",
      "loss before training is 0.0006307809231329114 -- epoch number 3734\n",
      "\n",
      "\n",
      "loss before training is 0.0006299696942910376 -- epoch number 3735\n",
      "\n",
      "\n",
      "loss before training is 0.0006291593846088998 -- epoch number 3736\n",
      "\n",
      "\n",
      "loss before training is 0.0006283499933027504 -- epoch number 3737\n",
      "\n",
      "\n",
      "loss before training is 0.0006275415195890448 -- epoch number 3738\n",
      "\n",
      "\n",
      "loss before training is 0.0006267339626844549 -- epoch number 3739\n",
      "\n",
      "\n",
      "loss before training is 0.0006259273218058755 -- epoch number 3740\n",
      "\n",
      "\n",
      "loss before training is 0.0006251215961704122 -- epoch number 3741\n",
      "\n",
      "\n",
      "loss before training is 0.0006243167849953804 -- epoch number 3742\n",
      "\n",
      "\n",
      "loss before training is 0.0006235128874983247 -- epoch number 3743\n",
      "\n",
      "\n",
      "loss before training is 0.0006227099028969996 -- epoch number 3744\n",
      "\n",
      "\n",
      "loss before training is 0.0006219078304093809 -- epoch number 3745\n",
      "\n",
      "\n",
      "loss before training is 0.0006211066692536621 -- epoch number 3746\n",
      "\n",
      "\n",
      "loss before training is 0.0006203064186482583 -- epoch number 3747\n",
      "\n",
      "\n",
      "loss before training is 0.0006195070778117997 -- epoch number 3748\n",
      "\n",
      "\n",
      "loss before training is 0.0006187086459631424 -- epoch number 3749\n",
      "\n",
      "\n",
      "loss before training is 0.0006179111223213655 -- epoch number 3750\n",
      "\n",
      "\n",
      "loss before training is 0.0006171145061057696 -- epoch number 3751\n",
      "\n",
      "\n",
      "loss before training is 0.0006163187965358666 -- epoch number 3752\n",
      "\n",
      "\n",
      "loss before training is 0.0006155239928314075 -- epoch number 3753\n",
      "\n",
      "\n",
      "loss before training is 0.0006147300942123594 -- epoch number 3754\n",
      "\n",
      "\n",
      "loss before training is 0.0006139370998989197 -- epoch number 3755\n",
      "\n",
      "\n",
      "loss before training is 0.0006131450091114951 -- epoch number 3756\n",
      "\n",
      "\n",
      "loss before training is 0.0006123538210707468 -- epoch number 3757\n",
      "\n",
      "\n",
      "loss before training is 0.0006115635349975273 -- epoch number 3758\n",
      "\n",
      "\n",
      "loss before training is 0.000610774150112951 -- epoch number 3759\n",
      "\n",
      "\n",
      "loss before training is 0.0006099856656383298 -- epoch number 3760\n",
      "\n",
      "\n",
      "loss before training is 0.0006091980807952261 -- epoch number 3761\n",
      "\n",
      "\n",
      "loss before training is 0.0006084113948054196 -- epoch number 3762\n",
      "\n",
      "\n",
      "loss before training is 0.0006076256068909213 -- epoch number 3763\n",
      "\n",
      "\n",
      "loss before training is 0.0006068407162739803 -- epoch number 3764\n",
      "\n",
      "\n",
      "loss before training is 0.0006060567221770582 -- epoch number 3765\n",
      "\n",
      "\n",
      "loss before training is 0.0006052736238228676 -- epoch number 3766\n",
      "\n",
      "\n",
      "loss before training is 0.0006044914204343474 -- epoch number 3767\n",
      "\n",
      "\n",
      "loss before training is 0.0006037101112346627 -- epoch number 3768\n",
      "\n",
      "\n",
      "loss before training is 0.0006029296954472124 -- epoch number 3769\n",
      "\n",
      "\n",
      "loss before training is 0.000602150172295644 -- epoch number 3770\n",
      "\n",
      "\n",
      "loss before training is 0.0006013715410038189 -- epoch number 3771\n",
      "\n",
      "\n",
      "loss before training is 0.0006005938007958446 -- epoch number 3772\n",
      "\n",
      "\n",
      "loss before training is 0.0005998169508960687 -- epoch number 3773\n",
      "\n",
      "\n",
      "loss before training is 0.0005990409905290652 -- epoch number 3774\n",
      "\n",
      "\n",
      "loss before training is 0.000598265918919651 -- epoch number 3775\n",
      "\n",
      "\n",
      "loss before training is 0.0005974917352928739 -- epoch number 3776\n",
      "\n",
      "\n",
      "loss before training is 0.0005967184388740314 -- epoch number 3777\n",
      "\n",
      "\n",
      "loss before training is 0.0005959460288886484 -- epoch number 3778\n",
      "\n",
      "\n",
      "loss before training is 0.0005951745045624965 -- epoch number 3779\n",
      "\n",
      "\n",
      "loss before training is 0.0005944038651215847 -- epoch number 3780\n",
      "\n",
      "\n",
      "loss before training is 0.0005936341097921634 -- epoch number 3781\n",
      "\n",
      "\n",
      "loss before training is 0.0005928652378007246 -- epoch number 3782\n",
      "\n",
      "\n",
      "loss before training is 0.0005920972483740008 -- epoch number 3783\n",
      "\n",
      "\n",
      "loss before training is 0.0005913301407389589 -- epoch number 3784\n",
      "\n",
      "\n",
      "loss before training is 0.0005905639141228292 -- epoch number 3785\n",
      "\n",
      "\n",
      "loss before training is 0.0005897985677530719 -- epoch number 3786\n",
      "\n",
      "\n",
      "loss before training is 0.0005890341008573862 -- epoch number 3787\n",
      "\n",
      "\n",
      "loss before training is 0.000588270512663733 -- epoch number 3788\n",
      "\n",
      "\n",
      "loss before training is 0.0005875078024002987 -- epoch number 3789\n",
      "\n",
      "\n",
      "loss before training is 0.000586745969295537 -- epoch number 3790\n",
      "\n",
      "\n",
      "loss before training is 0.0005859850125781277 -- epoch number 3791\n",
      "\n",
      "\n",
      "loss before training is 0.0005852249314770155 -- epoch number 3792\n",
      "\n",
      "\n",
      "loss before training is 0.0005844657252213859 -- epoch number 3793\n",
      "\n",
      "\n",
      "loss before training is 0.0005837073930406656 -- epoch number 3794\n",
      "\n",
      "\n",
      "loss before training is 0.0005829499341645423 -- epoch number 3795\n",
      "\n",
      "\n",
      "loss before training is 0.0005821933478229436 -- epoch number 3796\n",
      "\n",
      "\n",
      "loss before training is 0.0005814376332460572 -- epoch number 3797\n",
      "\n",
      "\n",
      "loss before training is 0.0005806827896643164 -- epoch number 3798\n",
      "\n",
      "\n",
      "loss before training is 0.000579928816308407 -- epoch number 3799\n",
      "\n",
      "\n",
      "loss before training is 0.0005791757124092615 -- epoch number 3800\n",
      "\n",
      "\n",
      "loss before training is 0.0005784234771980777 -- epoch number 3801\n",
      "\n",
      "\n",
      "loss before training is 0.0005776721099062946 -- epoch number 3802\n",
      "\n",
      "\n",
      "loss before training is 0.0005769216097656069 -- epoch number 3803\n",
      "\n",
      "\n",
      "loss before training is 0.0005761719760079715 -- epoch number 3804\n",
      "\n",
      "\n",
      "loss before training is 0.0005754232078655922 -- epoch number 3805\n",
      "\n",
      "\n",
      "loss before training is 0.0005746753045709379 -- epoch number 3806\n",
      "\n",
      "\n",
      "loss before training is 0.0005739282653567279 -- epoch number 3807\n",
      "\n",
      "\n",
      "loss before training is 0.000573182089455927 -- epoch number 3808\n",
      "\n",
      "\n",
      "loss before training is 0.0005724367761017824 -- epoch number 3809\n",
      "\n",
      "\n",
      "loss before training is 0.0005716923245277801 -- epoch number 3810\n",
      "\n",
      "\n",
      "loss before training is 0.0005709487339676746 -- epoch number 3811\n",
      "\n",
      "\n",
      "loss before training is 0.0005702060036554698 -- epoch number 3812\n",
      "\n",
      "\n",
      "loss before training is 0.0005694641328254437 -- epoch number 3813\n",
      "\n",
      "\n",
      "loss before training is 0.0005687231207121215 -- epoch number 3814\n",
      "\n",
      "\n",
      "loss before training is 0.0005679829665502966 -- epoch number 3815\n",
      "\n",
      "\n",
      "loss before training is 0.0005672436695750256 -- epoch number 3816\n",
      "\n",
      "\n",
      "loss before training is 0.0005665052290216198 -- epoch number 3817\n",
      "\n",
      "\n",
      "loss before training is 0.0005657676441256593 -- epoch number 3818\n",
      "\n",
      "\n",
      "loss before training is 0.0005650309141229882 -- epoch number 3819\n",
      "\n",
      "\n",
      "loss before training is 0.0005642950382497122 -- epoch number 3820\n",
      "\n",
      "\n",
      "loss before training is 0.000563560015742205 -- epoch number 3821\n",
      "\n",
      "\n",
      "loss before training is 0.0005628258458370966 -- epoch number 3822\n",
      "\n",
      "\n",
      "loss before training is 0.0005620925277712994 -- epoch number 3823\n",
      "\n",
      "\n",
      "loss before training is 0.0005613600607819723 -- epoch number 3824\n",
      "\n",
      "\n",
      "loss before training is 0.0005606284441065547 -- epoch number 3825\n",
      "\n",
      "\n",
      "loss before training is 0.0005598976769827505 -- epoch number 3826\n",
      "\n",
      "\n",
      "loss before training is 0.0005591677586485326 -- epoch number 3827\n",
      "\n",
      "\n",
      "loss before training is 0.0005584386883421395 -- epoch number 3828\n",
      "\n",
      "\n",
      "loss before training is 0.0005577104653020814 -- epoch number 3829\n",
      "\n",
      "\n",
      "loss before training is 0.000556983088767138 -- epoch number 3830\n",
      "\n",
      "\n",
      "loss before training is 0.0005562565579763649 -- epoch number 3831\n",
      "\n",
      "\n",
      "loss before training is 0.0005555308721690734 -- epoch number 3832\n",
      "\n",
      "\n",
      "loss before training is 0.0005548060305848649 -- epoch number 3833\n",
      "\n",
      "\n",
      "loss before training is 0.0005540820324636055 -- epoch number 3834\n",
      "\n",
      "\n",
      "loss before training is 0.000553358877045427 -- epoch number 3835\n",
      "\n",
      "\n",
      "loss before training is 0.0005526365635707495 -- epoch number 3836\n",
      "\n",
      "\n",
      "loss before training is 0.0005519150912802518 -- epoch number 3837\n",
      "\n",
      "\n",
      "loss before training is 0.000551194459414901 -- epoch number 3838\n",
      "\n",
      "\n",
      "loss before training is 0.0005504746672159325 -- epoch number 3839\n",
      "\n",
      "\n",
      "loss before training is 0.0005497557139248488 -- epoch number 3840\n",
      "\n",
      "\n",
      "loss before training is 0.0005490375987834507 -- epoch number 3841\n",
      "\n",
      "\n",
      "loss before training is 0.0005483203210337967 -- epoch number 3842\n",
      "\n",
      "\n",
      "loss before training is 0.0005476038799182241 -- epoch number 3843\n",
      "\n",
      "\n",
      "loss before training is 0.000546888274679368 -- epoch number 3844\n",
      "\n",
      "\n",
      "loss before training is 0.0005461735045601133 -- epoch number 3845\n",
      "\n",
      "\n",
      "loss before training is 0.0005454595688036479 -- epoch number 3846\n",
      "\n",
      "\n",
      "loss before training is 0.0005447464666534242 -- epoch number 3847\n",
      "\n",
      "\n",
      "loss before training is 0.0005440341973531868 -- epoch number 3848\n",
      "\n",
      "\n",
      "loss before training is 0.0005433227601469514 -- epoch number 3849\n",
      "\n",
      "\n",
      "loss before training is 0.0005426121542790251 -- epoch number 3850\n",
      "\n",
      "\n",
      "loss before training is 0.0005419023789939814 -- epoch number 3851\n",
      "\n",
      "\n",
      "loss before training is 0.0005411934335366967 -- epoch number 3852\n",
      "\n",
      "\n",
      "loss before training is 0.0005404853171523066 -- epoch number 3853\n",
      "\n",
      "\n",
      "loss before training is 0.0005397780290862593 -- epoch number 3854\n",
      "\n",
      "\n",
      "loss before training is 0.0005390715685842703 -- epoch number 3855\n",
      "\n",
      "\n",
      "loss before training is 0.0005383659348923327 -- epoch number 3856\n",
      "\n",
      "\n",
      "loss before training is 0.0005376611272567403 -- epoch number 3857\n",
      "\n",
      "\n",
      "loss before training is 0.0005369571449240699 -- epoch number 3858\n",
      "\n",
      "\n",
      "loss before training is 0.00053625398714118 -- epoch number 3859\n",
      "\n",
      "\n",
      "loss before training is 0.000535551653155217 -- epoch number 3860\n",
      "\n",
      "\n",
      "loss before training is 0.0005348501422136174 -- epoch number 3861\n",
      "\n",
      "\n",
      "loss before training is 0.0005341494535641061 -- epoch number 3862\n",
      "\n",
      "\n",
      "loss before training is 0.0005334495864546954 -- epoch number 3863\n",
      "\n",
      "\n",
      "loss before training is 0.0005327505401336922 -- epoch number 3864\n",
      "\n",
      "\n",
      "loss before training is 0.0005320523138496832 -- epoch number 3865\n",
      "\n",
      "\n",
      "loss before training is 0.0005313549068515522 -- epoch number 3866\n",
      "\n",
      "\n",
      "loss before training is 0.0005306583183884787 -- epoch number 3867\n",
      "\n",
      "\n",
      "loss before training is 0.00052996254770992 -- epoch number 3868\n",
      "\n",
      "\n",
      "loss before training is 0.0005292675940656458 -- epoch number 3869\n",
      "\n",
      "\n",
      "loss before training is 0.0005285734567056983 -- epoch number 3870\n",
      "\n",
      "\n",
      "loss before training is 0.0005278801348804264 -- epoch number 3871\n",
      "\n",
      "\n",
      "loss before training is 0.0005271876278404653 -- epoch number 3872\n",
      "\n",
      "\n",
      "loss before training is 0.000526495934836748 -- epoch number 3873\n",
      "\n",
      "\n",
      "loss before training is 0.0005258050551205076 -- epoch number 3874\n",
      "\n",
      "\n",
      "loss before training is 0.0005251149879432597 -- epoch number 3875\n",
      "\n",
      "\n",
      "loss before training is 0.0005244257325568314 -- epoch number 3876\n",
      "\n",
      "\n",
      "loss before training is 0.0005237372882133341 -- epoch number 3877\n",
      "\n",
      "\n",
      "loss before training is 0.0005230496541651852 -- epoch number 3878\n",
      "\n",
      "\n",
      "loss before training is 0.0005223628296650949 -- epoch number 3879\n",
      "\n",
      "\n",
      "loss before training is 0.000521676813966068 -- epoch number 3880\n",
      "\n",
      "\n",
      "loss before training is 0.0005209916063214186 -- epoch number 3881\n",
      "\n",
      "\n",
      "loss before training is 0.0005203072059847556 -- epoch number 3882\n",
      "\n",
      "\n",
      "loss before training is 0.0005196236122099831 -- epoch number 3883\n",
      "\n",
      "\n",
      "loss before training is 0.0005189408242513119 -- epoch number 3884\n",
      "\n",
      "\n",
      "loss before training is 0.0005182588413632526 -- epoch number 3885\n",
      "\n",
      "\n",
      "loss before training is 0.0005175776628006128 -- epoch number 3886\n",
      "\n",
      "\n",
      "loss before training is 0.0005168972878185086 -- epoch number 3887\n",
      "\n",
      "\n",
      "loss before training is 0.0005162177156723559 -- epoch number 3888\n",
      "\n",
      "\n",
      "loss before training is 0.0005155389456178762 -- epoch number 3889\n",
      "\n",
      "\n",
      "loss before training is 0.0005148609769110898 -- epoch number 3890\n",
      "\n",
      "\n",
      "loss before training is 0.0005141838088083227 -- epoch number 3891\n",
      "\n",
      "\n",
      "loss before training is 0.0005135074405662132 -- epoch number 3892\n",
      "\n",
      "\n",
      "loss before training is 0.0005128318714416919 -- epoch number 3893\n",
      "\n",
      "\n",
      "loss before training is 0.0005121571006920069 -- epoch number 3894\n",
      "\n",
      "\n",
      "loss before training is 0.0005114831275747105 -- epoch number 3895\n",
      "\n",
      "\n",
      "loss before training is 0.0005108099513476569 -- epoch number 3896\n",
      "\n",
      "\n",
      "loss before training is 0.0005101375712690081 -- epoch number 3897\n",
      "\n",
      "\n",
      "loss before training is 0.000509465986597244 -- epoch number 3898\n",
      "\n",
      "\n",
      "loss before training is 0.0005087951965911397 -- epoch number 3899\n",
      "\n",
      "\n",
      "loss before training is 0.0005081252005097871 -- epoch number 3900\n",
      "\n",
      "\n",
      "loss before training is 0.0005074559976125849 -- epoch number 3901\n",
      "\n",
      "\n",
      "loss before training is 0.0005067875871592523 -- epoch number 3902\n",
      "\n",
      "\n",
      "loss before training is 0.0005061199684098002 -- epoch number 3903\n",
      "\n",
      "\n",
      "loss before training is 0.0005054531406245645 -- epoch number 3904\n",
      "\n",
      "\n",
      "loss before training is 0.0005047871030641927 -- epoch number 3905\n",
      "\n",
      "\n",
      "loss before training is 0.0005041218549896372 -- epoch number 3906\n",
      "\n",
      "\n",
      "loss before training is 0.0005034573956621686 -- epoch number 3907\n",
      "\n",
      "\n",
      "loss before training is 0.0005027937243433726 -- epoch number 3908\n",
      "\n",
      "\n",
      "loss before training is 0.0005021308402951419 -- epoch number 3909\n",
      "\n",
      "\n",
      "loss before training is 0.0005014687427796884 -- epoch number 3910\n",
      "\n",
      "\n",
      "loss before training is 0.0005008074310595429 -- epoch number 3911\n",
      "\n",
      "\n",
      "loss before training is 0.0005001469043975392 -- epoch number 3912\n",
      "\n",
      "\n",
      "loss before training is 0.0004994871620568423 -- epoch number 3913\n",
      "\n",
      "\n",
      "loss before training is 0.0004988282033009202 -- epoch number 3914\n",
      "\n",
      "\n",
      "loss before training is 0.0004981700273935692 -- epoch number 3915\n",
      "\n",
      "\n",
      "loss before training is 0.0004975126335988915 -- epoch number 3916\n",
      "\n",
      "\n",
      "loss before training is 0.0004968560211813199 -- epoch number 3917\n",
      "\n",
      "\n",
      "loss before training is 0.0004962001894055982 -- epoch number 3918\n",
      "\n",
      "\n",
      "loss before training is 0.0004955451375367873 -- epoch number 3919\n",
      "\n",
      "\n",
      "loss before training is 0.0004948908648402758 -- epoch number 3920\n",
      "\n",
      "\n",
      "loss before training is 0.000494237370581767 -- epoch number 3921\n",
      "\n",
      "\n",
      "loss before training is 0.0004935846540272793 -- epoch number 3922\n",
      "\n",
      "\n",
      "loss before training is 0.0004929327144431662 -- epoch number 3923\n",
      "\n",
      "\n",
      "loss before training is 0.0004922815510960933 -- epoch number 3924\n",
      "\n",
      "\n",
      "loss before training is 0.000491631163253046 -- epoch number 3925\n",
      "\n",
      "\n",
      "loss before training is 0.000490981550181344 -- epoch number 3926\n",
      "\n",
      "\n",
      "loss before training is 0.0004903327111486166 -- epoch number 3927\n",
      "\n",
      "\n",
      "loss before training is 0.0004896846454228239 -- epoch number 3928\n",
      "\n",
      "\n",
      "loss before training is 0.000489037352272253 -- epoch number 3929\n",
      "\n",
      "\n",
      "loss before training is 0.0004883908309655054 -- epoch number 3930\n",
      "\n",
      "\n",
      "loss before training is 0.0004877450807715199 -- epoch number 3931\n",
      "\n",
      "\n",
      "loss before training is 0.00048710010095955714 -- epoch number 3932\n",
      "\n",
      "\n",
      "loss before training is 0.0004864558907991995 -- epoch number 3933\n",
      "\n",
      "\n",
      "loss before training is 0.0004858124495603559 -- epoch number 3934\n",
      "\n",
      "\n",
      "loss before training is 0.0004851697765132658 -- epoch number 3935\n",
      "\n",
      "\n",
      "loss before training is 0.0004845278709285061 -- epoch number 3936\n",
      "\n",
      "\n",
      "loss before training is 0.00048388673207695705 -- epoch number 3937\n",
      "\n",
      "\n",
      "loss before training is 0.0004832463592298514 -- epoch number 3938\n",
      "\n",
      "\n",
      "loss before training is 0.0004826067516587424 -- epoch number 3939\n",
      "\n",
      "\n",
      "loss before training is 0.0004819679086355092 -- epoch number 3940\n",
      "\n",
      "\n",
      "loss before training is 0.000481329829432365 -- epoch number 3941\n",
      "\n",
      "\n",
      "loss before training is 0.0004806925133218545 -- epoch number 3942\n",
      "\n",
      "\n",
      "loss before training is 0.0004800559595768531 -- epoch number 3943\n",
      "\n",
      "\n",
      "loss before training is 0.0004794201674705665 -- epoch number 3944\n",
      "\n",
      "\n",
      "loss before training is 0.00047878513627653304 -- epoch number 3945\n",
      "\n",
      "\n",
      "loss before training is 0.00047815086526862183 -- epoch number 3946\n",
      "\n",
      "\n",
      "loss before training is 0.0004775173537210426 -- epoch number 3947\n",
      "\n",
      "\n",
      "loss before training is 0.00047688460090832766 -- epoch number 3948\n",
      "\n",
      "\n",
      "loss before training is 0.0004762526061053528 -- epoch number 3949\n",
      "\n",
      "\n",
      "loss before training is 0.00047562136858732117 -- epoch number 3950\n",
      "\n",
      "\n",
      "loss before training is 0.0004749908876297799 -- epoch number 3951\n",
      "\n",
      "\n",
      "loss before training is 0.00047436116250860143 -- epoch number 3952\n",
      "\n",
      "\n",
      "loss before training is 0.0004737321925000003 -- epoch number 3953\n",
      "\n",
      "\n",
      "loss before training is 0.0004731039768805314 -- epoch number 3954\n",
      "\n",
      "\n",
      "loss before training is 0.0004724765149270751 -- epoch number 3955\n",
      "\n",
      "\n",
      "loss before training is 0.0004718498059168561 -- epoch number 3956\n",
      "\n",
      "\n",
      "loss before training is 0.0004712238491274401 -- epoch number 3957\n",
      "\n",
      "\n",
      "loss before training is 0.00047059864383672967 -- epoch number 3958\n",
      "\n",
      "\n",
      "loss before training is 0.0004699741893229586 -- epoch number 3959\n",
      "\n",
      "\n",
      "loss before training is 0.00046935048486471484 -- epoch number 3960\n",
      "\n",
      "\n",
      "loss before training is 0.00046872752974090994 -- epoch number 3961\n",
      "\n",
      "\n",
      "loss before training is 0.0004681053232308022 -- epoch number 3962\n",
      "\n",
      "\n",
      "loss before training is 0.00046748386461400207 -- epoch number 3963\n",
      "\n",
      "\n",
      "loss before training is 0.0004668631531704415 -- epoch number 3964\n",
      "\n",
      "\n",
      "loss before training is 0.00046624318818040775 -- epoch number 3965\n",
      "\n",
      "\n",
      "loss before training is 0.00046562396892452565 -- epoch number 3966\n",
      "\n",
      "\n",
      "loss before training is 0.00046500549468376606 -- epoch number 3967\n",
      "\n",
      "\n",
      "loss before training is 0.00046438776473943863 -- epoch number 3968\n",
      "\n",
      "\n",
      "loss before training is 0.00046377077837319675 -- epoch number 3969\n",
      "\n",
      "\n",
      "loss before training is 0.00046315453486704325 -- epoch number 3970\n",
      "\n",
      "\n",
      "loss before training is 0.0004625390335033206 -- epoch number 3971\n",
      "\n",
      "\n",
      "loss before training is 0.00046192427356471705 -- epoch number 3972\n",
      "\n",
      "\n",
      "loss before training is 0.00046131025433427064 -- epoch number 3973\n",
      "\n",
      "\n",
      "loss before training is 0.00046069697509535697 -- epoch number 3974\n",
      "\n",
      "\n",
      "loss before training is 0.0004600844351317063 -- epoch number 3975\n",
      "\n",
      "\n",
      "loss before training is 0.0004594726337273946 -- epoch number 3976\n",
      "\n",
      "\n",
      "loss before training is 0.00045886157016683483 -- epoch number 3977\n",
      "\n",
      "\n",
      "loss before training is 0.0004582512437348015 -- epoch number 3978\n",
      "\n",
      "\n",
      "loss before training is 0.0004576416537164148 -- epoch number 3979\n",
      "\n",
      "\n",
      "loss before training is 0.0004570327993971378 -- epoch number 3980\n",
      "\n",
      "\n",
      "loss before training is 0.000456424680062786 -- epoch number 3981\n",
      "\n",
      "\n",
      "loss before training is 0.00045581729499952656 -- epoch number 3982\n",
      "\n",
      "\n",
      "loss before training is 0.0004552106434938677 -- epoch number 3983\n",
      "\n",
      "\n",
      "loss before training is 0.00045460472483268216 -- epoch number 3984\n",
      "\n",
      "\n",
      "loss before training is 0.000453999538303183 -- epoch number 3985\n",
      "\n",
      "\n",
      "loss before training is 0.0004533950831929363 -- epoch number 3986\n",
      "\n",
      "\n",
      "loss before training is 0.0004527913587898697 -- epoch number 3987\n",
      "\n",
      "\n",
      "loss before training is 0.0004521883643822457 -- epoch number 3988\n",
      "\n",
      "\n",
      "loss before training is 0.0004515860992586958 -- epoch number 3989\n",
      "\n",
      "\n",
      "loss before training is 0.0004509845627081932 -- epoch number 3990\n",
      "\n",
      "\n",
      "loss before training is 0.0004503837540200803 -- epoch number 3991\n",
      "\n",
      "\n",
      "loss before training is 0.00044978367248402955 -- epoch number 3992\n",
      "\n",
      "\n",
      "loss before training is 0.0004491843173900918 -- epoch number 3993\n",
      "\n",
      "\n",
      "loss before training is 0.00044858568802865785 -- epoch number 3994\n",
      "\n",
      "\n",
      "loss before training is 0.00044798778369047905 -- epoch number 3995\n",
      "\n",
      "\n",
      "loss before training is 0.0004473906036666646 -- epoch number 3996\n",
      "\n",
      "\n",
      "loss before training is 0.00044679414724867303 -- epoch number 3997\n",
      "\n",
      "\n",
      "loss before training is 0.00044619841372833097 -- epoch number 3998\n",
      "\n",
      "\n",
      "loss before training is 0.00044560340239781064 -- epoch number 3999\n",
      "\n",
      "\n",
      "loss before training is 0.0004450091125496493 -- epoch number 4000\n",
      "\n",
      "\n",
      "loss before training is 0.000444415543476742 -- epoch number 4001\n",
      "\n",
      "\n",
      "loss before training is 0.0004438226944723345 -- epoch number 4002\n",
      "\n",
      "\n",
      "loss before training is 0.0004432305648300422 -- epoch number 4003\n",
      "\n",
      "\n",
      "loss before training is 0.0004426391538438338 -- epoch number 4004\n",
      "\n",
      "\n",
      "loss before training is 0.0004420484608080402 -- epoch number 4005\n",
      "\n",
      "\n",
      "loss before training is 0.00044145848501734626 -- epoch number 4006\n",
      "\n",
      "\n",
      "loss before training is 0.00044086922576680844 -- epoch number 4007\n",
      "\n",
      "\n",
      "loss before training is 0.00044028068235183517 -- epoch number 4008\n",
      "\n",
      "\n",
      "loss before training is 0.0004396928540681978 -- epoch number 4009\n",
      "\n",
      "\n",
      "loss before training is 0.00043910574021203676 -- epoch number 4010\n",
      "\n",
      "\n",
      "loss before training is 0.0004385193400798443 -- epoch number 4011\n",
      "\n",
      "\n",
      "loss before training is 0.00043793365296848445 -- epoch number 4012\n",
      "\n",
      "\n",
      "loss before training is 0.0004373486781751791 -- epoch number 4013\n",
      "\n",
      "\n",
      "loss before training is 0.00043676441499751364 -- epoch number 4014\n",
      "\n",
      "\n",
      "loss before training is 0.0004361808627334425 -- epoch number 4015\n",
      "\n",
      "\n",
      "loss before training is 0.00043559802068127856 -- epoch number 4016\n",
      "\n",
      "\n",
      "loss before training is 0.00043501588813970454 -- epoch number 4017\n",
      "\n",
      "\n",
      "loss before training is 0.0004344344644077646 -- epoch number 4018\n",
      "\n",
      "\n",
      "loss before training is 0.00043385374878486977 -- epoch number 4019\n",
      "\n",
      "\n",
      "loss before training is 0.0004332737405708015 -- epoch number 4020\n",
      "\n",
      "\n",
      "loss before training is 0.0004326944390656969 -- epoch number 4021\n",
      "\n",
      "\n",
      "loss before training is 0.00043211584357007204 -- epoch number 4022\n",
      "\n",
      "\n",
      "loss before training is 0.0004315379533848055 -- epoch number 4023\n",
      "\n",
      "\n",
      "loss before training is 0.00043096076781114147 -- epoch number 4024\n",
      "\n",
      "\n",
      "loss before training is 0.0004303842861506958 -- epoch number 4025\n",
      "\n",
      "\n",
      "loss before training is 0.0004298085077054506 -- epoch number 4026\n",
      "\n",
      "\n",
      "loss before training is 0.0004292334317777598 -- epoch number 4027\n",
      "\n",
      "\n",
      "loss before training is 0.00042865905767034383 -- epoch number 4028\n",
      "\n",
      "\n",
      "loss before training is 0.0004280853846862897 -- epoch number 4029\n",
      "\n",
      "\n",
      "loss before training is 0.00042751241212906754 -- epoch number 4030\n",
      "\n",
      "\n",
      "loss before training is 0.00042694013930250194 -- epoch number 4031\n",
      "\n",
      "\n",
      "loss before training is 0.0004263685655107989 -- epoch number 4032\n",
      "\n",
      "\n",
      "loss before training is 0.0004257976900585311 -- epoch number 4033\n",
      "\n",
      "\n",
      "loss before training is 0.00042522751225064937 -- epoch number 4034\n",
      "\n",
      "\n",
      "loss before training is 0.0004246580313924661 -- epoch number 4035\n",
      "\n",
      "\n",
      "loss before training is 0.00042408924678967875 -- epoch number 4036\n",
      "\n",
      "\n",
      "loss before training is 0.0004235211577483474 -- epoch number 4037\n",
      "\n",
      "\n",
      "loss before training is 0.0004229537635749091 -- epoch number 4038\n",
      "\n",
      "\n",
      "loss before training is 0.0004223870635761774 -- epoch number 4039\n",
      "\n",
      "\n",
      "loss before training is 0.00042182105705933736 -- epoch number 4040\n",
      "\n",
      "\n",
      "loss before training is 0.000421255743331948 -- epoch number 4041\n",
      "\n",
      "\n",
      "loss before training is 0.00042069112170194654 -- epoch number 4042\n",
      "\n",
      "\n",
      "loss before training is 0.00042012719147764186 -- epoch number 4043\n",
      "\n",
      "\n",
      "loss before training is 0.0004195639519677183 -- epoch number 4044\n",
      "\n",
      "\n",
      "loss before training is 0.0004190014024812447 -- epoch number 4045\n",
      "\n",
      "\n",
      "loss before training is 0.00041843954232765354 -- epoch number 4046\n",
      "\n",
      "\n",
      "loss before training is 0.00041787837081676174 -- epoch number 4047\n",
      "\n",
      "\n",
      "loss before training is 0.0004173178872587655 -- epoch number 4048\n",
      "\n",
      "\n",
      "loss before training is 0.0004167580909642317 -- epoch number 4049\n",
      "\n",
      "\n",
      "loss before training is 0.0004161989812441146 -- epoch number 4050\n",
      "\n",
      "\n",
      "loss before training is 0.00041564055740973404 -- epoch number 4051\n",
      "\n",
      "\n",
      "loss before training is 0.00041508281877280156 -- epoch number 4052\n",
      "\n",
      "\n",
      "loss before training is 0.0004145257646453982 -- epoch number 4053\n",
      "\n",
      "\n",
      "loss before training is 0.00041396939433999364 -- epoch number 4054\n",
      "\n",
      "\n",
      "loss before training is 0.00041341370716943077 -- epoch number 4055\n",
      "\n",
      "\n",
      "loss before training is 0.00041285870244693135 -- epoch number 4056\n",
      "\n",
      "\n",
      "loss before training is 0.00041230437948611067 -- epoch number 4057\n",
      "\n",
      "\n",
      "loss before training is 0.0004117507376009431 -- epoch number 4058\n",
      "\n",
      "\n",
      "loss before training is 0.0004111977761058032 -- epoch number 4059\n",
      "\n",
      "\n",
      "loss before training is 0.0004106454943154447 -- epoch number 4060\n",
      "\n",
      "\n",
      "loss before training is 0.0004100938915449915 -- epoch number 4061\n",
      "\n",
      "\n",
      "loss before training is 0.0004095429671099648 -- epoch number 4062\n",
      "\n",
      "\n",
      "loss before training is 0.0004089927203262628 -- epoch number 4063\n",
      "\n",
      "\n",
      "loss before training is 0.0004084431505101613 -- epoch number 4064\n",
      "\n",
      "\n",
      "loss before training is 0.00040789425697832903 -- epoch number 4065\n",
      "\n",
      "\n",
      "loss before training is 0.0004073460390478163 -- epoch number 4066\n",
      "\n",
      "\n",
      "loss before training is 0.0004067984960360504 -- epoch number 4067\n",
      "\n",
      "\n",
      "loss before training is 0.0004062516272608569 -- epoch number 4068\n",
      "\n",
      "\n",
      "loss before training is 0.0004057054320404322 -- epoch number 4069\n",
      "\n",
      "\n",
      "loss before training is 0.00040515990969336544 -- epoch number 4070\n",
      "\n",
      "\n",
      "loss before training is 0.000404615059538634 -- epoch number 4071\n",
      "\n",
      "\n",
      "loss before training is 0.00040407088089559624 -- epoch number 4072\n",
      "\n",
      "\n",
      "loss before training is 0.0004035273730840027 -- epoch number 4073\n",
      "\n",
      "\n",
      "loss before training is 0.0004029845354239807 -- epoch number 4074\n",
      "\n",
      "\n",
      "loss before training is 0.0004024423672360556 -- epoch number 4075\n",
      "\n",
      "\n",
      "loss before training is 0.000401900867841134 -- epoch number 4076\n",
      "\n",
      "\n",
      "loss before training is 0.00040136003656051917 -- epoch number 4077\n",
      "\n",
      "\n",
      "loss before training is 0.0004008198727158855 -- epoch number 4078\n",
      "\n",
      "\n",
      "loss before training is 0.00040028037562931545 -- epoch number 4079\n",
      "\n",
      "\n",
      "loss before training is 0.0003997415446232684 -- epoch number 4080\n",
      "\n",
      "\n",
      "loss before training is 0.00039920337902059366 -- epoch number 4081\n",
      "\n",
      "\n",
      "loss before training is 0.0003986658781445348 -- epoch number 4082\n",
      "\n",
      "\n",
      "loss before training is 0.0003981290413187253 -- epoch number 4083\n",
      "\n",
      "\n",
      "loss before training is 0.00039759286786718545 -- epoch number 4084\n",
      "\n",
      "\n",
      "loss before training is 0.00039705735711433195 -- epoch number 4085\n",
      "\n",
      "\n",
      "loss before training is 0.00039652250838496255 -- epoch number 4086\n",
      "\n",
      "\n",
      "loss before training is 0.0003959883210042704 -- epoch number 4087\n",
      "\n",
      "\n",
      "loss before training is 0.0003954547942978542 -- epoch number 4088\n",
      "\n",
      "\n",
      "loss before training is 0.0003949219275916806 -- epoch number 4089\n",
      "\n",
      "\n",
      "loss before training is 0.00039438972021213037 -- epoch number 4090\n",
      "\n",
      "\n",
      "loss before training is 0.00039385817148596136 -- epoch number 4091\n",
      "\n",
      "\n",
      "loss before training is 0.0003933272807403347 -- epoch number 4092\n",
      "\n",
      "\n",
      "loss before training is 0.00039279704730279966 -- epoch number 4093\n",
      "\n",
      "\n",
      "loss before training is 0.0003922674705012991 -- epoch number 4094\n",
      "\n",
      "\n",
      "loss before training is 0.0003917385496641764 -- epoch number 4095\n",
      "\n",
      "\n",
      "loss before training is 0.0003912102841201595 -- epoch number 4096\n",
      "\n",
      "\n",
      "loss before training is 0.0003906826731983818 -- epoch number 4097\n",
      "\n",
      "\n",
      "loss before training is 0.0003901557162283586 -- epoch number 4098\n",
      "\n",
      "\n",
      "loss before training is 0.00038962941254001783 -- epoch number 4099\n",
      "\n",
      "\n",
      "loss before training is 0.00038910376146366146 -- epoch number 4100\n",
      "\n",
      "\n",
      "loss before training is 0.0003885787623300099 -- epoch number 4101\n",
      "\n",
      "\n",
      "loss before training is 0.00038805441447016466 -- epoch number 4102\n",
      "\n",
      "\n",
      "loss before training is 0.00038753071721563245 -- epoch number 4103\n",
      "\n",
      "\n",
      "loss before training is 0.00038700766989831236 -- epoch number 4104\n",
      "\n",
      "\n",
      "loss before training is 0.0003864852718504967 -- epoch number 4105\n",
      "\n",
      "\n",
      "loss before training is 0.0003859635224048886 -- epoch number 4106\n",
      "\n",
      "\n",
      "loss before training is 0.0003854424208945747 -- epoch number 4107\n",
      "\n",
      "\n",
      "loss before training is 0.00038492196665305126 -- epoch number 4108\n",
      "\n",
      "\n",
      "loss before training is 0.00038440215901420507 -- epoch number 4109\n",
      "\n",
      "\n",
      "loss before training is 0.00038388299731232864 -- epoch number 4110\n",
      "\n",
      "\n",
      "loss before training is 0.0003833644808821101 -- epoch number 4111\n",
      "\n",
      "\n",
      "loss before training is 0.00038284660905862965 -- epoch number 4112\n",
      "\n",
      "\n",
      "loss before training is 0.00038232938117738506 -- epoch number 4113\n",
      "\n",
      "\n",
      "loss before training is 0.0003818127965742595 -- epoch number 4114\n",
      "\n",
      "\n",
      "loss before training is 0.00038129685458554376 -- epoch number 4115\n",
      "\n",
      "\n",
      "loss before training is 0.00038078155454792224 -- epoch number 4116\n",
      "\n",
      "\n",
      "loss before training is 0.0003802668957984909 -- epoch number 4117\n",
      "\n",
      "\n",
      "loss before training is 0.0003797528776747401 -- epoch number 4118\n",
      "\n",
      "\n",
      "loss before training is 0.0003792394995145593 -- epoch number 4119\n",
      "\n",
      "\n",
      "loss before training is 0.0003787267606562499 -- epoch number 4120\n",
      "\n",
      "\n",
      "loss before training is 0.0003782146604385066 -- epoch number 4121\n",
      "\n",
      "\n",
      "loss before training is 0.00037770319820042993 -- epoch number 4122\n",
      "\n",
      "\n",
      "loss before training is 0.0003771923732815268 -- epoch number 4123\n",
      "\n",
      "\n",
      "loss before training is 0.0003766821850216956 -- epoch number 4124\n",
      "\n",
      "\n",
      "loss before training is 0.0003761726327612542 -- epoch number 4125\n",
      "\n",
      "\n",
      "loss before training is 0.00037566371584091463 -- epoch number 4126\n",
      "\n",
      "\n",
      "loss before training is 0.00037515543360179353 -- epoch number 4127\n",
      "\n",
      "\n",
      "loss before training is 0.0003746477853854123 -- epoch number 4128\n",
      "\n",
      "\n",
      "loss before training is 0.0003741407705337032 -- epoch number 4129\n",
      "\n",
      "\n",
      "loss before training is 0.0003736343883889956 -- epoch number 4130\n",
      "\n",
      "\n",
      "loss before training is 0.0003731286382940276 -- epoch number 4131\n",
      "\n",
      "\n",
      "loss before training is 0.0003726235195919396 -- epoch number 4132\n",
      "\n",
      "\n",
      "loss before training is 0.0003721190316262847 -- epoch number 4133\n",
      "\n",
      "\n",
      "loss before training is 0.00037161517374101203 -- epoch number 4134\n",
      "\n",
      "\n",
      "loss before training is 0.00037111194528049107 -- epoch number 4135\n",
      "\n",
      "\n",
      "loss before training is 0.00037060934558948557 -- epoch number 4136\n",
      "\n",
      "\n",
      "loss before training is 0.0003701073740131707 -- epoch number 4137\n",
      "\n",
      "\n",
      "loss before training is 0.0003696060298971292 -- epoch number 4138\n",
      "\n",
      "\n",
      "loss before training is 0.0003691053125873532 -- epoch number 4139\n",
      "\n",
      "\n",
      "loss before training is 0.0003686052214302411 -- epoch number 4140\n",
      "\n",
      "\n",
      "loss before training is 0.0003681057557725957 -- epoch number 4141\n",
      "\n",
      "\n",
      "loss before training is 0.00036760691496163573 -- epoch number 4142\n",
      "\n",
      "\n",
      "loss before training is 0.00036710869834498297 -- epoch number 4143\n",
      "\n",
      "\n",
      "loss before training is 0.000366611105270666 -- epoch number 4144\n",
      "\n",
      "\n",
      "loss before training is 0.00036611413508713257 -- epoch number 4145\n",
      "\n",
      "\n",
      "loss before training is 0.00036561778714322944 -- epoch number 4146\n",
      "\n",
      "\n",
      "loss before training is 0.0003651220607882234 -- epoch number 4147\n",
      "\n",
      "\n",
      "loss before training is 0.0003646269553717771 -- epoch number 4148\n",
      "\n",
      "\n",
      "loss before training is 0.0003641324702439786 -- epoch number 4149\n",
      "\n",
      "\n",
      "loss before training is 0.000363638604755315 -- epoch number 4150\n",
      "\n",
      "\n",
      "loss before training is 0.00036314535825669465 -- epoch number 4151\n",
      "\n",
      "\n",
      "loss before training is 0.00036265273009942545 -- epoch number 4152\n",
      "\n",
      "\n",
      "loss before training is 0.00036216071963524326 -- epoch number 4153\n",
      "\n",
      "\n",
      "loss before training is 0.0003616693262162712 -- epoch number 4154\n",
      "\n",
      "\n",
      "loss before training is 0.00036117854919506744 -- epoch number 4155\n",
      "\n",
      "\n",
      "loss before training is 0.0003606883879245899 -- epoch number 4156\n",
      "\n",
      "\n",
      "loss before training is 0.00036019884175821494 -- epoch number 4157\n",
      "\n",
      "\n",
      "loss before training is 0.00035970991004972703 -- epoch number 4158\n",
      "\n",
      "\n",
      "loss before training is 0.0003592215921533287 -- epoch number 4159\n",
      "\n",
      "\n",
      "loss before training is 0.0003587338874236306 -- epoch number 4160\n",
      "\n",
      "\n",
      "loss before training is 0.0003582467952156575 -- epoch number 4161\n",
      "\n",
      "\n",
      "loss before training is 0.00035776031488485044 -- epoch number 4162\n",
      "\n",
      "\n",
      "loss before training is 0.00035727444578706756 -- epoch number 4163\n",
      "\n",
      "\n",
      "loss before training is 0.00035678918727857187 -- epoch number 4164\n",
      "\n",
      "\n",
      "loss before training is 0.00035630453871604887 -- epoch number 4165\n",
      "\n",
      "\n",
      "loss before training is 0.0003558204994565931 -- epoch number 4166\n",
      "\n",
      "\n",
      "loss before training is 0.00035533706885772253 -- epoch number 4167\n",
      "\n",
      "\n",
      "loss before training is 0.00035485424627736286 -- epoch number 4168\n",
      "\n",
      "\n",
      "loss before training is 0.0003543720310738599 -- epoch number 4169\n",
      "\n",
      "\n",
      "loss before training is 0.00035389042260596627 -- epoch number 4170\n",
      "\n",
      "\n",
      "loss before training is 0.0003534094202328673 -- epoch number 4171\n",
      "\n",
      "\n",
      "loss before training is 0.00035292902331414704 -- epoch number 4172\n",
      "\n",
      "\n",
      "loss before training is 0.0003524492312098131 -- epoch number 4173\n",
      "\n",
      "\n",
      "loss before training is 0.0003519700432802982 -- epoch number 4174\n",
      "\n",
      "\n",
      "loss before training is 0.00035149145888644024 -- epoch number 4175\n",
      "\n",
      "\n",
      "loss before training is 0.00035101347738949833 -- epoch number 4176\n",
      "\n",
      "\n",
      "loss before training is 0.0003505360981511458 -- epoch number 4177\n",
      "\n",
      "\n",
      "loss before training is 0.00035005932053348084 -- epoch number 4178\n",
      "\n",
      "\n",
      "loss before training is 0.00034958314389901775 -- epoch number 4179\n",
      "\n",
      "\n",
      "loss before training is 0.00034910756761068293 -- epoch number 4180\n",
      "\n",
      "\n",
      "loss before training is 0.00034863259103182996 -- epoch number 4181\n",
      "\n",
      "\n",
      "loss before training is 0.0003481582135262225 -- epoch number 4182\n",
      "\n",
      "\n",
      "loss before training is 0.0003476844344580495 -- epoch number 4183\n",
      "\n",
      "\n",
      "loss before training is 0.00034721125319191795 -- epoch number 4184\n",
      "\n",
      "\n",
      "loss before training is 0.0003467386690928512 -- epoch number 4185\n",
      "\n",
      "\n",
      "loss before training is 0.00034626668152629066 -- epoch number 4186\n",
      "\n",
      "\n",
      "loss before training is 0.00034579528985810744 -- epoch number 4187\n",
      "\n",
      "\n",
      "loss before training is 0.0003453244934545881 -- epoch number 4188\n",
      "\n",
      "\n",
      "loss before training is 0.0003448542916824276 -- epoch number 4189\n",
      "\n",
      "\n",
      "loss before training is 0.00034438468390875806 -- epoch number 4190\n",
      "\n",
      "\n",
      "loss before training is 0.00034391566950112823 -- epoch number 4191\n",
      "\n",
      "\n",
      "loss before training is 0.0003434472478275008 -- epoch number 4192\n",
      "\n",
      "\n",
      "loss before training is 0.000342979418256264 -- epoch number 4193\n",
      "\n",
      "\n",
      "loss before training is 0.0003425121801562299 -- epoch number 4194\n",
      "\n",
      "\n",
      "loss before training is 0.00034204553289662843 -- epoch number 4195\n",
      "\n",
      "\n",
      "loss before training is 0.0003415794758471168 -- epoch number 4196\n",
      "\n",
      "\n",
      "loss before training is 0.0003411140083777648 -- epoch number 4197\n",
      "\n",
      "\n",
      "loss before training is 0.0003406491298590732 -- epoch number 4198\n",
      "\n",
      "\n",
      "loss before training is 0.00034018483966196007 -- epoch number 4199\n",
      "\n",
      "\n",
      "loss before training is 0.00033972113715777144 -- epoch number 4200\n",
      "\n",
      "\n",
      "loss before training is 0.00033925802171827274 -- epoch number 4201\n",
      "\n",
      "\n",
      "loss before training is 0.00033879549271564977 -- epoch number 4202\n",
      "\n",
      "\n",
      "loss before training is 0.0003383335495225164 -- epoch number 4203\n",
      "\n",
      "\n",
      "loss before training is 0.0003378721915119109 -- epoch number 4204\n",
      "\n",
      "\n",
      "loss before training is 0.0003374114180572865 -- epoch number 4205\n",
      "\n",
      "\n",
      "loss before training is 0.0003369512285325337 -- epoch number 4206\n",
      "\n",
      "\n",
      "loss before training is 0.00033649162231195665 -- epoch number 4207\n",
      "\n",
      "\n",
      "loss before training is 0.00033603259877029127 -- epoch number 4208\n",
      "\n",
      "\n",
      "loss before training is 0.00033557415728268974 -- epoch number 4209\n",
      "\n",
      "\n",
      "loss before training is 0.00033511629722473625 -- epoch number 4210\n",
      "\n",
      "\n",
      "loss before training is 0.00033465901797243415 -- epoch number 4211\n",
      "\n",
      "\n",
      "loss before training is 0.000334202318902218 -- epoch number 4212\n",
      "\n",
      "\n",
      "loss before training is 0.00033374619939094435 -- epoch number 4213\n",
      "\n",
      "\n",
      "loss before training is 0.00033329065881589504 -- epoch number 4214\n",
      "\n",
      "\n",
      "loss before training is 0.00033283569655478035 -- epoch number 4215\n",
      "\n",
      "\n",
      "loss before training is 0.00033238131198573594 -- epoch number 4216\n",
      "\n",
      "\n",
      "loss before training is 0.00033192750448731844 -- epoch number 4217\n",
      "\n",
      "\n",
      "loss before training is 0.0003314742734385173 -- epoch number 4218\n",
      "\n",
      "\n",
      "loss before training is 0.00033102161821874744 -- epoch number 4219\n",
      "\n",
      "\n",
      "loss before training is 0.0003305695382078451 -- epoch number 4220\n",
      "\n",
      "\n",
      "loss before training is 0.00033011803278608316 -- epoch number 4221\n",
      "\n",
      "\n",
      "loss before training is 0.00032966710133415153 -- epoch number 4222\n",
      "\n",
      "\n",
      "loss before training is 0.0003292167432331762 -- epoch number 4223\n",
      "\n",
      "\n",
      "loss before training is 0.0003287669578647062 -- epoch number 4224\n",
      "\n",
      "\n",
      "loss before training is 0.0003283177446107125 -- epoch number 4225\n",
      "\n",
      "\n",
      "loss before training is 0.000327869102853608 -- epoch number 4226\n",
      "\n",
      "\n",
      "loss before training is 0.00032742103197622207 -- epoch number 4227\n",
      "\n",
      "\n",
      "loss before training is 0.0003269735313618177 -- epoch number 4228\n",
      "\n",
      "\n",
      "loss before training is 0.00032652660039408297 -- epoch number 4229\n",
      "\n",
      "\n",
      "loss before training is 0.00032608023845714186 -- epoch number 4230\n",
      "\n",
      "\n",
      "loss before training is 0.0003256344449355309 -- epoch number 4231\n",
      "\n",
      "\n",
      "loss before training is 0.0003251892192142377 -- epoch number 4232\n",
      "\n",
      "\n",
      "loss before training is 0.0003247445606786621 -- epoch number 4233\n",
      "\n",
      "\n",
      "loss before training is 0.00032430046871463993 -- epoch number 4234\n",
      "\n",
      "\n",
      "loss before training is 0.00032385694270843445 -- epoch number 4235\n",
      "\n",
      "\n",
      "loss before training is 0.00032341398204674366 -- epoch number 4236\n",
      "\n",
      "\n",
      "loss before training is 0.00032297158611668835 -- epoch number 4237\n",
      "\n",
      "\n",
      "loss before training is 0.00032252975430582527 -- epoch number 4238\n",
      "\n",
      "\n",
      "loss before training is 0.000322088486002135 -- epoch number 4239\n",
      "\n",
      "\n",
      "loss before training is 0.0003216477805940362 -- epoch number 4240\n",
      "\n",
      "\n",
      "loss before training is 0.0003212076374703728 -- epoch number 4241\n",
      "\n",
      "\n",
      "loss before training is 0.00032076805602041815 -- epoch number 4242\n",
      "\n",
      "\n",
      "loss before training is 0.0003203290356338852 -- epoch number 4243\n",
      "\n",
      "\n",
      "loss before training is 0.0003198905757009091 -- epoch number 4244\n",
      "\n",
      "\n",
      "loss before training is 0.0003194526756120574 -- epoch number 4245\n",
      "\n",
      "\n",
      "loss before training is 0.00031901533475833175 -- epoch number 4246\n",
      "\n",
      "\n",
      "loss before training is 0.0003185785525311651 -- epoch number 4247\n",
      "\n",
      "\n",
      "loss before training is 0.0003181423283224207 -- epoch number 4248\n",
      "\n",
      "\n",
      "loss before training is 0.0003177066615243977 -- epoch number 4249\n",
      "\n",
      "\n",
      "loss before training is 0.0003172715515298166 -- epoch number 4250\n",
      "\n",
      "\n",
      "loss before training is 0.00031683699773184785 -- epoch number 4251\n",
      "\n",
      "\n",
      "loss before training is 0.0003164029995240771 -- epoch number 4252\n",
      "\n",
      "\n",
      "loss before training is 0.00031596955630053156 -- epoch number 4253\n",
      "\n",
      "\n",
      "loss before training is 0.00031553666745566886 -- epoch number 4254\n",
      "\n",
      "\n",
      "loss before training is 0.00031510433238437737 -- epoch number 4255\n",
      "\n",
      "\n",
      "loss before training is 0.0003146725504819835 -- epoch number 4256\n",
      "\n",
      "\n",
      "loss before training is 0.00031424132114424535 -- epoch number 4257\n",
      "\n",
      "\n",
      "loss before training is 0.00031381064376735147 -- epoch number 4258\n",
      "\n",
      "\n",
      "loss before training is 0.0003133805177479259 -- epoch number 4259\n",
      "\n",
      "\n",
      "loss before training is 0.0003129509424830228 -- epoch number 4260\n",
      "\n",
      "\n",
      "loss before training is 0.00031252191737013294 -- epoch number 4261\n",
      "\n",
      "\n",
      "loss before training is 0.0003120934418071852 -- epoch number 4262\n",
      "\n",
      "\n",
      "loss before training is 0.00031166551519253797 -- epoch number 4263\n",
      "\n",
      "\n",
      "loss before training is 0.00031123813692498283 -- epoch number 4264\n",
      "\n",
      "\n",
      "loss before training is 0.0003108113064037484 -- epoch number 4265\n",
      "\n",
      "\n",
      "loss before training is 0.0003103850230284931 -- epoch number 4266\n",
      "\n",
      "\n",
      "loss before training is 0.00030995928619931875 -- epoch number 4267\n",
      "\n",
      "\n",
      "loss before training is 0.0003095340953167521 -- epoch number 4268\n",
      "\n",
      "\n",
      "loss before training is 0.00030910944978176284 -- epoch number 4269\n",
      "\n",
      "\n",
      "loss before training is 0.0003086853489957486 -- epoch number 4270\n",
      "\n",
      "\n",
      "loss before training is 0.00030826179236054946 -- epoch number 4271\n",
      "\n",
      "\n",
      "loss before training is 0.000307838779278434 -- epoch number 4272\n",
      "\n",
      "\n",
      "loss before training is 0.00030741630915211095 -- epoch number 4273\n",
      "\n",
      "\n",
      "loss before training is 0.0003069943813847237 -- epoch number 4274\n",
      "\n",
      "\n",
      "loss before training is 0.0003065729953798488 -- epoch number 4275\n",
      "\n",
      "\n",
      "loss before training is 0.00030615215054150295 -- epoch number 4276\n",
      "\n",
      "\n",
      "loss before training is 0.0003057318462741339 -- epoch number 4277\n",
      "\n",
      "\n",
      "loss before training is 0.00030531208198263105 -- epoch number 4278\n",
      "\n",
      "\n",
      "loss before training is 0.0003048928570723169 -- epoch number 4279\n",
      "\n",
      "\n",
      "loss before training is 0.00030447417094894597 -- epoch number 4280\n",
      "\n",
      "\n",
      "loss before training is 0.00030405602301871967 -- epoch number 4281\n",
      "\n",
      "\n",
      "loss before training is 0.0003036384126882696 -- epoch number 4282\n",
      "\n",
      "\n",
      "loss before training is 0.0003032213393646602 -- epoch number 4283\n",
      "\n",
      "\n",
      "loss before training is 0.0003028048024554002 -- epoch number 4284\n",
      "\n",
      "\n",
      "loss before training is 0.00030238880136843234 -- epoch number 4285\n",
      "\n",
      "\n",
      "loss before training is 0.00030197333551213953 -- epoch number 4286\n",
      "\n",
      "\n",
      "loss before training is 0.00030155840429533604 -- epoch number 4287\n",
      "\n",
      "\n",
      "loss before training is 0.0003011440071272769 -- epoch number 4288\n",
      "\n",
      "\n",
      "loss before training is 0.00030073014341765365 -- epoch number 4289\n",
      "\n",
      "\n",
      "loss before training is 0.00030031681257659804 -- epoch number 4290\n",
      "\n",
      "\n",
      "loss before training is 0.0002999040140146753 -- epoch number 4291\n",
      "\n",
      "\n",
      "loss before training is 0.00029949174714289295 -- epoch number 4292\n",
      "\n",
      "\n",
      "loss before training is 0.000299080011372695 -- epoch number 4293\n",
      "\n",
      "\n",
      "loss before training is 0.00029866880611595934 -- epoch number 4294\n",
      "\n",
      "\n",
      "loss before training is 0.0002982581307850077 -- epoch number 4295\n",
      "\n",
      "\n",
      "loss before training is 0.00029784798479259747 -- epoch number 4296\n",
      "\n",
      "\n",
      "loss before training is 0.0002974383675519274 -- epoch number 4297\n",
      "\n",
      "\n",
      "loss before training is 0.00029702927847663024 -- epoch number 4298\n",
      "\n",
      "\n",
      "loss before training is 0.00029662071698077693 -- epoch number 4299\n",
      "\n",
      "\n",
      "loss before training is 0.0002962126824788874 -- epoch number 4300\n",
      "\n",
      "\n",
      "loss before training is 0.0002958051743859047 -- epoch number 4301\n",
      "\n",
      "\n",
      "loss before training is 0.00029539819211722186 -- epoch number 4302\n",
      "\n",
      "\n",
      "loss before training is 0.00029499173508866906 -- epoch number 4303\n",
      "\n",
      "\n",
      "loss before training is 0.00029458580271651396 -- epoch number 4304\n",
      "\n",
      "\n",
      "loss before training is 0.0002941803944174643 -- epoch number 4305\n",
      "\n",
      "\n",
      "loss before training is 0.00029377550960866866 -- epoch number 4306\n",
      "\n",
      "\n",
      "loss before training is 0.0002933711477077094 -- epoch number 4307\n",
      "\n",
      "\n",
      "loss before training is 0.0002929673081326162 -- epoch number 4308\n",
      "\n",
      "\n",
      "loss before training is 0.00029256399030185346 -- epoch number 4309\n",
      "\n",
      "\n",
      "loss before training is 0.0002921611936343245 -- epoch number 4310\n",
      "\n",
      "\n",
      "loss before training is 0.0002917589175493791 -- epoch number 4311\n",
      "\n",
      "\n",
      "loss before training is 0.00029135716146680077 -- epoch number 4312\n",
      "\n",
      "\n",
      "loss before training is 0.00029095592480681394 -- epoch number 4313\n",
      "\n",
      "\n",
      "loss before training is 0.00029055520699008323 -- epoch number 4314\n",
      "\n",
      "\n",
      "loss before training is 0.0002901550074377181 -- epoch number 4315\n",
      "\n",
      "\n",
      "loss before training is 0.0002897553255712607 -- epoch number 4316\n",
      "\n",
      "\n",
      "loss before training is 0.00028935616081270245 -- epoch number 4317\n",
      "\n",
      "\n",
      "loss before training is 0.00028895751258446273 -- epoch number 4318\n",
      "\n",
      "\n",
      "loss before training is 0.00028855938030941707 -- epoch number 4319\n",
      "\n",
      "\n",
      "loss before training is 0.00028816176341086783 -- epoch number 4320\n",
      "\n",
      "\n",
      "loss before training is 0.0002877646613125708 -- epoch number 4321\n",
      "\n",
      "\n",
      "loss before training is 0.0002873680734387108 -- epoch number 4322\n",
      "\n",
      "\n",
      "loss before training is 0.0002869719992139192 -- epoch number 4323\n",
      "\n",
      "\n",
      "loss before training is 0.00028657643806327145 -- epoch number 4324\n",
      "\n",
      "\n",
      "loss before training is 0.00028618138941227634 -- epoch number 4325\n",
      "\n",
      "\n",
      "loss before training is 0.0002857868526868917 -- epoch number 4326\n",
      "\n",
      "\n",
      "loss before training is 0.0002853928273135118 -- epoch number 4327\n",
      "\n",
      "\n",
      "loss before training is 0.00028499931271897563 -- epoch number 4328\n",
      "\n",
      "\n",
      "loss before training is 0.00028460630833055815 -- epoch number 4329\n",
      "\n",
      "\n",
      "loss before training is 0.0002842138135759836 -- epoch number 4330\n",
      "\n",
      "\n",
      "loss before training is 0.00028382182788340947 -- epoch number 4331\n",
      "\n",
      "\n",
      "loss before training is 0.0002834303506814446 -- epoch number 4332\n",
      "\n",
      "\n",
      "loss before training is 0.00028303938139912833 -- epoch number 4333\n",
      "\n",
      "\n",
      "loss before training is 0.0002826489194659503 -- epoch number 4334\n",
      "\n",
      "\n",
      "loss before training is 0.0002822589643118391 -- epoch number 4335\n",
      "\n",
      "\n",
      "loss before training is 0.0002818695153671673 -- epoch number 4336\n",
      "\n",
      "\n",
      "loss before training is 0.00028148057206274534 -- epoch number 4337\n",
      "\n",
      "\n",
      "loss before training is 0.00028109213382983115 -- epoch number 4338\n",
      "\n",
      "\n",
      "loss before training is 0.0002807042001001176 -- epoch number 4339\n",
      "\n",
      "\n",
      "loss before training is 0.0002803167703057475 -- epoch number 4340\n",
      "\n",
      "\n",
      "loss before training is 0.00027992984387930297 -- epoch number 4341\n",
      "\n",
      "\n",
      "loss before training is 0.00027954342025380906 -- epoch number 4342\n",
      "\n",
      "\n",
      "loss before training is 0.00027915749886272797 -- epoch number 4343\n",
      "\n",
      "\n",
      "loss before training is 0.0002787720791399711 -- epoch number 4344\n",
      "\n",
      "\n",
      "loss before training is 0.00027838716051989095 -- epoch number 4345\n",
      "\n",
      "\n",
      "loss before training is 0.00027800274243728294 -- epoch number 4346\n",
      "\n",
      "\n",
      "loss before training is 0.0002776188243273832 -- epoch number 4347\n",
      "\n",
      "\n",
      "loss before training is 0.000277235405625871 -- epoch number 4348\n",
      "\n",
      "\n",
      "loss before training is 0.00027685248576886953 -- epoch number 4349\n",
      "\n",
      "\n",
      "loss before training is 0.0002764700641929461 -- epoch number 4350\n",
      "\n",
      "\n",
      "loss before training is 0.0002760881403351067 -- epoch number 4351\n",
      "\n",
      "\n",
      "loss before training is 0.0002757067136328068 -- epoch number 4352\n",
      "\n",
      "\n",
      "loss before training is 0.0002753257835239369 -- epoch number 4353\n",
      "\n",
      "\n",
      "loss before training is 0.0002749453494468384 -- epoch number 4354\n",
      "\n",
      "\n",
      "loss before training is 0.0002745654108402901 -- epoch number 4355\n",
      "\n",
      "\n",
      "loss before training is 0.0002741859671435147 -- epoch number 4356\n",
      "\n",
      "\n",
      "loss before training is 0.00027380701779618417 -- epoch number 4357\n",
      "\n",
      "\n",
      "loss before training is 0.00027342856223840735 -- epoch number 4358\n",
      "\n",
      "\n",
      "loss before training is 0.00027305059991073713 -- epoch number 4359\n",
      "\n",
      "\n",
      "loss before training is 0.0002726731302541721 -- epoch number 4360\n",
      "\n",
      "\n",
      "loss before training is 0.00027229615271015474 -- epoch number 4361\n",
      "\n",
      "\n",
      "loss before training is 0.0002719196667205703 -- epoch number 4362\n",
      "\n",
      "\n",
      "loss before training is 0.00027154367172774343 -- epoch number 4363\n",
      "\n",
      "\n",
      "loss before training is 0.0002711681671744506 -- epoch number 4364\n",
      "\n",
      "\n",
      "loss before training is 0.0002707931525039011 -- epoch number 4365\n",
      "\n",
      "\n",
      "loss before training is 0.0002704186271597649 -- epoch number 4366\n",
      "\n",
      "\n",
      "loss before training is 0.0002700445905861318 -- epoch number 4367\n",
      "\n",
      "\n",
      "loss before training is 0.00026967104222756 -- epoch number 4368\n",
      "\n",
      "\n",
      "loss before training is 0.00026929798152903166 -- epoch number 4369\n",
      "\n",
      "\n",
      "loss before training is 0.0002689254079359886 -- epoch number 4370\n",
      "\n",
      "\n",
      "loss before training is 0.00026855332089430233 -- epoch number 4371\n",
      "\n",
      "\n",
      "loss before training is 0.0002681817198503005 -- epoch number 4372\n",
      "\n",
      "\n",
      "loss before training is 0.000267810604250749 -- epoch number 4373\n",
      "\n",
      "\n",
      "loss before training is 0.000267439973542856 -- epoch number 4374\n",
      "\n",
      "\n",
      "loss before training is 0.0002670698271742774 -- epoch number 4375\n",
      "\n",
      "\n",
      "loss before training is 0.00026670016459311315 -- epoch number 4376\n",
      "\n",
      "\n",
      "loss before training is 0.0002663309852479025 -- epoch number 4377\n",
      "\n",
      "\n",
      "loss before training is 0.00026596228858763536 -- epoch number 4378\n",
      "\n",
      "\n",
      "loss before training is 0.00026559407406174206 -- epoch number 4379\n",
      "\n",
      "\n",
      "loss before training is 0.0002652263411200964 -- epoch number 4380\n",
      "\n",
      "\n",
      "loss before training is 0.0002648590892130225 -- epoch number 4381\n",
      "\n",
      "\n",
      "loss before training is 0.0002644923177912821 -- epoch number 4382\n",
      "\n",
      "\n",
      "loss before training is 0.0002641260263060773 -- epoch number 4383\n",
      "\n",
      "\n",
      "loss before training is 0.00026376021420906995 -- epoch number 4384\n",
      "\n",
      "\n",
      "loss before training is 0.00026339488095235145 -- epoch number 4385\n",
      "\n",
      "\n",
      "loss before training is 0.00026303002598846353 -- epoch number 4386\n",
      "\n",
      "\n",
      "loss before training is 0.0002626656487703943 -- epoch number 4387\n",
      "\n",
      "\n",
      "loss before training is 0.0002623017487515745 -- epoch number 4388\n",
      "\n",
      "\n",
      "loss before training is 0.0002619383253858739 -- epoch number 4389\n",
      "\n",
      "\n",
      "loss before training is 0.00026157537812761657 -- epoch number 4390\n",
      "\n",
      "\n",
      "loss before training is 0.0002612129064315636 -- epoch number 4391\n",
      "\n",
      "\n",
      "loss before training is 0.00026085090975292157 -- epoch number 4392\n",
      "\n",
      "\n",
      "loss before training is 0.0002604893875473481 -- epoch number 4393\n",
      "\n",
      "\n",
      "loss before training is 0.00026012833927093615 -- epoch number 4394\n",
      "\n",
      "\n",
      "loss before training is 0.00025976776438023315 -- epoch number 4395\n",
      "\n",
      "\n",
      "loss before training is 0.00025940766233221557 -- epoch number 4396\n",
      "\n",
      "\n",
      "loss before training is 0.0002590480325843233 -- epoch number 4397\n",
      "\n",
      "\n",
      "loss before training is 0.00025868887459443103 -- epoch number 4398\n",
      "\n",
      "\n",
      "loss before training is 0.0002583301878208524 -- epoch number 4399\n",
      "\n",
      "\n",
      "loss before training is 0.00025797197172236047 -- epoch number 4400\n",
      "\n",
      "\n",
      "loss before training is 0.00025761422575816057 -- epoch number 4401\n",
      "\n",
      "\n",
      "loss before training is 0.00025725694938790833 -- epoch number 4402\n",
      "\n",
      "\n",
      "loss before training is 0.0002569001420717036 -- epoch number 4403\n",
      "\n",
      "\n",
      "loss before training is 0.0002565438032700884 -- epoch number 4404\n",
      "\n",
      "\n",
      "loss before training is 0.00025618793244405215 -- epoch number 4405\n",
      "\n",
      "\n",
      "loss before training is 0.0002558325290550251 -- epoch number 4406\n",
      "\n",
      "\n",
      "loss before training is 0.0002554775925648867 -- epoch number 4407\n",
      "\n",
      "\n",
      "loss before training is 0.0002551231224359648 -- epoch number 4408\n",
      "\n",
      "\n",
      "loss before training is 0.0002547691181310202 -- epoch number 4409\n",
      "\n",
      "\n",
      "loss before training is 0.0002544155791132658 -- epoch number 4410\n",
      "\n",
      "\n",
      "loss before training is 0.00025406250484635954 -- epoch number 4411\n",
      "\n",
      "\n",
      "loss before training is 0.00025370989479440233 -- epoch number 4412\n",
      "\n",
      "\n",
      "loss before training is 0.00025335774842194134 -- epoch number 4413\n",
      "\n",
      "\n",
      "loss before training is 0.00025300606519396726 -- epoch number 4414\n",
      "\n",
      "\n",
      "loss before training is 0.00025265484457591354 -- epoch number 4415\n",
      "\n",
      "\n",
      "loss before training is 0.00025230408603366675 -- epoch number 4416\n",
      "\n",
      "\n",
      "loss before training is 0.0002519537890335442 -- epoch number 4417\n",
      "\n",
      "\n",
      "loss before training is 0.00025160395304231974 -- epoch number 4418\n",
      "\n",
      "\n",
      "loss before training is 0.00025125457752720696 -- epoch number 4419\n",
      "\n",
      "\n",
      "loss before training is 0.0002509056619558671 -- epoch number 4420\n",
      "\n",
      "\n",
      "loss before training is 0.0002505572057964044 -- epoch number 4421\n",
      "\n",
      "\n",
      "loss before training is 0.0002502092085173624 -- epoch number 4422\n",
      "\n",
      "\n",
      "loss before training is 0.0002498616695877415 -- epoch number 4423\n",
      "\n",
      "\n",
      "loss before training is 0.0002495145884769744 -- epoch number 4424\n",
      "\n",
      "\n",
      "loss before training is 0.0002491679646549458 -- epoch number 4425\n",
      "\n",
      "\n",
      "loss before training is 0.000248821797591987 -- epoch number 4426\n",
      "\n",
      "\n",
      "loss before training is 0.00024847608675886325 -- epoch number 4427\n",
      "\n",
      "\n",
      "loss before training is 0.0002481308316267956 -- epoch number 4428\n",
      "\n",
      "\n",
      "loss before training is 0.00024778603166744346 -- epoch number 4429\n",
      "\n",
      "\n",
      "loss before training is 0.00024744168635291823 -- epoch number 4430\n",
      "\n",
      "\n",
      "loss before training is 0.00024709779515576143 -- epoch number 4431\n",
      "\n",
      "\n",
      "loss before training is 0.0002467543575489781 -- epoch number 4432\n",
      "\n",
      "\n",
      "loss before training is 0.00024641137300599977 -- epoch number 4433\n",
      "\n",
      "\n",
      "loss before training is 0.0002460688410007141 -- epoch number 4434\n",
      "\n",
      "\n",
      "loss before training is 0.0002457267610074512 -- epoch number 4435\n",
      "\n",
      "\n",
      "loss before training is 0.000245385132500984 -- epoch number 4436\n",
      "\n",
      "\n",
      "loss before training is 0.00024504395495653075 -- epoch number 4437\n",
      "\n",
      "\n",
      "loss before training is 0.0002447032278497518 -- epoch number 4438\n",
      "\n",
      "\n",
      "loss before training is 0.00024436295065675755 -- epoch number 4439\n",
      "\n",
      "\n",
      "loss before training is 0.00024402312285409547 -- epoch number 4440\n",
      "\n",
      "\n",
      "loss before training is 0.0002436837439187655 -- epoch number 4441\n",
      "\n",
      "\n",
      "loss before training is 0.00024334481332820344 -- epoch number 4442\n",
      "\n",
      "\n",
      "loss before training is 0.00024300633056029613 -- epoch number 4443\n",
      "\n",
      "\n",
      "loss before training is 0.00024266829509337468 -- epoch number 4444\n",
      "\n",
      "\n",
      "loss before training is 0.0002423307064062064 -- epoch number 4445\n",
      "\n",
      "\n",
      "loss before training is 0.00024199356397801574 -- epoch number 4446\n",
      "\n",
      "\n",
      "loss before training is 0.00024165686728845802 -- epoch number 4447\n",
      "\n",
      "\n",
      "loss before training is 0.00024132061581764525 -- epoch number 4448\n",
      "\n",
      "\n",
      "loss before training is 0.0002409848090461219 -- epoch number 4449\n",
      "\n",
      "\n",
      "loss before training is 0.00024064944645488527 -- epoch number 4450\n",
      "\n",
      "\n",
      "loss before training is 0.00024031452752537805 -- epoch number 4451\n",
      "\n",
      "\n",
      "loss before training is 0.00023998005173947372 -- epoch number 4452\n",
      "\n",
      "\n",
      "loss before training is 0.00023964601857950741 -- epoch number 4453\n",
      "\n",
      "\n",
      "loss before training is 0.00023931242752824354 -- epoch number 4454\n",
      "\n",
      "\n",
      "loss before training is 0.00023897927806890298 -- epoch number 4455\n",
      "\n",
      "\n",
      "loss before training is 0.00023864656968513781 -- epoch number 4456\n",
      "\n",
      "\n",
      "loss before training is 0.00023831430186105622 -- epoch number 4457\n",
      "\n",
      "\n",
      "loss before training is 0.00023798247408120222 -- epoch number 4458\n",
      "\n",
      "\n",
      "loss before training is 0.00023765108583056706 -- epoch number 4459\n",
      "\n",
      "\n",
      "loss before training is 0.00023732013659458567 -- epoch number 4460\n",
      "\n",
      "\n",
      "loss before training is 0.0002369896258591355 -- epoch number 4461\n",
      "\n",
      "\n",
      "loss before training is 0.0002366595531105364 -- epoch number 4462\n",
      "\n",
      "\n",
      "loss before training is 0.00023632991783555712 -- epoch number 4463\n",
      "\n",
      "\n",
      "loss before training is 0.00023600071952140577 -- epoch number 4464\n",
      "\n",
      "\n",
      "loss before training is 0.00023567195765573484 -- epoch number 4465\n",
      "\n",
      "\n",
      "loss before training is 0.0002353436317266403 -- epoch number 4466\n",
      "\n",
      "\n",
      "loss before training is 0.00023501574122266472 -- epoch number 4467\n",
      "\n",
      "\n",
      "loss before training is 0.00023468828563278515 -- epoch number 4468\n",
      "\n",
      "\n",
      "loss before training is 0.00023436126444643604 -- epoch number 4469\n",
      "\n",
      "\n",
      "loss before training is 0.00023403467715348315 -- epoch number 4470\n",
      "\n",
      "\n",
      "loss before training is 0.00023370852324424227 -- epoch number 4471\n",
      "\n",
      "\n",
      "loss before training is 0.0002333828022094702 -- epoch number 4472\n",
      "\n",
      "\n",
      "loss before training is 0.00023305751354036524 -- epoch number 4473\n",
      "\n",
      "\n",
      "loss before training is 0.00023273265672857179 -- epoch number 4474\n",
      "\n",
      "\n",
      "loss before training is 0.0002324082312661787 -- epoch number 4475\n",
      "\n",
      "\n",
      "loss before training is 0.00023208423664571216 -- epoch number 4476\n",
      "\n",
      "\n",
      "loss before training is 0.00023176067236014718 -- epoch number 4477\n",
      "\n",
      "\n",
      "loss before training is 0.00023143753790289578 -- epoch number 4478\n",
      "\n",
      "\n",
      "loss before training is 0.00023111483276782032 -- epoch number 4479\n",
      "\n",
      "\n",
      "loss before training is 0.0002307925564492246 -- epoch number 4480\n",
      "\n",
      "\n",
      "loss before training is 0.00023047070844184708 -- epoch number 4481\n",
      "\n",
      "\n",
      "loss before training is 0.00023014928824088013 -- epoch number 4482\n",
      "\n",
      "\n",
      "loss before training is 0.00022982829534194966 -- epoch number 4483\n",
      "\n",
      "\n",
      "loss before training is 0.0002295077292411299 -- epoch number 4484\n",
      "\n",
      "\n",
      "loss before training is 0.00022918758943493708 -- epoch number 4485\n",
      "\n",
      "\n",
      "loss before training is 0.00022886787542032537 -- epoch number 4486\n",
      "\n",
      "\n",
      "loss before training is 0.00022854858669470022 -- epoch number 4487\n",
      "\n",
      "\n",
      "loss before training is 0.00022822972275589887 -- epoch number 4488\n",
      "\n",
      "\n",
      "loss before training is 0.00022791128310220994 -- epoch number 4489\n",
      "\n",
      "\n",
      "loss before training is 0.00022759326723236008 -- epoch number 4490\n",
      "\n",
      "\n",
      "loss before training is 0.00022727567464552028 -- epoch number 4491\n",
      "\n",
      "\n",
      "loss before training is 0.00022695850484129732 -- epoch number 4492\n",
      "\n",
      "\n",
      "loss before training is 0.00022664175731974863 -- epoch number 4493\n",
      "\n",
      "\n",
      "loss before training is 0.0002263254315813698 -- epoch number 4494\n",
      "\n",
      "\n",
      "loss before training is 0.00022600952712710002 -- epoch number 4495\n",
      "\n",
      "\n",
      "loss before training is 0.00022569404345831515 -- epoch number 4496\n",
      "\n",
      "\n",
      "loss before training is 0.00022537898007684266 -- epoch number 4497\n",
      "\n",
      "\n",
      "loss before training is 0.0002250643364849394 -- epoch number 4498\n",
      "\n",
      "\n",
      "loss before training is 0.00022475011218531466 -- epoch number 4499\n",
      "\n",
      "\n",
      "loss before training is 0.00022443630668111448 -- epoch number 4500\n",
      "\n",
      "\n",
      "loss before training is 0.00022412291947592698 -- epoch number 4501\n",
      "\n",
      "\n",
      "loss before training is 0.00022380995007378207 -- epoch number 4502\n",
      "\n",
      "\n",
      "loss before training is 0.00022349739797915063 -- epoch number 4503\n",
      "\n",
      "\n",
      "loss before training is 0.00022318526269694564 -- epoch number 4504\n",
      "\n",
      "\n",
      "loss before training is 0.00022287354373252114 -- epoch number 4505\n",
      "\n",
      "\n",
      "loss before training is 0.00022256224059167212 -- epoch number 4506\n",
      "\n",
      "\n",
      "loss before training is 0.00022225135278063402 -- epoch number 4507\n",
      "\n",
      "\n",
      "loss before training is 0.00022194087980608742 -- epoch number 4508\n",
      "\n",
      "\n",
      "loss before training is 0.00022163082117514443 -- epoch number 4509\n",
      "\n",
      "\n",
      "loss before training is 0.00022132117639536933 -- epoch number 4510\n",
      "\n",
      "\n",
      "loss before training is 0.00022101194497476274 -- epoch number 4511\n",
      "\n",
      "\n",
      "loss before training is 0.00022070312642176148 -- epoch number 4512\n",
      "\n",
      "\n",
      "loss before training is 0.00022039472024525022 -- epoch number 4513\n",
      "\n",
      "\n",
      "loss before training is 0.00022008672595454963 -- epoch number 4514\n",
      "\n",
      "\n",
      "loss before training is 0.0002197791430594204 -- epoch number 4515\n",
      "\n",
      "\n",
      "loss before training is 0.00021947197107006895 -- epoch number 4516\n",
      "\n",
      "\n",
      "loss before training is 0.0002191652094971363 -- epoch number 4517\n",
      "\n",
      "\n",
      "loss before training is 0.00021885885785170807 -- epoch number 4518\n",
      "\n",
      "\n",
      "loss before training is 0.00021855291564530535 -- epoch number 4519\n",
      "\n",
      "\n",
      "loss before training is 0.00021824738238989297 -- epoch number 4520\n",
      "\n",
      "\n",
      "loss before training is 0.00021794225759787613 -- epoch number 4521\n",
      "\n",
      "\n",
      "loss before training is 0.00021763754078209786 -- epoch number 4522\n",
      "\n",
      "\n",
      "loss before training is 0.00021733323145584492 -- epoch number 4523\n",
      "\n",
      "\n",
      "loss before training is 0.00021702932913283192 -- epoch number 4524\n",
      "\n",
      "\n",
      "loss before training is 0.00021672583332723 -- epoch number 4525\n",
      "\n",
      "\n",
      "loss before training is 0.00021642274355363687 -- epoch number 4526\n",
      "\n",
      "\n",
      "loss before training is 0.00021612005932710002 -- epoch number 4527\n",
      "\n",
      "\n",
      "loss before training is 0.00021581778016309763 -- epoch number 4528\n",
      "\n",
      "\n",
      "loss before training is 0.00021551590557754828 -- epoch number 4529\n",
      "\n",
      "\n",
      "loss before training is 0.00021521443508681535 -- epoch number 4530\n",
      "\n",
      "\n",
      "loss before training is 0.00021491336820769573 -- epoch number 4531\n",
      "\n",
      "\n",
      "loss before training is 0.00021461270445743183 -- epoch number 4532\n",
      "\n",
      "\n",
      "loss before training is 0.00021431244335369385 -- epoch number 4533\n",
      "\n",
      "\n",
      "loss before training is 0.0002140125844146014 -- epoch number 4534\n",
      "\n",
      "\n",
      "loss before training is 0.00021371312715871154 -- epoch number 4535\n",
      "\n",
      "\n",
      "loss before training is 0.00021341407110501284 -- epoch number 4536\n",
      "\n",
      "\n",
      "loss before training is 0.00021311541577294157 -- epoch number 4537\n",
      "\n",
      "\n",
      "loss before training is 0.0002128171606823647 -- epoch number 4538\n",
      "\n",
      "\n",
      "loss before training is 0.00021251930535359513 -- epoch number 4539\n",
      "\n",
      "\n",
      "loss before training is 0.0002122218493073735 -- epoch number 4540\n",
      "\n",
      "\n",
      "loss before training is 0.0002119247920648889 -- epoch number 4541\n",
      "\n",
      "\n",
      "loss before training is 0.00021162813314776232 -- epoch number 4542\n",
      "\n",
      "\n",
      "loss before training is 0.0002113318720780588 -- epoch number 4543\n",
      "\n",
      "\n",
      "loss before training is 0.00021103600837827328 -- epoch number 4544\n",
      "\n",
      "\n",
      "loss before training is 0.0002107405415713418 -- epoch number 4545\n",
      "\n",
      "\n",
      "loss before training is 0.0002104454711806439 -- epoch number 4546\n",
      "\n",
      "\n",
      "loss before training is 0.0002101507967299865 -- epoch number 4547\n",
      "\n",
      "\n",
      "loss before training is 0.00020985651774362273 -- epoch number 4548\n",
      "\n",
      "\n",
      "loss before training is 0.00020956263374623452 -- epoch number 4549\n",
      "\n",
      "\n",
      "loss before training is 0.000209269144262949 -- epoch number 4550\n",
      "\n",
      "\n",
      "loss before training is 0.00020897604881932867 -- epoch number 4551\n",
      "\n",
      "\n",
      "loss before training is 0.00020868334694136955 -- epoch number 4552\n",
      "\n",
      "\n",
      "loss before training is 0.0002083910381555055 -- epoch number 4553\n",
      "\n",
      "\n",
      "loss before training is 0.0002080991219886074 -- epoch number 4554\n",
      "\n",
      "\n",
      "loss before training is 0.0002078075979679904 -- epoch number 4555\n",
      "\n",
      "\n",
      "loss before training is 0.00020751646562139177 -- epoch number 4556\n",
      "\n",
      "\n",
      "loss before training is 0.00020722572447699804 -- epoch number 4557\n",
      "\n",
      "\n",
      "loss before training is 0.0002069353740634262 -- epoch number 4558\n",
      "\n",
      "\n",
      "loss before training is 0.00020664541390972852 -- epoch number 4559\n",
      "\n",
      "\n",
      "loss before training is 0.0002063558435453975 -- epoch number 4560\n",
      "\n",
      "\n",
      "loss before training is 0.00020606666250035612 -- epoch number 4561\n",
      "\n",
      "\n",
      "loss before training is 0.0002057778703049712 -- epoch number 4562\n",
      "\n",
      "\n",
      "loss before training is 0.00020548946649003827 -- epoch number 4563\n",
      "\n",
      "\n",
      "loss before training is 0.00020520145058679218 -- epoch number 4564\n",
      "\n",
      "\n",
      "loss before training is 0.00020491382212690118 -- epoch number 4565\n",
      "\n",
      "\n",
      "loss before training is 0.00020462658064246961 -- epoch number 4566\n",
      "\n",
      "\n",
      "loss before training is 0.00020433972566603965 -- epoch number 4567\n",
      "\n",
      "\n",
      "loss before training is 0.00020405325673058535 -- epoch number 4568\n",
      "\n",
      "\n",
      "loss before training is 0.00020376717336951708 -- epoch number 4569\n",
      "\n",
      "\n",
      "loss before training is 0.00020348147511668272 -- epoch number 4570\n",
      "\n",
      "\n",
      "loss before training is 0.00020319616150635736 -- epoch number 4571\n",
      "\n",
      "\n",
      "loss before training is 0.00020291123207326144 -- epoch number 4572\n",
      "\n",
      "\n",
      "loss before training is 0.00020262668635254063 -- epoch number 4573\n",
      "\n",
      "\n",
      "loss before training is 0.00020234252387978075 -- epoch number 4574\n",
      "\n",
      "\n",
      "loss before training is 0.00020205874419100293 -- epoch number 4575\n",
      "\n",
      "\n",
      "loss before training is 0.00020177534682265787 -- epoch number 4576\n",
      "\n",
      "\n",
      "loss before training is 0.00020149233131163113 -- epoch number 4577\n",
      "\n",
      "\n",
      "loss before training is 0.00020120969719524646 -- epoch number 4578\n",
      "\n",
      "\n",
      "loss before training is 0.00020092744401125888 -- epoch number 4579\n",
      "\n",
      "\n",
      "loss before training is 0.00020064557129785232 -- epoch number 4580\n",
      "\n",
      "\n",
      "loss before training is 0.0002003640785936549 -- epoch number 4581\n",
      "\n",
      "\n",
      "loss before training is 0.00020008296543772044 -- epoch number 4582\n",
      "\n",
      "\n",
      "loss before training is 0.00019980223136953674 -- epoch number 4583\n",
      "\n",
      "\n",
      "loss before training is 0.00019952187592902886 -- epoch number 4584\n",
      "\n",
      "\n",
      "loss before training is 0.00019924189865655158 -- epoch number 4585\n",
      "\n",
      "\n",
      "loss before training is 0.0001989622990928915 -- epoch number 4586\n",
      "\n",
      "\n",
      "loss before training is 0.0001986830767792722 -- epoch number 4587\n",
      "\n",
      "\n",
      "loss before training is 0.00019840423125734618 -- epoch number 4588\n",
      "\n",
      "\n",
      "loss before training is 0.0001981257620692049 -- epoch number 4589\n",
      "\n",
      "\n",
      "loss before training is 0.0001978476687573639 -- epoch number 4590\n",
      "\n",
      "\n",
      "loss before training is 0.0001975699508647738 -- epoch number 4591\n",
      "\n",
      "\n",
      "loss before training is 0.00019729260793482288 -- epoch number 4592\n",
      "\n",
      "\n",
      "loss before training is 0.00019701563951132273 -- epoch number 4593\n",
      "\n",
      "\n",
      "loss before training is 0.00019673904513852657 -- epoch number 4594\n",
      "\n",
      "\n",
      "loss before training is 0.00019646282436110981 -- epoch number 4595\n",
      "\n",
      "\n",
      "loss before training is 0.00019618697672418297 -- epoch number 4596\n",
      "\n",
      "\n",
      "loss before training is 0.00019591150177329455 -- epoch number 4597\n",
      "\n",
      "\n",
      "loss before training is 0.00019563639905441447 -- epoch number 4598\n",
      "\n",
      "\n",
      "loss before training is 0.00019536166811394987 -- epoch number 4599\n",
      "\n",
      "\n",
      "loss before training is 0.00019508730849873915 -- epoch number 4600\n",
      "\n",
      "\n",
      "loss before training is 0.000194813319756047 -- epoch number 4601\n",
      "\n",
      "\n",
      "loss before training is 0.00019453970143357626 -- epoch number 4602\n",
      "\n",
      "\n",
      "loss before training is 0.00019426645307945147 -- epoch number 4603\n",
      "\n",
      "\n",
      "loss before training is 0.0001939935742422393 -- epoch number 4604\n",
      "\n",
      "\n",
      "loss before training is 0.00019372106447092344 -- epoch number 4605\n",
      "\n",
      "\n",
      "loss before training is 0.0001934489233149303 -- epoch number 4606\n",
      "\n",
      "\n",
      "loss before training is 0.00019317715032410654 -- epoch number 4607\n",
      "\n",
      "\n",
      "loss before training is 0.00019290574504873543 -- epoch number 4608\n",
      "\n",
      "\n",
      "loss before training is 0.00019263470703952682 -- epoch number 4609\n",
      "\n",
      "\n",
      "loss before training is 0.0001923640358476252 -- epoch number 4610\n",
      "\n",
      "\n",
      "loss before training is 0.00019209373102459563 -- epoch number 4611\n",
      "\n",
      "\n",
      "loss before training is 0.00019182379212243918 -- epoch number 4612\n",
      "\n",
      "\n",
      "loss before training is 0.00019155421869358736 -- epoch number 4613\n",
      "\n",
      "\n",
      "loss before training is 0.0001912850102908956 -- epoch number 4614\n",
      "\n",
      "\n",
      "loss before training is 0.00019101616646765272 -- epoch number 4615\n",
      "\n",
      "\n",
      "loss before training is 0.00019074768677757443 -- epoch number 4616\n",
      "\n",
      "\n",
      "loss before training is 0.00019047957077480534 -- epoch number 4617\n",
      "\n",
      "\n",
      "loss before training is 0.0001902118180139182 -- epoch number 4618\n",
      "\n",
      "\n",
      "loss before training is 0.00018994442804991585 -- epoch number 4619\n",
      "\n",
      "\n",
      "loss before training is 0.00018967740043822733 -- epoch number 4620\n",
      "\n",
      "\n",
      "loss before training is 0.00018941073473470953 -- epoch number 4621\n",
      "\n",
      "\n",
      "loss before training is 0.0001891444304956533 -- epoch number 4622\n",
      "\n",
      "\n",
      "loss before training is 0.00018887848727776793 -- epoch number 4623\n",
      "\n",
      "\n",
      "loss before training is 0.00018861290463819685 -- epoch number 4624\n",
      "\n",
      "\n",
      "loss before training is 0.00018834768213451018 -- epoch number 4625\n",
      "\n",
      "\n",
      "loss before training is 0.00018808281932470227 -- epoch number 4626\n",
      "\n",
      "\n",
      "loss before training is 0.0001878183157671985 -- epoch number 4627\n",
      "\n",
      "\n",
      "loss before training is 0.00018755417102084922 -- epoch number 4628\n",
      "\n",
      "\n",
      "loss before training is 0.00018729038464493234 -- epoch number 4629\n",
      "\n",
      "\n",
      "loss before training is 0.0001870269561991498 -- epoch number 4630\n",
      "\n",
      "\n",
      "loss before training is 0.00018676388524363694 -- epoch number 4631\n",
      "\n",
      "\n",
      "loss before training is 0.00018650117133894856 -- epoch number 4632\n",
      "\n",
      "\n",
      "loss before training is 0.0001862388140460681 -- epoch number 4633\n",
      "\n",
      "\n",
      "loss before training is 0.00018597681292640886 -- epoch number 4634\n",
      "\n",
      "\n",
      "loss before training is 0.00018571516754180474 -- epoch number 4635\n",
      "\n",
      "\n",
      "loss before training is 0.0001854538774545138 -- epoch number 4636\n",
      "\n",
      "\n",
      "loss before training is 0.00018519294222723058 -- epoch number 4637\n",
      "\n",
      "\n",
      "loss before training is 0.0001849323614230607 -- epoch number 4638\n",
      "\n",
      "\n",
      "loss before training is 0.0001846721346055489 -- epoch number 4639\n",
      "\n",
      "\n",
      "loss before training is 0.00018441226133865418 -- epoch number 4640\n",
      "\n",
      "\n",
      "loss before training is 0.00018415274118676673 -- epoch number 4641\n",
      "\n",
      "\n",
      "loss before training is 0.0001838935737146987 -- epoch number 4642\n",
      "\n",
      "\n",
      "loss before training is 0.0001836347584876903 -- epoch number 4643\n",
      "\n",
      "\n",
      "loss before training is 0.00018337629507139995 -- epoch number 4644\n",
      "\n",
      "\n",
      "loss before training is 0.00018311818303192012 -- epoch number 4645\n",
      "\n",
      "\n",
      "loss before training is 0.00018286042193575442 -- epoch number 4646\n",
      "\n",
      "\n",
      "loss before training is 0.00018260301134984613 -- epoch number 4647\n",
      "\n",
      "\n",
      "loss before training is 0.00018234595084155088 -- epoch number 4648\n",
      "\n",
      "\n",
      "loss before training is 0.0001820892399786488 -- epoch number 4649\n",
      "\n",
      "\n",
      "loss before training is 0.00018183287832935222 -- epoch number 4650\n",
      "\n",
      "\n",
      "loss before training is 0.00018157686546228173 -- epoch number 4651\n",
      "\n",
      "\n",
      "loss before training is 0.0001813212009465002 -- epoch number 4652\n",
      "\n",
      "\n",
      "loss before training is 0.00018106588435147684 -- epoch number 4653\n",
      "\n",
      "\n",
      "loss before training is 0.00018081091524711266 -- epoch number 4654\n",
      "\n",
      "\n",
      "loss before training is 0.00018055629320372973 -- epoch number 4655\n",
      "\n",
      "\n",
      "loss before training is 0.00018030201779207095 -- epoch number 4656\n",
      "\n",
      "\n",
      "loss before training is 0.00018004808858330335 -- epoch number 4657\n",
      "\n",
      "\n",
      "loss before training is 0.00017979450514901576 -- epoch number 4658\n",
      "\n",
      "\n",
      "loss before training is 0.0001795412670612181 -- epoch number 4659\n",
      "\n",
      "\n",
      "loss before training is 0.00017928837389234349 -- epoch number 4660\n",
      "\n",
      "\n",
      "loss before training is 0.00017903582521524685 -- epoch number 4661\n",
      "\n",
      "\n",
      "loss before training is 0.00017878362060320426 -- epoch number 4662\n",
      "\n",
      "\n",
      "loss before training is 0.0001785317596299103 -- epoch number 4663\n",
      "\n",
      "\n",
      "loss before training is 0.00017828024186948598 -- epoch number 4664\n",
      "\n",
      "\n",
      "loss before training is 0.00017802906689646798 -- epoch number 4665\n",
      "\n",
      "\n",
      "loss before training is 0.00017777823428581977 -- epoch number 4666\n",
      "\n",
      "\n",
      "loss before training is 0.00017752774361292053 -- epoch number 4667\n",
      "\n",
      "\n",
      "loss before training is 0.00017727759445357246 -- epoch number 4668\n",
      "\n",
      "\n",
      "loss before training is 0.00017702778638399458 -- epoch number 4669\n",
      "\n",
      "\n",
      "loss before training is 0.0001767783189808317 -- epoch number 4670\n",
      "\n",
      "\n",
      "loss before training is 0.00017652919182114342 -- epoch number 4671\n",
      "\n",
      "\n",
      "loss before training is 0.00017628040448241285 -- epoch number 4672\n",
      "\n",
      "\n",
      "loss before training is 0.00017603195654254103 -- epoch number 4673\n",
      "\n",
      "\n",
      "loss before training is 0.00017578384757984517 -- epoch number 4674\n",
      "\n",
      "\n",
      "loss before training is 0.00017553607717307168 -- epoch number 4675\n",
      "\n",
      "\n",
      "loss before training is 0.00017528864490137357 -- epoch number 4676\n",
      "\n",
      "\n",
      "loss before training is 0.00017504155034433184 -- epoch number 4677\n",
      "\n",
      "\n",
      "loss before training is 0.00017479479308193935 -- epoch number 4678\n",
      "\n",
      "\n",
      "loss before training is 0.0001745483726946144 -- epoch number 4679\n",
      "\n",
      "\n",
      "loss before training is 0.00017430228876318924 -- epoch number 4680\n",
      "\n",
      "\n",
      "loss before training is 0.00017405654086891648 -- epoch number 4681\n",
      "\n",
      "\n",
      "loss before training is 0.00017381112859346558 -- epoch number 4682\n",
      "\n",
      "\n",
      "loss before training is 0.00017356605151892183 -- epoch number 4683\n",
      "\n",
      "\n",
      "loss before training is 0.00017332130922779215 -- epoch number 4684\n",
      "\n",
      "\n",
      "loss before training is 0.0001730769013029984 -- epoch number 4685\n",
      "\n",
      "\n",
      "loss before training is 0.0001728328273278807 -- epoch number 4686\n",
      "\n",
      "\n",
      "loss before training is 0.00017258908688619367 -- epoch number 4687\n",
      "\n",
      "\n",
      "loss before training is 0.00017234567956211222 -- epoch number 4688\n",
      "\n",
      "\n",
      "loss before training is 0.00017210260494022998 -- epoch number 4689\n",
      "\n",
      "\n",
      "loss before training is 0.00017185986260554744 -- epoch number 4690\n",
      "\n",
      "\n",
      "loss before training is 0.00017161745214349473 -- epoch number 4691\n",
      "\n",
      "\n",
      "loss before training is 0.00017137537313990494 -- epoch number 4692\n",
      "\n",
      "\n",
      "loss before training is 0.00017113362518103787 -- epoch number 4693\n",
      "\n",
      "\n",
      "loss before training is 0.00017089220785356286 -- epoch number 4694\n",
      "\n",
      "\n",
      "loss before training is 0.00017065112074456603 -- epoch number 4695\n",
      "\n",
      "\n",
      "loss before training is 0.00017041036344155183 -- epoch number 4696\n",
      "\n",
      "\n",
      "loss before training is 0.00017016993553243395 -- epoch number 4697\n",
      "\n",
      "\n",
      "loss before training is 0.00016992983660554903 -- epoch number 4698\n",
      "\n",
      "\n",
      "loss before training is 0.00016969006624963808 -- epoch number 4699\n",
      "\n",
      "\n",
      "loss before training is 0.00016945062405386997 -- epoch number 4700\n",
      "\n",
      "\n",
      "loss before training is 0.00016921150960781756 -- epoch number 4701\n",
      "\n",
      "\n",
      "loss before training is 0.0001689727225014713 -- epoch number 4702\n",
      "\n",
      "\n",
      "loss before training is 0.00016873426232523443 -- epoch number 4703\n",
      "\n",
      "\n",
      "loss before training is 0.00016849612866993166 -- epoch number 4704\n",
      "\n",
      "\n",
      "loss before training is 0.00016825832112678685 -- epoch number 4705\n",
      "\n",
      "\n",
      "loss before training is 0.00016802083928744977 -- epoch number 4706\n",
      "\n",
      "\n",
      "loss before training is 0.00016778368274397986 -- epoch number 4707\n",
      "\n",
      "\n",
      "loss before training is 0.00016754685108884908 -- epoch number 4708\n",
      "\n",
      "\n",
      "loss before training is 0.00016731034391494204 -- epoch number 4709\n",
      "\n",
      "\n",
      "loss before training is 0.00016707416081555504 -- epoch number 4710\n",
      "\n",
      "\n",
      "loss before training is 0.0001668383013843999 -- epoch number 4711\n",
      "\n",
      "\n",
      "loss before training is 0.00016660276521560048 -- epoch number 4712\n",
      "\n",
      "\n",
      "loss before training is 0.0001663675519036892 -- epoch number 4713\n",
      "\n",
      "\n",
      "loss before training is 0.00016613266104361307 -- epoch number 4714\n",
      "\n",
      "\n",
      "loss before training is 0.00016589809223073205 -- epoch number 4715\n",
      "\n",
      "\n",
      "loss before training is 0.00016566384506081449 -- epoch number 4716\n",
      "\n",
      "\n",
      "loss before training is 0.000165429919130042 -- epoch number 4717\n",
      "\n",
      "\n",
      "loss before training is 0.00016519631403500936 -- epoch number 4718\n",
      "\n",
      "\n",
      "loss before training is 0.00016496302937271388 -- epoch number 4719\n",
      "\n",
      "\n",
      "loss before training is 0.0001647300647405768 -- epoch number 4720\n",
      "\n",
      "\n",
      "loss before training is 0.00016449741973642172 -- epoch number 4721\n",
      "\n",
      "\n",
      "loss before training is 0.00016426509395847975 -- epoch number 4722\n",
      "\n",
      "\n",
      "loss before training is 0.0001640330870053993 -- epoch number 4723\n",
      "\n",
      "\n",
      "loss before training is 0.00016380139847623534 -- epoch number 4724\n",
      "\n",
      "\n",
      "loss before training is 0.00016357002797045043 -- epoch number 4725\n",
      "\n",
      "\n",
      "loss before training is 0.00016333897508792302 -- epoch number 4726\n",
      "\n",
      "\n",
      "loss before training is 0.00016310823942893506 -- epoch number 4727\n",
      "\n",
      "\n",
      "loss before training is 0.00016287782059417943 -- epoch number 4728\n",
      "\n",
      "\n",
      "loss before training is 0.00016264771818475584 -- epoch number 4729\n",
      "\n",
      "\n",
      "loss before training is 0.00016241793180218087 -- epoch number 4730\n",
      "\n",
      "\n",
      "loss before training is 0.000162188461048369 -- epoch number 4731\n",
      "\n",
      "\n",
      "loss before training is 0.000161959305525649 -- epoch number 4732\n",
      "\n",
      "\n",
      "loss before training is 0.00016173046483675685 -- epoch number 4733\n",
      "\n",
      "\n",
      "loss before training is 0.00016150193858483722 -- epoch number 4734\n",
      "\n",
      "\n",
      "loss before training is 0.00016127372637344056 -- epoch number 4735\n",
      "\n",
      "\n",
      "loss before training is 0.00016104582780652582 -- epoch number 4736\n",
      "\n",
      "\n",
      "loss before training is 0.0001608182424884596 -- epoch number 4737\n",
      "\n",
      "\n",
      "loss before training is 0.00016059097002401544 -- epoch number 4738\n",
      "\n",
      "\n",
      "loss before training is 0.00016036401001837222 -- epoch number 4739\n",
      "\n",
      "\n",
      "loss before training is 0.00016013736207711924 -- epoch number 4740\n",
      "\n",
      "\n",
      "loss before training is 0.00015991102580624947 -- epoch number 4741\n",
      "\n",
      "\n",
      "loss before training is 0.00015968500081216003 -- epoch number 4742\n",
      "\n",
      "\n",
      "loss before training is 0.00015945928670165933 -- epoch number 4743\n",
      "\n",
      "\n",
      "loss before training is 0.00015923388308195887 -- epoch number 4744\n",
      "\n",
      "\n",
      "loss before training is 0.0001590087895606763 -- epoch number 4745\n",
      "\n",
      "\n",
      "loss before training is 0.0001587840057458333 -- epoch number 4746\n",
      "\n",
      "\n",
      "loss before training is 0.00015855953124586014 -- epoch number 4747\n",
      "\n",
      "\n",
      "loss before training is 0.00015833536566958365 -- epoch number 4748\n",
      "\n",
      "\n",
      "loss before training is 0.00015811150862625055 -- epoch number 4749\n",
      "\n",
      "\n",
      "loss before training is 0.0001578879597254969 -- epoch number 4750\n",
      "\n",
      "\n",
      "loss before training is 0.0001576647185773734 -- epoch number 4751\n",
      "\n",
      "\n",
      "loss before training is 0.00015744178479232864 -- epoch number 4752\n",
      "\n",
      "\n",
      "loss before training is 0.0001572191579812196 -- epoch number 4753\n",
      "\n",
      "\n",
      "loss before training is 0.00015699683775530272 -- epoch number 4754\n",
      "\n",
      "\n",
      "loss before training is 0.0001567748237262427 -- epoch number 4755\n",
      "\n",
      "\n",
      "loss before training is 0.0001565531155061047 -- epoch number 4756\n",
      "\n",
      "\n",
      "loss before training is 0.0001563317127073562 -- epoch number 4757\n",
      "\n",
      "\n",
      "loss before training is 0.0001561106149428713 -- epoch number 4758\n",
      "\n",
      "\n",
      "loss before training is 0.0001558898218259215 -- epoch number 4759\n",
      "\n",
      "\n",
      "loss before training is 0.0001556693329701868 -- epoch number 4760\n",
      "\n",
      "\n",
      "loss before training is 0.0001554491479897423 -- epoch number 4761\n",
      "\n",
      "\n",
      "loss before training is 0.00015522926649907498 -- epoch number 4762\n",
      "\n",
      "\n",
      "loss before training is 0.0001550096881130639 -- epoch number 4763\n",
      "\n",
      "\n",
      "loss before training is 0.00015479041244699618 -- epoch number 4764\n",
      "\n",
      "\n",
      "loss before training is 0.00015457143911655323 -- epoch number 4765\n",
      "\n",
      "\n",
      "loss before training is 0.00015435276773782773 -- epoch number 4766\n",
      "\n",
      "\n",
      "loss before training is 0.00015413439792730523 -- epoch number 4767\n",
      "\n",
      "\n",
      "loss before training is 0.00015391632930187487 -- epoch number 4768\n",
      "\n",
      "\n",
      "loss before training is 0.0001536985614788276 -- epoch number 4769\n",
      "\n",
      "\n",
      "loss before training is 0.00015348109407585308 -- epoch number 4770\n",
      "\n",
      "\n",
      "loss before training is 0.00015326392671103723 -- epoch number 4771\n",
      "\n",
      "\n",
      "loss before training is 0.0001530470590028747 -- epoch number 4772\n",
      "\n",
      "\n",
      "loss before training is 0.00015283049057025416 -- epoch number 4773\n",
      "\n",
      "\n",
      "loss before training is 0.00015261422103246417 -- epoch number 4774\n",
      "\n",
      "\n",
      "loss before training is 0.00015239825000918974 -- epoch number 4775\n",
      "\n",
      "\n",
      "loss before training is 0.00015218257712052276 -- epoch number 4776\n",
      "\n",
      "\n",
      "loss before training is 0.00015196720198694763 -- epoch number 4777\n",
      "\n",
      "\n",
      "loss before training is 0.00015175212422934698 -- epoch number 4778\n",
      "\n",
      "\n",
      "loss before training is 0.00015153734346900553 -- epoch number 4779\n",
      "\n",
      "\n",
      "loss before training is 0.00015132285932760353 -- epoch number 4780\n",
      "\n",
      "\n",
      "loss before training is 0.00015110867142721998 -- epoch number 4781\n",
      "\n",
      "\n",
      "loss before training is 0.00015089477939033157 -- epoch number 4782\n",
      "\n",
      "\n",
      "loss before training is 0.0001506811828398109 -- epoch number 4783\n",
      "\n",
      "\n",
      "loss before training is 0.00015046788139893146 -- epoch number 4784\n",
      "\n",
      "\n",
      "loss before training is 0.00015025487469135868 -- epoch number 4785\n",
      "\n",
      "\n",
      "loss before training is 0.00015004216234115844 -- epoch number 4786\n",
      "\n",
      "\n",
      "loss before training is 0.00014982974397279635 -- epoch number 4787\n",
      "\n",
      "\n",
      "loss before training is 0.00014961761921112338 -- epoch number 4788\n",
      "\n",
      "\n",
      "loss before training is 0.00014940578768139716 -- epoch number 4789\n",
      "\n",
      "\n",
      "loss before training is 0.00014919424900926883 -- epoch number 4790\n",
      "\n",
      "\n",
      "loss before training is 0.0001489830028207818 -- epoch number 4791\n",
      "\n",
      "\n",
      "loss before training is 0.00014877204874237575 -- epoch number 4792\n",
      "\n",
      "\n",
      "loss before training is 0.0001485613864008883 -- epoch number 4793\n",
      "\n",
      "\n",
      "loss before training is 0.00014835101542355243 -- epoch number 4794\n",
      "\n",
      "\n",
      "loss before training is 0.00014814093543799115 -- epoch number 4795\n",
      "\n",
      "\n",
      "loss before training is 0.0001479311460722242 -- epoch number 4796\n",
      "\n",
      "\n",
      "loss before training is 0.0001477216469546685 -- epoch number 4797\n",
      "\n",
      "\n",
      "loss before training is 0.00014751243771413114 -- epoch number 4798\n",
      "\n",
      "\n",
      "loss before training is 0.0001473035179798184 -- epoch number 4799\n",
      "\n",
      "\n",
      "loss before training is 0.00014709488738132067 -- epoch number 4800\n",
      "\n",
      "\n",
      "loss before training is 0.0001468865455486316 -- epoch number 4801\n",
      "\n",
      "\n",
      "loss before training is 0.00014667849211213063 -- epoch number 4802\n",
      "\n",
      "\n",
      "loss before training is 0.00014647072670259773 -- epoch number 4803\n",
      "\n",
      "\n",
      "loss before training is 0.00014626324895119683 -- epoch number 4804\n",
      "\n",
      "\n",
      "loss before training is 0.00014605605848949036 -- epoch number 4805\n",
      "\n",
      "\n",
      "loss before training is 0.0001458491549494338 -- epoch number 4806\n",
      "\n",
      "\n",
      "loss before training is 0.00014564253796336987 -- epoch number 4807\n",
      "\n",
      "\n",
      "loss before training is 0.00014543620716403176 -- epoch number 4808\n",
      "\n",
      "\n",
      "loss before training is 0.0001452301621845546 -- epoch number 4809\n",
      "\n",
      "\n",
      "loss before training is 0.00014502440265845546 -- epoch number 4810\n",
      "\n",
      "\n",
      "loss before training is 0.00014481892821964132 -- epoch number 4811\n",
      "\n",
      "\n",
      "loss before training is 0.00014461373850242017 -- epoch number 4812\n",
      "\n",
      "\n",
      "loss before training is 0.0001444088331414793 -- epoch number 4813\n",
      "\n",
      "\n",
      "loss before training is 0.0001442042117719025 -- epoch number 4814\n",
      "\n",
      "\n",
      "loss before training is 0.00014399987402916294 -- epoch number 4815\n",
      "\n",
      "\n",
      "loss before training is 0.00014379581954912242 -- epoch number 4816\n",
      "\n",
      "\n",
      "loss before training is 0.0001435920479680344 -- epoch number 4817\n",
      "\n",
      "\n",
      "loss before training is 0.00014338855892254157 -- epoch number 4818\n",
      "\n",
      "\n",
      "loss before training is 0.00014318535204967415 -- epoch number 4819\n",
      "\n",
      "\n",
      "loss before training is 0.00014298242698684887 -- epoch number 4820\n",
      "\n",
      "\n",
      "loss before training is 0.00014277978337187767 -- epoch number 4821\n",
      "\n",
      "\n",
      "loss before training is 0.00014257742084295777 -- epoch number 4822\n",
      "\n",
      "\n",
      "loss before training is 0.0001423753390386728 -- epoch number 4823\n",
      "\n",
      "\n",
      "loss before training is 0.0001421735375979965 -- epoch number 4824\n",
      "\n",
      "\n",
      "loss before training is 0.0001419720161602933 -- epoch number 4825\n",
      "\n",
      "\n",
      "loss before training is 0.00014177077436530776 -- epoch number 4826\n",
      "\n",
      "\n",
      "loss before training is 0.00014156981185317963 -- epoch number 4827\n",
      "\n",
      "\n",
      "loss before training is 0.00014136912826442986 -- epoch number 4828\n",
      "\n",
      "\n",
      "loss before training is 0.0001411687232399711 -- epoch number 4829\n",
      "\n",
      "\n",
      "loss before training is 0.00014096859642109588 -- epoch number 4830\n",
      "\n",
      "\n",
      "loss before training is 0.00014076874744949086 -- epoch number 4831\n",
      "\n",
      "\n",
      "loss before training is 0.00014056917596722457 -- epoch number 4832\n",
      "\n",
      "\n",
      "loss before training is 0.00014036988161675364 -- epoch number 4833\n",
      "\n",
      "\n",
      "loss before training is 0.00014017086404091456 -- epoch number 4834\n",
      "\n",
      "\n",
      "loss before training is 0.00013997212288293918 -- epoch number 4835\n",
      "\n",
      "\n",
      "loss before training is 0.00013977365778643526 -- epoch number 4836\n",
      "\n",
      "\n",
      "loss before training is 0.00013957546839540053 -- epoch number 4837\n",
      "\n",
      "\n",
      "loss before training is 0.00013937755435421595 -- epoch number 4838\n",
      "\n",
      "\n",
      "loss before training is 0.00013917991530764648 -- epoch number 4839\n",
      "\n",
      "\n",
      "loss before training is 0.00013898255090084424 -- epoch number 4840\n",
      "\n",
      "\n",
      "loss before training is 0.00013878546077933983 -- epoch number 4841\n",
      "\n",
      "\n",
      "loss before training is 0.00013858864458905383 -- epoch number 4842\n",
      "\n",
      "\n",
      "loss before training is 0.0001383921019762868 -- epoch number 4843\n",
      "\n",
      "\n",
      "loss before training is 0.00013819583258771942 -- epoch number 4844\n",
      "\n",
      "\n",
      "loss before training is 0.00013799983607042473 -- epoch number 4845\n",
      "\n",
      "\n",
      "loss before training is 0.00013780411207184922 -- epoch number 4846\n",
      "\n",
      "\n",
      "loss before training is 0.00013760866023982654 -- epoch number 4847\n",
      "\n",
      "\n",
      "loss before training is 0.00013741348022257334 -- epoch number 4848\n",
      "\n",
      "\n",
      "loss before training is 0.00013721857166868379 -- epoch number 4849\n",
      "\n",
      "\n",
      "loss before training is 0.0001370239342271377 -- epoch number 4850\n",
      "\n",
      "\n",
      "loss before training is 0.00013682956754729807 -- epoch number 4851\n",
      "\n",
      "\n",
      "loss before training is 0.00013663547127890367 -- epoch number 4852\n",
      "\n",
      "\n",
      "loss before training is 0.0001364416450720788 -- epoch number 4853\n",
      "\n",
      "\n",
      "loss before training is 0.00013624808857732695 -- epoch number 4854\n",
      "\n",
      "\n",
      "loss before training is 0.00013605480144553405 -- epoch number 4855\n",
      "\n",
      "\n",
      "loss before training is 0.00013586178332796123 -- epoch number 4856\n",
      "\n",
      "\n",
      "loss before training is 0.0001356690338762556 -- epoch number 4857\n",
      "\n",
      "\n",
      "loss before training is 0.00013547655274244366 -- epoch number 4858\n",
      "\n",
      "\n",
      "loss before training is 0.00013528433957892463 -- epoch number 4859\n",
      "\n",
      "\n",
      "loss before training is 0.0001350923940384875 -- epoch number 4860\n",
      "\n",
      "\n",
      "loss before training is 0.00013490071577429145 -- epoch number 4861\n",
      "\n",
      "\n",
      "loss before training is 0.0001347093044398815 -- epoch number 4862\n",
      "\n",
      "\n",
      "loss before training is 0.0001345181596891742 -- epoch number 4863\n",
      "\n",
      "\n",
      "loss before training is 0.00013432728117647113 -- epoch number 4864\n",
      "\n",
      "\n",
      "loss before training is 0.00013413666855644922 -- epoch number 4865\n",
      "\n",
      "\n",
      "loss before training is 0.0001339463214841606 -- epoch number 4866\n",
      "\n",
      "\n",
      "loss before training is 0.0001337562396150407 -- epoch number 4867\n",
      "\n",
      "\n",
      "loss before training is 0.00013356642260489588 -- epoch number 4868\n",
      "\n",
      "\n",
      "loss before training is 0.00013337687010991662 -- epoch number 4869\n",
      "\n",
      "\n",
      "loss before training is 0.00013318758178666566 -- epoch number 4870\n",
      "\n",
      "\n",
      "loss before training is 0.00013299855729208355 -- epoch number 4871\n",
      "\n",
      "\n",
      "loss before training is 0.00013280979628348558 -- epoch number 4872\n",
      "\n",
      "\n",
      "loss before training is 0.00013262129841856932 -- epoch number 4873\n",
      "\n",
      "\n",
      "loss before training is 0.00013243306335539834 -- epoch number 4874\n",
      "\n",
      "\n",
      "loss before training is 0.00013224509075242022 -- epoch number 4875\n",
      "\n",
      "\n",
      "loss before training is 0.00013205738026845595 -- epoch number 4876\n",
      "\n",
      "\n",
      "loss before training is 0.00013186993156270098 -- epoch number 4877\n",
      "\n",
      "\n",
      "loss before training is 0.000131682744294723 -- epoch number 4878\n",
      "\n",
      "\n",
      "loss before training is 0.00013149581812446813 -- epoch number 4879\n",
      "\n",
      "\n",
      "loss before training is 0.0001313091527122567 -- epoch number 4880\n",
      "\n",
      "\n",
      "loss before training is 0.00013112274771878086 -- epoch number 4881\n",
      "\n",
      "\n",
      "loss before training is 0.00013093660280511036 -- epoch number 4882\n",
      "\n",
      "\n",
      "loss before training is 0.00013075071763268289 -- epoch number 4883\n",
      "\n",
      "\n",
      "loss before training is 0.00013056509186331467 -- epoch number 4884\n",
      "\n",
      "\n",
      "loss before training is 0.0001303797251591939 -- epoch number 4885\n",
      "\n",
      "\n",
      "loss before training is 0.0001301946171828816 -- epoch number 4886\n",
      "\n",
      "\n",
      "loss before training is 0.00013000976759730958 -- epoch number 4887\n",
      "\n",
      "\n",
      "loss before training is 0.00012982517606578432 -- epoch number 4888\n",
      "\n",
      "\n",
      "loss before training is 0.000129640842251985 -- epoch number 4889\n",
      "\n",
      "\n",
      "loss before training is 0.0001294567658199593 -- epoch number 4890\n",
      "\n",
      "\n",
      "loss before training is 0.00012927294643412946 -- epoch number 4891\n",
      "\n",
      "\n",
      "loss before training is 0.00012908938375928768 -- epoch number 4892\n",
      "\n",
      "\n",
      "loss before training is 0.00012890607746060038 -- epoch number 4893\n",
      "\n",
      "\n",
      "loss before training is 0.0001287230272035973 -- epoch number 4894\n",
      "\n",
      "\n",
      "loss before training is 0.00012854023265419123 -- epoch number 4895\n",
      "\n",
      "\n",
      "loss before training is 0.00012835769347865238 -- epoch number 4896\n",
      "\n",
      "\n",
      "loss before training is 0.00012817540934362932 -- epoch number 4897\n",
      "\n",
      "\n",
      "loss before training is 0.00012799337991613847 -- epoch number 4898\n",
      "\n",
      "\n",
      "loss before training is 0.00012781160486356326 -- epoch number 4899\n",
      "\n",
      "\n",
      "loss before training is 0.00012763008385365942 -- epoch number 4900\n",
      "\n",
      "\n",
      "loss before training is 0.0001274488165545537 -- epoch number 4901\n",
      "\n",
      "\n",
      "loss before training is 0.00012726780263473694 -- epoch number 4902\n",
      "\n",
      "\n",
      "loss before training is 0.00012708704176306933 -- epoch number 4903\n",
      "\n",
      "\n",
      "loss before training is 0.00012690653360878068 -- epoch number 4904\n",
      "\n",
      "\n",
      "loss before training is 0.0001267262778414739 -- epoch number 4905\n",
      "\n",
      "\n",
      "loss before training is 0.00012654627413111218 -- epoch number 4906\n",
      "\n",
      "\n",
      "loss before training is 0.00012636652214802722 -- epoch number 4907\n",
      "\n",
      "\n",
      "loss before training is 0.00012618702156292375 -- epoch number 4908\n",
      "\n",
      "\n",
      "loss before training is 0.00012600777204686616 -- epoch number 4909\n",
      "\n",
      "\n",
      "loss before training is 0.00012582877327128964 -- epoch number 4910\n",
      "\n",
      "\n",
      "loss before training is 0.00012565002490799615 -- epoch number 4911\n",
      "\n",
      "\n",
      "loss before training is 0.00012547152662915507 -- epoch number 4912\n",
      "\n",
      "\n",
      "loss before training is 0.0001252932781072963 -- epoch number 4913\n",
      "\n",
      "\n",
      "loss before training is 0.00012511527901532335 -- epoch number 4914\n",
      "\n",
      "\n",
      "loss before training is 0.00012493752902650087 -- epoch number 4915\n",
      "\n",
      "\n",
      "loss before training is 0.0001247600278144563 -- epoch number 4916\n",
      "\n",
      "\n",
      "loss before training is 0.00012458277505318787 -- epoch number 4917\n",
      "\n",
      "\n",
      "loss before training is 0.0001244057704170568 -- epoch number 4918\n",
      "\n",
      "\n",
      "loss before training is 0.00012422901358078342 -- epoch number 4919\n",
      "\n",
      "\n",
      "loss before training is 0.0001240525042194607 -- epoch number 4920\n",
      "\n",
      "\n",
      "loss before training is 0.00012387624200853987 -- epoch number 4921\n",
      "\n",
      "\n",
      "loss before training is 0.0001237002266238364 -- epoch number 4922\n",
      "\n",
      "\n",
      "loss before training is 0.00012352445774153187 -- epoch number 4923\n",
      "\n",
      "\n",
      "loss before training is 0.00012334893503817244 -- epoch number 4924\n",
      "\n",
      "\n",
      "loss before training is 0.0001231736581906593 -- epoch number 4925\n",
      "\n",
      "\n",
      "loss before training is 0.0001229986268762645 -- epoch number 4926\n",
      "\n",
      "\n",
      "loss before training is 0.00012282384077261956 -- epoch number 4927\n",
      "\n",
      "\n",
      "loss before training is 0.0001226492995577182 -- epoch number 4928\n",
      "\n",
      "\n",
      "loss before training is 0.00012247500290991543 -- epoch number 4929\n",
      "\n",
      "\n",
      "loss before training is 0.00012230095050792854 -- epoch number 4930\n",
      "\n",
      "\n",
      "loss before training is 0.0001221271420308374 -- epoch number 4931\n",
      "\n",
      "\n",
      "loss before training is 0.00012195357715808072 -- epoch number 4932\n",
      "\n",
      "\n",
      "loss before training is 0.00012178025556945945 -- epoch number 4933\n",
      "\n",
      "\n",
      "loss before training is 0.00012160717694513568 -- epoch number 4934\n",
      "\n",
      "\n",
      "loss before training is 0.00012143434096562974 -- epoch number 4935\n",
      "\n",
      "\n",
      "loss before training is 0.00012126174731182568 -- epoch number 4936\n",
      "\n",
      "\n",
      "loss before training is 0.00012108939566496544 -- epoch number 4937\n",
      "\n",
      "\n",
      "loss before training is 0.00012091728570664651 -- epoch number 4938\n",
      "\n",
      "\n",
      "loss before training is 0.00012074541711883482 -- epoch number 4939\n",
      "\n",
      "\n",
      "loss before training is 0.00012057378958384615 -- epoch number 4940\n",
      "\n",
      "\n",
      "loss before training is 0.00012040240278436142 -- epoch number 4941\n",
      "\n",
      "\n",
      "loss before training is 0.00012023125640341485 -- epoch number 4942\n",
      "\n",
      "\n",
      "loss before training is 0.00012006035012440534 -- epoch number 4943\n",
      "\n",
      "\n",
      "loss before training is 0.00011988968363108263 -- epoch number 4944\n",
      "\n",
      "\n",
      "loss before training is 0.00011971925660756138 -- epoch number 4945\n",
      "\n",
      "\n",
      "loss before training is 0.00011954906873830987 -- epoch number 4946\n",
      "\n",
      "\n",
      "loss before training is 0.0001193791197081504 -- epoch number 4947\n",
      "\n",
      "\n",
      "loss before training is 0.0001192094092022686 -- epoch number 4948\n",
      "\n",
      "\n",
      "loss before training is 0.00011903993690620503 -- epoch number 4949\n",
      "\n",
      "\n",
      "loss before training is 0.00011887070250585501 -- epoch number 4950\n",
      "\n",
      "\n",
      "loss before training is 0.00011870170568746658 -- epoch number 4951\n",
      "\n",
      "\n",
      "loss before training is 0.00011853294613765512 -- epoch number 4952\n",
      "\n",
      "\n",
      "loss before training is 0.00011836442354337937 -- epoch number 4953\n",
      "\n",
      "\n",
      "loss before training is 0.00011819613759195864 -- epoch number 4954\n",
      "\n",
      "\n",
      "loss before training is 0.00011802808797106834 -- epoch number 4955\n",
      "\n",
      "\n",
      "loss before training is 0.00011786027436873845 -- epoch number 4956\n",
      "\n",
      "\n",
      "loss before training is 0.00011769269647335213 -- epoch number 4957\n",
      "\n",
      "\n",
      "loss before training is 0.00011752535397364641 -- epoch number 4958\n",
      "\n",
      "\n",
      "loss before training is 0.00011735824655871422 -- epoch number 4959\n",
      "\n",
      "\n",
      "loss before training is 0.00011719137391800212 -- epoch number 4960\n",
      "\n",
      "\n",
      "loss before training is 0.00011702473574130818 -- epoch number 4961\n",
      "\n",
      "\n",
      "loss before training is 0.00011685833171878938 -- epoch number 4962\n",
      "\n",
      "\n",
      "loss before training is 0.0001166921615409462 -- epoch number 4963\n",
      "\n",
      "\n",
      "loss before training is 0.00011652622489863715 -- epoch number 4964\n",
      "\n",
      "\n",
      "loss before training is 0.00011636052148307823 -- epoch number 4965\n",
      "\n",
      "\n",
      "loss before training is 0.00011619505098583072 -- epoch number 4966\n",
      "\n",
      "\n",
      "loss before training is 0.00011602981309880863 -- epoch number 4967\n",
      "\n",
      "\n",
      "loss before training is 0.00011586480751427851 -- epoch number 4968\n",
      "\n",
      "\n",
      "loss before training is 0.00011570003392486134 -- epoch number 4969\n",
      "\n",
      "\n",
      "loss before training is 0.00011553549202352351 -- epoch number 4970\n",
      "\n",
      "\n",
      "loss before training is 0.00011537118150358777 -- epoch number 4971\n",
      "\n",
      "\n",
      "loss before training is 0.00011520710205872404 -- epoch number 4972\n",
      "\n",
      "\n",
      "loss before training is 0.00011504325338295564 -- epoch number 4973\n",
      "\n",
      "\n",
      "loss before training is 0.0001148796351706512 -- epoch number 4974\n",
      "\n",
      "\n",
      "loss before training is 0.00011471624711653395 -- epoch number 4975\n",
      "\n",
      "\n",
      "loss before training is 0.00011455308891567426 -- epoch number 4976\n",
      "\n",
      "\n",
      "loss before training is 0.0001143901602634904 -- epoch number 4977\n",
      "\n",
      "\n",
      "loss before training is 0.00011422746085575734 -- epoch number 4978\n",
      "\n",
      "\n",
      "loss before training is 0.0001140649903885874 -- epoch number 4979\n",
      "\n",
      "\n",
      "loss before training is 0.00011390274855845083 -- epoch number 4980\n",
      "\n",
      "\n",
      "loss before training is 0.00011374073506216036 -- epoch number 4981\n",
      "\n",
      "\n",
      "loss before training is 0.0001135789495968787 -- epoch number 4982\n",
      "\n",
      "\n",
      "loss before training is 0.00011341739186011875 -- epoch number 4983\n",
      "\n",
      "\n",
      "loss before training is 0.00011325606154973382 -- epoch number 4984\n",
      "\n",
      "\n",
      "loss before training is 0.00011309495836393224 -- epoch number 4985\n",
      "\n",
      "\n",
      "loss before training is 0.00011293408200126591 -- epoch number 4986\n",
      "\n",
      "\n",
      "loss before training is 0.00011277343216063319 -- epoch number 4987\n",
      "\n",
      "\n",
      "loss before training is 0.00011261300854127812 -- epoch number 4988\n",
      "\n",
      "\n",
      "loss before training is 0.00011245281084279308 -- epoch number 4989\n",
      "\n",
      "\n",
      "loss before training is 0.00011229283876511357 -- epoch number 4990\n",
      "\n",
      "\n",
      "loss before training is 0.00011213309200852351 -- epoch number 4991\n",
      "\n",
      "\n",
      "loss before training is 0.00011197357027364967 -- epoch number 4992\n",
      "\n",
      "\n",
      "loss before training is 0.00011181427326146425 -- epoch number 4993\n",
      "\n",
      "\n",
      "loss before training is 0.00011165520067328517 -- epoch number 4994\n",
      "\n",
      "\n",
      "loss before training is 0.0001114963522107747 -- epoch number 4995\n",
      "\n",
      "\n",
      "loss before training is 0.0001113377275759398 -- epoch number 4996\n",
      "\n",
      "\n",
      "loss before training is 0.00011117932647112978 -- epoch number 4997\n",
      "\n",
      "\n",
      "loss before training is 0.00011102114859903888 -- epoch number 4998\n",
      "\n",
      "\n",
      "loss before training is 0.00011086319366270356 -- epoch number 4999\n",
      "\n",
      "\n",
      "loss before training is 0.00011070546136550337 -- epoch number 5000\n",
      "\n",
      "\n",
      "loss before training is 0.00011054795141116414 -- epoch number 5001\n",
      "\n",
      "\n",
      "loss before training is 0.00011039066350375029 -- epoch number 5002\n",
      "\n",
      "\n",
      "loss before training is 0.00011023359734767199 -- epoch number 5003\n",
      "\n",
      "\n",
      "loss before training is 0.00011007675264767598 -- epoch number 5004\n",
      "\n",
      "\n",
      "loss before training is 0.0001099201291088562 -- epoch number 5005\n",
      "\n",
      "\n",
      "loss before training is 0.00010976372643664608 -- epoch number 5006\n",
      "\n",
      "\n",
      "loss before training is 0.00010960754433682215 -- epoch number 5007\n",
      "\n",
      "\n",
      "loss before training is 0.00010945158251549765 -- epoch number 5008\n",
      "\n",
      "\n",
      "loss before training is 0.00010929584067913235 -- epoch number 5009\n",
      "\n",
      "\n",
      "loss before training is 0.0001091403185345198 -- epoch number 5010\n",
      "\n",
      "\n",
      "loss before training is 0.00010898501578879857 -- epoch number 5011\n",
      "\n",
      "\n",
      "loss before training is 0.00010882993214944648 -- epoch number 5012\n",
      "\n",
      "\n",
      "loss before training is 0.00010867506732427964 -- epoch number 5013\n",
      "\n",
      "\n",
      "loss before training is 0.00010852042102145549 -- epoch number 5014\n",
      "\n",
      "\n",
      "loss before training is 0.00010836599294946749 -- epoch number 5015\n",
      "\n",
      "\n",
      "loss before training is 0.00010821178281715004 -- epoch number 5016\n",
      "\n",
      "\n",
      "loss before training is 0.00010805779033367865 -- epoch number 5017\n",
      "\n",
      "\n",
      "loss before training is 0.00010790401520856016 -- epoch number 5018\n",
      "\n",
      "\n",
      "loss before training is 0.00010775045715164604 -- epoch number 5019\n",
      "\n",
      "\n",
      "loss before training is 0.00010759711587312023 -- epoch number 5020\n",
      "\n",
      "\n",
      "loss before training is 0.00010744399108351119 -- epoch number 5021\n",
      "\n",
      "\n",
      "loss before training is 0.00010729108249367847 -- epoch number 5022\n",
      "\n",
      "\n",
      "loss before training is 0.00010713838981481858 -- epoch number 5023\n",
      "\n",
      "\n",
      "loss before training is 0.00010698591275846796 -- epoch number 5024\n",
      "\n",
      "\n",
      "loss before training is 0.00010683365103649967 -- epoch number 5025\n",
      "\n",
      "\n",
      "loss before training is 0.0001066816043611177 -- epoch number 5026\n",
      "\n",
      "\n",
      "loss before training is 0.00010652977244486821 -- epoch number 5027\n",
      "\n",
      "\n",
      "loss before training is 0.00010637815500062951 -- epoch number 5028\n",
      "\n",
      "\n",
      "loss before training is 0.00010622675174161626 -- epoch number 5029\n",
      "\n",
      "\n",
      "loss before training is 0.00010607556238137658 -- epoch number 5030\n",
      "\n",
      "\n",
      "loss before training is 0.00010592458663379545 -- epoch number 5031\n",
      "\n",
      "\n",
      "loss before training is 0.0001057738242130902 -- epoch number 5032\n",
      "\n",
      "\n",
      "loss before training is 0.00010562327483381508 -- epoch number 5033\n",
      "\n",
      "\n",
      "loss before training is 0.00010547293821085693 -- epoch number 5034\n",
      "\n",
      "\n",
      "loss before training is 0.00010532281405943627 -- epoch number 5035\n",
      "\n",
      "\n",
      "loss before training is 0.00010517290209510535 -- epoch number 5036\n",
      "\n",
      "\n",
      "loss before training is 0.00010502320203375222 -- epoch number 5037\n",
      "\n",
      "\n",
      "loss before training is 0.00010487371359159774 -- epoch number 5038\n",
      "\n",
      "\n",
      "loss before training is 0.0001047244364851932 -- epoch number 5039\n",
      "\n",
      "\n",
      "loss before training is 0.00010457537043142339 -- epoch number 5040\n",
      "\n",
      "\n",
      "loss before training is 0.00010442651514750456 -- epoch number 5041\n",
      "\n",
      "\n",
      "loss before training is 0.00010427787035098574 -- epoch number 5042\n",
      "\n",
      "\n",
      "loss before training is 0.00010412943575974742 -- epoch number 5043\n",
      "\n",
      "\n",
      "loss before training is 0.00010398121109200188 -- epoch number 5044\n",
      "\n",
      "\n",
      "loss before training is 0.0001038331960662896 -- epoch number 5045\n",
      "\n",
      "\n",
      "loss before training is 0.00010368539040148472 -- epoch number 5046\n",
      "\n",
      "\n",
      "loss before training is 0.00010353779381679021 -- epoch number 5047\n",
      "\n",
      "\n",
      "loss before training is 0.00010339040603174045 -- epoch number 5048\n",
      "\n",
      "\n",
      "loss before training is 0.000103243226766197 -- epoch number 5049\n",
      "\n",
      "\n",
      "loss before training is 0.00010309625574035537 -- epoch number 5050\n",
      "\n",
      "\n",
      "loss before training is 0.00010294949267473503 -- epoch number 5051\n",
      "\n",
      "\n",
      "loss before training is 0.00010280293729018845 -- epoch number 5052\n",
      "\n",
      "\n",
      "loss before training is 0.00010265658930789782 -- epoch number 5053\n",
      "\n",
      "\n",
      "loss before training is 0.00010251044844936955 -- epoch number 5054\n",
      "\n",
      "\n",
      "loss before training is 0.0001023645144364419 -- epoch number 5055\n",
      "\n",
      "\n",
      "loss before training is 0.00010221878699127846 -- epoch number 5056\n",
      "\n",
      "\n",
      "loss before training is 0.0001020732658363721 -- epoch number 5057\n",
      "\n",
      "\n",
      "loss before training is 0.00010192795069454444 -- epoch number 5058\n",
      "\n",
      "\n",
      "loss before training is 0.00010178284128894118 -- epoch number 5059\n",
      "\n",
      "\n",
      "loss before training is 0.00010163793734303631 -- epoch number 5060\n",
      "\n",
      "\n",
      "loss before training is 0.00010149323858063193 -- epoch number 5061\n",
      "\n",
      "\n",
      "loss before training is 0.00010134874472585272 -- epoch number 5062\n",
      "\n",
      "\n",
      "loss before training is 0.00010120445550315125 -- epoch number 5063\n",
      "\n",
      "\n",
      "loss before training is 0.00010106037063730943 -- epoch number 5064\n",
      "\n",
      "\n",
      "loss before training is 0.00010091648985342973 -- epoch number 5065\n",
      "\n",
      "\n",
      "loss before training is 0.00010077281287694035 -- epoch number 5066\n",
      "\n",
      "\n",
      "loss before training is 0.0001006293394335986 -- epoch number 5067\n",
      "\n",
      "\n",
      "loss before training is 0.00010048606924948222 -- epoch number 5068\n",
      "\n",
      "\n",
      "loss before training is 0.00010034300205099576 -- epoch number 5069\n",
      "\n",
      "\n",
      "loss before training is 0.00010020013756486199 -- epoch number 5070\n",
      "\n",
      "\n",
      "loss before training is 0.00010005747551813833 -- epoch number 5071\n",
      "\n",
      "\n",
      "loss before training is 9.9915015638198e-05 -- epoch number 5072\n",
      "\n",
      "\n",
      "loss before training is 9.977275765273861e-05 -- epoch number 5073\n",
      "\n",
      "\n",
      "loss before training is 9.96307012897829e-05 -- epoch number 5074\n",
      "\n",
      "\n",
      "loss before training is 9.94888462776748e-05 -- epoch number 5075\n",
      "\n",
      "\n",
      "loss before training is 9.934719234508125e-05 -- epoch number 5076\n",
      "\n",
      "\n",
      "loss before training is 9.920573922098967e-05 -- epoch number 5077\n",
      "\n",
      "\n",
      "loss before training is 9.906448663471205e-05 -- epoch number 5078\n",
      "\n",
      "\n",
      "loss before training is 9.892343431588117e-05 -- epoch number 5079\n",
      "\n",
      "\n",
      "loss before training is 9.878258199445185e-05 -- epoch number 5080\n",
      "\n",
      "\n",
      "loss before training is 9.864192940069626e-05 -- epoch number 5081\n",
      "\n",
      "\n",
      "loss before training is 9.850147626521346e-05 -- epoch number 5082\n",
      "\n",
      "\n",
      "loss before training is 9.836122231892026e-05 -- epoch number 5083\n",
      "\n",
      "\n",
      "loss before training is 9.822116729305039e-05 -- epoch number 5084\n",
      "\n",
      "\n",
      "loss before training is 9.80813109191625e-05 -- epoch number 5085\n",
      "\n",
      "\n",
      "loss before training is 9.794165292913352e-05 -- epoch number 5086\n",
      "\n",
      "\n",
      "loss before training is 9.780219305516052e-05 -- epoch number 5087\n",
      "\n",
      "\n",
      "loss before training is 9.766293102975647e-05 -- epoch number 5088\n",
      "\n",
      "\n",
      "loss before training is 9.752386658575631e-05 -- epoch number 5089\n",
      "\n",
      "\n",
      "loss before training is 9.738499945631418e-05 -- epoch number 5090\n",
      "\n",
      "\n",
      "loss before training is 9.724632937489784e-05 -- epoch number 5091\n",
      "\n",
      "\n",
      "loss before training is 9.710785607530165e-05 -- epoch number 5092\n",
      "\n",
      "\n",
      "loss before training is 9.69695792916316e-05 -- epoch number 5093\n",
      "\n",
      "\n",
      "loss before training is 9.683149875830986e-05 -- epoch number 5094\n",
      "\n",
      "\n",
      "loss before training is 9.669361421008124e-05 -- epoch number 5095\n",
      "\n",
      "\n",
      "loss before training is 9.655592538200346e-05 -- epoch number 5096\n",
      "\n",
      "\n",
      "loss before training is 9.641843200945189e-05 -- epoch number 5097\n",
      "\n",
      "\n",
      "loss before training is 9.628113382812037e-05 -- epoch number 5098\n",
      "\n",
      "\n",
      "loss before training is 9.614403057401662e-05 -- epoch number 5099\n",
      "\n",
      "\n",
      "loss before training is 9.600712198346424e-05 -- epoch number 5100\n",
      "\n",
      "\n",
      "loss before training is 9.587040779310591e-05 -- epoch number 5101\n",
      "\n",
      "\n",
      "loss before training is 9.573388773989448e-05 -- epoch number 5102\n",
      "\n",
      "\n",
      "loss before training is 9.559756156110086e-05 -- epoch number 5103\n",
      "\n",
      "\n",
      "loss before training is 9.546142899431215e-05 -- epoch number 5104\n",
      "\n",
      "\n",
      "loss before training is 9.532548977742456e-05 -- epoch number 5105\n",
      "\n",
      "\n",
      "loss before training is 9.518974364865699e-05 -- epoch number 5106\n",
      "\n",
      "\n",
      "loss before training is 9.505419034653479e-05 -- epoch number 5107\n",
      "\n",
      "\n",
      "loss before training is 9.491882960989933e-05 -- epoch number 5108\n",
      "\n",
      "\n",
      "loss before training is 9.478366117790906e-05 -- epoch number 5109\n",
      "\n",
      "\n",
      "loss before training is 9.464868479002774e-05 -- epoch number 5110\n",
      "\n",
      "\n",
      "loss before training is 9.451390018603935e-05 -- epoch number 5111\n",
      "\n",
      "\n",
      "loss before training is 9.437930710603912e-05 -- epoch number 5112\n",
      "\n",
      "\n",
      "loss before training is 9.424490529043385e-05 -- epoch number 5113\n",
      "\n",
      "\n",
      "loss before training is 9.411069447993784e-05 -- epoch number 5114\n",
      "\n",
      "\n",
      "loss before training is 9.397667441558506e-05 -- epoch number 5115\n",
      "\n",
      "\n",
      "loss before training is 9.384284483871487e-05 -- epoch number 5116\n",
      "\n",
      "\n",
      "loss before training is 9.370920549098236e-05 -- epoch number 5117\n",
      "\n",
      "\n",
      "loss before training is 9.35757561143506e-05 -- epoch number 5118\n",
      "\n",
      "\n",
      "loss before training is 9.344249645109324e-05 -- epoch number 5119\n",
      "\n",
      "\n",
      "loss before training is 9.330942624379869e-05 -- epoch number 5120\n",
      "\n",
      "\n",
      "loss before training is 9.317654523535782e-05 -- epoch number 5121\n",
      "\n",
      "\n",
      "loss before training is 9.304385316897939e-05 -- epoch number 5122\n",
      "\n",
      "\n",
      "loss before training is 9.291134978817558e-05 -- epoch number 5123\n",
      "\n",
      "\n",
      "loss before training is 9.277903483677261e-05 -- epoch number 5124\n",
      "\n",
      "\n",
      "loss before training is 9.264690805890295e-05 -- epoch number 5125\n",
      "\n",
      "\n",
      "loss before training is 9.25149691990064e-05 -- epoch number 5126\n",
      "\n",
      "\n",
      "loss before training is 9.238321800183654e-05 -- epoch number 5127\n",
      "\n",
      "\n",
      "loss before training is 9.225165421244971e-05 -- epoch number 5128\n",
      "\n",
      "\n",
      "loss before training is 9.212027757621476e-05 -- epoch number 5129\n",
      "\n",
      "\n",
      "loss before training is 9.198908783880524e-05 -- epoch number 5130\n",
      "\n",
      "\n",
      "loss before training is 9.185808474620104e-05 -- epoch number 5131\n",
      "\n",
      "\n",
      "loss before training is 9.172726804469318e-05 -- epoch number 5132\n",
      "\n",
      "\n",
      "loss before training is 9.159663748087684e-05 -- epoch number 5133\n",
      "\n",
      "\n",
      "loss before training is 9.1466192801654e-05 -- epoch number 5134\n",
      "\n",
      "\n",
      "loss before training is 9.133593375423252e-05 -- epoch number 5135\n",
      "\n",
      "\n",
      "loss before training is 9.120586008612797e-05 -- epoch number 5136\n",
      "\n",
      "\n",
      "loss before training is 9.107597154516165e-05 -- epoch number 5137\n",
      "\n",
      "\n",
      "loss before training is 9.094626787945726e-05 -- epoch number 5138\n",
      "\n",
      "\n",
      "loss before training is 9.081674883744924e-05 -- epoch number 5139\n",
      "\n",
      "\n",
      "loss before training is 9.06874141678693e-05 -- epoch number 5140\n",
      "\n",
      "\n",
      "loss before training is 9.055826361976092e-05 -- epoch number 5141\n",
      "\n",
      "\n",
      "loss before training is 9.04292969424667e-05 -- epoch number 5142\n",
      "\n",
      "\n",
      "loss before training is 9.03005138856396e-05 -- epoch number 5143\n",
      "\n",
      "\n",
      "loss before training is 9.017191419922999e-05 -- epoch number 5144\n",
      "\n",
      "\n",
      "loss before training is 9.004349763349625e-05 -- epoch number 5145\n",
      "\n",
      "\n",
      "loss before training is 8.991526393899637e-05 -- epoch number 5146\n",
      "\n",
      "\n",
      "loss before training is 8.978721286659558e-05 -- epoch number 5147\n",
      "\n",
      "\n",
      "loss before training is 8.965934416745744e-05 -- epoch number 5148\n",
      "\n",
      "\n",
      "loss before training is 8.953165759305215e-05 -- epoch number 5149\n",
      "\n",
      "\n",
      "loss before training is 8.940415289514716e-05 -- epoch number 5150\n",
      "\n",
      "\n",
      "loss before training is 8.927682982581783e-05 -- epoch number 5151\n",
      "\n",
      "\n",
      "loss before training is 8.91496881374349e-05 -- epoch number 5152\n",
      "\n",
      "\n",
      "loss before training is 8.902272758267576e-05 -- epoch number 5153\n",
      "\n",
      "\n",
      "loss before training is 8.889594791451795e-05 -- epoch number 5154\n",
      "\n",
      "\n",
      "loss before training is 8.876934888623565e-05 -- epoch number 5155\n",
      "\n",
      "\n",
      "loss before training is 8.864293025140829e-05 -- epoch number 5156\n",
      "\n",
      "\n",
      "loss before training is 8.851669176391399e-05 -- epoch number 5157\n",
      "\n",
      "\n",
      "loss before training is 8.839063317793144e-05 -- epoch number 5158\n",
      "\n",
      "\n",
      "loss before training is 8.8264754247936e-05 -- epoch number 5159\n",
      "\n",
      "\n",
      "loss before training is 8.813905472870691e-05 -- epoch number 5160\n",
      "\n",
      "\n",
      "loss before training is 8.80135343753208e-05 -- epoch number 5161\n",
      "\n",
      "\n",
      "loss before training is 8.78881929431505e-05 -- epoch number 5162\n",
      "\n",
      "\n",
      "loss before training is 8.776303018787347e-05 -- epoch number 5163\n",
      "\n",
      "\n",
      "loss before training is 8.763804586545972e-05 -- epoch number 5164\n",
      "\n",
      "\n",
      "loss before training is 8.75132397321815e-05 -- epoch number 5165\n",
      "\n",
      "\n",
      "loss before training is 8.738861154460299e-05 -- epoch number 5166\n",
      "\n",
      "\n",
      "loss before training is 8.72641610595944e-05 -- epoch number 5167\n",
      "\n",
      "\n",
      "loss before training is 8.713988803431687e-05 -- epoch number 5168\n",
      "\n",
      "\n",
      "loss before training is 8.70157922262309e-05 -- epoch number 5169\n",
      "\n",
      "\n",
      "loss before training is 8.68918733930917e-05 -- epoch number 5170\n",
      "\n",
      "\n",
      "loss before training is 8.676813129295462e-05 -- epoch number 5171\n",
      "\n",
      "\n",
      "loss before training is 8.66445656841684e-05 -- epoch number 5172\n",
      "\n",
      "\n",
      "loss before training is 8.652117632537664e-05 -- epoch number 5173\n",
      "\n",
      "\n",
      "loss before training is 8.639796297552138e-05 -- epoch number 5174\n",
      "\n",
      "\n",
      "loss before training is 8.627492539384041e-05 -- epoch number 5175\n",
      "\n",
      "\n",
      "loss before training is 8.615206333986165e-05 -- epoch number 5176\n",
      "\n",
      "\n",
      "loss before training is 8.602937657341603e-05 -- epoch number 5177\n",
      "\n",
      "\n",
      "loss before training is 8.590686485461723e-05 -- epoch number 5178\n",
      "\n",
      "\n",
      "loss before training is 8.57845279438863e-05 -- epoch number 5179\n",
      "\n",
      "\n",
      "loss before training is 8.56623656019286e-05 -- epoch number 5180\n",
      "\n",
      "\n",
      "loss before training is 8.554037758974771e-05 -- epoch number 5181\n",
      "\n",
      "\n",
      "loss before training is 8.541856366864036e-05 -- epoch number 5182\n",
      "\n",
      "\n",
      "loss before training is 8.529692360019573e-05 -- epoch number 5183\n",
      "\n",
      "\n",
      "loss before training is 8.517545714629446e-05 -- epoch number 5184\n",
      "\n",
      "\n",
      "loss before training is 8.505416406911199e-05 -- epoch number 5185\n",
      "\n",
      "\n",
      "loss before training is 8.493304413111652e-05 -- epoch number 5186\n",
      "\n",
      "\n",
      "loss before training is 8.481209709506394e-05 -- epoch number 5187\n",
      "\n",
      "\n",
      "loss before training is 8.469132272400904e-05 -- epoch number 5188\n",
      "\n",
      "\n",
      "loss before training is 8.457072078129122e-05 -- epoch number 5189\n",
      "\n",
      "\n",
      "loss before training is 8.445029103054457e-05 -- epoch number 5190\n",
      "\n",
      "\n",
      "loss before training is 8.433003323569431e-05 -- epoch number 5191\n",
      "\n",
      "\n",
      "loss before training is 8.42099471609581e-05 -- epoch number 5192\n",
      "\n",
      "\n",
      "loss before training is 8.409003257083767e-05 -- epoch number 5193\n",
      "\n",
      "\n",
      "loss before training is 8.397028923012998e-05 -- epoch number 5194\n",
      "\n",
      "\n",
      "loss before training is 8.38507169039231e-05 -- epoch number 5195\n",
      "\n",
      "\n",
      "loss before training is 8.373131535759022e-05 -- epoch number 5196\n",
      "\n",
      "\n",
      "loss before training is 8.361208435679687e-05 -- epoch number 5197\n",
      "\n",
      "\n",
      "loss before training is 8.349302366749664e-05 -- epoch number 5198\n",
      "\n",
      "\n",
      "loss before training is 8.337413305593296e-05 -- epoch number 5199\n",
      "\n",
      "\n",
      "loss before training is 8.325541228863601e-05 -- epoch number 5200\n",
      "\n",
      "\n",
      "loss before training is 8.31368611324255e-05 -- epoch number 5201\n",
      "\n",
      "\n",
      "loss before training is 8.30184793544087e-05 -- epoch number 5202\n",
      "\n",
      "\n",
      "loss before training is 8.290026672198092e-05 -- epoch number 5203\n",
      "\n",
      "\n",
      "loss before training is 8.278222300282593e-05 -- epoch number 5204\n",
      "\n",
      "\n",
      "loss before training is 8.26643479649101e-05 -- epoch number 5205\n",
      "\n",
      "\n",
      "loss before training is 8.25466413764927e-05 -- epoch number 5206\n",
      "\n",
      "\n",
      "loss before training is 8.242910300611676e-05 -- epoch number 5207\n",
      "\n",
      "\n",
      "loss before training is 8.231173262261194e-05 -- epoch number 5208\n",
      "\n",
      "\n",
      "loss before training is 8.219452999509282e-05 -- epoch number 5209\n",
      "\n",
      "\n",
      "loss before training is 8.207749489296196e-05 -- epoch number 5210\n",
      "\n",
      "\n",
      "loss before training is 8.19606270859055e-05 -- epoch number 5211\n",
      "\n",
      "\n",
      "loss before training is 8.184392634389589e-05 -- epoch number 5212\n",
      "\n",
      "\n",
      "loss before training is 8.172739243718976e-05 -- epoch number 5213\n",
      "\n",
      "\n",
      "loss before training is 8.161102513632977e-05 -- epoch number 5214\n",
      "\n",
      "\n",
      "loss before training is 8.149482421214216e-05 -- epoch number 5215\n",
      "\n",
      "\n",
      "loss before training is 8.137878943573879e-05 -- epoch number 5216\n",
      "\n",
      "\n",
      "loss before training is 8.126292057851218e-05 -- epoch number 5217\n",
      "\n",
      "\n",
      "loss before training is 8.1147217412141e-05 -- epoch number 5218\n",
      "\n",
      "\n",
      "loss before training is 8.103167970858625e-05 -- epoch number 5219\n",
      "\n",
      "\n",
      "loss before training is 8.09163072400927e-05 -- epoch number 5220\n",
      "\n",
      "\n",
      "loss before training is 8.080109977918955e-05 -- epoch number 5221\n",
      "\n",
      "\n",
      "loss before training is 8.068605709868382e-05 -- epoch number 5222\n",
      "\n",
      "\n",
      "loss before training is 8.057117897166974e-05 -- epoch number 5223\n",
      "\n",
      "\n",
      "loss before training is 8.045646517152144e-05 -- epoch number 5224\n",
      "\n",
      "\n",
      "loss before training is 8.034191547189168e-05 -- epoch number 5225\n",
      "\n",
      "\n",
      "loss before training is 8.022752964672244e-05 -- epoch number 5226\n",
      "\n",
      "\n",
      "loss before training is 8.011330747022861e-05 -- epoch number 5227\n",
      "\n",
      "\n",
      "loss before training is 7.999924871691222e-05 -- epoch number 5228\n",
      "\n",
      "\n",
      "loss before training is 7.988535316155245e-05 -- epoch number 5229\n",
      "\n",
      "\n",
      "loss before training is 7.97716205792099e-05 -- epoch number 5230\n",
      "\n",
      "\n",
      "loss before training is 7.965805074522557e-05 -- epoch number 5231\n",
      "\n",
      "\n",
      "loss before training is 7.954464343521728e-05 -- epoch number 5232\n",
      "\n",
      "\n",
      "loss before training is 7.943139842508929e-05 -- epoch number 5233\n",
      "\n",
      "\n",
      "loss before training is 7.931831549101613e-05 -- epoch number 5234\n",
      "\n",
      "\n",
      "loss before training is 7.920539440946045e-05 -- epoch number 5235\n",
      "\n",
      "\n",
      "loss before training is 7.909263495715754e-05 -- epoch number 5236\n",
      "\n",
      "\n",
      "loss before training is 7.898003691112287e-05 -- epoch number 5237\n",
      "\n",
      "\n",
      "loss before training is 7.886760004865074e-05 -- epoch number 5238\n",
      "\n",
      "\n",
      "loss before training is 7.875532414731076e-05 -- epoch number 5239\n",
      "\n",
      "\n",
      "loss before training is 7.864320898495647e-05 -- epoch number 5240\n",
      "\n",
      "\n",
      "loss before training is 7.853125433971099e-05 -- epoch number 5241\n",
      "\n",
      "\n",
      "loss before training is 7.841945998998041e-05 -- epoch number 5242\n",
      "\n",
      "\n",
      "loss before training is 7.830782571444438e-05 -- epoch number 5243\n",
      "\n",
      "\n",
      "loss before training is 7.819635129206074e-05 -- epoch number 5244\n",
      "\n",
      "\n",
      "loss before training is 7.808503650206233e-05 -- epoch number 5245\n",
      "\n",
      "\n",
      "loss before training is 7.797388112396057e-05 -- epoch number 5246\n",
      "\n",
      "\n",
      "loss before training is 7.786288493754107e-05 -- epoch number 5247\n",
      "\n",
      "\n",
      "loss before training is 7.775204772286495e-05 -- epoch number 5248\n",
      "\n",
      "\n",
      "loss before training is 7.76413692602657e-05 -- epoch number 5249\n",
      "\n",
      "\n",
      "loss before training is 7.753084933035774e-05 -- epoch number 5250\n",
      "\n",
      "\n",
      "loss before training is 7.74204877140256e-05 -- epoch number 5251\n",
      "\n",
      "\n",
      "loss before training is 7.731028419243107e-05 -- epoch number 5252\n",
      "\n",
      "\n",
      "loss before training is 7.720023854700746e-05 -- epoch number 5253\n",
      "\n",
      "\n",
      "loss before training is 7.709035055946412e-05 -- epoch number 5254\n",
      "\n",
      "\n",
      "loss before training is 7.698062001178231e-05 -- epoch number 5255\n",
      "\n",
      "\n",
      "loss before training is 7.687104668622013e-05 -- epoch number 5256\n",
      "\n",
      "\n",
      "loss before training is 7.676163036530336e-05 -- epoch number 5257\n",
      "\n",
      "\n",
      "loss before training is 7.665237083183406e-05 -- epoch number 5258\n",
      "\n",
      "\n",
      "loss before training is 7.654326786888738e-05 -- epoch number 5259\n",
      "\n",
      "\n",
      "loss before training is 7.643432125980925e-05 -- epoch number 5260\n",
      "\n",
      "\n",
      "loss before training is 7.632553078821758e-05 -- epoch number 5261\n",
      "\n",
      "\n",
      "loss before training is 7.621689623800352e-05 -- epoch number 5262\n",
      "\n",
      "\n",
      "loss before training is 7.61084173933269e-05 -- epoch number 5263\n",
      "\n",
      "\n",
      "loss before training is 7.600009403862212e-05 -- epoch number 5264\n",
      "\n",
      "\n",
      "loss before training is 7.589192595859212e-05 -- epoch number 5265\n",
      "\n",
      "\n",
      "loss before training is 7.57839129382126e-05 -- epoch number 5266\n",
      "\n",
      "\n",
      "loss before training is 7.567605476272509e-05 -- epoch number 5267\n",
      "\n",
      "\n",
      "loss before training is 7.556835121764915e-05 -- epoch number 5268\n",
      "\n",
      "\n",
      "loss before training is 7.546080208876657e-05 -- epoch number 5269\n",
      "\n",
      "\n",
      "loss before training is 7.535340716213369e-05 -- epoch number 5270\n",
      "\n",
      "\n",
      "loss before training is 7.524616622407326e-05 -- epoch number 5271\n",
      "\n",
      "\n",
      "loss before training is 7.513907906117913e-05 -- epoch number 5272\n",
      "\n",
      "\n",
      "loss before training is 7.503214546031137e-05 -- epoch number 5273\n",
      "\n",
      "\n",
      "loss before training is 7.492536520860119e-05 -- epoch number 5274\n",
      "\n",
      "\n",
      "loss before training is 7.481873809344827e-05 -- epoch number 5275\n",
      "\n",
      "\n",
      "loss before training is 7.471226390251833e-05 -- epoch number 5276\n",
      "\n",
      "\n",
      "loss before training is 7.460594242374361e-05 -- epoch number 5277\n",
      "\n",
      "\n",
      "loss before training is 7.449977344532967e-05 -- epoch number 5278\n",
      "\n",
      "\n",
      "loss before training is 7.439375675574444e-05 -- epoch number 5279\n",
      "\n",
      "\n",
      "loss before training is 7.428789214372093e-05 -- epoch number 5280\n",
      "\n",
      "\n",
      "loss before training is 7.41821793982632e-05 -- epoch number 5281\n",
      "\n",
      "\n",
      "loss before training is 7.407661830864442e-05 -- epoch number 5282\n",
      "\n",
      "\n",
      "loss before training is 7.397120866439417e-05 -- epoch number 5283\n",
      "\n",
      "\n",
      "loss before training is 7.386595025531574e-05 -- epoch number 5284\n",
      "\n",
      "\n",
      "loss before training is 7.376084287147674e-05 -- epoch number 5285\n",
      "\n",
      "\n",
      "loss before training is 7.365588630320651e-05 -- epoch number 5286\n",
      "\n",
      "\n",
      "loss before training is 7.355108034110515e-05 -- epoch number 5287\n",
      "\n",
      "\n",
      "loss before training is 7.344642477603316e-05 -- epoch number 5288\n",
      "\n",
      "\n",
      "loss before training is 7.334191939911507e-05 -- epoch number 5289\n",
      "\n",
      "\n",
      "loss before training is 7.323756400174417e-05 -- epoch number 5290\n",
      "\n",
      "\n",
      "loss before training is 7.313335837557563e-05 -- epoch number 5291\n",
      "\n",
      "\n",
      "loss before training is 7.302930231252612e-05 -- epoch number 5292\n",
      "\n",
      "\n",
      "loss before training is 7.292539560477871e-05 -- epoch number 5293\n",
      "\n",
      "\n",
      "loss before training is 7.28216380447765e-05 -- epoch number 5294\n",
      "\n",
      "\n",
      "loss before training is 7.271802942523034e-05 -- epoch number 5295\n",
      "\n",
      "\n",
      "loss before training is 7.26145695391097e-05 -- epoch number 5296\n",
      "\n",
      "\n",
      "loss before training is 7.251125817964883e-05 -- epoch number 5297\n",
      "\n",
      "\n",
      "loss before training is 7.24080951403403e-05 -- epoch number 5298\n",
      "\n",
      "\n",
      "loss before training is 7.230508021494422e-05 -- epoch number 5299\n",
      "\n",
      "\n",
      "loss before training is 7.220221319747891e-05 -- epoch number 5300\n",
      "\n",
      "\n",
      "loss before training is 7.209949388222444e-05 -- epoch number 5301\n",
      "\n",
      "\n",
      "loss before training is 7.19969220637219e-05 -- epoch number 5302\n",
      "\n",
      "\n",
      "loss before training is 7.189449753677399e-05 -- epoch number 5303\n",
      "\n",
      "\n",
      "loss before training is 7.179222009644223e-05 -- epoch number 5304\n",
      "\n",
      "\n",
      "loss before training is 7.169008953805082e-05 -- epoch number 5305\n",
      "\n",
      "\n",
      "loss before training is 7.158810565718303e-05 -- epoch number 5306\n",
      "\n",
      "\n",
      "loss before training is 7.148626824968191e-05 -- epoch number 5307\n",
      "\n",
      "\n",
      "loss before training is 7.138457711164792e-05 -- epoch number 5308\n",
      "\n",
      "\n",
      "loss before training is 7.128303203944597e-05 -- epoch number 5309\n",
      "\n",
      "\n",
      "loss before training is 7.118163282969249e-05 -- epoch number 5310\n",
      "\n",
      "\n",
      "loss before training is 7.108037927926956e-05 -- epoch number 5311\n",
      "\n",
      "\n",
      "loss before training is 7.097927118531594e-05 -- epoch number 5312\n",
      "\n",
      "\n",
      "loss before training is 7.087830834522652e-05 -- epoch number 5313\n",
      "\n",
      "\n",
      "loss before training is 7.077749055665392e-05 -- epoch number 5314\n",
      "\n",
      "\n",
      "loss before training is 7.067681761750991e-05 -- epoch number 5315\n",
      "\n",
      "\n",
      "loss before training is 7.057628932596486e-05 -- epoch number 5316\n",
      "\n",
      "\n",
      "loss before training is 7.04759054804449e-05 -- epoch number 5317\n",
      "\n",
      "\n",
      "loss before training is 7.037566587963248e-05 -- epoch number 5318\n",
      "\n",
      "\n",
      "loss before training is 7.02755703224685e-05 -- epoch number 5319\n",
      "\n",
      "\n",
      "loss before training is 7.017561860814813e-05 -- epoch number 5320\n",
      "\n",
      "\n",
      "loss before training is 7.007581053612179e-05 -- epoch number 5321\n",
      "\n",
      "\n",
      "loss before training is 6.997614590609971e-05 -- epoch number 5322\n",
      "\n",
      "\n",
      "loss before training is 6.98766245180431e-05 -- epoch number 5323\n",
      "\n",
      "\n",
      "loss before training is 6.977724617217244e-05 -- epoch number 5324\n",
      "\n",
      "\n",
      "loss before training is 6.96780106689625e-05 -- epoch number 5325\n",
      "\n",
      "\n",
      "loss before training is 6.957891780913944e-05 -- epoch number 5326\n",
      "\n",
      "\n",
      "loss before training is 6.94799673936877e-05 -- epoch number 5327\n",
      "\n",
      "\n",
      "loss before training is 6.938115922384456e-05 -- epoch number 5328\n",
      "\n",
      "\n",
      "loss before training is 6.928249310110123e-05 -- epoch number 5329\n",
      "\n",
      "\n",
      "loss before training is 6.918396882720376e-05 -- epoch number 5330\n",
      "\n",
      "\n",
      "loss before training is 6.908558620414929e-05 -- epoch number 5331\n",
      "\n",
      "\n",
      "loss before training is 6.898734503418949e-05 -- epoch number 5332\n",
      "\n",
      "\n",
      "loss before training is 6.888924511982993e-05 -- epoch number 5333\n",
      "\n",
      "\n",
      "loss before training is 6.879128626382887e-05 -- epoch number 5334\n",
      "\n",
      "\n",
      "loss before training is 6.869346826919496e-05 -- epoch number 5335\n",
      "\n",
      "\n",
      "loss before training is 6.859579093918961e-05 -- epoch number 5336\n",
      "\n",
      "\n",
      "loss before training is 6.849825407732826e-05 -- epoch number 5337\n",
      "\n",
      "\n",
      "loss before training is 6.840085748737558e-05 -- epoch number 5338\n",
      "\n",
      "\n",
      "loss before training is 6.83036009733488e-05 -- epoch number 5339\n",
      "\n",
      "\n",
      "loss before training is 6.820648433951606e-05 -- epoch number 5340\n",
      "\n",
      "\n",
      "loss before training is 6.810950739039574e-05 -- epoch number 5341\n",
      "\n",
      "\n",
      "loss before training is 6.80126699307573e-05 -- epoch number 5342\n",
      "\n",
      "\n",
      "loss before training is 6.791597176562237e-05 -- epoch number 5343\n",
      "\n",
      "\n",
      "loss before training is 6.781941270025865e-05 -- epoch number 5344\n",
      "\n",
      "\n",
      "loss before training is 6.772299254018588e-05 -- epoch number 5345\n",
      "\n",
      "\n",
      "loss before training is 6.762671109117609e-05 -- epoch number 5346\n",
      "\n",
      "\n",
      "loss before training is 6.753056815924556e-05 -- epoch number 5347\n",
      "\n",
      "\n",
      "loss before training is 6.743456355066274e-05 -- epoch number 5348\n",
      "\n",
      "\n",
      "loss before training is 6.73386970719433e-05 -- epoch number 5349\n",
      "\n",
      "\n",
      "loss before training is 6.724296852985293e-05 -- epoch number 5350\n",
      "\n",
      "\n",
      "loss before training is 6.714737773140632e-05 -- epoch number 5351\n",
      "\n",
      "\n",
      "loss before training is 6.705192448386146e-05 -- epoch number 5352\n",
      "\n",
      "\n",
      "loss before training is 6.695660859473022e-05 -- epoch number 5353\n",
      "\n",
      "\n",
      "loss before training is 6.686142987176634e-05 -- epoch number 5354\n",
      "\n",
      "\n",
      "loss before training is 6.676638812297677e-05 -- epoch number 5355\n",
      "\n",
      "\n",
      "loss before training is 6.667148315661056e-05 -- epoch number 5356\n",
      "\n",
      "\n",
      "loss before training is 6.657671478116455e-05 -- epoch number 5357\n",
      "\n",
      "\n",
      "loss before training is 6.648208280538349e-05 -- epoch number 5358\n",
      "\n",
      "\n",
      "loss before training is 6.63875870382569e-05 -- epoch number 5359\n",
      "\n",
      "\n",
      "loss before training is 6.629322728902171e-05 -- epoch number 5360\n",
      "\n",
      "\n",
      "loss before training is 6.619900336715803e-05 -- epoch number 5361\n",
      "\n",
      "\n",
      "loss before training is 6.610491508239413e-05 -- epoch number 5362\n",
      "\n",
      "\n",
      "loss before training is 6.601096224470265e-05 -- epoch number 5363\n",
      "\n",
      "\n",
      "loss before training is 6.591714466429972e-05 -- epoch number 5364\n",
      "\n",
      "\n",
      "loss before training is 6.58234621516486e-05 -- epoch number 5365\n",
      "\n",
      "\n",
      "loss before training is 6.572991451745357e-05 -- epoch number 5366\n",
      "\n",
      "\n",
      "loss before training is 6.563650157266654e-05 -- epoch number 5367\n",
      "\n",
      "\n",
      "loss before training is 6.554322312847883e-05 -- epoch number 5368\n",
      "\n",
      "\n",
      "loss before training is 6.545007899633307e-05 -- epoch number 5369\n",
      "\n",
      "\n",
      "loss before training is 6.535706898790682e-05 -- epoch number 5370\n",
      "\n",
      "\n",
      "loss before training is 6.526419291512608e-05 -- epoch number 5371\n",
      "\n",
      "\n",
      "loss before training is 6.517145059015666e-05 -- epoch number 5372\n",
      "\n",
      "\n",
      "loss before training is 6.507884182540915e-05 -- epoch number 5373\n",
      "\n",
      "\n",
      "loss before training is 6.49863664335378e-05 -- epoch number 5374\n",
      "\n",
      "\n",
      "loss before training is 6.489402422743297e-05 -- epoch number 5375\n",
      "\n",
      "\n",
      "loss before training is 6.480181502023242e-05 -- epoch number 5376\n",
      "\n",
      "\n",
      "loss before training is 6.470973862531382e-05 -- epoch number 5377\n",
      "\n",
      "\n",
      "loss before training is 6.461779485629422e-05 -- epoch number 5378\n",
      "\n",
      "\n",
      "loss before training is 6.452598352703643e-05 -- epoch number 5379\n",
      "\n",
      "\n",
      "loss before training is 6.443430445164068e-05 -- epoch number 5380\n",
      "\n",
      "\n",
      "loss before training is 6.434275744444663e-05 -- epoch number 5381\n",
      "\n",
      "\n",
      "loss before training is 6.425134232003742e-05 -- epoch number 5382\n",
      "\n",
      "\n",
      "loss before training is 6.416005889323513e-05 -- epoch number 5383\n",
      "\n",
      "\n",
      "loss before training is 6.406890697909874e-05 -- epoch number 5384\n",
      "\n",
      "\n",
      "loss before training is 6.397788639293136e-05 -- epoch number 5385\n",
      "\n",
      "\n",
      "loss before training is 6.388699695027142e-05 -- epoch number 5386\n",
      "\n",
      "\n",
      "loss before training is 6.379623846690076e-05 -- epoch number 5387\n",
      "\n",
      "\n",
      "loss before training is 6.37056107588344e-05 -- epoch number 5388\n",
      "\n",
      "\n",
      "loss before training is 6.361511364233078e-05 -- epoch number 5389\n",
      "\n",
      "\n",
      "loss before training is 6.35247469338856e-05 -- epoch number 5390\n",
      "\n",
      "\n",
      "loss before training is 6.343451045022838e-05 -- epoch number 5391\n",
      "\n",
      "\n",
      "loss before training is 6.334440400833198e-05 -- epoch number 5392\n",
      "\n",
      "\n",
      "loss before training is 6.325442742540325e-05 -- epoch number 5393\n",
      "\n",
      "\n",
      "loss before training is 6.316458051888868e-05 -- epoch number 5394\n",
      "\n",
      "\n",
      "loss before training is 6.307486310646931e-05 -- epoch number 5395\n",
      "\n",
      "\n",
      "loss before training is 6.298527500606478e-05 -- epoch number 5396\n",
      "\n",
      "\n",
      "loss before training is 6.289581603582993e-05 -- epoch number 5397\n",
      "\n",
      "\n",
      "loss before training is 6.280648601415928e-05 -- epoch number 5398\n",
      "\n",
      "\n",
      "loss before training is 6.271728475967561e-05 -- epoch number 5399\n",
      "\n",
      "\n",
      "loss before training is 6.262821209124571e-05 -- epoch number 5400\n",
      "\n",
      "\n",
      "loss before training is 6.253926782796607e-05 -- epoch number 5401\n",
      "\n",
      "\n",
      "loss before training is 6.245045178917373e-05 -- epoch number 5402\n",
      "\n",
      "\n",
      "loss before training is 6.23617637944357e-05 -- epoch number 5403\n",
      "\n",
      "\n",
      "loss before training is 6.227320366355567e-05 -- epoch number 5404\n",
      "\n",
      "\n",
      "loss before training is 6.218477121657328e-05 -- epoch number 5405\n",
      "\n",
      "\n",
      "loss before training is 6.209646627375832e-05 -- epoch number 5406\n",
      "\n",
      "\n",
      "loss before training is 6.200828865561954e-05 -- epoch number 5407\n",
      "\n",
      "\n",
      "loss before training is 6.192023818289531e-05 -- epoch number 5408\n",
      "\n",
      "\n",
      "loss before training is 6.18323146765603e-05 -- epoch number 5409\n",
      "\n",
      "\n",
      "loss before training is 6.174451795782069e-05 -- epoch number 5410\n",
      "\n",
      "\n",
      "loss before training is 6.165684784811547e-05 -- epoch number 5411\n",
      "\n",
      "\n",
      "loss before training is 6.15693041691176e-05 -- epoch number 5412\n",
      "\n",
      "\n",
      "loss before training is 6.14818867427327e-05 -- epoch number 5413\n",
      "\n",
      "\n",
      "loss before training is 6.139459539109546e-05 -- epoch number 5414\n",
      "\n",
      "\n",
      "loss before training is 6.130742993657824e-05 -- epoch number 5415\n",
      "\n",
      "\n",
      "loss before training is 6.122039020177886e-05 -- epoch number 5416\n",
      "\n",
      "\n",
      "loss before training is 6.113347600952924e-05 -- epoch number 5417\n",
      "\n",
      "\n",
      "loss before training is 6.104668718289401e-05 -- epoch number 5418\n",
      "\n",
      "\n",
      "loss before training is 6.0960023545166934e-05 -- epoch number 5419\n",
      "\n",
      "\n",
      "loss before training is 6.087348491987203e-05 -- epoch number 5420\n",
      "\n",
      "\n",
      "loss before training is 6.078707113076553e-05 -- epoch number 5421\n",
      "\n",
      "\n",
      "loss before training is 6.0700782001833e-05 -- epoch number 5422\n",
      "\n",
      "\n",
      "loss before training is 6.061461735728912e-05 -- epoch number 5423\n",
      "\n",
      "\n",
      "loss before training is 6.052857702157934e-05 -- epoch number 5424\n",
      "\n",
      "\n",
      "loss before training is 6.044266081938009e-05 -- epoch number 5425\n",
      "\n",
      "\n",
      "loss before training is 6.03568685755912e-05 -- epoch number 5426\n",
      "\n",
      "\n",
      "loss before training is 6.0271200115348344e-05 -- epoch number 5427\n",
      "\n",
      "\n",
      "loss before training is 6.018565526401159e-05 -- epoch number 5428\n",
      "\n",
      "\n",
      "loss before training is 6.010023384717181e-05 -- epoch number 5429\n",
      "\n",
      "\n",
      "loss before training is 6.0014935690646816e-05 -- epoch number 5430\n",
      "\n",
      "\n",
      "loss before training is 5.992976062048085e-05 -- epoch number 5431\n",
      "\n",
      "\n",
      "loss before training is 5.984470846295015e-05 -- epoch number 5432\n",
      "\n",
      "\n",
      "loss before training is 5.9759779044555545e-05 -- epoch number 5433\n",
      "\n",
      "\n",
      "loss before training is 5.967497219202351e-05 -- epoch number 5434\n",
      "\n",
      "\n",
      "loss before training is 5.959028773231022e-05 -- epoch number 5435\n",
      "\n",
      "\n",
      "loss before training is 5.9505725492598736e-05 -- epoch number 5436\n",
      "\n",
      "\n",
      "loss before training is 5.9421285300296394e-05 -- epoch number 5437\n",
      "\n",
      "\n",
      "loss before training is 5.9336966983037726e-05 -- epoch number 5438\n",
      "\n",
      "\n",
      "loss before training is 5.925277036868384e-05 -- epoch number 5439\n",
      "\n",
      "\n",
      "loss before training is 5.916869528532062e-05 -- epoch number 5440\n",
      "\n",
      "\n",
      "loss before training is 5.9084741561262604e-05 -- epoch number 5441\n",
      "\n",
      "\n",
      "loss before training is 5.900090902504268e-05 -- epoch number 5442\n",
      "\n",
      "\n",
      "loss before training is 5.891719750542532e-05 -- epoch number 5443\n",
      "\n",
      "\n",
      "loss before training is 5.883360683139678e-05 -- epoch number 5444\n",
      "\n",
      "\n",
      "loss before training is 5.8750136832167584e-05 -- epoch number 5445\n",
      "\n",
      "\n",
      "loss before training is 5.866678733717572e-05 -- epoch number 5446\n",
      "\n",
      "\n",
      "loss before training is 5.858355817607719e-05 -- epoch number 5447\n",
      "\n",
      "\n",
      "loss before training is 5.850044917875848e-05 -- epoch number 5448\n",
      "\n",
      "\n",
      "loss before training is 5.841746017532502e-05 -- epoch number 5449\n",
      "\n",
      "\n",
      "loss before training is 5.8334590996104486e-05 -- epoch number 5450\n",
      "\n",
      "\n",
      "loss before training is 5.8251841471653053e-05 -- epoch number 5451\n",
      "\n",
      "\n",
      "loss before training is 5.816921143274582e-05 -- epoch number 5452\n",
      "\n",
      "\n",
      "loss before training is 5.808670071038023e-05 -- epoch number 5453\n",
      "\n",
      "\n",
      "loss before training is 5.800430913577796e-05 -- epoch number 5454\n",
      "\n",
      "\n",
      "loss before training is 5.79220365403801e-05 -- epoch number 5455\n",
      "\n",
      "\n",
      "loss before training is 5.7839882755851706e-05 -- epoch number 5456\n",
      "\n",
      "\n",
      "loss before training is 5.7757847614079344e-05 -- epoch number 5457\n",
      "\n",
      "\n",
      "loss before training is 5.767593094717054e-05 -- epoch number 5458\n",
      "\n",
      "\n",
      "loss before training is 5.7594132587451703e-05 -- epoch number 5459\n",
      "\n",
      "\n",
      "loss before training is 5.751245236747177e-05 -- epoch number 5460\n",
      "\n",
      "\n",
      "loss before training is 5.743089012000248e-05 -- epoch number 5461\n",
      "\n",
      "\n",
      "loss before training is 5.734944567803255e-05 -- epoch number 5462\n",
      "\n",
      "\n",
      "loss before training is 5.7268118874771823e-05 -- epoch number 5463\n",
      "\n",
      "\n",
      "loss before training is 5.7186909543649826e-05 -- epoch number 5464\n",
      "\n",
      "\n",
      "loss before training is 5.710581751831722e-05 -- epoch number 5465\n",
      "\n",
      "\n",
      "loss before training is 5.7024842632642245e-05 -- epoch number 5466\n",
      "\n",
      "\n",
      "loss before training is 5.6943984720712266e-05 -- epoch number 5467\n",
      "\n",
      "\n",
      "loss before training is 5.686324361683348e-05 -- epoch number 5468\n",
      "\n",
      "\n",
      "loss before training is 5.678261915553258e-05 -- epoch number 5469\n",
      "\n",
      "\n",
      "loss before training is 5.670211117155277e-05 -- epoch number 5470\n",
      "\n",
      "\n",
      "loss before training is 5.662171949985515e-05 -- epoch number 5471\n",
      "\n",
      "\n",
      "loss before training is 5.6541443975620854e-05 -- epoch number 5472\n",
      "\n",
      "\n",
      "loss before training is 5.646128443424516e-05 -- epoch number 5473\n",
      "\n",
      "\n",
      "loss before training is 5.63812407113458e-05 -- epoch number 5474\n",
      "\n",
      "\n",
      "loss before training is 5.630131264275158e-05 -- epoch number 5475\n",
      "\n",
      "\n",
      "loss before training is 5.62215000645128e-05 -- epoch number 5476\n",
      "\n",
      "\n",
      "loss before training is 5.614180281289485e-05 -- epoch number 5477\n",
      "\n",
      "\n",
      "loss before training is 5.606222072438046e-05 -- epoch number 5478\n",
      "\n",
      "\n",
      "loss before training is 5.5982753635665586e-05 -- epoch number 5479\n",
      "\n",
      "\n",
      "loss before training is 5.590340138366637e-05 -- epoch number 5480\n",
      "\n",
      "\n",
      "loss before training is 5.5824163805512536e-05 -- epoch number 5481\n",
      "\n",
      "\n",
      "loss before training is 5.574504073854679e-05 -- epoch number 5482\n",
      "\n",
      "\n",
      "loss before training is 5.566603202033287e-05 -- epoch number 5483\n",
      "\n",
      "\n",
      "loss before training is 5.558713748864445e-05 -- epoch number 5484\n",
      "\n",
      "\n",
      "loss before training is 5.5508356981471575e-05 -- epoch number 5485\n",
      "\n",
      "\n",
      "loss before training is 5.5429690337019836e-05 -- epoch number 5486\n",
      "\n",
      "\n",
      "loss before training is 5.5351137393708734e-05 -- epoch number 5487\n",
      "\n",
      "\n",
      "loss before training is 5.5272697990169835e-05 -- epoch number 5488\n",
      "\n",
      "\n",
      "loss before training is 5.519437196524975e-05 -- epoch number 5489\n",
      "\n",
      "\n",
      "loss before training is 5.51161591580106e-05 -- epoch number 5490\n",
      "\n",
      "\n",
      "loss before training is 5.5038059407725196e-05 -- epoch number 5491\n",
      "\n",
      "\n",
      "loss before training is 5.496007255387829e-05 -- epoch number 5492\n",
      "\n",
      "\n",
      "loss before training is 5.488219843617333e-05 -- epoch number 5493\n",
      "\n",
      "\n",
      "loss before training is 5.48044368945201e-05 -- epoch number 5494\n",
      "\n",
      "\n",
      "loss before training is 5.472678776904251e-05 -- epoch number 5495\n",
      "\n",
      "\n",
      "loss before training is 5.4649250900079404e-05 -- epoch number 5496\n",
      "\n",
      "\n",
      "loss before training is 5.457182612817675e-05 -- epoch number 5497\n",
      "\n",
      "\n",
      "loss before training is 5.449451329409659e-05 -- epoch number 5498\n",
      "\n",
      "\n",
      "loss before training is 5.441731223880972e-05 -- epoch number 5499\n",
      "\n",
      "\n",
      "loss before training is 5.4340222803498224e-05 -- epoch number 5500\n",
      "\n",
      "\n",
      "loss before training is 5.426324482955629e-05 -- epoch number 5501\n",
      "\n",
      "\n",
      "loss before training is 5.4186378158589335e-05 -- epoch number 5502\n",
      "\n",
      "\n",
      "loss before training is 5.410962263240983e-05 -- epoch number 5503\n",
      "\n",
      "\n",
      "loss before training is 5.403297809304425e-05 -- epoch number 5504\n",
      "\n",
      "\n",
      "loss before training is 5.3956444382728365e-05 -- epoch number 5505\n",
      "\n",
      "\n",
      "loss before training is 5.388002134390381e-05 -- epoch number 5506\n",
      "\n",
      "\n",
      "loss before training is 5.380370881922726e-05 -- epoch number 5507\n",
      "\n",
      "\n",
      "loss before training is 5.372750665156138e-05 -- epoch number 5508\n",
      "\n",
      "\n",
      "loss before training is 5.36514146839787e-05 -- epoch number 5509\n",
      "\n",
      "\n",
      "loss before training is 5.3575432759759005e-05 -- epoch number 5510\n",
      "\n",
      "\n",
      "loss before training is 5.349956072239505e-05 -- epoch number 5511\n",
      "\n",
      "\n",
      "loss before training is 5.3423798415583166e-05 -- epoch number 5512\n",
      "\n",
      "\n",
      "loss before training is 5.3348145683228046e-05 -- epoch number 5513\n",
      "\n",
      "\n",
      "loss before training is 5.327260236944748e-05 -- epoch number 5514\n",
      "\n",
      "\n",
      "loss before training is 5.31971683185601e-05 -- epoch number 5515\n",
      "\n",
      "\n",
      "loss before training is 5.31218433750948e-05 -- epoch number 5516\n",
      "\n",
      "\n",
      "loss before training is 5.3046627383789024e-05 -- epoch number 5517\n",
      "\n",
      "\n",
      "loss before training is 5.297152018958616e-05 -- epoch number 5518\n",
      "\n",
      "\n",
      "loss before training is 5.289652163763322e-05 -- epoch number 5519\n",
      "\n",
      "\n",
      "loss before training is 5.28216315732901e-05 -- epoch number 5520\n",
      "\n",
      "\n",
      "loss before training is 5.274684984211732e-05 -- epoch number 5521\n",
      "\n",
      "\n",
      "loss before training is 5.267217628988307e-05 -- epoch number 5522\n",
      "\n",
      "\n",
      "loss before training is 5.259761076256131e-05 -- epoch number 5523\n",
      "\n",
      "\n",
      "loss before training is 5.2523153106330726e-05 -- epoch number 5524\n",
      "\n",
      "\n",
      "loss before training is 5.2448803167577554e-05 -- epoch number 5525\n",
      "\n",
      "\n",
      "loss before training is 5.237456079289109e-05 -- epoch number 5526\n",
      "\n",
      "\n",
      "loss before training is 5.230042582906695e-05 -- epoch number 5527\n",
      "\n",
      "\n",
      "loss before training is 5.222639812310191e-05 -- epoch number 5528\n",
      "\n",
      "\n",
      "loss before training is 5.215247752220169e-05 -- epoch number 5529\n",
      "\n",
      "\n",
      "loss before training is 5.207866387377282e-05 -- epoch number 5530\n",
      "\n",
      "\n",
      "loss before training is 5.200495702542579e-05 -- epoch number 5531\n",
      "\n",
      "\n",
      "loss before training is 5.1931356824978854e-05 -- epoch number 5532\n",
      "\n",
      "\n",
      "loss before training is 5.185786312044639e-05 -- epoch number 5533\n",
      "\n",
      "\n",
      "loss before training is 5.1784475760053685e-05 -- epoch number 5534\n",
      "\n",
      "\n",
      "loss before training is 5.1711194592222707e-05 -- epoch number 5535\n",
      "\n",
      "\n",
      "loss before training is 5.163801946558111e-05 -- epoch number 5536\n",
      "\n",
      "\n",
      "loss before training is 5.1564950228960454e-05 -- epoch number 5537\n",
      "\n",
      "\n",
      "loss before training is 5.149198673139024e-05 -- epoch number 5538\n",
      "\n",
      "\n",
      "loss before training is 5.1419128822106564e-05 -- epoch number 5539\n",
      "\n",
      "\n",
      "loss before training is 5.1346376350542906e-05 -- epoch number 5540\n",
      "\n",
      "\n",
      "loss before training is 5.1273729166339134e-05 -- epoch number 5541\n",
      "\n",
      "\n",
      "loss before training is 5.120118711933044e-05 -- epoch number 5542\n",
      "\n",
      "\n",
      "loss before training is 5.11287500595605e-05 -- epoch number 5543\n",
      "\n",
      "\n",
      "loss before training is 5.105641783726683e-05 -- epoch number 5544\n",
      "\n",
      "\n",
      "loss before training is 5.098419030289085e-05 -- epoch number 5545\n",
      "\n",
      "\n",
      "loss before training is 5.091206730707458e-05 -- epoch number 5546\n",
      "\n",
      "\n",
      "loss before training is 5.084004870066127e-05 -- epoch number 5547\n",
      "\n",
      "\n",
      "loss before training is 5.076813433468903e-05 -- epoch number 5548\n",
      "\n",
      "\n",
      "loss before training is 5.069632406040185e-05 -- epoch number 5549\n",
      "\n",
      "\n",
      "loss before training is 5.0624617729239134e-05 -- epoch number 5550\n",
      "\n",
      "\n",
      "loss before training is 5.0553015192841155e-05 -- epoch number 5551\n",
      "\n",
      "\n",
      "loss before training is 5.0481516303047584e-05 -- epoch number 5552\n",
      "\n",
      "\n",
      "loss before training is 5.041012091189528e-05 -- epoch number 5553\n",
      "\n",
      "\n",
      "loss before training is 5.0338828871621395e-05 -- epoch number 5554\n",
      "\n",
      "\n",
      "loss before training is 5.026764003465861e-05 -- epoch number 5555\n",
      "\n",
      "\n",
      "loss before training is 5.0196554253640276e-05 -- epoch number 5556\n",
      "\n",
      "\n",
      "loss before training is 5.012557138139952e-05 -- epoch number 5557\n",
      "\n",
      "\n",
      "loss before training is 5.005469127096099e-05 -- epoch number 5558\n",
      "\n",
      "\n",
      "loss before training is 4.99839137755521e-05 -- epoch number 5559\n",
      "\n",
      "\n",
      "loss before training is 4.991323874859669e-05 -- epoch number 5560\n",
      "\n",
      "\n",
      "loss before training is 4.9842666043710976e-05 -- epoch number 5561\n",
      "\n",
      "\n",
      "loss before training is 4.9772195514713845e-05 -- epoch number 5562\n",
      "\n",
      "\n",
      "loss before training is 4.970182701561867e-05 -- epoch number 5563\n",
      "\n",
      "\n",
      "loss before training is 4.9631560400632894e-05 -- epoch number 5564\n",
      "\n",
      "\n",
      "loss before training is 4.956139552416306e-05 -- epoch number 5565\n",
      "\n",
      "\n",
      "loss before training is 4.949133224080948e-05 -- epoch number 5566\n",
      "\n",
      "\n",
      "loss before training is 4.9421370405368094e-05 -- epoch number 5567\n",
      "\n",
      "\n",
      "loss before training is 4.93515098728324e-05 -- epoch number 5568\n",
      "\n",
      "\n",
      "loss before training is 4.928175049838801e-05 -- epoch number 5569\n",
      "\n",
      "\n",
      "loss before training is 4.921209213741742e-05 -- epoch number 5570\n",
      "\n",
      "\n",
      "loss before training is 4.9142534645498905e-05 -- epoch number 5571\n",
      "\n",
      "\n",
      "loss before training is 4.9073077878400746e-05 -- epoch number 5572\n",
      "\n",
      "\n",
      "loss before training is 4.900372169209001e-05 -- epoch number 5573\n",
      "\n",
      "\n",
      "loss before training is 4.8934465942724924e-05 -- epoch number 5574\n",
      "\n",
      "\n",
      "loss before training is 4.886531048665963e-05 -- epoch number 5575\n",
      "\n",
      "\n",
      "loss before training is 4.879625518044028e-05 -- epoch number 5576\n",
      "\n",
      "\n",
      "loss before training is 4.872729988080729e-05 -- epoch number 5577\n",
      "\n",
      "\n",
      "loss before training is 4.865844444469225e-05 -- epoch number 5578\n",
      "\n",
      "\n",
      "loss before training is 4.8589688729223296e-05 -- epoch number 5579\n",
      "\n",
      "\n",
      "loss before training is 4.852103259171621e-05 -- epoch number 5580\n",
      "\n",
      "\n",
      "loss before training is 4.8452475889685165e-05 -- epoch number 5581\n",
      "\n",
      "\n",
      "loss before training is 4.8384018480830435e-05 -- epoch number 5582\n",
      "\n",
      "\n",
      "loss before training is 4.8315660223049104e-05 -- epoch number 5583\n",
      "\n",
      "\n",
      "loss before training is 4.824740097442781e-05 -- epoch number 5584\n",
      "\n",
      "\n",
      "loss before training is 4.8179240593242934e-05 -- epoch number 5585\n",
      "\n",
      "\n",
      "loss before training is 4.811117893796703e-05 -- epoch number 5586\n",
      "\n",
      "\n",
      "loss before training is 4.804321586725861e-05 -- epoch number 5587\n",
      "\n",
      "\n",
      "loss before training is 4.7975351239970974e-05 -- epoch number 5588\n",
      "\n",
      "\n",
      "loss before training is 4.790758491514529e-05 -- epoch number 5589\n",
      "\n",
      "\n",
      "loss before training is 4.783991675201502e-05 -- epoch number 5590\n",
      "\n",
      "\n",
      "loss before training is 4.7772346610003776e-05 -- epoch number 5591\n",
      "\n",
      "\n",
      "loss before training is 4.77048743487213e-05 -- epoch number 5592\n",
      "\n",
      "\n",
      "loss before training is 4.7637499827972487e-05 -- epoch number 5593\n",
      "\n",
      "\n",
      "loss before training is 4.757022290774975e-05 -- epoch number 5594\n",
      "\n",
      "\n",
      "loss before training is 4.750304344823378e-05 -- epoch number 5595\n",
      "\n",
      "\n",
      "loss before training is 4.743596130979409e-05 -- epoch number 5596\n",
      "\n",
      "\n",
      "loss before training is 4.736897635299098e-05 -- epoch number 5597\n",
      "\n",
      "\n",
      "loss before training is 4.730208843857272e-05 -- epoch number 5598\n",
      "\n",
      "\n",
      "loss before training is 4.723529742747623e-05 -- epoch number 5599\n",
      "\n",
      "\n",
      "loss before training is 4.716860318082394e-05 -- epoch number 5600\n",
      "\n",
      "\n",
      "loss before training is 4.710200555992876e-05 -- epoch number 5601\n",
      "\n",
      "\n",
      "loss before training is 4.7035504426292334e-05 -- epoch number 5602\n",
      "\n",
      "\n",
      "loss before training is 4.696909964160203e-05 -- epoch number 5603\n",
      "\n",
      "\n",
      "loss before training is 4.690279106773052e-05 -- epoch number 5604\n",
      "\n",
      "\n",
      "loss before training is 4.683657856674307e-05 -- epoch number 5605\n",
      "\n",
      "\n",
      "loss before training is 4.677046200088695e-05 -- epoch number 5606\n",
      "\n",
      "\n",
      "loss before training is 4.670444123259829e-05 -- epoch number 5607\n",
      "\n",
      "\n",
      "loss before training is 4.66385161244992e-05 -- epoch number 5608\n",
      "\n",
      "\n",
      "loss before training is 4.657268653939731e-05 -- epoch number 5609\n",
      "\n",
      "\n",
      "loss before training is 4.650695234028758e-05 -- epoch number 5610\n",
      "\n",
      "\n",
      "loss before training is 4.644131339034972e-05 -- epoch number 5611\n",
      "\n",
      "\n",
      "loss before training is 4.637576955294931e-05 -- epoch number 5612\n",
      "\n",
      "\n",
      "loss before training is 4.6310320691637154e-05 -- epoch number 5613\n",
      "\n",
      "\n",
      "loss before training is 4.6244966670147954e-05 -- epoch number 5614\n",
      "\n",
      "\n",
      "loss before training is 4.617970735240478e-05 -- epoch number 5615\n",
      "\n",
      "\n",
      "loss before training is 4.611454260251167e-05 -- epoch number 5616\n",
      "\n",
      "\n",
      "loss before training is 4.604947228475898e-05 -- epoch number 5617\n",
      "\n",
      "\n",
      "loss before training is 4.598449626362164e-05 -- epoch number 5618\n",
      "\n",
      "\n",
      "loss before training is 4.591961440375633e-05 -- epoch number 5619\n",
      "\n",
      "\n",
      "loss before training is 4.585482657000523e-05 -- epoch number 5620\n",
      "\n",
      "\n",
      "loss before training is 4.579013262739493e-05 -- epoch number 5621\n",
      "\n",
      "\n",
      "loss before training is 4.572553244113427e-05 -- epoch number 5622\n",
      "\n",
      "\n",
      "loss before training is 4.566102587661374e-05 -- epoch number 5623\n",
      "\n",
      "\n",
      "loss before training is 4.559661279941064e-05 -- epoch number 5624\n",
      "\n",
      "\n",
      "loss before training is 4.553229307528055e-05 -- epoch number 5625\n",
      "\n",
      "\n",
      "loss before training is 4.546806657016486e-05 -- epoch number 5626\n",
      "\n",
      "\n",
      "loss before training is 4.5403933150185566e-05 -- epoch number 5627\n",
      "\n",
      "\n",
      "loss before training is 4.533989268164714e-05 -- epoch number 5628\n",
      "\n",
      "\n",
      "loss before training is 4.527594503103658e-05 -- epoch number 5629\n",
      "\n",
      "\n",
      "loss before training is 4.5212090065021955e-05 -- epoch number 5630\n",
      "\n",
      "\n",
      "loss before training is 4.514832765045028e-05 -- epoch number 5631\n",
      "\n",
      "\n",
      "loss before training is 4.508465765435516e-05 -- epoch number 5632\n",
      "\n",
      "\n",
      "loss before training is 4.502107994394724e-05 -- epoch number 5633\n",
      "\n",
      "\n",
      "loss before training is 4.495759438661706e-05 -- epoch number 5634\n",
      "\n",
      "\n",
      "loss before training is 4.4894200849939905e-05 -- epoch number 5635\n",
      "\n",
      "\n",
      "loss before training is 4.483089920166726e-05 -- epoch number 5636\n",
      "\n",
      "\n",
      "loss before training is 4.476768930973283e-05 -- epoch number 5637\n",
      "\n",
      "\n",
      "loss before training is 4.470457104225088e-05 -- epoch number 5638\n",
      "\n",
      "\n",
      "loss before training is 4.464154426751299e-05 -- epoch number 5639\n",
      "\n",
      "\n",
      "loss before training is 4.45786088539924e-05 -- epoch number 5640\n",
      "\n",
      "\n",
      "loss before training is 4.451576467033941e-05 -- epoch number 5641\n",
      "\n",
      "\n",
      "loss before training is 4.4453011585386265e-05 -- epoch number 5642\n",
      "\n",
      "\n",
      "loss before training is 4.439034946814203e-05 -- epoch number 5643\n",
      "\n",
      "\n",
      "loss before training is 4.4327778187794664e-05 -- epoch number 5644\n",
      "\n",
      "\n",
      "loss before training is 4.4265297613710623e-05 -- epoch number 5645\n",
      "\n",
      "\n",
      "loss before training is 4.420290761543409e-05 -- epoch number 5646\n",
      "\n",
      "\n",
      "loss before training is 4.4140608062688425e-05 -- epoch number 5647\n",
      "\n",
      "\n",
      "loss before training is 4.407839882537348e-05 -- epoch number 5648\n",
      "\n",
      "\n",
      "loss before training is 4.4016279773568374e-05 -- epoch number 5649\n",
      "\n",
      "\n",
      "loss before training is 4.395425077752743e-05 -- epoch number 5650\n",
      "\n",
      "\n",
      "loss before training is 4.3892311707683285e-05 -- epoch number 5651\n",
      "\n",
      "\n",
      "loss before training is 4.3830462434645175e-05 -- epoch number 5652\n",
      "\n",
      "\n",
      "loss before training is 4.376870282920048e-05 -- epoch number 5653\n",
      "\n",
      "\n",
      "loss before training is 4.370703276231047e-05 -- epoch number 5654\n",
      "\n",
      "\n",
      "loss before training is 4.3645452105113444e-05 -- epoch number 5655\n",
      "\n",
      "\n",
      "loss before training is 4.3583960728925416e-05 -- epoch number 5656\n",
      "\n",
      "\n",
      "loss before training is 4.352255850523641e-05 -- epoch number 5657\n",
      "\n",
      "\n",
      "loss before training is 4.346124530571411e-05 -- epoch number 5658\n",
      "\n",
      "\n",
      "loss before training is 4.340002100219904e-05 -- epoch number 5659\n",
      "\n",
      "\n",
      "loss before training is 4.333888546670862e-05 -- epoch number 5660\n",
      "\n",
      "\n",
      "loss before training is 4.3277838571435374e-05 -- epoch number 5661\n",
      "\n",
      "\n",
      "loss before training is 4.3216880188744916e-05 -- epoch number 5662\n",
      "\n",
      "\n",
      "loss before training is 4.315601019117995e-05 -- epoch number 5663\n",
      "\n",
      "\n",
      "loss before training is 4.309522845145612e-05 -- epoch number 5664\n",
      "\n",
      "\n",
      "loss before training is 4.303453484246339e-05 -- epoch number 5665\n",
      "\n",
      "\n",
      "loss before training is 4.2973929237265934e-05 -- epoch number 5666\n",
      "\n",
      "\n",
      "loss before training is 4.2913411509100735e-05 -- epoch number 5667\n",
      "\n",
      "\n",
      "loss before training is 4.285298153137991e-05 -- epoch number 5668\n",
      "\n",
      "\n",
      "loss before training is 4.279263917768651e-05 -- epoch number 5669\n",
      "\n",
      "\n",
      "loss before training is 4.2732384321780614e-05 -- epoch number 5670\n",
      "\n",
      "\n",
      "loss before training is 4.267221683759058e-05 -- epoch number 5671\n",
      "\n",
      "\n",
      "loss before training is 4.261213659922113e-05 -- epoch number 5672\n",
      "\n",
      "\n",
      "loss before training is 4.255214348094781e-05 -- epoch number 5673\n",
      "\n",
      "\n",
      "loss before training is 4.249223735721891e-05 -- epoch number 5674\n",
      "\n",
      "\n",
      "loss before training is 4.2432418102654064e-05 -- epoch number 5675\n",
      "\n",
      "\n",
      "loss before training is 4.2372685592045856e-05 -- epoch number 5676\n",
      "\n",
      "\n",
      "loss before training is 4.231303970035718e-05 -- epoch number 5677\n",
      "\n",
      "\n",
      "loss before training is 4.225348030272496e-05 -- epoch number 5678\n",
      "\n",
      "\n",
      "loss before training is 4.2194007274453734e-05 -- epoch number 5679\n",
      "\n",
      "\n",
      "loss before training is 4.213462049102202e-05 -- epoch number 5680\n",
      "\n",
      "\n",
      "loss before training is 4.207531982807844e-05 -- epoch number 5681\n",
      "\n",
      "\n",
      "loss before training is 4.201610516144094e-05 -- epoch number 5682\n",
      "\n",
      "\n",
      "loss before training is 4.195697636709938e-05 -- epoch number 5683\n",
      "\n",
      "\n",
      "loss before training is 4.189793332121367e-05 -- epoch number 5684\n",
      "\n",
      "\n",
      "loss before training is 4.183897590011211e-05 -- epoch number 5685\n",
      "\n",
      "\n",
      "loss before training is 4.178010398029628e-05 -- epoch number 5686\n",
      "\n",
      "\n",
      "loss before training is 4.172131743843337e-05 -- epoch number 5687\n",
      "\n",
      "\n",
      "loss before training is 4.16626161513633e-05 -- epoch number 5688\n",
      "\n",
      "\n",
      "loss before training is 4.16039999960914e-05 -- epoch number 5689\n",
      "\n",
      "\n",
      "loss before training is 4.154546884979549e-05 -- epoch number 5690\n",
      "\n",
      "\n",
      "loss before training is 4.148702258982193e-05 -- epoch number 5691\n",
      "\n",
      "\n",
      "loss before training is 4.1428661093682276e-05 -- epoch number 5692\n",
      "\n",
      "\n",
      "loss before training is 4.1370384239060774e-05 -- epoch number 5693\n",
      "\n",
      "\n",
      "loss before training is 4.131219190380791e-05 -- epoch number 5694\n",
      "\n",
      "\n",
      "loss before training is 4.125408396594022e-05 -- epoch number 5695\n",
      "\n",
      "\n",
      "loss before training is 4.1196060303644866e-05 -- epoch number 5696\n",
      "\n",
      "\n",
      "loss before training is 4.113812079527554e-05 -- epoch number 5697\n",
      "\n",
      "\n",
      "loss before training is 4.1080265319353794e-05 -- epoch number 5698\n",
      "\n",
      "\n",
      "loss before training is 4.102249375456641e-05 -- epoch number 5699\n",
      "\n",
      "\n",
      "loss before training is 4.0964805979769066e-05 -- epoch number 5700\n",
      "\n",
      "\n",
      "loss before training is 4.090720187398517e-05 -- epoch number 5701\n",
      "\n",
      "\n",
      "loss before training is 4.084968131640042e-05 -- epoch number 5702\n",
      "\n",
      "\n",
      "loss before training is 4.079224418637084e-05 -- epoch number 5703\n",
      "\n",
      "\n",
      "loss before training is 4.073489036341649e-05 -- epoch number 5704\n",
      "\n",
      "\n",
      "loss before training is 4.067761972722535e-05 -- epoch number 5705\n",
      "\n",
      "\n",
      "loss before training is 4.0620432157648074e-05 -- epoch number 5706\n",
      "\n",
      "\n",
      "loss before training is 4.0563327534704326e-05 -- epoch number 5707\n",
      "\n",
      "\n",
      "loss before training is 4.050630573857607e-05 -- epoch number 5708\n",
      "\n",
      "\n",
      "loss before training is 4.0449366649612715e-05 -- epoch number 5709\n",
      "\n",
      "\n",
      "loss before training is 4.0392510148326525e-05 -- epoch number 5710\n",
      "\n",
      "\n",
      "loss before training is 4.033573611539538e-05 -- epoch number 5711\n",
      "\n",
      "\n",
      "loss before training is 4.027904443166289e-05 -- epoch number 5712\n",
      "\n",
      "\n",
      "loss before training is 4.0222434978134467e-05 -- epoch number 5713\n",
      "\n",
      "\n",
      "loss before training is 4.0165907635981367e-05 -- epoch number 5714\n",
      "\n",
      "\n",
      "loss before training is 4.010946228653859e-05 -- epoch number 5715\n",
      "\n",
      "\n",
      "loss before training is 4.005309881130552e-05 -- epoch number 5716\n",
      "\n",
      "\n",
      "loss before training is 3.9996817091941635e-05 -- epoch number 5717\n",
      "\n",
      "\n",
      "loss before training is 3.994061701027325e-05 -- epoch number 5718\n",
      "\n",
      "\n",
      "loss before training is 3.988449844829018e-05 -- epoch number 5719\n",
      "\n",
      "\n",
      "loss before training is 3.982846128814238e-05 -- epoch number 5720\n",
      "\n",
      "\n",
      "loss before training is 3.977250541214347e-05 -- epoch number 5721\n",
      "\n",
      "\n",
      "loss before training is 3.97166307027702e-05 -- epoch number 5722\n",
      "\n",
      "\n",
      "loss before training is 3.9660837042661796e-05 -- epoch number 5723\n",
      "\n",
      "\n",
      "loss before training is 3.960512431461866e-05 -- epoch number 5724\n",
      "\n",
      "\n",
      "loss before training is 3.954949240160323e-05 -- epoch number 5725\n",
      "\n",
      "\n",
      "loss before training is 3.949394118674109e-05 -- epoch number 5726\n",
      "\n",
      "\n",
      "loss before training is 3.943847055331552e-05 -- epoch number 5727\n",
      "\n",
      "\n",
      "loss before training is 3.938308038477711e-05 -- epoch number 5728\n",
      "\n",
      "\n",
      "loss before training is 3.9327770564731954e-05 -- epoch number 5729\n",
      "\n",
      "\n",
      "loss before training is 3.927254097694972e-05 -- epoch number 5730\n",
      "\n",
      "\n",
      "loss before training is 3.921739150536121e-05 -- epoch number 5731\n",
      "\n",
      "\n",
      "loss before training is 3.916232203405536e-05 -- epoch number 5732\n",
      "\n",
      "\n",
      "loss before training is 3.9107332447283844e-05 -- epoch number 5733\n",
      "\n",
      "\n",
      "loss before training is 3.905242262945836e-05 -- epoch number 5734\n",
      "\n",
      "\n",
      "loss before training is 3.8997592465147796e-05 -- epoch number 5735\n",
      "\n",
      "\n",
      "loss before training is 3.894284183908395e-05 -- epoch number 5736\n",
      "\n",
      "\n",
      "loss before training is 3.8888170636156095e-05 -- epoch number 5737\n",
      "\n",
      "\n",
      "loss before training is 3.883357874141418e-05 -- epoch number 5738\n",
      "\n",
      "\n",
      "loss before training is 3.877906604006696e-05 -- epoch number 5739\n",
      "\n",
      "\n",
      "loss before training is 3.872463241748161e-05 -- epoch number 5740\n",
      "\n",
      "\n",
      "loss before training is 3.86702777591829e-05 -- epoch number 5741\n",
      "\n",
      "\n",
      "loss before training is 3.8616001950857455e-05 -- epoch number 5742\n",
      "\n",
      "\n",
      "loss before training is 3.856180487834729e-05 -- epoch number 5743\n",
      "\n",
      "\n",
      "loss before training is 3.850768642765348e-05 -- epoch number 5744\n",
      "\n",
      "\n",
      "loss before training is 3.845364648493574e-05 -- epoch number 5745\n",
      "\n",
      "\n",
      "loss before training is 3.839968493651095e-05 -- epoch number 5746\n",
      "\n",
      "\n",
      "loss before training is 3.834580166885211e-05 -- epoch number 5747\n",
      "\n",
      "\n",
      "loss before training is 3.829199656859326e-05 -- epoch number 5748\n",
      "\n",
      "\n",
      "loss before training is 3.8238269522521945e-05 -- epoch number 5749\n",
      "\n",
      "\n",
      "loss before training is 3.8184620417584426e-05 -- epoch number 5750\n",
      "\n",
      "\n",
      "loss before training is 3.8131049140883363e-05 -- epoch number 5751\n",
      "\n",
      "\n",
      "loss before training is 3.80775555796776e-05 -- epoch number 5752\n",
      "\n",
      "\n",
      "loss before training is 3.802413962138466e-05 -- epoch number 5753\n",
      "\n",
      "\n",
      "loss before training is 3.7970801153574787e-05 -- epoch number 5754\n",
      "\n",
      "\n",
      "loss before training is 3.791754006397604e-05 -- epoch number 5755\n",
      "\n",
      "\n",
      "loss before training is 3.7864356240471924e-05 -- epoch number 5756\n",
      "\n",
      "\n",
      "loss before training is 3.781124957110305e-05 -- epoch number 5757\n",
      "\n",
      "\n",
      "loss before training is 3.7758219944063925e-05 -- epoch number 5758\n",
      "\n",
      "\n",
      "loss before training is 3.770526724770215e-05 -- epoch number 5759\n",
      "\n",
      "\n",
      "loss before training is 3.765239137052686e-05 -- epoch number 5760\n",
      "\n",
      "\n",
      "loss before training is 3.759959220119379e-05 -- epoch number 5761\n",
      "\n",
      "\n",
      "loss before training is 3.7546869628520734e-05 -- epoch number 5762\n",
      "\n",
      "\n",
      "loss before training is 3.7494223541475204e-05 -- epoch number 5763\n",
      "\n",
      "\n",
      "loss before training is 3.7441653829179365e-05 -- epoch number 5764\n",
      "\n",
      "\n",
      "loss before training is 3.738916038091317e-05 -- epoch number 5765\n",
      "\n",
      "\n",
      "loss before training is 3.733674308610618e-05 -- epoch number 5766\n",
      "\n",
      "\n",
      "loss before training is 3.728440183434288e-05 -- epoch number 5767\n",
      "\n",
      "\n",
      "loss before training is 3.723213651536327e-05 -- epoch number 5768\n",
      "\n",
      "\n",
      "loss before training is 3.7179947019057294e-05 -- epoch number 5769\n",
      "\n",
      "\n",
      "loss before training is 3.7127833235471294e-05 -- epoch number 5770\n",
      "\n",
      "\n",
      "loss before training is 3.7075795054801454e-05 -- epoch number 5771\n",
      "\n",
      "\n",
      "loss before training is 3.7023832367401093e-05 -- epoch number 5772\n",
      "\n",
      "\n",
      "loss before training is 3.697194506377052e-05 -- epoch number 5773\n",
      "\n",
      "\n",
      "loss before training is 3.6920133034565574e-05 -- epoch number 5774\n",
      "\n",
      "\n",
      "loss before training is 3.686839617059533e-05 -- epoch number 5775\n",
      "\n",
      "\n",
      "loss before training is 3.6816734362817865e-05 -- epoch number 5776\n",
      "\n",
      "\n",
      "loss before training is 3.676514750234421e-05 -- epoch number 5777\n",
      "\n",
      "\n",
      "loss before training is 3.67136354804381e-05 -- epoch number 5778\n",
      "\n",
      "\n",
      "loss before training is 3.6662198188514735e-05 -- epoch number 5779\n",
      "\n",
      "\n",
      "loss before training is 3.661083551813882e-05 -- epoch number 5780\n",
      "\n",
      "\n",
      "loss before training is 3.65595473610265e-05 -- epoch number 5781\n",
      "\n",
      "\n",
      "loss before training is 3.6508333609044385e-05 -- epoch number 5782\n",
      "\n",
      "\n",
      "loss before training is 3.645719415421345e-05 -- epoch number 5783\n",
      "\n",
      "\n",
      "loss before training is 3.6406128888699155e-05 -- epoch number 5784\n",
      "\n",
      "\n",
      "loss before training is 3.635513770482244e-05 -- epoch number 5785\n",
      "\n",
      "\n",
      "loss before training is 3.630422049505114e-05 -- epoch number 5786\n",
      "\n",
      "\n",
      "loss before training is 3.625337715200422e-05 -- epoch number 5787\n",
      "\n",
      "\n",
      "loss before training is 3.6202607568450225e-05 -- epoch number 5788\n",
      "\n",
      "\n",
      "loss before training is 3.6151911637305996e-05 -- epoch number 5789\n",
      "\n",
      "\n",
      "loss before training is 3.610128925164172e-05 -- epoch number 5790\n",
      "\n",
      "\n",
      "loss before training is 3.6050740304671076e-05 -- epoch number 5791\n",
      "\n",
      "\n",
      "loss before training is 3.600026468976138e-05 -- epoch number 5792\n",
      "\n",
      "\n",
      "loss before training is 3.5949862300425e-05 -- epoch number 5793\n",
      "\n",
      "\n",
      "loss before training is 3.5899533030326545e-05 -- epoch number 5794\n",
      "\n",
      "\n",
      "loss before training is 3.584927677327615e-05 -- epoch number 5795\n",
      "\n",
      "\n",
      "loss before training is 3.579909342323378e-05 -- epoch number 5796\n",
      "\n",
      "\n",
      "loss before training is 3.574898287430603e-05 -- epoch number 5797\n",
      "\n",
      "\n",
      "loss before training is 3.5698945020749496e-05 -- epoch number 5798\n",
      "\n",
      "\n",
      "loss before training is 3.564897975696546e-05 -- epoch number 5799\n",
      "\n",
      "\n",
      "loss before training is 3.5599086977505645e-05 -- epoch number 5800\n",
      "\n",
      "\n",
      "loss before training is 3.55492665770669e-05 -- epoch number 5801\n",
      "\n",
      "\n",
      "loss before training is 3.549951845049521e-05 -- epoch number 5802\n",
      "\n",
      "\n",
      "loss before training is 3.544984249278057e-05 -- epoch number 5803\n",
      "\n",
      "\n",
      "loss before training is 3.5400238599062945e-05 -- epoch number 5804\n",
      "\n",
      "\n",
      "loss before training is 3.535070666462499e-05 -- epoch number 5805\n",
      "\n",
      "\n",
      "loss before training is 3.5301246584900725e-05 -- epoch number 5806\n",
      "\n",
      "\n",
      "loss before training is 3.525185825546548e-05 -- epoch number 5807\n",
      "\n",
      "\n",
      "loss before training is 3.520254157204477e-05 -- epoch number 5808\n",
      "\n",
      "\n",
      "loss before training is 3.51532964305062e-05 -- epoch number 5809\n",
      "\n",
      "\n",
      "loss before training is 3.5104122726864514e-05 -- epoch number 5810\n",
      "\n",
      "\n",
      "loss before training is 3.505502035728128e-05 -- epoch number 5811\n",
      "\n",
      "\n",
      "loss before training is 3.500598921806162e-05 -- epoch number 5812\n",
      "\n",
      "\n",
      "loss before training is 3.4957029205654e-05 -- epoch number 5813\n",
      "\n",
      "\n",
      "loss before training is 3.490814021665819e-05 -- epoch number 5814\n",
      "\n",
      "\n",
      "loss before training is 3.4859322147810645e-05 -- epoch number 5815\n",
      "\n",
      "\n",
      "loss before training is 3.481057489599826e-05 -- epoch number 5816\n",
      "\n",
      "\n",
      "loss before training is 3.476189835824936e-05 -- epoch number 5817\n",
      "\n",
      "\n",
      "loss before training is 3.471329243173728e-05 -- epoch number 5818\n",
      "\n",
      "\n",
      "loss before training is 3.466475701377848e-05 -- epoch number 5819\n",
      "\n",
      "\n",
      "loss before training is 3.461629200183444e-05 -- epoch number 5820\n",
      "\n",
      "\n",
      "loss before training is 3.456789729350983e-05 -- epoch number 5821\n",
      "\n",
      "\n",
      "loss before training is 3.451957278655276e-05 -- epoch number 5822\n",
      "\n",
      "\n",
      "loss before training is 3.447131837885407e-05 -- epoch number 5823\n",
      "\n",
      "\n",
      "loss before training is 3.4423133968448984e-05 -- epoch number 5824\n",
      "\n",
      "\n",
      "loss before training is 3.437501945351413e-05 -- epoch number 5825\n",
      "\n",
      "\n",
      "loss before training is 3.43269747323688e-05 -- epoch number 5826\n",
      "\n",
      "\n",
      "loss before training is 3.427899970347591e-05 -- epoch number 5827\n",
      "\n",
      "\n",
      "loss before training is 3.423109426544015e-05 -- epoch number 5828\n",
      "\n",
      "\n",
      "loss before training is 3.418325831700828e-05 -- epoch number 5829\n",
      "\n",
      "\n",
      "loss before training is 3.413549175706959e-05 -- epoch number 5830\n",
      "\n",
      "\n",
      "loss before training is 3.408779448465429e-05 -- epoch number 5831\n",
      "\n",
      "\n",
      "loss before training is 3.404016639893574e-05 -- epoch number 5832\n",
      "\n",
      "\n",
      "loss before training is 3.399260739922622e-05 -- epoch number 5833\n",
      "\n",
      "\n",
      "loss before training is 3.3945117384980765e-05 -- epoch number 5834\n",
      "\n",
      "\n",
      "loss before training is 3.3897696255796945e-05 -- epoch number 5835\n",
      "\n",
      "\n",
      "loss before training is 3.3850343911409736e-05 -- epoch number 5836\n",
      "\n",
      "\n",
      "loss before training is 3.3803060251697886e-05 -- epoch number 5837\n",
      "\n",
      "\n",
      "loss before training is 3.375584517667921e-05 -- epoch number 5838\n",
      "\n",
      "\n",
      "loss before training is 3.370869858651337e-05 -- epoch number 5839\n",
      "\n",
      "\n",
      "loss before training is 3.366162038149776e-05 -- epoch number 5840\n",
      "\n",
      "\n",
      "loss before training is 3.36146104620709e-05 -- epoch number 5841\n",
      "\n",
      "\n",
      "loss before training is 3.3567668728813155e-05 -- epoch number 5842\n",
      "\n",
      "\n",
      "loss before training is 3.3520795082440835e-05 -- epoch number 5843\n",
      "\n",
      "\n",
      "loss before training is 3.3473989423813194e-05 -- epoch number 5844\n",
      "\n",
      "\n",
      "loss before training is 3.342725165392549e-05 -- epoch number 5845\n",
      "\n",
      "\n",
      "loss before training is 3.338058167391574e-05 -- epoch number 5846\n",
      "\n",
      "\n",
      "loss before training is 3.333397938505732e-05 -- epoch number 5847\n",
      "\n",
      "\n",
      "loss before training is 3.328744468876427e-05 -- epoch number 5848\n",
      "\n",
      "\n",
      "loss before training is 3.324097748658954e-05 -- epoch number 5849\n",
      "\n",
      "\n",
      "loss before training is 3.319457768022386e-05 -- epoch number 5850\n",
      "\n",
      "\n",
      "loss before training is 3.314824517149589e-05 -- epoch number 5851\n",
      "\n",
      "\n",
      "loss before training is 3.31019798623728e-05 -- epoch number 5852\n",
      "\n",
      "\n",
      "loss before training is 3.305578165495916e-05 -- epoch number 5853\n",
      "\n",
      "\n",
      "loss before training is 3.300965045149888e-05 -- epoch number 5854\n",
      "\n",
      "\n",
      "loss before training is 3.29635861543701e-05 -- epoch number 5855\n",
      "\n",
      "\n",
      "loss before training is 3.291758866609167e-05 -- epoch number 5856\n",
      "\n",
      "\n",
      "loss before training is 3.287165788931826e-05 -- epoch number 5857\n",
      "\n",
      "\n",
      "loss before training is 3.2825793726840186e-05 -- epoch number 5858\n",
      "\n",
      "\n",
      "loss before training is 3.277999608158823e-05 -- epoch number 5859\n",
      "\n",
      "\n",
      "loss before training is 3.2734264856624536e-05 -- epoch number 5860\n",
      "\n",
      "\n",
      "loss before training is 3.268859995515367e-05 -- epoch number 5861\n",
      "\n",
      "\n",
      "loss before training is 3.2643001280511754e-05 -- epoch number 5862\n",
      "\n",
      "\n",
      "loss before training is 3.25974687361731e-05 -- epoch number 5863\n",
      "\n",
      "\n",
      "loss before training is 3.255200222574734e-05 -- epoch number 5864\n",
      "\n",
      "\n",
      "loss before training is 3.250660165298078e-05 -- epoch number 5865\n",
      "\n",
      "\n",
      "loss before training is 3.2461266921754285e-05 -- epoch number 5866\n",
      "\n",
      "\n",
      "loss before training is 3.241599793608504e-05 -- epoch number 5867\n",
      "\n",
      "\n",
      "loss before training is 3.237079460012428e-05 -- epoch number 5868\n",
      "\n",
      "\n",
      "loss before training is 3.2325656818160346e-05 -- epoch number 5869\n",
      "\n",
      "\n",
      "loss before training is 3.228058449461378e-05 -- epoch number 5870\n",
      "\n",
      "\n",
      "loss before training is 3.2235577534042175e-05 -- epoch number 5871\n",
      "\n",
      "\n",
      "loss before training is 3.219063584113563e-05 -- epoch number 5872\n",
      "\n",
      "\n",
      "loss before training is 3.2145759320721966e-05 -- epoch number 5873\n",
      "\n",
      "\n",
      "loss before training is 3.210094787775893e-05 -- epoch number 5874\n",
      "\n",
      "\n",
      "loss before training is 3.205620141734155e-05 -- epoch number 5875\n",
      "\n",
      "\n",
      "loss before training is 3.201151984469693e-05 -- epoch number 5876\n",
      "\n",
      "\n",
      "loss before training is 3.196690306518614e-05 -- epoch number 5877\n",
      "\n",
      "\n",
      "loss before training is 3.192235098430576e-05 -- epoch number 5878\n",
      "\n",
      "\n",
      "loss before training is 3.187786350768286e-05 -- epoch number 5879\n",
      "\n",
      "\n",
      "loss before training is 3.183344054107914e-05 -- epoch number 5880\n",
      "\n",
      "\n",
      "loss before training is 3.178908199038858e-05 -- epoch number 5881\n",
      "\n",
      "\n",
      "loss before training is 3.1744787761639394e-05 -- epoch number 5882\n",
      "\n",
      "\n",
      "loss before training is 3.170055776099122e-05 -- epoch number 5883\n",
      "\n",
      "\n",
      "loss before training is 3.165639189473707e-05 -- epoch number 5884\n",
      "\n",
      "\n",
      "loss before training is 3.161229006930083e-05 -- epoch number 5885\n",
      "\n",
      "\n",
      "loss before training is 3.156825219124022e-05 -- epoch number 5886\n",
      "\n",
      "\n",
      "loss before training is 3.1524278167244737e-05 -- epoch number 5887\n",
      "\n",
      "\n",
      "loss before training is 3.1480367904132564e-05 -- epoch number 5888\n",
      "\n",
      "\n",
      "loss before training is 3.143652130885881e-05 -- epoch number 5889\n",
      "\n",
      "\n",
      "loss before training is 3.13927382885063e-05 -- epoch number 5890\n",
      "\n",
      "\n",
      "loss before training is 3.134901875028983e-05 -- epoch number 5891\n",
      "\n",
      "\n",
      "loss before training is 3.130536260155756e-05 -- epoch number 5892\n",
      "\n",
      "\n",
      "loss before training is 3.126176974978378e-05 -- epoch number 5893\n",
      "\n",
      "\n",
      "loss before training is 3.121824010257899e-05 -- epoch number 5894\n",
      "\n",
      "\n",
      "loss before training is 3.117477356768155e-05 -- epoch number 5895\n",
      "\n",
      "\n",
      "loss before training is 3.1131370052959315e-05 -- epoch number 5896\n",
      "\n",
      "\n",
      "loss before training is 3.108802946641285e-05 -- epoch number 5897\n",
      "\n",
      "\n",
      "loss before training is 3.104475171617189e-05 -- epoch number 5898\n",
      "\n",
      "\n",
      "loss before training is 3.1001536710495474e-05 -- epoch number 5899\n",
      "\n",
      "\n",
      "loss before training is 3.0958384357771986e-05 -- epoch number 5900\n",
      "\n",
      "\n",
      "loss before training is 3.091529456652231e-05 -- epoch number 5901\n",
      "\n",
      "\n",
      "loss before training is 3.0872267245393247e-05 -- epoch number 5902\n",
      "\n",
      "\n",
      "loss before training is 3.082930230316345e-05 -- epoch number 5903\n",
      "\n",
      "\n",
      "loss before training is 3.0786399648738934e-05 -- epoch number 5904\n",
      "\n",
      "\n",
      "loss before training is 3.074355919115593e-05 -- epoch number 5905\n",
      "\n",
      "\n",
      "loss before training is 3.0700780839578984e-05 -- epoch number 5906\n",
      "\n",
      "\n",
      "loss before training is 3.065806450329982e-05 -- epoch number 5907\n",
      "\n",
      "\n",
      "loss before training is 3.061541009174215e-05 -- epoch number 5908\n",
      "\n",
      "\n",
      "loss before training is 3.057281751445429e-05 -- epoch number 5909\n",
      "\n",
      "\n",
      "loss before training is 3.05302866811134e-05 -- epoch number 5910\n",
      "\n",
      "\n",
      "loss before training is 3.048781750152798e-05 -- epoch number 5911\n",
      "\n",
      "\n",
      "loss before training is 3.044540988562958e-05 -- epoch number 5912\n",
      "\n",
      "\n",
      "loss before training is 3.0403063743479855e-05 -- epoch number 5913\n",
      "\n",
      "\n",
      "loss before training is 3.0360778985268672e-05 -- epoch number 5914\n",
      "\n",
      "\n",
      "loss before training is 3.031855552131019e-05 -- epoch number 5915\n",
      "\n",
      "\n",
      "loss before training is 3.0276393262049566e-05 -- epoch number 5916\n",
      "\n",
      "\n",
      "loss before training is 3.0234292118054595e-05 -- epoch number 5917\n",
      "\n",
      "\n",
      "loss before training is 3.019225200002252e-05 -- epoch number 5918\n",
      "\n",
      "\n",
      "loss before training is 3.0150272818778708e-05 -- epoch number 5919\n",
      "\n",
      "\n",
      "loss before training is 3.0108354485271473e-05 -- epoch number 5920\n",
      "\n",
      "\n",
      "loss before training is 3.006649691057843e-05 -- epoch number 5921\n",
      "\n",
      "\n",
      "loss before training is 3.0024700005900344e-05 -- epoch number 5922\n",
      "\n",
      "\n",
      "loss before training is 2.9982963682565745e-05 -- epoch number 5923\n",
      "\n",
      "\n",
      "loss before training is 2.9941287852029115e-05 -- epoch number 5924\n",
      "\n",
      "\n",
      "loss before training is 2.9899672425871216e-05 -- epoch number 5925\n",
      "\n",
      "\n",
      "loss before training is 2.985811731579557e-05 -- epoch number 5926\n",
      "\n",
      "\n",
      "loss before training is 2.9816622433633932e-05 -- epoch number 5927\n",
      "\n",
      "\n",
      "loss before training is 2.977518769134063e-05 -- epoch number 5928\n",
      "\n",
      "\n",
      "loss before training is 2.973381300099792e-05 -- epoch number 5929\n",
      "\n",
      "\n",
      "loss before training is 2.969249827481048e-05 -- epoch number 5930\n",
      "\n",
      "\n",
      "loss before training is 2.965124342510778e-05 -- epoch number 5931\n",
      "\n",
      "\n",
      "loss before training is 2.96100483643461e-05 -- epoch number 5932\n",
      "\n",
      "\n",
      "loss before training is 2.95689130051031e-05 -- epoch number 5933\n",
      "\n",
      "\n",
      "loss before training is 2.9527837260082144e-05 -- epoch number 5934\n",
      "\n",
      "\n",
      "loss before training is 2.9486821042110424e-05 -- epoch number 5935\n",
      "\n",
      "\n",
      "loss before training is 2.9445864264139483e-05 -- epoch number 5936\n",
      "\n",
      "\n",
      "loss before training is 2.940496683924387e-05 -- epoch number 5937\n",
      "\n",
      "\n",
      "loss before training is 2.9364128680620777e-05 -- epoch number 5938\n",
      "\n",
      "\n",
      "loss before training is 2.932334970159259e-05 -- epoch number 5939\n",
      "\n",
      "\n",
      "loss before training is 2.92826298156045e-05 -- epoch number 5940\n",
      "\n",
      "\n",
      "loss before training is 2.9241968936223302e-05 -- epoch number 5941\n",
      "\n",
      "\n",
      "loss before training is 2.920136697714055e-05 -- epoch number 5942\n",
      "\n",
      "\n",
      "loss before training is 2.916082385216861e-05 -- epoch number 5943\n",
      "\n",
      "\n",
      "loss before training is 2.912033947524422e-05 -- epoch number 5944\n",
      "\n",
      "\n",
      "loss before training is 2.907991376042667e-05 -- epoch number 5945\n",
      "\n",
      "\n",
      "loss before training is 2.903954662189409e-05 -- epoch number 5946\n",
      "\n",
      "\n",
      "loss before training is 2.89992379739505e-05 -- epoch number 5947\n",
      "\n",
      "\n",
      "loss before training is 2.895898773102089e-05 -- epoch number 5948\n",
      "\n",
      "\n",
      "loss before training is 2.8918795807651842e-05 -- epoch number 5949\n",
      "\n",
      "\n",
      "loss before training is 2.8878662118509594e-05 -- epoch number 5950\n",
      "\n",
      "\n",
      "loss before training is 2.8838586578384942e-05 -- epoch number 5951\n",
      "\n",
      "\n",
      "loss before training is 2.879856910218766e-05 -- epoch number 5952\n",
      "\n",
      "\n",
      "loss before training is 2.875860960495113e-05 -- epoch number 5953\n",
      "\n",
      "\n",
      "loss before training is 2.8718708001826564e-05 -- epoch number 5954\n",
      "\n",
      "\n",
      "loss before training is 2.867886420808764e-05 -- epoch number 5955\n",
      "\n",
      "\n",
      "loss before training is 2.8639078139127935e-05 -- epoch number 5956\n",
      "\n",
      "\n",
      "loss before training is 2.8599349710464947e-05 -- epoch number 5957\n",
      "\n",
      "\n",
      "loss before training is 2.8559678837730642e-05 -- epoch number 5958\n",
      "\n",
      "\n",
      "loss before training is 2.8520065436680683e-05 -- epoch number 5959\n",
      "\n",
      "\n",
      "loss before training is 2.8480509423192417e-05 -- epoch number 5960\n",
      "\n",
      "\n",
      "loss before training is 2.8441010713258078e-05 -- epoch number 5961\n",
      "\n",
      "\n",
      "loss before training is 2.8401569222993917e-05 -- epoch number 5962\n",
      "\n",
      "\n",
      "loss before training is 2.836218486863412e-05 -- epoch number 5963\n",
      "\n",
      "\n",
      "loss before training is 2.832285756653149e-05 -- epoch number 5964\n",
      "\n",
      "\n",
      "loss before training is 2.828358723315948e-05 -- epoch number 5965\n",
      "\n",
      "\n",
      "loss before training is 2.824437378511046e-05 -- epoch number 5966\n",
      "\n",
      "\n",
      "loss before training is 2.820521713909471e-05 -- epoch number 5967\n",
      "\n",
      "\n",
      "loss before training is 2.8166117211942363e-05 -- epoch number 5968\n",
      "\n",
      "\n",
      "loss before training is 2.8127073920601387e-05 -- epoch number 5969\n",
      "\n",
      "\n",
      "loss before training is 2.808808718213749e-05 -- epoch number 5970\n",
      "\n",
      "\n",
      "loss before training is 2.8049156913736794e-05 -- epoch number 5971\n",
      "\n",
      "\n",
      "loss before training is 2.8010283032702707e-05 -- epoch number 5972\n",
      "\n",
      "\n",
      "loss before training is 2.7971465456454643e-05 -- epoch number 5973\n",
      "\n",
      "\n",
      "loss before training is 2.793270410253328e-05 -- epoch number 5974\n",
      "\n",
      "\n",
      "loss before training is 2.7893998888594003e-05 -- epoch number 5975\n",
      "\n",
      "\n",
      "loss before training is 2.785534973241054e-05 -- epoch number 5976\n",
      "\n",
      "\n",
      "loss before training is 2.781675655187557e-05 -- epoch number 5977\n",
      "\n",
      "\n",
      "loss before training is 2.7778219264997032e-05 -- epoch number 5978\n",
      "\n",
      "\n",
      "loss before training is 2.7739737789900256e-05 -- epoch number 5979\n",
      "\n",
      "\n",
      "loss before training is 2.7701312044828854e-05 -- epoch number 5980\n",
      "\n",
      "\n",
      "loss before training is 2.7662941948140862e-05 -- epoch number 5981\n",
      "\n",
      "\n",
      "loss before training is 2.7624627418312686e-05 -- epoch number 5982\n",
      "\n",
      "\n",
      "loss before training is 2.7586368373935844e-05 -- epoch number 5983\n",
      "\n",
      "\n",
      "loss before training is 2.754816473371968e-05 -- epoch number 5984\n",
      "\n",
      "\n",
      "loss before training is 2.7510016416489258e-05 -- epoch number 5985\n",
      "\n",
      "\n",
      "loss before training is 2.7471923341185064e-05 -- epoch number 5986\n",
      "\n",
      "\n",
      "loss before training is 2.74338854268634e-05 -- epoch number 5987\n",
      "\n",
      "\n",
      "loss before training is 2.7395902592695704e-05 -- epoch number 5988\n",
      "\n",
      "\n",
      "loss before training is 2.735797475796992e-05 -- epoch number 5989\n",
      "\n",
      "\n",
      "loss before training is 2.7320101842089743e-05 -- epoch number 5990\n",
      "\n",
      "\n",
      "loss before training is 2.7282283764572408e-05 -- epoch number 5991\n",
      "\n",
      "\n",
      "loss before training is 2.7244520445051298e-05 -- epoch number 5992\n",
      "\n",
      "\n",
      "loss before training is 2.7206811803276203e-05 -- epoch number 5993\n",
      "\n",
      "\n",
      "loss before training is 2.716915775910817e-05 -- epoch number 5994\n",
      "\n",
      "\n",
      "loss before training is 2.7131558232524664e-05 -- epoch number 5995\n",
      "\n",
      "\n",
      "loss before training is 2.70940131436185e-05 -- epoch number 5996\n",
      "\n",
      "\n",
      "loss before training is 2.705652241259597e-05 -- epoch number 5997\n",
      "\n",
      "\n",
      "loss before training is 2.7019085959776095e-05 -- epoch number 5998\n",
      "\n",
      "\n",
      "loss before training is 2.6981703705595597e-05 -- epoch number 5999\n",
      "\n",
      "\n",
      "loss before training is 2.694437557060143e-05 -- epoch number 6000\n",
      "\n",
      "\n",
      "loss before training is 2.6907101475453818e-05 -- epoch number 6001\n",
      "\n",
      "\n",
      "loss before training is 2.6869881340930043e-05 -- epoch number 6002\n",
      "\n",
      "\n",
      "loss before training is 2.6832715087919268e-05 -- epoch number 6003\n",
      "\n",
      "\n",
      "loss before training is 2.6795602637422166e-05 -- epoch number 6004\n",
      "\n",
      "\n",
      "loss before training is 2.6758543910554417e-05 -- epoch number 6005\n",
      "\n",
      "\n",
      "loss before training is 2.6721538828544663e-05 -- epoch number 6006\n",
      "\n",
      "\n",
      "loss before training is 2.668458731273271e-05 -- epoch number 6007\n",
      "\n",
      "\n",
      "loss before training is 2.66476892845726e-05 -- epoch number 6008\n",
      "\n",
      "\n",
      "loss before training is 2.6610844665630182e-05 -- epoch number 6009\n",
      "\n",
      "\n",
      "loss before training is 2.6574053377583583e-05 -- epoch number 6010\n",
      "\n",
      "\n",
      "loss before training is 2.653731534222411e-05 -- epoch number 6011\n",
      "\n",
      "\n",
      "loss before training is 2.6500630481452935e-05 -- epoch number 6012\n",
      "\n",
      "\n",
      "loss before training is 2.6463998717285834e-05 -- epoch number 6013\n",
      "\n",
      "\n",
      "loss before training is 2.6427419971847876e-05 -- epoch number 6014\n",
      "\n",
      "\n",
      "loss before training is 2.6390894167377565e-05 -- epoch number 6015\n",
      "\n",
      "\n",
      "loss before training is 2.6354421226224e-05 -- epoch number 6016\n",
      "\n",
      "\n",
      "loss before training is 2.6318001070846775e-05 -- epoch number 6017\n",
      "\n",
      "\n",
      "loss before training is 2.6281633623818806e-05 -- epoch number 6018\n",
      "\n",
      "\n",
      "loss before training is 2.6245318807821102e-05 -- epoch number 6019\n",
      "\n",
      "\n",
      "loss before training is 2.620905654564861e-05 -- epoch number 6020\n",
      "\n",
      "\n",
      "loss before training is 2.6172846760205277e-05 -- epoch number 6021\n",
      "\n",
      "\n",
      "loss before training is 2.613668937450512e-05 -- epoch number 6022\n",
      "\n",
      "\n",
      "loss before training is 2.610058431167396e-05 -- epoch number 6023\n",
      "\n",
      "\n",
      "loss before training is 2.6064531494946297e-05 -- epoch number 6024\n",
      "\n",
      "\n",
      "loss before training is 2.6028530847669007e-05 -- epoch number 6025\n",
      "\n",
      "\n",
      "loss before training is 2.5992582293297033e-05 -- epoch number 6026\n",
      "\n",
      "\n",
      "loss before training is 2.59566857553946e-05 -- epoch number 6027\n",
      "\n",
      "\n",
      "loss before training is 2.5920841157637734e-05 -- epoch number 6028\n",
      "\n",
      "\n",
      "loss before training is 2.5885048423811924e-05 -- epoch number 6029\n",
      "\n",
      "\n",
      "loss before training is 2.58493074778088e-05 -- epoch number 6030\n",
      "\n",
      "\n",
      "loss before training is 2.58136182436324e-05 -- epoch number 6031\n",
      "\n",
      "\n",
      "loss before training is 2.5777980645396458e-05 -- epoch number 6032\n",
      "\n",
      "\n",
      "loss before training is 2.5742394607319624e-05 -- epoch number 6033\n",
      "\n",
      "\n",
      "loss before training is 2.57068600537338e-05 -- epoch number 6034\n",
      "\n",
      "\n",
      "loss before training is 2.5671376909076404e-05 -- epoch number 6035\n",
      "\n",
      "\n",
      "loss before training is 2.563594509789523e-05 -- epoch number 6036\n",
      "\n",
      "\n",
      "loss before training is 2.560056454484546e-05 -- epoch number 6037\n",
      "\n",
      "\n",
      "loss before training is 2.5565235174690096e-05 -- epoch number 6038\n",
      "\n",
      "\n",
      "loss before training is 2.5529956912303315e-05 -- epoch number 6039\n",
      "\n",
      "\n",
      "loss before training is 2.549472968266223e-05 -- epoch number 6040\n",
      "\n",
      "\n",
      "loss before training is 2.5459553410854687e-05 -- epoch number 6041\n",
      "\n",
      "\n",
      "loss before training is 2.542442802207821e-05 -- epoch number 6042\n",
      "\n",
      "\n",
      "loss before training is 2.538935344163205e-05 -- epoch number 6043\n",
      "\n",
      "\n",
      "loss before training is 2.535432959492823e-05 -- epoch number 6044\n",
      "\n",
      "\n",
      "loss before training is 2.5319356407483583e-05 -- epoch number 6045\n",
      "\n",
      "\n",
      "loss before training is 2.5284433804922316e-05 -- epoch number 6046\n",
      "\n",
      "\n",
      "loss before training is 2.524956171297581e-05 -- epoch number 6047\n",
      "\n",
      "\n",
      "loss before training is 2.5214740057481577e-05 -- epoch number 6048\n",
      "\n",
      "\n",
      "loss before training is 2.5179968764384296e-05 -- epoch number 6049\n",
      "\n",
      "\n",
      "loss before training is 2.5145247759735285e-05 -- epoch number 6050\n",
      "\n",
      "\n",
      "loss before training is 2.511057696969224e-05 -- epoch number 6051\n",
      "\n",
      "\n",
      "loss before training is 2.5075956320517675e-05 -- epoch number 6052\n",
      "\n",
      "\n",
      "loss before training is 2.504138573858282e-05 -- epoch number 6053\n",
      "\n",
      "\n",
      "loss before training is 2.500686515036202e-05 -- epoch number 6054\n",
      "\n",
      "\n",
      "loss before training is 2.4972394482437876e-05 -- epoch number 6055\n",
      "\n",
      "\n",
      "loss before training is 2.4937973661496598e-05 -- epoch number 6056\n",
      "\n",
      "\n",
      "loss before training is 2.4903602614330346e-05 -- epoch number 6057\n",
      "\n",
      "\n",
      "loss before training is 2.4869281267837927e-05 -- epoch number 6058\n",
      "\n",
      "\n",
      "loss before training is 2.483500954902209e-05 -- epoch number 6059\n",
      "\n",
      "\n",
      "loss before training is 2.4800787384991124e-05 -- epoch number 6060\n",
      "\n",
      "\n",
      "loss before training is 2.4766614702958402e-05 -- epoch number 6061\n",
      "\n",
      "\n",
      "loss before training is 2.4732491430241254e-05 -- epoch number 6062\n",
      "\n",
      "\n",
      "loss before training is 2.469841749426304e-05 -- epoch number 6063\n",
      "\n",
      "\n",
      "loss before training is 2.4664392822549753e-05 -- epoch number 6064\n",
      "\n",
      "\n",
      "loss before training is 2.463041734273377e-05 -- epoch number 6065\n",
      "\n",
      "\n",
      "loss before training is 2.4596490982550314e-05 -- epoch number 6066\n",
      "\n",
      "\n",
      "loss before training is 2.4562613669839533e-05 -- epoch number 6067\n",
      "\n",
      "\n",
      "loss before training is 2.4528785332544153e-05 -- epoch number 6068\n",
      "\n",
      "\n",
      "loss before training is 2.4495005898713967e-05 -- epoch number 6069\n",
      "\n",
      "\n",
      "loss before training is 2.446127529649693e-05 -- epoch number 6070\n",
      "\n",
      "\n",
      "loss before training is 2.4427593454150617e-05 -- epoch number 6071\n",
      "\n",
      "\n",
      "loss before training is 2.4393960300031644e-05 -- epoch number 6072\n",
      "\n",
      "\n",
      "loss before training is 2.4360375762601814e-05 -- epoch number 6073\n",
      "\n",
      "\n",
      "loss before training is 2.4326839770424684e-05 -- epoch number 6074\n",
      "\n",
      "\n",
      "loss before training is 2.4293352252169226e-05 -- epoch number 6075\n",
      "\n",
      "\n",
      "loss before training is 2.4259913136604832e-05 -- epoch number 6076\n",
      "\n",
      "\n",
      "loss before training is 2.422652235260426e-05 -- epoch number 6077\n",
      "\n",
      "\n",
      "loss before training is 2.4193179829144445e-05 -- epoch number 6078\n",
      "\n",
      "\n",
      "loss before training is 2.4159885495301457e-05 -- epoch number 6079\n",
      "\n",
      "\n",
      "loss before training is 2.412663928025662e-05 -- epoch number 6080\n",
      "\n",
      "\n",
      "loss before training is 2.409344111329247e-05 -- epoch number 6081\n",
      "\n",
      "\n",
      "loss before training is 2.4060290923792066e-05 -- epoch number 6082\n",
      "\n",
      "\n",
      "loss before training is 2.4027188641243114e-05 -- epoch number 6083\n",
      "\n",
      "\n",
      "loss before training is 2.3994134195233323e-05 -- epoch number 6084\n",
      "\n",
      "\n",
      "loss before training is 2.3961127515451374e-05 -- epoch number 6085\n",
      "\n",
      "\n",
      "loss before training is 2.3928168531689125e-05 -- epoch number 6086\n",
      "\n",
      "\n",
      "loss before training is 2.3895257173838964e-05 -- epoch number 6087\n",
      "\n",
      "\n",
      "loss before training is 2.3862393371894204e-05 -- epoch number 6088\n",
      "\n",
      "\n",
      "loss before training is 2.382957705594905e-05 -- epoch number 6089\n",
      "\n",
      "\n",
      "loss before training is 2.3796808156199127e-05 -- epoch number 6090\n",
      "\n",
      "\n",
      "loss before training is 2.376408660294142e-05 -- epoch number 6091\n",
      "\n",
      "\n",
      "loss before training is 2.3731412326571182e-05 -- epoch number 6092\n",
      "\n",
      "\n",
      "loss before training is 2.3698785257587385e-05 -- epoch number 6093\n",
      "\n",
      "\n",
      "loss before training is 2.3666205326587567e-05 -- epoch number 6094\n",
      "\n",
      "\n",
      "loss before training is 2.363367246426868e-05 -- epoch number 6095\n",
      "\n",
      "\n",
      "loss before training is 2.360118660143047e-05 -- epoch number 6096\n",
      "\n",
      "\n",
      "loss before training is 2.3568747668969632e-05 -- epoch number 6097\n",
      "\n",
      "\n",
      "loss before training is 2.3536355597883804e-05 -- epoch number 6098\n",
      "\n",
      "\n",
      "loss before training is 2.350401031927174e-05 -- epoch number 6099\n",
      "\n",
      "\n",
      "loss before training is 2.3471711764329434e-05 -- epoch number 6100\n",
      "\n",
      "\n",
      "loss before training is 2.3439459864353933e-05 -- epoch number 6101\n",
      "\n",
      "\n",
      "loss before training is 2.340725455074084e-05 -- epoch number 6102\n",
      "\n",
      "\n",
      "loss before training is 2.337509575498501e-05 -- epoch number 6103\n",
      "\n",
      "\n",
      "loss before training is 2.3342983408680275e-05 -- epoch number 6104\n",
      "\n",
      "\n",
      "loss before training is 2.331091744352008e-05 -- epoch number 6105\n",
      "\n",
      "\n",
      "loss before training is 2.3278897791296035e-05 -- epoch number 6106\n",
      "\n",
      "\n",
      "loss before training is 2.3246924383897095e-05 -- epoch number 6107\n",
      "\n",
      "\n",
      "loss before training is 2.321499715331337e-05 -- epoch number 6108\n",
      "\n",
      "\n",
      "loss before training is 2.3183116031630943e-05 -- epoch number 6109\n",
      "\n",
      "\n",
      "loss before training is 2.3151280951035042e-05 -- epoch number 6110\n",
      "\n",
      "\n",
      "loss before training is 2.3119491843809794e-05 -- epoch number 6111\n",
      "\n",
      "\n",
      "loss before training is 2.3087748642335117e-05 -- epoch number 6112\n",
      "\n",
      "\n",
      "loss before training is 2.3056051279090733e-05 -- epoch number 6113\n",
      "\n",
      "\n",
      "loss before training is 2.3024399686653628e-05 -- epoch number 6114\n",
      "\n",
      "\n",
      "loss before training is 2.29927937976982e-05 -- epoch number 6115\n",
      "\n",
      "\n",
      "loss before training is 2.2961233544996208e-05 -- epoch number 6116\n",
      "\n",
      "\n",
      "loss before training is 2.292971886141537e-05 -- epoch number 6117\n",
      "\n",
      "\n",
      "loss before training is 2.2898249679922533e-05 -- epoch number 6118\n",
      "\n",
      "\n",
      "loss before training is 2.2866825933580867e-05 -- epoch number 6119\n",
      "\n",
      "\n",
      "loss before training is 2.283544755555124e-05 -- epoch number 6120\n",
      "\n",
      "\n",
      "loss before training is 2.280411447908904e-05 -- epoch number 6121\n",
      "\n",
      "\n",
      "loss before training is 2.277282663754851e-05 -- epoch number 6122\n",
      "\n",
      "\n",
      "loss before training is 2.2741583964379207e-05 -- epoch number 6123\n",
      "\n",
      "\n",
      "loss before training is 2.271038639312701e-05 -- epoch number 6124\n",
      "\n",
      "\n",
      "loss before training is 2.267923385743507e-05 -- epoch number 6125\n",
      "\n",
      "\n",
      "loss before training is 2.264812629104139e-05 -- epoch number 6126\n",
      "\n",
      "\n",
      "loss before training is 2.2617063627781108e-05 -- epoch number 6127\n",
      "\n",
      "\n",
      "loss before training is 2.258604580158379e-05 -- epoch number 6128\n",
      "\n",
      "\n",
      "loss before training is 2.2555072746477065e-05 -- epoch number 6129\n",
      "\n",
      "\n",
      "loss before training is 2.2524144396580654e-05 -- epoch number 6130\n",
      "\n",
      "\n",
      "loss before training is 2.2493260686111674e-05 -- epoch number 6131\n",
      "\n",
      "\n",
      "loss before training is 2.246242154938513e-05 -- epoch number 6132\n",
      "\n",
      "\n",
      "loss before training is 2.2431626920805033e-05 -- epoch number 6133\n",
      "\n",
      "\n",
      "loss before training is 2.24008767348767e-05 -- epoch number 6134\n",
      "\n",
      "\n",
      "loss before training is 2.2370170926196168e-05 -- epoch number 6135\n",
      "\n",
      "\n",
      "loss before training is 2.2339509429456888e-05 -- epoch number 6136\n",
      "\n",
      "\n",
      "loss before training is 2.230889217944611e-05 -- epoch number 6137\n",
      "\n",
      "\n",
      "loss before training is 2.227831911104393e-05 -- epoch number 6138\n",
      "\n",
      "\n",
      "loss before training is 2.2247790159227158e-05 -- epoch number 6139\n",
      "\n",
      "\n",
      "loss before training is 2.221730525906618e-05 -- epoch number 6140\n",
      "\n",
      "\n",
      "loss before training is 2.218686434572493e-05 -- epoch number 6141\n",
      "\n",
      "\n",
      "loss before training is 2.2156467354461787e-05 -- epoch number 6142\n",
      "\n",
      "\n",
      "loss before training is 2.212611422063032e-05 -- epoch number 6143\n",
      "\n",
      "\n",
      "loss before training is 2.2095804879674982e-05 -- epoch number 6144\n",
      "\n",
      "\n",
      "loss before training is 2.206553926713667e-05 -- epoch number 6145\n",
      "\n",
      "\n",
      "loss before training is 2.2035317318648145e-05 -- epoch number 6146\n",
      "\n",
      "\n",
      "loss before training is 2.2005138969935305e-05 -- epoch number 6147\n",
      "\n",
      "\n",
      "loss before training is 2.1975004156820306e-05 -- epoch number 6148\n",
      "\n",
      "\n",
      "loss before training is 2.1944912815213328e-05 -- epoch number 6149\n",
      "\n",
      "\n",
      "loss before training is 2.1914864881122317e-05 -- epoch number 6150\n",
      "\n",
      "\n",
      "loss before training is 2.1884860290645436e-05 -- epoch number 6151\n",
      "\n",
      "\n",
      "loss before training is 2.1854898979974498e-05 -- epoch number 6152\n",
      "\n",
      "\n",
      "loss before training is 2.1824980885393295e-05 -- epoch number 6153\n",
      "\n",
      "\n",
      "loss before training is 2.179510594327928e-05 -- epoch number 6154\n",
      "\n",
      "\n",
      "loss before training is 2.1765274090100726e-05 -- epoch number 6155\n",
      "\n",
      "\n",
      "loss before training is 2.1735485262419055e-05 -- epoch number 6156\n",
      "\n",
      "\n",
      "loss before training is 2.1705739396888568e-05 -- epoch number 6157\n",
      "\n",
      "\n",
      "loss before training is 2.1676036430254376e-05 -- epoch number 6158\n",
      "\n",
      "\n",
      "loss before training is 2.1646376299353618e-05 -- epoch number 6159\n",
      "\n",
      "\n",
      "loss before training is 2.161675894111521e-05 -- epoch number 6160\n",
      "\n",
      "\n",
      "loss before training is 2.15871842925597e-05 -- epoch number 6161\n",
      "\n",
      "\n",
      "loss before training is 2.1557652290799896e-05 -- epoch number 6162\n",
      "\n",
      "\n",
      "loss before training is 2.1528162873038252e-05 -- epoch number 6163\n",
      "\n",
      "\n",
      "loss before training is 2.1498715976570366e-05 -- epoch number 6164\n",
      "\n",
      "\n",
      "loss before training is 2.1469311538782125e-05 -- epoch number 6165\n",
      "\n",
      "\n",
      "loss before training is 2.1439949497148917e-05 -- epoch number 6166\n",
      "\n",
      "\n",
      "loss before training is 2.1410629789239897e-05 -- epoch number 6167\n",
      "\n",
      "\n",
      "loss before training is 2.13813523527131e-05 -- epoch number 6168\n",
      "\n",
      "\n",
      "loss before training is 2.1352117125317693e-05 -- epoch number 6169\n",
      "\n",
      "\n",
      "loss before training is 2.1322924044892473e-05 -- epoch number 6170\n",
      "\n",
      "\n",
      "loss before training is 2.129377304936828e-05 -- epoch number 6171\n",
      "\n",
      "\n",
      "loss before training is 2.1264664076764097e-05 -- epoch number 6172\n",
      "\n",
      "\n",
      "loss before training is 2.1235597065191354e-05 -- epoch number 6173\n",
      "\n",
      "\n",
      "loss before training is 2.1206571952849116e-05 -- epoch number 6174\n",
      "\n",
      "\n",
      "loss before training is 2.1177588678028437e-05 -- epoch number 6175\n",
      "\n",
      "\n",
      "loss before training is 2.114864717910882e-05 -- epoch number 6176\n",
      "\n",
      "\n",
      "loss before training is 2.1119747394558568e-05 -- epoch number 6177\n",
      "\n",
      "\n",
      "loss before training is 2.109088926293864e-05 -- epoch number 6178\n",
      "\n",
      "\n",
      "loss before training is 2.1062072722895572e-05 -- epoch number 6179\n",
      "\n",
      "\n",
      "loss before training is 2.1033297713168432e-05 -- epoch number 6180\n",
      "\n",
      "\n",
      "loss before training is 2.100456417258177e-05 -- epoch number 6181\n",
      "\n",
      "\n",
      "loss before training is 2.0975872040053505e-05 -- epoch number 6182\n",
      "\n",
      "\n",
      "loss before training is 2.094722125458679e-05 -- epoch number 6183\n",
      "\n",
      "\n",
      "loss before training is 2.091861175527638e-05 -- epoch number 6184\n",
      "\n",
      "\n",
      "loss before training is 2.0890043481302145e-05 -- epoch number 6185\n",
      "\n",
      "\n",
      "loss before training is 2.0861516371936518e-05 -- epoch number 6186\n",
      "\n",
      "\n",
      "loss before training is 2.0833030366537286e-05 -- epoch number 6187\n",
      "\n",
      "\n",
      "loss before training is 2.0804585404551944e-05 -- epoch number 6188\n",
      "\n",
      "\n",
      "loss before training is 2.077618142551577e-05 -- epoch number 6189\n",
      "\n",
      "\n",
      "loss before training is 2.074781836905159e-05 -- epoch number 6190\n",
      "\n",
      "\n",
      "loss before training is 2.071949617487199e-05 -- epoch number 6191\n",
      "\n",
      "\n",
      "loss before training is 2.0691214782774003e-05 -- epoch number 6192\n",
      "\n",
      "\n",
      "loss before training is 2.066297413264655e-05 -- epoch number 6193\n",
      "\n",
      "\n",
      "loss before training is 2.063477416446226e-05 -- epoch number 6194\n",
      "\n",
      "\n",
      "loss before training is 2.0606614818283103e-05 -- epoch number 6195\n",
      "\n",
      "\n",
      "loss before training is 2.0578496034258155e-05 -- epoch number 6196\n",
      "\n",
      "\n",
      "loss before training is 2.0550417752624097e-05 -- epoch number 6197\n",
      "\n",
      "\n",
      "loss before training is 2.0522379913703613e-05 -- epoch number 6198\n",
      "\n",
      "\n",
      "loss before training is 2.0494382457906495e-05 -- epoch number 6199\n",
      "\n",
      "\n",
      "loss before training is 2.0466425325731012e-05 -- epoch number 6200\n",
      "\n",
      "\n",
      "loss before training is 2.0438508457759278e-05 -- epoch number 6201\n",
      "\n",
      "\n",
      "loss before training is 2.041063179466299e-05 -- epoch number 6202\n",
      "\n",
      "\n",
      "loss before training is 2.038279527719724e-05 -- epoch number 6203\n",
      "\n",
      "\n",
      "loss before training is 2.035499884620685e-05 -- epoch number 6204\n",
      "\n",
      "\n",
      "loss before training is 2.0327242442620745e-05 -- epoch number 6205\n",
      "\n",
      "\n",
      "loss before training is 2.0299526007452964e-05 -- epoch number 6206\n",
      "\n",
      "\n",
      "loss before training is 2.027184948180634e-05 -- epoch number 6207\n",
      "\n",
      "\n",
      "loss before training is 2.0244212806868093e-05 -- epoch number 6208\n",
      "\n",
      "\n",
      "loss before training is 2.0216615923910552e-05 -- epoch number 6209\n",
      "\n",
      "\n",
      "loss before training is 2.0189058774292636e-05 -- epoch number 6210\n",
      "\n",
      "\n",
      "loss before training is 2.0161541299459017e-05 -- epoch number 6211\n",
      "\n",
      "\n",
      "loss before training is 2.013406344093925e-05 -- epoch number 6212\n",
      "\n",
      "\n",
      "loss before training is 2.0106625140347447e-05 -- epoch number 6213\n",
      "\n",
      "\n",
      "loss before training is 2.0079226339383683e-05 -- epoch number 6214\n",
      "\n",
      "\n",
      "loss before training is 2.0051866979833172e-05 -- epoch number 6215\n",
      "\n",
      "\n",
      "loss before training is 2.0024547003567113e-05 -- epoch number 6216\n",
      "\n",
      "\n",
      "loss before training is 1.999726635253825e-05 -- epoch number 6217\n",
      "\n",
      "\n",
      "loss before training is 1.9970024968787485e-05 -- epoch number 6218\n",
      "\n",
      "\n",
      "loss before training is 1.994282279443843e-05 -- epoch number 6219\n",
      "\n",
      "\n",
      "loss before training is 1.9915659771699806e-05 -- epoch number 6220\n",
      "\n",
      "\n",
      "loss before training is 1.9888535842864105e-05 -- epoch number 6221\n",
      "\n",
      "\n",
      "loss before training is 1.9861450950309004e-05 -- epoch number 6222\n",
      "\n",
      "\n",
      "loss before training is 1.9834405036494806e-05 -- epoch number 6223\n",
      "\n",
      "\n",
      "loss before training is 1.980739804396755e-05 -- epoch number 6224\n",
      "\n",
      "\n",
      "loss before training is 1.9780429915354968e-05 -- epoch number 6225\n",
      "\n",
      "\n",
      "loss before training is 1.975350059337161e-05 -- epoch number 6226\n",
      "\n",
      "\n",
      "loss before training is 1.9726610020813035e-05 -- epoch number 6227\n",
      "\n",
      "\n",
      "loss before training is 1.9699758140558984e-05 -- epoch number 6228\n",
      "\n",
      "\n",
      "loss before training is 1.967294489557329e-05 -- epoch number 6229\n",
      "\n",
      "\n",
      "loss before training is 1.964617022890234e-05 -- epoch number 6230\n",
      "\n",
      "\n",
      "loss before training is 1.9619434083676132e-05 -- epoch number 6231\n",
      "\n",
      "\n",
      "loss before training is 1.9592736403107836e-05 -- epoch number 6232\n",
      "\n",
      "\n",
      "loss before training is 1.9566077130492472e-05 -- epoch number 6233\n",
      "\n",
      "\n",
      "loss before training is 1.953945620920959e-05 -- epoch number 6234\n",
      "\n",
      "\n",
      "loss before training is 1.951287358271997e-05 -- epoch number 6235\n",
      "\n",
      "\n",
      "loss before training is 1.948632919456747e-05 -- epoch number 6236\n",
      "\n",
      "\n",
      "loss before training is 1.945982298837974e-05 -- epoch number 6237\n",
      "\n",
      "\n",
      "loss before training is 1.94333549078645e-05 -- epoch number 6238\n",
      "\n",
      "\n",
      "loss before training is 1.9406924896813695e-05 -- epoch number 6239\n",
      "\n",
      "\n",
      "loss before training is 1.938053289910024e-05 -- epoch number 6240\n",
      "\n",
      "\n",
      "loss before training is 1.935417885867897e-05 -- epoch number 6241\n",
      "\n",
      "\n",
      "loss before training is 1.9327862719587534e-05 -- epoch number 6242\n",
      "\n",
      "\n",
      "loss before training is 1.9301584425945318e-05 -- epoch number 6243\n",
      "\n",
      "\n",
      "loss before training is 1.927534392195283e-05 -- epoch number 6244\n",
      "\n",
      "\n",
      "loss before training is 1.924914115189161e-05 -- epoch number 6245\n",
      "\n",
      "\n",
      "loss before training is 1.9222976060125803e-05 -- epoch number 6246\n",
      "\n",
      "\n",
      "loss before training is 1.9196848591101492e-05 -- epoch number 6247\n",
      "\n",
      "\n",
      "loss before training is 1.9170758689343844e-05 -- epoch number 6248\n",
      "\n",
      "\n",
      "loss before training is 1.914470629946116e-05 -- epoch number 6249\n",
      "\n",
      "\n",
      "loss before training is 1.9118691366140812e-05 -- epoch number 6250\n",
      "\n",
      "\n",
      "loss before training is 1.909271383415303e-05 -- epoch number 6251\n",
      "\n",
      "\n",
      "loss before training is 1.9066773648347842e-05 -- epoch number 6252\n",
      "\n",
      "\n",
      "loss before training is 1.9040870753655897e-05 -- epoch number 6253\n",
      "\n",
      "\n",
      "loss before training is 1.9015005095089057e-05 -- epoch number 6254\n",
      "\n",
      "\n",
      "loss before training is 1.89891766177382e-05 -- epoch number 6255\n",
      "\n",
      "\n",
      "loss before training is 1.8963385266776287e-05 -- epoch number 6256\n",
      "\n",
      "\n",
      "loss before training is 1.8937630987456043e-05 -- epoch number 6257\n",
      "\n",
      "\n",
      "loss before training is 1.891191372510855e-05 -- epoch number 6258\n",
      "\n",
      "\n",
      "loss before training is 1.8886233425147526e-05 -- epoch number 6259\n",
      "\n",
      "\n",
      "loss before training is 1.8860590033064747e-05 -- epoch number 6260\n",
      "\n",
      "\n",
      "loss before training is 1.8834983494433072e-05 -- epoch number 6261\n",
      "\n",
      "\n",
      "loss before training is 1.8809413754903415e-05 -- epoch number 6262\n",
      "\n",
      "\n",
      "loss before training is 1.8783880760208635e-05 -- epoch number 6263\n",
      "\n",
      "\n",
      "loss before training is 1.875838445615773e-05 -- epoch number 6264\n",
      "\n",
      "\n",
      "loss before training is 1.8732924788641766e-05 -- epoch number 6265\n",
      "\n",
      "\n",
      "loss before training is 1.8707501703630702e-05 -- epoch number 6266\n",
      "\n",
      "\n",
      "loss before training is 1.868211514717241e-05 -- epoch number 6267\n",
      "\n",
      "\n",
      "loss before training is 1.8656765065394316e-05 -- epoch number 6268\n",
      "\n",
      "\n",
      "loss before training is 1.8631451404503164e-05 -- epoch number 6269\n",
      "\n",
      "\n",
      "loss before training is 1.8606174110784178e-05 -- epoch number 6270\n",
      "\n",
      "\n",
      "loss before training is 1.858093313060059e-05 -- epoch number 6271\n",
      "\n",
      "\n",
      "loss before training is 1.855572841039567e-05 -- epoch number 6272\n",
      "\n",
      "\n",
      "loss before training is 1.8530559896689728e-05 -- epoch number 6273\n",
      "\n",
      "\n",
      "loss before training is 1.8505427536082336e-05 -- epoch number 6274\n",
      "\n",
      "\n",
      "loss before training is 1.8480331275251072e-05 -- epoch number 6275\n",
      "\n",
      "\n",
      "loss before training is 1.8455271060950004e-05 -- epoch number 6276\n",
      "\n",
      "\n",
      "loss before training is 1.8430246840015172e-05 -- epoch number 6277\n",
      "\n",
      "\n",
      "loss before training is 1.8405258559356228e-05 -- epoch number 6278\n",
      "\n",
      "\n",
      "loss before training is 1.8380306165963753e-05 -- epoch number 6279\n",
      "\n",
      "\n",
      "loss before training is 1.8355389606904237e-05 -- epoch number 6280\n",
      "\n",
      "\n",
      "loss before training is 1.8330508829321497e-05 -- epoch number 6281\n",
      "\n",
      "\n",
      "loss before training is 1.8305663780438213e-05 -- epoch number 6282\n",
      "\n",
      "\n",
      "loss before training is 1.8280854407553444e-05 -- epoch number 6283\n",
      "\n",
      "\n",
      "loss before training is 1.8256080658045397e-05 -- epoch number 6284\n",
      "\n",
      "\n",
      "loss before training is 1.823134247936567e-05 -- epoch number 6285\n",
      "\n",
      "\n",
      "loss before training is 1.8206639819046135e-05 -- epoch number 6286\n",
      "\n",
      "\n",
      "loss before training is 1.8181972624694706e-05 -- epoch number 6287\n",
      "\n",
      "\n",
      "loss before training is 1.81573408439961e-05 -- epoch number 6288\n",
      "\n",
      "\n",
      "loss before training is 1.8132744424711587e-05 -- epoch number 6289\n",
      "\n",
      "\n",
      "loss before training is 1.8108183314678013e-05 -- epoch number 6290\n",
      "\n",
      "\n",
      "loss before training is 1.8083657461811172e-05 -- epoch number 6291\n",
      "\n",
      "\n",
      "loss before training is 1.8059166814101402e-05 -- epoch number 6292\n",
      "\n",
      "\n",
      "loss before training is 1.8034711319615938e-05 -- epoch number 6293\n",
      "\n",
      "\n",
      "loss before training is 1.801029092649772e-05 -- epoch number 6294\n",
      "\n",
      "\n",
      "loss before training is 1.7985905582967004e-05 -- epoch number 6295\n",
      "\n",
      "\n",
      "loss before training is 1.796155523731761e-05 -- epoch number 6296\n",
      "\n",
      "\n",
      "loss before training is 1.79372398379225e-05 -- epoch number 6297\n",
      "\n",
      "\n",
      "loss before training is 1.7912959333227187e-05 -- epoch number 6298\n",
      "\n",
      "\n",
      "loss before training is 1.788871367175497e-05 -- epoch number 6299\n",
      "\n",
      "\n",
      "loss before training is 1.786450280210393e-05 -- epoch number 6300\n",
      "\n",
      "\n",
      "loss before training is 1.7840326672947867e-05 -- epoch number 6301\n",
      "\n",
      "\n",
      "loss before training is 1.7816185233035274e-05 -- epoch number 6302\n",
      "\n",
      "\n",
      "loss before training is 1.7792078431189747e-05 -- epoch number 6303\n",
      "\n",
      "\n",
      "loss before training is 1.7768006216312143e-05 -- epoch number 6304\n",
      "\n",
      "\n",
      "loss before training is 1.7743968537375626e-05 -- epoch number 6305\n",
      "\n",
      "\n",
      "loss before training is 1.771996534342941e-05 -- epoch number 6306\n",
      "\n",
      "\n",
      "loss before training is 1.7695996583597776e-05 -- epoch number 6307\n",
      "\n",
      "\n",
      "loss before training is 1.767206220707885e-05 -- epoch number 6308\n",
      "\n",
      "\n",
      "loss before training is 1.7648162163147186e-05 -- epoch number 6309\n",
      "\n",
      "\n",
      "loss before training is 1.7624296401149585e-05 -- epoch number 6310\n",
      "\n",
      "\n",
      "loss before training is 1.760046487050748e-05 -- epoch number 6311\n",
      "\n",
      "\n",
      "loss before training is 1.7576667520718878e-05 -- epoch number 6312\n",
      "\n",
      "\n",
      "loss before training is 1.7552904301353645e-05 -- epoch number 6313\n",
      "\n",
      "\n",
      "loss before training is 1.752917516205679e-05 -- epoch number 6314\n",
      "\n",
      "\n",
      "loss before training is 1.7505480052545664e-05 -- epoch number 6315\n",
      "\n",
      "\n",
      "loss before training is 1.7481818922614512e-05 -- epoch number 6316\n",
      "\n",
      "\n",
      "loss before training is 1.745819172212878e-05 -- epoch number 6317\n",
      "\n",
      "\n",
      "loss before training is 1.7434598401028916e-05 -- epoch number 6318\n",
      "\n",
      "\n",
      "loss before training is 1.7411038909327644e-05 -- epoch number 6319\n",
      "\n",
      "\n",
      "loss before training is 1.7387513197112256e-05 -- epoch number 6320\n",
      "\n",
      "\n",
      "loss before training is 1.7364021214543202e-05 -- epoch number 6321\n",
      "\n",
      "\n",
      "loss before training is 1.7340562911853374e-05 -- epoch number 6322\n",
      "\n",
      "\n",
      "loss before training is 1.7317138239350072e-05 -- epoch number 6323\n",
      "\n",
      "\n",
      "loss before training is 1.7293747147413066e-05 -- epoch number 6324\n",
      "\n",
      "\n",
      "loss before training is 1.7270389586495045e-05 -- epoch number 6325\n",
      "\n",
      "\n",
      "loss before training is 1.7247065507120635e-05 -- epoch number 6326\n",
      "\n",
      "\n",
      "loss before training is 1.722377485988917e-05 -- epoch number 6327\n",
      "\n",
      "\n",
      "loss before training is 1.720051759546994e-05 -- epoch number 6328\n",
      "\n",
      "\n",
      "loss before training is 1.717729366460817e-05 -- epoch number 6329\n",
      "\n",
      "\n",
      "loss before training is 1.7154103018118083e-05 -- epoch number 6330\n",
      "\n",
      "\n",
      "loss before training is 1.7130945606888507e-05 -- epoch number 6331\n",
      "\n",
      "\n",
      "loss before training is 1.710782138187997e-05 -- epoch number 6332\n",
      "\n",
      "\n",
      "loss before training is 1.708473029412403e-05 -- epoch number 6333\n",
      "\n",
      "\n",
      "loss before training is 1.706167229472578e-05 -- epoch number 6334\n",
      "\n",
      "\n",
      "loss before training is 1.703864733486137e-05 -- epoch number 6335\n",
      "\n",
      "\n",
      "loss before training is 1.701565536577908e-05 -- epoch number 6336\n",
      "\n",
      "\n",
      "loss before training is 1.6992696338799098e-05 -- epoch number 6337\n",
      "\n",
      "\n",
      "loss before training is 1.6969770205311922e-05 -- epoch number 6338\n",
      "\n",
      "\n",
      "loss before training is 1.694687691678104e-05 -- epoch number 6339\n",
      "\n",
      "\n",
      "loss before training is 1.6924016424741588e-05 -- epoch number 6340\n",
      "\n",
      "\n",
      "loss before training is 1.6901188680798314e-05 -- epoch number 6341\n",
      "\n",
      "\n",
      "loss before training is 1.6878393636628674e-05 -- epoch number 6342\n",
      "\n",
      "\n",
      "loss before training is 1.685563124398017e-05 -- epoch number 6343\n",
      "\n",
      "\n",
      "loss before training is 1.6832901454672394e-05 -- epoch number 6344\n",
      "\n",
      "\n",
      "loss before training is 1.6810204220594767e-05 -- epoch number 6345\n",
      "\n",
      "\n",
      "loss before training is 1.678753949370853e-05 -- epoch number 6346\n",
      "\n",
      "\n",
      "loss before training is 1.676490722604456e-05 -- epoch number 6347\n",
      "\n",
      "\n",
      "loss before training is 1.6742307369705612e-05 -- epoch number 6348\n",
      "\n",
      "\n",
      "loss before training is 1.6719739876863678e-05 -- epoch number 6349\n",
      "\n",
      "\n",
      "loss before training is 1.6697204699761908e-05 -- epoch number 6350\n",
      "\n",
      "\n",
      "loss before training is 1.6674701790713714e-05 -- epoch number 6351\n",
      "\n",
      "\n",
      "loss before training is 1.6652231102102586e-05 -- epoch number 6352\n",
      "\n",
      "\n",
      "loss before training is 1.662979258638108e-05 -- epoch number 6353\n",
      "\n",
      "\n",
      "loss before training is 1.66073861960742e-05 -- epoch number 6354\n",
      "\n",
      "\n",
      "loss before training is 1.6585011883775056e-05 -- epoch number 6355\n",
      "\n",
      "\n",
      "loss before training is 1.656266960214655e-05 -- epoch number 6356\n",
      "\n",
      "\n",
      "loss before training is 1.6540359303922512e-05 -- epoch number 6357\n",
      "\n",
      "\n",
      "loss before training is 1.6518080941904797e-05 -- epoch number 6358\n",
      "\n",
      "\n",
      "loss before training is 1.6495834468965648e-05 -- epoch number 6359\n",
      "\n",
      "\n",
      "loss before training is 1.647361983804666e-05 -- epoch number 6360\n",
      "\n",
      "\n",
      "loss before training is 1.6451437002159877e-05 -- epoch number 6361\n",
      "\n",
      "\n",
      "loss before training is 1.642928591438348e-05 -- epoch number 6362\n",
      "\n",
      "\n",
      "loss before training is 1.640716652786859e-05 -- epoch number 6363\n",
      "\n",
      "\n",
      "loss before training is 1.6385078795831923e-05 -- epoch number 6364\n",
      "\n",
      "\n",
      "loss before training is 1.636302267156141e-05 -- epoch number 6365\n",
      "\n",
      "\n",
      "loss before training is 1.6340998108412878e-05 -- epoch number 6366\n",
      "\n",
      "\n",
      "loss before training is 1.6319005059811522e-05 -- epoch number 6367\n",
      "\n",
      "\n",
      "loss before training is 1.6297043479249704e-05 -- epoch number 6368\n",
      "\n",
      "\n",
      "loss before training is 1.6275113320290884e-05 -- epoch number 6369\n",
      "\n",
      "\n",
      "loss before training is 1.6253214536564483e-05 -- epoch number 6370\n",
      "\n",
      "\n",
      "loss before training is 1.6231347081769674e-05 -- epoch number 6371\n",
      "\n",
      "\n",
      "loss before training is 1.6209510909672926e-05 -- epoch number 6372\n",
      "\n",
      "\n",
      "loss before training is 1.6187705974109222e-05 -- epoch number 6373\n",
      "\n",
      "\n",
      "loss before training is 1.616593222898269e-05 -- epoch number 6374\n",
      "\n",
      "\n",
      "loss before training is 1.6144189628263382e-05 -- epoch number 6375\n",
      "\n",
      "\n",
      "loss before training is 1.6122478125991197e-05 -- epoch number 6376\n",
      "\n",
      "\n",
      "loss before training is 1.6100797676271998e-05 -- epoch number 6377\n",
      "\n",
      "\n",
      "loss before training is 1.6079148233280854e-05 -- epoch number 6378\n",
      "\n",
      "\n",
      "loss before training is 1.6057529751259494e-05 -- epoch number 6379\n",
      "\n",
      "\n",
      "loss before training is 1.6035942184518018e-05 -- epoch number 6380\n",
      "\n",
      "\n",
      "loss before training is 1.601438548743261e-05 -- epoch number 6381\n",
      "\n",
      "\n",
      "loss before training is 1.599285961444747e-05 -- epoch number 6382\n",
      "\n",
      "\n",
      "loss before training is 1.5971364520074353e-05 -- epoch number 6383\n",
      "\n",
      "\n",
      "loss before training is 1.5949900158891317e-05 -- epoch number 6384\n",
      "\n",
      "\n",
      "loss before training is 1.5928466485543133e-05 -- epoch number 6385\n",
      "\n",
      "\n",
      "loss before training is 1.5907063454744113e-05 -- epoch number 6386\n",
      "\n",
      "\n",
      "loss before training is 1.588569102127155e-05 -- epoch number 6387\n",
      "\n",
      "\n",
      "loss before training is 1.5864349139972266e-05 -- epoch number 6388\n",
      "\n",
      "\n",
      "loss before training is 1.5843037765758542e-05 -- epoch number 6389\n",
      "\n",
      "\n",
      "loss before training is 1.582175685360885e-05 -- epoch number 6390\n",
      "\n",
      "\n",
      "loss before training is 1.58005063585699e-05 -- epoch number 6391\n",
      "\n",
      "\n",
      "loss before training is 1.5779286235751727e-05 -- epoch number 6392\n",
      "\n",
      "\n",
      "loss before training is 1.575809644033379e-05 -- epoch number 6393\n",
      "\n",
      "\n",
      "loss before training is 1.573693692755995e-05 -- epoch number 6394\n",
      "\n",
      "\n",
      "loss before training is 1.571580765274049e-05 -- epoch number 6395\n",
      "\n",
      "\n",
      "loss before training is 1.5694708571250847e-05 -- epoch number 6396\n",
      "\n",
      "\n",
      "loss before training is 1.567363963853404e-05 -- epoch number 6397\n",
      "\n",
      "\n",
      "loss before training is 1.5652600810097804e-05 -- epoch number 6398\n",
      "\n",
      "\n",
      "loss before training is 1.56315920415141e-05 -- epoch number 6399\n",
      "\n",
      "\n",
      "loss before training is 1.5610613288424407e-05 -- epoch number 6400\n",
      "\n",
      "\n",
      "loss before training is 1.558966450653172e-05 -- epoch number 6401\n",
      "\n",
      "\n",
      "loss before training is 1.5568745651606616e-05 -- epoch number 6402\n",
      "\n",
      "\n",
      "loss before training is 1.5547856679484488e-05 -- epoch number 6403\n",
      "\n",
      "\n",
      "loss before training is 1.5526997546066123e-05 -- epoch number 6404\n",
      "\n",
      "\n",
      "loss before training is 1.550616820731512e-05 -- epoch number 6405\n",
      "\n",
      "\n",
      "loss before training is 1.5485368619265115e-05 -- epoch number 6406\n",
      "\n",
      "\n",
      "loss before training is 1.5464598738010187e-05 -- epoch number 6407\n",
      "\n",
      "\n",
      "loss before training is 1.5443858519710544e-05 -- epoch number 6408\n",
      "\n",
      "\n",
      "loss before training is 1.542314792059208e-05 -- epoch number 6409\n",
      "\n",
      "\n",
      "loss before training is 1.540246689694357e-05 -- epoch number 6410\n",
      "\n",
      "\n",
      "loss before training is 1.53818154051208e-05 -- epoch number 6411\n",
      "\n",
      "\n",
      "loss before training is 1.536119340154217e-05 -- epoch number 6412\n",
      "\n",
      "\n",
      "loss before training is 1.534060084269069e-05 -- epoch number 6413\n",
      "\n",
      "\n",
      "loss before training is 1.532003768511412e-05 -- epoch number 6414\n",
      "\n",
      "\n",
      "loss before training is 1.5299503885424078e-05 -- epoch number 6415\n",
      "\n",
      "\n",
      "loss before training is 1.527899940029691e-05 -- epoch number 6416\n",
      "\n",
      "\n",
      "loss before training is 1.5258524186472222e-05 -- epoch number 6417\n",
      "\n",
      "\n",
      "loss before training is 1.5238078200753631e-05 -- epoch number 6418\n",
      "\n",
      "\n",
      "loss before training is 1.5217661400008787e-05 -- epoch number 6419\n",
      "\n",
      "\n",
      "loss before training is 1.5197273741169686e-05 -- epoch number 6420\n",
      "\n",
      "\n",
      "loss before training is 1.5176915181230984e-05 -- epoch number 6421\n",
      "\n",
      "\n",
      "loss before training is 1.5156585677251856e-05 -- epoch number 6422\n",
      "\n",
      "\n",
      "loss before training is 1.5136285186352678e-05 -- epoch number 6423\n",
      "\n",
      "\n",
      "loss before training is 1.511601366572144e-05 -- epoch number 6424\n",
      "\n",
      "\n",
      "loss before training is 1.5095771072604208e-05 -- epoch number 6425\n",
      "\n",
      "\n",
      "loss before training is 1.5075557364315529e-05 -- epoch number 6426\n",
      "\n",
      "\n",
      "loss before training is 1.5055372498228833e-05 -- epoch number 6427\n",
      "\n",
      "\n",
      "loss before training is 1.5035216431782026e-05 -- epoch number 6428\n",
      "\n",
      "\n",
      "loss before training is 1.5015089122477703e-05 -- epoch number 6429\n",
      "\n",
      "\n",
      "loss before training is 1.4994990527878697e-05 -- epoch number 6430\n",
      "\n",
      "\n",
      "loss before training is 1.4974920605611428e-05 -- epoch number 6431\n",
      "\n",
      "\n",
      "loss before training is 1.4954879313366002e-05 -- epoch number 6432\n",
      "\n",
      "\n",
      "loss before training is 1.49348666088932e-05 -- epoch number 6433\n",
      "\n",
      "\n",
      "loss before training is 1.4914882450008262e-05 -- epoch number 6434\n",
      "\n",
      "\n",
      "loss before training is 1.489492679458775e-05 -- epoch number 6435\n",
      "\n",
      "\n",
      "loss before training is 1.4874999600569844e-05 -- epoch number 6436\n",
      "\n",
      "\n",
      "loss before training is 1.4855100825957015e-05 -- epoch number 6437\n",
      "\n",
      "\n",
      "loss before training is 1.4835230428812119e-05 -- epoch number 6438\n",
      "\n",
      "\n",
      "loss before training is 1.4815388367259823e-05 -- epoch number 6439\n",
      "\n",
      "\n",
      "loss before training is 1.4795574599489037e-05 -- epoch number 6440\n",
      "\n",
      "\n",
      "loss before training is 1.4775789083747484e-05 -- epoch number 6441\n",
      "\n",
      "\n",
      "loss before training is 1.4756031778347454e-05 -- epoch number 6442\n",
      "\n",
      "\n",
      "loss before training is 1.4736302641660616e-05 -- epoch number 6443\n",
      "\n",
      "\n",
      "loss before training is 1.4716601632121295e-05 -- epoch number 6444\n",
      "\n",
      "\n",
      "loss before training is 1.46969287082258e-05 -- epoch number 6445\n",
      "\n",
      "\n",
      "loss before training is 1.467728382853101e-05 -- epoch number 6446\n",
      "\n",
      "\n",
      "loss before training is 1.4657666951655794e-05 -- epoch number 6447\n",
      "\n",
      "\n",
      "loss before training is 1.4638078036279136e-05 -- epoch number 6448\n",
      "\n",
      "\n",
      "loss before training is 1.461851704114315e-05 -- epoch number 6449\n",
      "\n",
      "\n",
      "loss before training is 1.459898392504888e-05 -- epoch number 6450\n",
      "\n",
      "\n",
      "loss before training is 1.4579478646859017e-05 -- epoch number 6451\n",
      "\n",
      "\n",
      "loss before training is 1.4560001165498495e-05 -- epoch number 6452\n",
      "\n",
      "\n",
      "loss before training is 1.454055143995096e-05 -- epoch number 6453\n",
      "\n",
      "\n",
      "loss before training is 1.4521129429262701e-05 -- epoch number 6454\n",
      "\n",
      "\n",
      "loss before training is 1.450173509253898e-05 -- epoch number 6455\n",
      "\n",
      "\n",
      "loss before training is 1.4482368388946946e-05 -- epoch number 6456\n",
      "\n",
      "\n",
      "loss before training is 1.446302927771335e-05 -- epoch number 6457\n",
      "\n",
      "\n",
      "loss before training is 1.4443717718124736e-05 -- epoch number 6458\n",
      "\n",
      "\n",
      "loss before training is 1.44244336695312e-05 -- epoch number 6459\n",
      "\n",
      "\n",
      "loss before training is 1.4405177091338115e-05 -- epoch number 6460\n",
      "\n",
      "\n",
      "loss before training is 1.4385947943014471e-05 -- epoch number 6461\n",
      "\n",
      "\n",
      "loss before training is 1.4366746184088418e-05 -- epoch number 6462\n",
      "\n",
      "\n",
      "loss before training is 1.434757177414774e-05 -- epoch number 6463\n",
      "\n",
      "\n",
      "loss before training is 1.4328424672840593e-05 -- epoch number 6464\n",
      "\n",
      "\n",
      "loss before training is 1.4309304839874021e-05 -- epoch number 6465\n",
      "\n",
      "\n",
      "loss before training is 1.429021223501539e-05 -- epoch number 6466\n",
      "\n",
      "\n",
      "loss before training is 1.4271146818091573e-05 -- epoch number 6467\n",
      "\n",
      "\n",
      "loss before training is 1.4252108548988908e-05 -- epoch number 6468\n",
      "\n",
      "\n",
      "loss before training is 1.423309738765383e-05 -- epoch number 6469\n",
      "\n",
      "\n",
      "loss before training is 1.4214113294090897e-05 -- epoch number 6470\n",
      "\n",
      "\n",
      "loss before training is 1.41951562283645e-05 -- epoch number 6471\n",
      "\n",
      "\n",
      "loss before training is 1.417622615059805e-05 -- epoch number 6472\n",
      "\n",
      "\n",
      "loss before training is 1.4157323020974972e-05 -- epoch number 6473\n",
      "\n",
      "\n",
      "loss before training is 1.4138446799736388e-05 -- epoch number 6474\n",
      "\n",
      "\n",
      "loss before training is 1.4119597447182277e-05 -- epoch number 6475\n",
      "\n",
      "\n",
      "loss before training is 1.4100774923673403e-05 -- epoch number 6476\n",
      "\n",
      "\n",
      "loss before training is 1.4081979189627083e-05 -- epoch number 6477\n",
      "\n",
      "\n",
      "loss before training is 1.4063210205520078e-05 -- epoch number 6478\n",
      "\n",
      "\n",
      "loss before training is 1.4044467931887687e-05 -- epoch number 6479\n",
      "\n",
      "\n",
      "loss before training is 1.4025752329324376e-05 -- epoch number 6480\n",
      "\n",
      "\n",
      "loss before training is 1.4007063358482531e-05 -- epoch number 6481\n",
      "\n",
      "\n",
      "loss before training is 1.398840098007212e-05 -- epoch number 6482\n",
      "\n",
      "\n",
      "loss before training is 1.3969765154862087e-05 -- epoch number 6483\n",
      "\n",
      "\n",
      "loss before training is 1.3951155843679733e-05 -- epoch number 6484\n",
      "\n",
      "\n",
      "loss before training is 1.3932573007410548e-05 -- epoch number 6485\n",
      "\n",
      "\n",
      "loss before training is 1.3914016606996996e-05 -- epoch number 6486\n",
      "\n",
      "\n",
      "loss before training is 1.389548660343999e-05 -- epoch number 6487\n",
      "\n",
      "\n",
      "loss before training is 1.3876982957799295e-05 -- epoch number 6488\n",
      "\n",
      "\n",
      "loss before training is 1.3858505631190409e-05 -- epoch number 6489\n",
      "\n",
      "\n",
      "loss before training is 1.3840054584788603e-05 -- epoch number 6490\n",
      "\n",
      "\n",
      "loss before training is 1.3821629779824826e-05 -- epoch number 6491\n",
      "\n",
      "\n",
      "loss before training is 1.3803231177588347e-05 -- epoch number 6492\n",
      "\n",
      "\n",
      "loss before training is 1.3784858739427165e-05 -- epoch number 6493\n",
      "\n",
      "\n",
      "loss before training is 1.3766512426743234e-05 -- epoch number 6494\n",
      "\n",
      "\n",
      "loss before training is 1.374819220100003e-05 -- epoch number 6495\n",
      "\n",
      "\n",
      "loss before training is 1.3729898023714636e-05 -- epoch number 6496\n",
      "\n",
      "\n",
      "loss before training is 1.3711629856463157e-05 -- epoch number 6497\n",
      "\n",
      "\n",
      "loss before training is 1.3693387660877731e-05 -- epoch number 6498\n",
      "\n",
      "\n",
      "loss before training is 1.3675171398647967e-05 -- epoch number 6499\n",
      "\n",
      "\n",
      "loss before training is 1.3656981031520748e-05 -- epoch number 6500\n",
      "\n",
      "\n",
      "loss before training is 1.3638816521298346e-05 -- epoch number 6501\n",
      "\n",
      "\n",
      "loss before training is 1.3620677829840723e-05 -- epoch number 6502\n",
      "\n",
      "\n",
      "loss before training is 1.3602564919064455e-05 -- epoch number 6503\n",
      "\n",
      "\n",
      "loss before training is 1.3584477750941322e-05 -- epoch number 6504\n",
      "\n",
      "\n",
      "loss before training is 1.3566416287502447e-05 -- epoch number 6505\n",
      "\n",
      "\n",
      "loss before training is 1.3548380490832109e-05 -- epoch number 6506\n",
      "\n",
      "\n",
      "loss before training is 1.35303703230716e-05 -- epoch number 6507\n",
      "\n",
      "\n",
      "loss before training is 1.3512385746421339e-05 -- epoch number 6508\n",
      "\n",
      "\n",
      "loss before training is 1.349442672313265e-05 -- epoch number 6509\n",
      "\n",
      "\n",
      "loss before training is 1.3476493215517223e-05 -- epoch number 6510\n",
      "\n",
      "\n",
      "loss before training is 1.345858518594084e-05 -- epoch number 6511\n",
      "\n",
      "\n",
      "loss before training is 1.3440702596825697e-05 -- epoch number 6512\n",
      "\n",
      "\n",
      "loss before training is 1.3422845410649373e-05 -- epoch number 6513\n",
      "\n",
      "\n",
      "loss before training is 1.340501358994548e-05 -- epoch number 6514\n",
      "\n",
      "\n",
      "loss before training is 1.3387207097302595e-05 -- epoch number 6515\n",
      "\n",
      "\n",
      "loss before training is 1.3369425895366287e-05 -- epoch number 6516\n",
      "\n",
      "\n",
      "loss before training is 1.3351669946835548e-05 -- epoch number 6517\n",
      "\n",
      "\n",
      "loss before training is 1.3333939214466047e-05 -- epoch number 6518\n",
      "\n",
      "\n",
      "loss before training is 1.3316233661068868e-05 -- epoch number 6519\n",
      "\n",
      "\n",
      "loss before training is 1.3298553249509643e-05 -- epoch number 6520\n",
      "\n",
      "\n",
      "loss before training is 1.3280897942710383e-05 -- epoch number 6521\n",
      "\n",
      "\n",
      "loss before training is 1.3263267703646063e-05 -- epoch number 6522\n",
      "\n",
      "\n",
      "loss before training is 1.3245662495348192e-05 -- epoch number 6523\n",
      "\n",
      "\n",
      "loss before training is 1.322808228090307e-05 -- epoch number 6524\n",
      "\n",
      "\n",
      "loss before training is 1.3210527023451592e-05 -- epoch number 6525\n",
      "\n",
      "\n",
      "loss before training is 1.3192996686188827e-05 -- epoch number 6526\n",
      "\n",
      "\n",
      "loss before training is 1.3175491232365212e-05 -- epoch number 6527\n",
      "\n",
      "\n",
      "loss before training is 1.3158010625285918e-05 -- epoch number 6528\n",
      "\n",
      "\n",
      "loss before training is 1.3140554828311108e-05 -- epoch number 6529\n",
      "\n",
      "\n",
      "loss before training is 1.3123123804852139e-05 -- epoch number 6530\n",
      "\n",
      "\n",
      "loss before training is 1.3105717518379514e-05 -- epoch number 6531\n",
      "\n",
      "\n",
      "loss before training is 1.3088335932414463e-05 -- epoch number 6532\n",
      "\n",
      "\n",
      "loss before training is 1.3070979010534396e-05 -- epoch number 6533\n",
      "\n",
      "\n",
      "loss before training is 1.3053646716368753e-05 -- epoch number 6534\n",
      "\n",
      "\n",
      "loss before training is 1.3036339013603589e-05 -- epoch number 6535\n",
      "\n",
      "\n",
      "loss before training is 1.3019055865976743e-05 -- epoch number 6536\n",
      "\n",
      "\n",
      "loss before training is 1.30017972372818e-05 -- epoch number 6537\n",
      "\n",
      "\n",
      "loss before training is 1.2984563091363772e-05 -- epoch number 6538\n",
      "\n",
      "\n",
      "loss before training is 1.296735339212364e-05 -- epoch number 6539\n",
      "\n",
      "\n",
      "loss before training is 1.2950168103514478e-05 -- epoch number 6540\n",
      "\n",
      "\n",
      "loss before training is 1.2933007189544444e-05 -- epoch number 6541\n",
      "\n",
      "\n",
      "loss before training is 1.2915870614273807e-05 -- epoch number 6542\n",
      "\n",
      "\n",
      "loss before training is 1.2898758341816932e-05 -- epoch number 6543\n",
      "\n",
      "\n",
      "loss before training is 1.2881670336341886e-05 -- epoch number 6544\n",
      "\n",
      "\n",
      "loss before training is 1.2864606562068026e-05 -- epoch number 6545\n",
      "\n",
      "\n",
      "loss before training is 1.2847566983271403e-05 -- epoch number 6546\n",
      "\n",
      "\n",
      "loss before training is 1.2830551564277106e-05 -- epoch number 6547\n",
      "\n",
      "\n",
      "loss before training is 1.2813560269466818e-05 -- epoch number 6548\n",
      "\n",
      "\n",
      "loss before training is 1.2796593063272656e-05 -- epoch number 6549\n",
      "\n",
      "\n",
      "loss before training is 1.2779649910180666e-05 -- epoch number 6550\n",
      "\n",
      "\n",
      "loss before training is 1.2762730774730006e-05 -- epoch number 6551\n",
      "\n",
      "\n",
      "loss before training is 1.2745835621511785e-05 -- epoch number 6552\n",
      "\n",
      "\n",
      "loss before training is 1.2728964415170275e-05 -- epoch number 6553\n",
      "\n",
      "\n",
      "loss before training is 1.271211712040252e-05 -- epoch number 6554\n",
      "\n",
      "\n",
      "loss before training is 1.2695293701956903e-05 -- epoch number 6555\n",
      "\n",
      "\n",
      "loss before training is 1.2678494124635646e-05 -- epoch number 6556\n",
      "\n",
      "\n",
      "loss before training is 1.266171835329283e-05 -- epoch number 6557\n",
      "\n",
      "\n",
      "loss before training is 1.2644966352834077e-05 -- epoch number 6558\n",
      "\n",
      "\n",
      "loss before training is 1.2628238088217808e-05 -- epoch number 6559\n",
      "\n",
      "\n",
      "loss before training is 1.2611533524454452e-05 -- epoch number 6560\n",
      "\n",
      "\n",
      "loss before training is 1.2594852626607336e-05 -- epoch number 6561\n",
      "\n",
      "\n",
      "loss before training is 1.2578195359790418e-05 -- epoch number 6562\n",
      "\n",
      "\n",
      "loss before training is 1.2561561689169847e-05 -- epoch number 6563\n",
      "\n",
      "\n",
      "loss before training is 1.2544951579964115e-05 -- epoch number 6564\n",
      "\n",
      "\n",
      "loss before training is 1.2528364997443205e-05 -- epoch number 6565\n",
      "\n",
      "\n",
      "loss before training is 1.2511801906928462e-05 -- epoch number 6566\n",
      "\n",
      "\n",
      "loss before training is 1.249526227379368e-05 -- epoch number 6567\n",
      "\n",
      "\n",
      "loss before training is 1.247874606346217e-05 -- epoch number 6568\n",
      "\n",
      "\n",
      "loss before training is 1.246225324141135e-05 -- epoch number 6569\n",
      "\n",
      "\n",
      "loss before training is 1.244578377316841e-05 -- epoch number 6570\n",
      "\n",
      "\n",
      "loss before training is 1.2429337624312155e-05 -- epoch number 6571\n",
      "\n",
      "\n",
      "loss before training is 1.2412914760472109e-05 -- epoch number 6572\n",
      "\n",
      "\n",
      "loss before training is 1.2396515147330166e-05 -- epoch number 6573\n",
      "\n",
      "\n",
      "loss before training is 1.2380138750618058e-05 -- epoch number 6574\n",
      "\n",
      "\n",
      "loss before training is 1.2363785536118974e-05 -- epoch number 6575\n",
      "\n",
      "\n",
      "loss before training is 1.2347455469666881e-05 -- epoch number 6576\n",
      "\n",
      "\n",
      "loss before training is 1.2331148517147383e-05 -- epoch number 6577\n",
      "\n",
      "\n",
      "loss before training is 1.2314864644495275e-05 -- epoch number 6578\n",
      "\n",
      "\n",
      "loss before training is 1.2298603817697251e-05 -- epoch number 6579\n",
      "\n",
      "\n",
      "loss before training is 1.2282366002790648e-05 -- epoch number 6580\n",
      "\n",
      "\n",
      "loss before training is 1.2266151165863207e-05 -- epoch number 6581\n",
      "\n",
      "\n",
      "loss before training is 1.2249959273052577e-05 -- epoch number 6582\n",
      "\n",
      "\n",
      "loss before training is 1.2233790290547514e-05 -- epoch number 6583\n",
      "\n",
      "\n",
      "loss before training is 1.2217644184586342e-05 -- epoch number 6584\n",
      "\n",
      "\n",
      "loss before training is 1.2201520921457944e-05 -- epoch number 6585\n",
      "\n",
      "\n",
      "loss before training is 1.2185420467503044e-05 -- epoch number 6586\n",
      "\n",
      "\n",
      "loss before training is 1.2169342789108674e-05 -- epoch number 6587\n",
      "\n",
      "\n",
      "loss before training is 1.21532878527163e-05 -- epoch number 6588\n",
      "\n",
      "\n",
      "loss before training is 1.2137255624813596e-05 -- epoch number 6589\n",
      "\n",
      "\n",
      "loss before training is 1.2121246071941027e-05 -- epoch number 6590\n",
      "\n",
      "\n",
      "loss before training is 1.2105259160686909e-05 -- epoch number 6591\n",
      "\n",
      "\n",
      "loss before training is 1.208929485769054e-05 -- epoch number 6592\n",
      "\n",
      "\n",
      "loss before training is 1.207335312964005e-05 -- epoch number 6593\n",
      "\n",
      "\n",
      "loss before training is 1.20574339432733e-05 -- epoch number 6594\n",
      "\n",
      "\n",
      "loss before training is 1.2041537265378171e-05 -- epoch number 6595\n",
      "\n",
      "\n",
      "loss before training is 1.202566306279156e-05 -- epoch number 6596\n",
      "\n",
      "\n",
      "loss before training is 1.200981130239994e-05 -- epoch number 6597\n",
      "\n",
      "\n",
      "loss before training is 1.199398195113919e-05 -- epoch number 6598\n",
      "\n",
      "\n",
      "loss before training is 1.1978174975994553e-05 -- epoch number 6599\n",
      "\n",
      "\n",
      "loss before training is 1.1962390343999082e-05 -- epoch number 6600\n",
      "\n",
      "\n",
      "loss before training is 1.1946628022237381e-05 -- epoch number 6601\n",
      "\n",
      "\n",
      "loss before training is 1.193088797784103e-05 -- epoch number 6602\n",
      "\n",
      "\n",
      "loss before training is 1.1915170177990827e-05 -- epoch number 6603\n",
      "\n",
      "\n",
      "loss before training is 1.1899474589918428e-05 -- epoch number 6604\n",
      "\n",
      "\n",
      "loss before training is 1.1883801180900676e-05 -- epoch number 6605\n",
      "\n",
      "\n",
      "loss before training is 1.186814991826694e-05 -- epoch number 6606\n",
      "\n",
      "\n",
      "loss before training is 1.1852520769392552e-05 -- epoch number 6607\n",
      "\n",
      "\n",
      "loss before training is 1.1836913701702816e-05 -- epoch number 6608\n",
      "\n",
      "\n",
      "loss before training is 1.1821328682671142e-05 -- epoch number 6609\n",
      "\n",
      "\n",
      "loss before training is 1.1805765679819762e-05 -- epoch number 6610\n",
      "\n",
      "\n",
      "loss before training is 1.1790224660718752e-05 -- epoch number 6611\n",
      "\n",
      "\n",
      "loss before training is 1.1774705592986616e-05 -- epoch number 6612\n",
      "\n",
      "\n",
      "loss before training is 1.1759208444290649e-05 -- epoch number 6613\n",
      "\n",
      "\n",
      "loss before training is 1.1743733182345117e-05 -- epoch number 6614\n",
      "\n",
      "\n",
      "loss before training is 1.1728279774914296e-05 -- epoch number 6615\n",
      "\n",
      "\n",
      "loss before training is 1.171284818980815e-05 -- epoch number 6616\n",
      "\n",
      "\n",
      "loss before training is 1.1697438394886541e-05 -- epoch number 6617\n",
      "\n",
      "\n",
      "loss before training is 1.1682050358057047e-05 -- epoch number 6618\n",
      "\n",
      "\n",
      "loss before training is 1.1666684047273353e-05 -- epoch number 6619\n",
      "\n",
      "\n",
      "loss before training is 1.165133943053934e-05 -- epoch number 6620\n",
      "\n",
      "\n",
      "loss before training is 1.1636016475904393e-05 -- epoch number 6621\n",
      "\n",
      "\n",
      "loss before training is 1.1620715151466841e-05 -- epoch number 6622\n",
      "\n",
      "\n",
      "loss before training is 1.1605435425371577e-05 -- epoch number 6623\n",
      "\n",
      "\n",
      "loss before training is 1.1590177265812786e-05 -- epoch number 6624\n",
      "\n",
      "\n",
      "loss before training is 1.1574940641030034e-05 -- epoch number 6625\n",
      "\n",
      "\n",
      "loss before training is 1.1559725519310911e-05 -- epoch number 6626\n",
      "\n",
      "\n",
      "loss before training is 1.154453186899072e-05 -- epoch number 6627\n",
      "\n",
      "\n",
      "loss before training is 1.1529359658451986e-05 -- epoch number 6628\n",
      "\n",
      "\n",
      "loss before training is 1.1514208856123665e-05 -- epoch number 6629\n",
      "\n",
      "\n",
      "loss before training is 1.1499079430482424e-05 -- epoch number 6630\n",
      "\n",
      "\n",
      "loss before training is 1.148397135005102e-05 -- epoch number 6631\n",
      "\n",
      "\n",
      "loss before training is 1.146888458339994e-05 -- epoch number 6632\n",
      "\n",
      "\n",
      "loss before training is 1.1453819099147108e-05 -- epoch number 6633\n",
      "\n",
      "\n",
      "loss before training is 1.1438774865955831e-05 -- epoch number 6634\n",
      "\n",
      "\n",
      "loss before training is 1.142375185253675e-05 -- epoch number 6635\n",
      "\n",
      "\n",
      "loss before training is 1.1408750027647513e-05 -- epoch number 6636\n",
      "\n",
      "\n",
      "loss before training is 1.1393769360092055e-05 -- epoch number 6637\n",
      "\n",
      "\n",
      "loss before training is 1.1378809818720713e-05 -- epoch number 6638\n",
      "\n",
      "\n",
      "loss before training is 1.1363871372430421e-05 -- epoch number 6639\n",
      "\n",
      "\n",
      "loss before training is 1.1348953990164047e-05 -- epoch number 6640\n",
      "\n",
      "\n",
      "loss before training is 1.1334057640912116e-05 -- epoch number 6641\n",
      "\n",
      "\n",
      "loss before training is 1.1319182293709378e-05 -- epoch number 6642\n",
      "\n",
      "\n",
      "loss before training is 1.1304327917638835e-05 -- epoch number 6643\n",
      "\n",
      "\n",
      "loss before training is 1.1289494481828091e-05 -- epoch number 6644\n",
      "\n",
      "\n",
      "loss before training is 1.127468195545163e-05 -- epoch number 6645\n",
      "\n",
      "\n",
      "loss before training is 1.125989030772899e-05 -- epoch number 6646\n",
      "\n",
      "\n",
      "loss before training is 1.1245119507926438e-05 -- epoch number 6647\n",
      "\n",
      "\n",
      "loss before training is 1.1230369525356375e-05 -- epoch number 6648\n",
      "\n",
      "\n",
      "loss before training is 1.1215640329376138e-05 -- epoch number 6649\n",
      "\n",
      "\n",
      "loss before training is 1.1200931889389116e-05 -- epoch number 6650\n",
      "\n",
      "\n",
      "loss before training is 1.1186244174844262e-05 -- epoch number 6651\n",
      "\n",
      "\n",
      "loss before training is 1.1171577155235942e-05 -- epoch number 6652\n",
      "\n",
      "\n",
      "loss before training is 1.1156930800105042e-05 -- epoch number 6653\n",
      "\n",
      "\n",
      "loss before training is 1.1142305079036126e-05 -- epoch number 6654\n",
      "\n",
      "\n",
      "loss before training is 1.1127699961661132e-05 -- epoch number 6655\n",
      "\n",
      "\n",
      "loss before training is 1.1113115417655546e-05 -- epoch number 6656\n",
      "\n",
      "\n",
      "loss before training is 1.1098551416741274e-05 -- epoch number 6657\n",
      "\n",
      "\n",
      "loss before training is 1.1084007928684279e-05 -- epoch number 6658\n",
      "\n",
      "\n",
      "loss before training is 1.1069484923297452e-05 -- epoch number 6659\n",
      "\n",
      "\n",
      "loss before training is 1.105498237043678e-05 -- epoch number 6660\n",
      "\n",
      "\n",
      "loss before training is 1.1040500240003849e-05 -- epoch number 6661\n",
      "\n",
      "\n",
      "loss before training is 1.1026038501946503e-05 -- epoch number 6662\n",
      "\n",
      "\n",
      "loss before training is 1.101159712625476e-05 -- epoch number 6663\n",
      "\n",
      "\n",
      "loss before training is 1.0997176082966492e-05 -- epoch number 6664\n",
      "\n",
      "\n",
      "loss before training is 1.0982775342161321e-05 -- epoch number 6665\n",
      "\n",
      "\n",
      "loss before training is 1.0968394873965285e-05 -- epoch number 6666\n",
      "\n",
      "\n",
      "loss before training is 1.0954034648549469e-05 -- epoch number 6667\n",
      "\n",
      "\n",
      "loss before training is 1.093969463612791e-05 -- epoch number 6668\n",
      "\n",
      "\n",
      "loss before training is 1.0925374806960218e-05 -- epoch number 6669\n",
      "\n",
      "\n",
      "loss before training is 1.0911075131349712e-05 -- epoch number 6670\n",
      "\n",
      "\n",
      "loss before training is 1.0896795579644677e-05 -- epoch number 6671\n",
      "\n",
      "\n",
      "loss before training is 1.0882536122237093e-05 -- epoch number 6672\n",
      "\n",
      "\n",
      "loss before training is 1.086829672956294e-05 -- epoch number 6673\n",
      "\n",
      "\n",
      "loss before training is 1.0854077372103907e-05 -- epoch number 6674\n",
      "\n",
      "\n",
      "loss before training is 1.0839878020383171e-05 -- epoch number 6675\n",
      "\n",
      "\n",
      "loss before training is 1.0825698644970312e-05 -- epoch number 6676\n",
      "\n",
      "\n",
      "loss before training is 1.0811539216478094e-05 -- epoch number 6677\n",
      "\n",
      "\n",
      "loss before training is 1.0797399705561752e-05 -- epoch number 6678\n",
      "\n",
      "\n",
      "loss before training is 1.0783280082922907e-05 -- epoch number 6679\n",
      "\n",
      "\n",
      "loss before training is 1.076918031930433e-05 -- epoch number 6680\n",
      "\n",
      "\n",
      "loss before training is 1.0755100385493945e-05 -- epoch number 6681\n",
      "\n",
      "\n",
      "loss before training is 1.0741040252323878e-05 -- epoch number 6682\n",
      "\n",
      "\n",
      "loss before training is 1.0726999890667932e-05 -- epoch number 6683\n",
      "\n",
      "\n",
      "loss before training is 1.0712979271444428e-05 -- epoch number 6684\n",
      "\n",
      "\n",
      "loss before training is 1.0698978365615016e-05 -- epoch number 6685\n",
      "\n",
      "\n",
      "loss before training is 1.0684997144185752e-05 -- epoch number 6686\n",
      "\n",
      "\n",
      "loss before training is 1.0671035578204113e-05 -- epoch number 6687\n",
      "\n",
      "\n",
      "loss before training is 1.0657093638761966e-05 -- epoch number 6688\n",
      "\n",
      "\n",
      "loss before training is 1.0643171296993408e-05 -- epoch number 6689\n",
      "\n",
      "\n",
      "loss before training is 1.0629268524077186e-05 -- epoch number 6690\n",
      "\n",
      "\n",
      "loss before training is 1.0615385291233972e-05 -- epoch number 6691\n",
      "\n",
      "\n",
      "loss before training is 1.0601521569727627e-05 -- epoch number 6692\n",
      "\n",
      "\n",
      "loss before training is 1.058767733086493e-05 -- epoch number 6693\n",
      "\n",
      "\n",
      "loss before training is 1.0573852545994992e-05 -- epoch number 6694\n",
      "\n",
      "\n",
      "loss before training is 1.0560047186511355e-05 -- epoch number 6695\n",
      "\n",
      "\n",
      "loss before training is 1.0546261223848224e-05 -- epoch number 6696\n",
      "\n",
      "\n",
      "loss before training is 1.053249462948388e-05 -- epoch number 6697\n",
      "\n",
      "\n",
      "loss before training is 1.051874737493862e-05 -- epoch number 6698\n",
      "\n",
      "\n",
      "loss before training is 1.0505019431775103e-05 -- epoch number 6699\n",
      "\n",
      "\n",
      "loss before training is 1.049131077159935e-05 -- epoch number 6700\n",
      "\n",
      "\n",
      "loss before training is 1.0477621366058795e-05 -- epoch number 6701\n",
      "\n",
      "\n",
      "loss before training is 1.0463951186844104e-05 -- epoch number 6702\n",
      "\n",
      "\n",
      "loss before training is 1.0450300205687305e-05 -- epoch number 6703\n",
      "\n",
      "\n",
      "loss before training is 1.043666839436331e-05 -- epoch number 6704\n",
      "\n",
      "\n",
      "loss before training is 1.0423055724689313e-05 -- epoch number 6705\n",
      "\n",
      "\n",
      "loss before training is 1.040946216852341e-05 -- epoch number 6706\n",
      "\n",
      "\n",
      "loss before training is 1.0395887697767583e-05 -- epoch number 6707\n",
      "\n",
      "\n",
      "loss before training is 1.038233228436423e-05 -- epoch number 6708\n",
      "\n",
      "\n",
      "loss before training is 1.0368795900298927e-05 -- epoch number 6709\n",
      "\n",
      "\n",
      "loss before training is 1.0355278517597469e-05 -- epoch number 6710\n",
      "\n",
      "\n",
      "loss before training is 1.0341780108329834e-05 -- epoch number 6711\n",
      "\n",
      "\n",
      "loss before training is 1.0328300644604642e-05 -- epoch number 6712\n",
      "\n",
      "\n",
      "loss before training is 1.031484009857529e-05 -- epoch number 6713\n",
      "\n",
      "\n",
      "loss before training is 1.0301398442434355e-05 -- epoch number 6714\n",
      "\n",
      "\n",
      "loss before training is 1.0287975648417452e-05 -- epoch number 6715\n",
      "\n",
      "\n",
      "loss before training is 1.0274571688801837e-05 -- epoch number 6716\n",
      "\n",
      "\n",
      "loss before training is 1.0261186535904018e-05 -- epoch number 6717\n",
      "\n",
      "\n",
      "loss before training is 1.0247820162085026e-05 -- epoch number 6718\n",
      "\n",
      "\n",
      "loss before training is 1.0234472539745222e-05 -- epoch number 6719\n",
      "\n",
      "\n",
      "loss before training is 1.0221143641325475e-05 -- epoch number 6720\n",
      "\n",
      "\n",
      "loss before training is 1.0207833439309668e-05 -- epoch number 6721\n",
      "\n",
      "\n",
      "loss before training is 1.0194541906222714e-05 -- epoch number 6722\n",
      "\n",
      "\n",
      "loss before training is 1.018126901462902e-05 -- epoch number 6723\n",
      "\n",
      "\n",
      "loss before training is 1.0168014737135277e-05 -- epoch number 6724\n",
      "\n",
      "\n",
      "loss before training is 1.0154779046389034e-05 -- epoch number 6725\n",
      "\n",
      "\n",
      "loss before training is 1.0141561915077382e-05 -- epoch number 6726\n",
      "\n",
      "\n",
      "loss before training is 1.012836331593106e-05 -- epoch number 6727\n",
      "\n",
      "\n",
      "loss before training is 1.0115183221718273e-05 -- epoch number 6728\n",
      "\n",
      "\n",
      "loss before training is 1.0102021605250628e-05 -- epoch number 6729\n",
      "\n",
      "\n",
      "loss before training is 1.008887843937784e-05 -- epoch number 6730\n",
      "\n",
      "\n",
      "loss before training is 1.0075753696992825e-05 -- epoch number 6731\n",
      "\n",
      "\n",
      "loss before training is 1.00626473510276e-05 -- epoch number 6732\n",
      "\n",
      "\n",
      "loss before training is 1.0049559374454032e-05 -- epoch number 6733\n",
      "\n",
      "\n",
      "loss before training is 1.0036489740286251e-05 -- epoch number 6734\n",
      "\n",
      "\n",
      "loss before training is 1.0023438421576433e-05 -- epoch number 6735\n",
      "\n",
      "\n",
      "loss before training is 1.0010405391419416e-05 -- epoch number 6736\n",
      "\n",
      "\n",
      "loss before training is 9.9973906229482e-06 -- epoch number 6737\n",
      "\n",
      "\n",
      "loss before training is 9.98439408933773e-06 -- epoch number 6738\n",
      "\n",
      "\n",
      "loss before training is 9.971415763801354e-06 -- epoch number 6739\n",
      "\n",
      "\n",
      "loss before training is 9.958455619593996e-06 -- epoch number 6740\n",
      "\n",
      "\n",
      "loss before training is 9.945513630009093e-06 -- epoch number 6741\n",
      "\n",
      "\n",
      "loss before training is 9.932589768381927e-06 -- epoch number 6742\n",
      "\n",
      "\n",
      "loss before training is 9.919684008085013e-06 -- epoch number 6743\n",
      "\n",
      "\n",
      "loss before training is 9.906796322533516e-06 -- epoch number 6744\n",
      "\n",
      "\n",
      "loss before training is 9.893926685180353e-06 -- epoch number 6745\n",
      "\n",
      "\n",
      "loss before training is 9.881075069518209e-06 -- epoch number 6746\n",
      "\n",
      "\n",
      "loss before training is 9.868241449081494e-06 -- epoch number 6747\n",
      "\n",
      "\n",
      "loss before training is 9.855425797441747e-06 -- epoch number 6748\n",
      "\n",
      "\n",
      "loss before training is 9.842628088210737e-06 -- epoch number 6749\n",
      "\n",
      "\n",
      "loss before training is 9.829848295040109e-06 -- epoch number 6750\n",
      "\n",
      "\n",
      "loss before training is 9.817086391620956e-06 -- epoch number 6751\n",
      "\n",
      "\n",
      "loss before training is 9.804342351683494e-06 -- epoch number 6752\n",
      "\n",
      "\n",
      "loss before training is 9.79161614899713e-06 -- epoch number 6753\n",
      "\n",
      "\n",
      "loss before training is 9.778907757370195e-06 -- epoch number 6754\n",
      "\n",
      "\n",
      "loss before training is 9.766217150651055e-06 -- epoch number 6755\n",
      "\n",
      "\n",
      "loss before training is 9.753544302727015e-06 -- epoch number 6756\n",
      "\n",
      "\n",
      "loss before training is 9.740889187522917e-06 -- epoch number 6757\n",
      "\n",
      "\n",
      "loss before training is 9.728251779004711e-06 -- epoch number 6758\n",
      "\n",
      "\n",
      "loss before training is 9.715632051176521e-06 -- epoch number 6759\n",
      "\n",
      "\n",
      "loss before training is 9.703029978080719e-06 -- epoch number 6760\n",
      "\n",
      "\n",
      "loss before training is 9.690445533798657e-06 -- epoch number 6761\n",
      "\n",
      "\n",
      "loss before training is 9.677878692451726e-06 -- epoch number 6762\n",
      "\n",
      "\n",
      "loss before training is 9.665329428198523e-06 -- epoch number 6763\n",
      "\n",
      "\n",
      "loss before training is 9.652797715237103e-06 -- epoch number 6764\n",
      "\n",
      "\n",
      "loss before training is 9.640283527803126e-06 -- epoch number 6765\n",
      "\n",
      "\n",
      "loss before training is 9.62778684017292e-06 -- epoch number 6766\n",
      "\n",
      "\n",
      "loss before training is 9.615307626658727e-06 -- epoch number 6767\n",
      "\n",
      "\n",
      "loss before training is 9.60284586161285e-06 -- epoch number 6768\n",
      "\n",
      "\n",
      "loss before training is 9.590401519425294e-06 -- epoch number 6769\n",
      "\n",
      "\n",
      "loss before training is 9.577974574525236e-06 -- epoch number 6770\n",
      "\n",
      "\n",
      "loss before training is 9.56556500137885e-06 -- epoch number 6771\n",
      "\n",
      "\n",
      "loss before training is 9.553172774491169e-06 -- epoch number 6772\n",
      "\n",
      "\n",
      "loss before training is 9.540797868405429e-06 -- epoch number 6773\n",
      "\n",
      "\n",
      "loss before training is 9.528440257702982e-06 -- epoch number 6774\n",
      "\n",
      "\n",
      "loss before training is 9.516099917002411e-06 -- epoch number 6775\n",
      "\n",
      "\n",
      "loss before training is 9.503776820961678e-06 -- epoch number 6776\n",
      "\n",
      "\n",
      "loss before training is 9.491470944275616e-06 -- epoch number 6777\n",
      "\n",
      "\n",
      "loss before training is 9.479182261677602e-06 -- epoch number 6778\n",
      "\n",
      "\n",
      "loss before training is 9.466910747937414e-06 -- epoch number 6779\n",
      "\n",
      "\n",
      "loss before training is 9.454656377864832e-06 -- epoch number 6780\n",
      "\n",
      "\n",
      "loss before training is 9.442419126304884e-06 -- epoch number 6781\n",
      "\n",
      "\n",
      "loss before training is 9.430198968142576e-06 -- epoch number 6782\n",
      "\n",
      "\n",
      "loss before training is 9.41799587829878e-06 -- epoch number 6783\n",
      "\n",
      "\n",
      "loss before training is 9.405809831732273e-06 -- epoch number 6784\n",
      "\n",
      "\n",
      "loss before training is 9.393640803440226e-06 -- epoch number 6785\n",
      "\n",
      "\n",
      "loss before training is 9.38148876845538e-06 -- epoch number 6786\n",
      "\n",
      "\n",
      "loss before training is 9.36935370185022e-06 -- epoch number 6787\n",
      "\n",
      "\n",
      "loss before training is 9.357235578732229e-06 -- epoch number 6788\n",
      "\n",
      "\n",
      "loss before training is 9.345134374247751e-06 -- epoch number 6789\n",
      "\n",
      "\n",
      "loss before training is 9.333050063579683e-06 -- epoch number 6790\n",
      "\n",
      "\n",
      "loss before training is 9.320982621947941e-06 -- epoch number 6791\n",
      "\n",
      "\n",
      "loss before training is 9.308932024609898e-06 -- epoch number 6792\n",
      "\n",
      "\n",
      "loss before training is 9.296898246859689e-06 -- epoch number 6793\n",
      "\n",
      "\n",
      "loss before training is 9.284881264028343e-06 -- epoch number 6794\n",
      "\n",
      "\n",
      "loss before training is 9.272881051484303e-06 -- epoch number 6795\n",
      "\n",
      "\n",
      "loss before training is 9.260897584632386e-06 -- epoch number 6796\n",
      "\n",
      "\n",
      "loss before training is 9.24893083891446e-06 -- epoch number 6797\n",
      "\n",
      "\n",
      "loss before training is 9.236980789808564e-06 -- epoch number 6798\n",
      "\n",
      "\n",
      "loss before training is 9.22504741283104e-06 -- epoch number 6799\n",
      "\n",
      "\n",
      "loss before training is 9.2131306835324e-06 -- epoch number 6800\n",
      "\n",
      "\n",
      "loss before training is 9.201230577502355e-06 -- epoch number 6801\n",
      "\n",
      "\n",
      "loss before training is 9.189347070365499e-06 -- epoch number 6802\n",
      "\n",
      "\n",
      "loss before training is 9.177480137782416e-06 -- epoch number 6803\n",
      "\n",
      "\n",
      "loss before training is 9.16562975545286e-06 -- epoch number 6804\n",
      "\n",
      "\n",
      "loss before training is 9.153795899109634e-06 -- epoch number 6805\n",
      "\n",
      "\n",
      "loss before training is 9.141978544523798e-06 -- epoch number 6806\n",
      "\n",
      "\n",
      "loss before training is 9.130177667502445e-06 -- epoch number 6807\n",
      "\n",
      "\n",
      "loss before training is 9.118393243888746e-06 -- epoch number 6808\n",
      "\n",
      "\n",
      "loss before training is 9.106625249561816e-06 -- epoch number 6809\n",
      "\n",
      "\n",
      "loss before training is 9.094873660437128e-06 -- epoch number 6810\n",
      "\n",
      "\n",
      "loss before training is 9.083138452465978e-06 -- epoch number 6811\n",
      "\n",
      "\n",
      "loss before training is 9.071419601636428e-06 -- epoch number 6812\n",
      "\n",
      "\n",
      "loss before training is 9.059717083970414e-06 -- epoch number 6813\n",
      "\n",
      "\n",
      "loss before training is 9.048030875528687e-06 -- epoch number 6814\n",
      "\n",
      "\n",
      "loss before training is 9.03636095240616e-06 -- epoch number 6815\n",
      "\n",
      "\n",
      "loss before training is 9.024707290732483e-06 -- epoch number 6816\n",
      "\n",
      "\n",
      "loss before training is 9.013069866675796e-06 -- epoch number 6817\n",
      "\n",
      "\n",
      "loss before training is 9.00144865643818e-06 -- epoch number 6818\n",
      "\n",
      "\n",
      "loss before training is 8.989843636256277e-06 -- epoch number 6819\n",
      "\n",
      "\n",
      "loss before training is 8.978254782405766e-06 -- epoch number 6820\n",
      "\n",
      "\n",
      "loss before training is 8.966682071193823e-06 -- epoch number 6821\n",
      "\n",
      "\n",
      "loss before training is 8.955125478965968e-06 -- epoch number 6822\n",
      "\n",
      "\n",
      "loss before training is 8.943584982102013e-06 -- epoch number 6823\n",
      "\n",
      "\n",
      "loss before training is 8.932060557017219e-06 -- epoch number 6824\n",
      "\n",
      "\n",
      "loss before training is 8.920552180161998e-06 -- epoch number 6825\n",
      "\n",
      "\n",
      "loss before training is 8.909059828022364e-06 -- epoch number 6826\n",
      "\n",
      "\n",
      "loss before training is 8.897583477119491e-06 -- epoch number 6827\n",
      "\n",
      "\n",
      "loss before training is 8.886123104010044e-06 -- epoch number 6828\n",
      "\n",
      "\n",
      "loss before training is 8.874678685284174e-06 -- epoch number 6829\n",
      "\n",
      "\n",
      "loss before training is 8.86325019756935e-06 -- epoch number 6830\n",
      "\n",
      "\n",
      "loss before training is 8.851837617526433e-06 -- epoch number 6831\n",
      "\n",
      "\n",
      "loss before training is 8.840440921852544e-06 -- epoch number 6832\n",
      "\n",
      "\n",
      "loss before training is 8.82906008727754e-06 -- epoch number 6833\n",
      "\n",
      "\n",
      "loss before training is 8.81769509056952e-06 -- epoch number 6834\n",
      "\n",
      "\n",
      "loss before training is 8.806345908527106e-06 -- epoch number 6835\n",
      "\n",
      "\n",
      "loss before training is 8.795012517988126e-06 -- epoch number 6836\n",
      "\n",
      "\n",
      "loss before training is 8.783694895821066e-06 -- epoch number 6837\n",
      "\n",
      "\n",
      "loss before training is 8.772393018931605e-06 -- epoch number 6838\n",
      "\n",
      "\n",
      "loss before training is 8.76110686425974e-06 -- epoch number 6839\n",
      "\n",
      "\n",
      "loss before training is 8.749836408778833e-06 -- epoch number 6840\n",
      "\n",
      "\n",
      "loss before training is 8.738581629498321e-06 -- epoch number 6841\n",
      "\n",
      "\n",
      "loss before training is 8.727342503459958e-06 -- epoch number 6842\n",
      "\n",
      "\n",
      "loss before training is 8.716119007741374e-06 -- epoch number 6843\n",
      "\n",
      "\n",
      "loss before training is 8.704911119455683e-06 -- epoch number 6844\n",
      "\n",
      "\n",
      "loss before training is 8.693718815747383e-06 -- epoch number 6845\n",
      "\n",
      "\n",
      "loss before training is 8.682542073797214e-06 -- epoch number 6846\n",
      "\n",
      "\n",
      "loss before training is 8.671380870819537e-06 -- epoch number 6847\n",
      "\n",
      "\n",
      "loss before training is 8.66023518406292e-06 -- epoch number 6848\n",
      "\n",
      "\n",
      "loss before training is 8.649104990809366e-06 -- epoch number 6849\n",
      "\n",
      "\n",
      "loss before training is 8.63799026837672e-06 -- epoch number 6850\n",
      "\n",
      "\n",
      "loss before training is 8.62689099411452e-06 -- epoch number 6851\n",
      "\n",
      "\n",
      "loss before training is 8.61580714540776e-06 -- epoch number 6852\n",
      "\n",
      "\n",
      "loss before training is 8.604738699674178e-06 -- epoch number 6853\n",
      "\n",
      "\n",
      "loss before training is 8.593685634367227e-06 -- epoch number 6854\n",
      "\n",
      "\n",
      "loss before training is 8.582647926971976e-06 -- epoch number 6855\n",
      "\n",
      "\n",
      "loss before training is 8.571625555008597e-06 -- epoch number 6856\n",
      "\n",
      "\n",
      "loss before training is 8.560618496029863e-06 -- epoch number 6857\n",
      "\n",
      "\n",
      "loss before training is 8.549626727622679e-06 -- epoch number 6858\n",
      "\n",
      "\n",
      "loss before training is 8.538650227408885e-06 -- epoch number 6859\n",
      "\n",
      "\n",
      "loss before training is 8.527688973041516e-06 -- epoch number 6860\n",
      "\n",
      "\n",
      "loss before training is 8.516742942208457e-06 -- epoch number 6861\n",
      "\n",
      "\n",
      "loss before training is 8.505812112630186e-06 -- epoch number 6862\n",
      "\n",
      "\n",
      "loss before training is 8.494896462061975e-06 -- epoch number 6863\n",
      "\n",
      "\n",
      "loss before training is 8.48399596829172e-06 -- epoch number 6864\n",
      "\n",
      "\n",
      "loss before training is 8.47311060913907e-06 -- epoch number 6865\n",
      "\n",
      "\n",
      "loss before training is 8.462240362459057e-06 -- epoch number 6866\n",
      "\n",
      "\n",
      "loss before training is 8.451385206138843e-06 -- epoch number 6867\n",
      "\n",
      "\n",
      "loss before training is 8.440545118099156e-06 -- epoch number 6868\n",
      "\n",
      "\n",
      "loss before training is 8.429720076293668e-06 -- epoch number 6869\n",
      "\n",
      "\n",
      "loss before training is 8.418910058708625e-06 -- epoch number 6870\n",
      "\n",
      "\n",
      "loss before training is 8.408115043363258e-06 -- epoch number 6871\n",
      "\n",
      "\n",
      "loss before training is 8.397335008311003e-06 -- epoch number 6872\n",
      "\n",
      "\n",
      "loss before training is 8.386569931636865e-06 -- epoch number 6873\n",
      "\n",
      "\n",
      "loss before training is 8.37581979145896e-06 -- epoch number 6874\n",
      "\n",
      "\n",
      "loss before training is 8.36508456592846e-06 -- epoch number 6875\n",
      "\n",
      "\n",
      "loss before training is 8.354364233228498e-06 -- epoch number 6876\n",
      "\n",
      "\n",
      "loss before training is 8.343658771576565e-06 -- epoch number 6877\n",
      "\n",
      "\n",
      "loss before training is 8.332968159221112e-06 -- epoch number 6878\n",
      "\n",
      "\n",
      "loss before training is 8.322292374443836e-06 -- epoch number 6879\n",
      "\n",
      "\n",
      "loss before training is 8.311631395558691e-06 -- epoch number 6880\n",
      "\n",
      "\n",
      "loss before training is 8.300985200912754e-06 -- epoch number 6881\n",
      "\n",
      "\n",
      "loss before training is 8.290353768884824e-06 -- epoch number 6882\n",
      "\n",
      "\n",
      "loss before training is 8.279737077886895e-06 -- epoch number 6883\n",
      "\n",
      "\n",
      "loss before training is 8.269135106362682e-06 -- epoch number 6884\n",
      "\n",
      "\n",
      "loss before training is 8.258547832788056e-06 -- epoch number 6885\n",
      "\n",
      "\n",
      "loss before training is 8.247975235671332e-06 -- epoch number 6886\n",
      "\n",
      "\n",
      "loss before training is 8.237417293553759e-06 -- epoch number 6887\n",
      "\n",
      "\n",
      "loss before training is 8.226873985007381e-06 -- epoch number 6888\n",
      "\n",
      "\n",
      "loss before training is 8.216345288637693e-06 -- epoch number 6889\n",
      "\n",
      "\n",
      "loss before training is 8.205831183080923e-06 -- epoch number 6890\n",
      "\n",
      "\n",
      "loss before training is 8.195331647006609e-06 -- epoch number 6891\n",
      "\n",
      "\n",
      "loss before training is 8.184846659115934e-06 -- epoch number 6892\n",
      "\n",
      "\n",
      "loss before training is 8.174376198140705e-06 -- epoch number 6893\n",
      "\n",
      "\n",
      "loss before training is 8.163920242846258e-06 -- epoch number 6894\n",
      "\n",
      "\n",
      "loss before training is 8.15347877202921e-06 -- epoch number 6895\n",
      "\n",
      "\n",
      "loss before training is 8.14305176451785e-06 -- epoch number 6896\n",
      "\n",
      "\n",
      "loss before training is 8.132639199171445e-06 -- epoch number 6897\n",
      "\n",
      "\n",
      "loss before training is 8.122241054882558e-06 -- epoch number 6898\n",
      "\n",
      "\n",
      "loss before training is 8.111857310574427e-06 -- epoch number 6899\n",
      "\n",
      "\n",
      "loss before training is 8.101487945201182e-06 -- epoch number 6900\n",
      "\n",
      "\n",
      "loss before training is 8.091132937750009e-06 -- epoch number 6901\n",
      "\n",
      "\n",
      "loss before training is 8.080792267238668e-06 -- epoch number 6902\n",
      "\n",
      "\n",
      "loss before training is 8.07046591271654e-06 -- epoch number 6903\n",
      "\n",
      "\n",
      "loss before training is 8.060153853264082e-06 -- epoch number 6904\n",
      "\n",
      "\n",
      "loss before training is 8.049856067993725e-06 -- epoch number 6905\n",
      "\n",
      "\n",
      "loss before training is 8.039572536048362e-06 -- epoch number 6906\n",
      "\n",
      "\n",
      "loss before training is 8.029303236604101e-06 -- epoch number 6907\n",
      "\n",
      "\n",
      "loss before training is 8.019048148865085e-06 -- epoch number 6908\n",
      "\n",
      "\n",
      "loss before training is 8.008807252068964e-06 -- epoch number 6909\n",
      "\n",
      "\n",
      "loss before training is 7.998580525484258e-06 -- epoch number 6910\n",
      "\n",
      "\n",
      "loss before training is 7.988367948410066e-06 -- epoch number 6911\n",
      "\n",
      "\n",
      "loss before training is 7.978169500176434e-06 -- epoch number 6912\n",
      "\n",
      "\n",
      "loss before training is 7.967985160144358e-06 -- epoch number 6913\n",
      "\n",
      "\n",
      "loss before training is 7.957814907706317e-06 -- epoch number 6914\n",
      "\n",
      "\n",
      "loss before training is 7.947658722285313e-06 -- epoch number 6915\n",
      "\n",
      "\n",
      "loss before training is 7.937516583335657e-06 -- epoch number 6916\n",
      "\n",
      "\n",
      "loss before training is 7.927388470341306e-06 -- epoch number 6917\n",
      "\n",
      "\n",
      "loss before training is 7.917274362818472e-06 -- epoch number 6918\n",
      "\n",
      "\n",
      "loss before training is 7.907174240312134e-06 -- epoch number 6919\n",
      "\n",
      "\n",
      "loss before training is 7.897088082399592e-06 -- epoch number 6920\n",
      "\n",
      "\n",
      "loss before training is 7.887015868688671e-06 -- epoch number 6921\n",
      "\n",
      "\n",
      "loss before training is 7.876957578817259e-06 -- epoch number 6922\n",
      "\n",
      "\n",
      "loss before training is 7.86691319245306e-06 -- epoch number 6923\n",
      "\n",
      "\n",
      "loss before training is 7.856882689295687e-06 -- epoch number 6924\n",
      "\n",
      "\n",
      "loss before training is 7.846866049074053e-06 -- epoch number 6925\n",
      "\n",
      "\n",
      "loss before training is 7.836863251548462e-06 -- epoch number 6926\n",
      "\n",
      "\n",
      "loss before training is 7.826874276508424e-06 -- epoch number 6927\n",
      "\n",
      "\n",
      "loss before training is 7.816899103775e-06 -- epoch number 6928\n",
      "\n",
      "\n",
      "loss before training is 7.806937713198051e-06 -- epoch number 6929\n",
      "\n",
      "\n",
      "loss before training is 7.796990084658744e-06 -- epoch number 6930\n",
      "\n",
      "\n",
      "loss before training is 7.787056198067808e-06 -- epoch number 6931\n",
      "\n",
      "\n",
      "loss before training is 7.77713603336661e-06 -- epoch number 6932\n",
      "\n",
      "\n",
      "loss before training is 7.767229570526026e-06 -- epoch number 6933\n",
      "\n",
      "\n",
      "loss before training is 7.75733678954768e-06 -- epoch number 6934\n",
      "\n",
      "\n",
      "loss before training is 7.747457670462421e-06 -- epoch number 6935\n",
      "\n",
      "\n",
      "loss before training is 7.73759219333114e-06 -- epoch number 6936\n",
      "\n",
      "\n",
      "loss before training is 7.727740338245179e-06 -- epoch number 6937\n",
      "\n",
      "\n",
      "loss before training is 7.7179020853252e-06 -- epoch number 6938\n",
      "\n",
      "\n",
      "loss before training is 7.708077414720994e-06 -- epoch number 6939\n",
      "\n",
      "\n",
      "loss before training is 7.698266306613993e-06 -- epoch number 6940\n",
      "\n",
      "\n",
      "loss before training is 7.68846874121393e-06 -- epoch number 6941\n",
      "\n",
      "\n",
      "loss before training is 7.678684698760615e-06 -- epoch number 6942\n",
      "\n",
      "\n",
      "loss before training is 7.66891415952312e-06 -- epoch number 6943\n",
      "\n",
      "\n",
      "loss before training is 7.659157103800386e-06 -- epoch number 6944\n",
      "\n",
      "\n",
      "loss before training is 7.64941351192088e-06 -- epoch number 6945\n",
      "\n",
      "\n",
      "loss before training is 7.639683364242576e-06 -- epoch number 6946\n",
      "\n",
      "\n",
      "loss before training is 7.629966641152611e-06 -- epoch number 6947\n",
      "\n",
      "\n",
      "loss before training is 7.6202633230682215e-06 -- epoch number 6948\n",
      "\n",
      "\n",
      "loss before training is 7.610573390435277e-06 -- epoch number 6949\n",
      "\n",
      "\n",
      "loss before training is 7.600896823728971e-06 -- epoch number 6950\n",
      "\n",
      "\n",
      "loss before training is 7.591233603454516e-06 -- epoch number 6951\n",
      "\n",
      "\n",
      "loss before training is 7.581583710144773e-06 -- epoch number 6952\n",
      "\n",
      "\n",
      "loss before training is 7.571947124364469e-06 -- epoch number 6953\n",
      "\n",
      "\n",
      "loss before training is 7.5623238267045775e-06 -- epoch number 6954\n",
      "\n",
      "\n",
      "loss before training is 7.552713797787002e-06 -- epoch number 6955\n",
      "\n",
      "\n",
      "loss before training is 7.543117018261731e-06 -- epoch number 6956\n",
      "\n",
      "\n",
      "loss before training is 7.533533468808125e-06 -- epoch number 6957\n",
      "\n",
      "\n",
      "loss before training is 7.52396313013488e-06 -- epoch number 6958\n",
      "\n",
      "\n",
      "loss before training is 7.514405982979137e-06 -- epoch number 6959\n",
      "\n",
      "\n",
      "loss before training is 7.504862008106775e-06 -- epoch number 6960\n",
      "\n",
      "\n",
      "loss before training is 7.495331186313212e-06 -- epoch number 6961\n",
      "\n",
      "\n",
      "loss before training is 7.485813498421494e-06 -- epoch number 6962\n",
      "\n",
      "\n",
      "loss before training is 7.47630892528499e-06 -- epoch number 6963\n",
      "\n",
      "\n",
      "loss before training is 7.466817447784224e-06 -- epoch number 6964\n",
      "\n",
      "\n",
      "loss before training is 7.45733904682935e-06 -- epoch number 6965\n",
      "\n",
      "\n",
      "loss before training is 7.4478737033587865e-06 -- epoch number 6966\n",
      "\n",
      "\n",
      "loss before training is 7.438421398339455e-06 -- epoch number 6967\n",
      "\n",
      "\n",
      "loss before training is 7.428982112766927e-06 -- epoch number 6968\n",
      "\n",
      "\n",
      "loss before training is 7.419555827665401e-06 -- epoch number 6969\n",
      "\n",
      "\n",
      "loss before training is 7.410142524087397e-06 -- epoch number 6970\n",
      "\n",
      "\n",
      "loss before training is 7.400742183114137e-06 -- epoch number 6971\n",
      "\n",
      "\n",
      "loss before training is 7.391354785854085e-06 -- epoch number 6972\n",
      "\n",
      "\n",
      "loss before training is 7.381980313445333e-06 -- epoch number 6973\n",
      "\n",
      "\n",
      "loss before training is 7.3726187470543e-06 -- epoch number 6974\n",
      "\n",
      "\n",
      "loss before training is 7.363270067873835e-06 -- epoch number 6975\n",
      "\n",
      "\n",
      "loss before training is 7.353934257126906e-06 -- epoch number 6976\n",
      "\n",
      "\n",
      "loss before training is 7.344611296064133e-06 -- epoch number 6977\n",
      "\n",
      "\n",
      "loss before training is 7.3353011659642324e-06 -- epoch number 6978\n",
      "\n",
      "\n",
      "loss before training is 7.326003848133168e-06 -- epoch number 6979\n",
      "\n",
      "\n",
      "loss before training is 7.316719323905964e-06 -- epoch number 6980\n",
      "\n",
      "\n",
      "loss before training is 7.307447574644653e-06 -- epoch number 6981\n",
      "\n",
      "\n",
      "loss before training is 7.298188581740764e-06 -- epoch number 6982\n",
      "\n",
      "\n",
      "loss before training is 7.288942326612132e-06 -- epoch number 6983\n",
      "\n",
      "\n",
      "loss before training is 7.279708790705127e-06 -- epoch number 6984\n",
      "\n",
      "\n",
      "loss before training is 7.2704879554943036e-06 -- epoch number 6985\n",
      "\n",
      "\n",
      "loss before training is 7.261279802480441e-06 -- epoch number 6986\n",
      "\n",
      "\n",
      "loss before training is 7.252084313194739e-06 -- epoch number 6987\n",
      "\n",
      "\n",
      "loss before training is 7.2429014691933944e-06 -- epoch number 6988\n",
      "\n",
      "\n",
      "loss before training is 7.2337312520614024e-06 -- epoch number 6989\n",
      "\n",
      "\n",
      "loss before training is 7.224573643411627e-06 -- epoch number 6990\n",
      "\n",
      "\n",
      "loss before training is 7.215428624884478e-06 -- epoch number 6991\n",
      "\n",
      "\n",
      "loss before training is 7.206296178147026e-06 -- epoch number 6992\n",
      "\n",
      "\n",
      "loss before training is 7.197176284894589e-06 -- epoch number 6993\n",
      "\n",
      "\n",
      "loss before training is 7.188068926849772e-06 -- epoch number 6994\n",
      "\n",
      "\n",
      "loss before training is 7.1789740857628134e-06 -- epoch number 6995\n",
      "\n",
      "\n",
      "loss before training is 7.169891743410739e-06 -- epoch number 6996\n",
      "\n",
      "\n",
      "loss before training is 7.16082188159797e-06 -- epoch number 6997\n",
      "\n",
      "\n",
      "loss before training is 7.151764482156649e-06 -- epoch number 6998\n",
      "\n",
      "\n",
      "loss before training is 7.142719526946341e-06 -- epoch number 6999\n",
      "\n",
      "\n",
      "loss before training is 7.133686997853148e-06 -- epoch number 7000\n",
      "\n",
      "\n",
      "loss before training is 7.1246668767905895e-06 -- epoch number 7001\n",
      "\n",
      "\n",
      "loss before training is 7.1156591456986834e-06 -- epoch number 7002\n",
      "\n",
      "\n",
      "loss before training is 7.1066637865460345e-06 -- epoch number 7003\n",
      "\n",
      "\n",
      "loss before training is 7.09768078132683e-06 -- epoch number 7004\n",
      "\n",
      "\n",
      "loss before training is 7.088710112062855e-06 -- epoch number 7005\n",
      "\n",
      "\n",
      "loss before training is 7.079751760803e-06 -- epoch number 7006\n",
      "\n",
      "\n",
      "loss before training is 7.070805709622364e-06 -- epoch number 7007\n",
      "\n",
      "\n",
      "loss before training is 7.061871940624272e-06 -- epoch number 7008\n",
      "\n",
      "\n",
      "loss before training is 7.0529504359370225e-06 -- epoch number 7009\n",
      "\n",
      "\n",
      "loss before training is 7.044041177717263e-06 -- epoch number 7010\n",
      "\n",
      "\n",
      "loss before training is 7.035144148147896e-06 -- epoch number 7011\n",
      "\n",
      "\n",
      "loss before training is 7.026259329437734e-06 -- epoch number 7012\n",
      "\n",
      "\n",
      "loss before training is 7.01738670382399e-06 -- epoch number 7013\n",
      "\n",
      "\n",
      "loss before training is 7.008526253568813e-06 -- epoch number 7014\n",
      "\n",
      "\n",
      "loss before training is 6.9996779609614745e-06 -- epoch number 7015\n",
      "\n",
      "\n",
      "loss before training is 6.990841808318615e-06 -- epoch number 7016\n",
      "\n",
      "\n",
      "loss before training is 6.9820177779822014e-06 -- epoch number 7017\n",
      "\n",
      "\n",
      "loss before training is 6.973205852321458e-06 -- epoch number 7018\n",
      "\n",
      "\n",
      "loss before training is 6.964406013731106e-06 -- epoch number 7019\n",
      "\n",
      "\n",
      "loss before training is 6.955618244634139e-06 -- epoch number 7020\n",
      "\n",
      "\n",
      "loss before training is 6.946842527477438e-06 -- epoch number 7021\n",
      "\n",
      "\n",
      "loss before training is 6.938078844736214e-06 -- epoch number 7022\n",
      "\n",
      "\n",
      "loss before training is 6.929327178910661e-06 -- epoch number 7023\n",
      "\n",
      "\n",
      "loss before training is 6.920587512527868e-06 -- epoch number 7024\n",
      "\n",
      "\n",
      "loss before training is 6.9118598281411735e-06 -- epoch number 7025\n",
      "\n",
      "\n",
      "loss before training is 6.90314410833e-06 -- epoch number 7026\n",
      "\n",
      "\n",
      "loss before training is 6.894440335699727e-06 -- epoch number 7027\n",
      "\n",
      "\n",
      "loss before training is 6.885748492880776e-06 -- epoch number 7028\n",
      "\n",
      "\n",
      "loss before training is 6.877068562531888e-06 -- epoch number 7029\n",
      "\n",
      "\n",
      "loss before training is 6.86840052733634e-06 -- epoch number 7030\n",
      "\n",
      "\n",
      "loss before training is 6.859744370002518e-06 -- epoch number 7031\n",
      "\n",
      "\n",
      "loss before training is 6.851100073267196e-06 -- epoch number 7032\n",
      "\n",
      "\n",
      "loss before training is 6.842467619891183e-06 -- epoch number 7033\n",
      "\n",
      "\n",
      "loss before training is 6.833846992661295e-06 -- epoch number 7034\n",
      "\n",
      "\n",
      "loss before training is 6.8252381743907194e-06 -- epoch number 7035\n",
      "\n",
      "\n",
      "loss before training is 6.816641147917954e-06 -- epoch number 7036\n",
      "\n",
      "\n",
      "loss before training is 6.808055896107922e-06 -- epoch number 7037\n",
      "\n",
      "\n",
      "loss before training is 6.7994824018497975e-06 -- epoch number 7038\n",
      "\n",
      "\n",
      "loss before training is 6.790920648059724e-06 -- epoch number 7039\n",
      "\n",
      "\n",
      "loss before training is 6.78237061767934e-06 -- epoch number 7040\n",
      "\n",
      "\n",
      "loss before training is 6.773832293674874e-06 -- epoch number 7041\n",
      "\n",
      "\n",
      "loss before training is 6.765305659039521e-06 -- epoch number 7042\n",
      "\n",
      "\n",
      "loss before training is 6.756790696790616e-06 -- epoch number 7043\n",
      "\n",
      "\n",
      "loss before training is 6.748287389971872e-06 -- epoch number 7044\n",
      "\n",
      "\n",
      "loss before training is 6.739795721652206e-06 -- epoch number 7045\n",
      "\n",
      "\n",
      "loss before training is 6.7313156749256445e-06 -- epoch number 7046\n",
      "\n",
      "\n",
      "loss before training is 6.722847232911485e-06 -- epoch number 7047\n",
      "\n",
      "\n",
      "loss before training is 6.714390378754615e-06 -- epoch number 7048\n",
      "\n",
      "\n",
      "loss before training is 6.705945095625472e-06 -- epoch number 7049\n",
      "\n",
      "\n",
      "loss before training is 6.6975113667193484e-06 -- epoch number 7050\n",
      "\n",
      "\n",
      "loss before training is 6.689089175256462e-06 -- epoch number 7051\n",
      "\n",
      "\n",
      "loss before training is 6.680678504482249e-06 -- epoch number 7052\n",
      "\n",
      "\n",
      "loss before training is 6.672279337668265e-06 -- epoch number 7053\n",
      "\n",
      "\n",
      "loss before training is 6.663891658109981e-06 -- epoch number 7054\n",
      "\n",
      "\n",
      "loss before training is 6.655515449127997e-06 -- epoch number 7055\n",
      "\n",
      "\n",
      "loss before training is 6.647150694068143e-06 -- epoch number 7056\n",
      "\n",
      "\n",
      "loss before training is 6.6387973763017255e-06 -- epoch number 7057\n",
      "\n",
      "\n",
      "loss before training is 6.630455479224739e-06 -- epoch number 7058\n",
      "\n",
      "\n",
      "loss before training is 6.622124986257294e-06 -- epoch number 7059\n",
      "\n",
      "\n",
      "loss before training is 6.613805880844957e-06 -- epoch number 7060\n",
      "\n",
      "\n",
      "loss before training is 6.605498146458406e-06 -- epoch number 7061\n",
      "\n",
      "\n",
      "loss before training is 6.59720176659201e-06 -- epoch number 7062\n",
      "\n",
      "\n",
      "loss before training is 6.588916724766783e-06 -- epoch number 7063\n",
      "\n",
      "\n",
      "loss before training is 6.580643004526243e-06 -- epoch number 7064\n",
      "\n",
      "\n",
      "loss before training is 6.572380589440137e-06 -- epoch number 7065\n",
      "\n",
      "\n",
      "loss before training is 6.5641294631022346e-06 -- epoch number 7066\n",
      "\n",
      "\n",
      "loss before training is 6.555889609130794e-06 -- epoch number 7067\n",
      "\n",
      "\n",
      "loss before training is 6.547661011168812e-06 -- epoch number 7068\n",
      "\n",
      "\n",
      "loss before training is 6.539443652884061e-06 -- epoch number 7069\n",
      "\n",
      "\n",
      "loss before training is 6.531237517968058e-06 -- epoch number 7070\n",
      "\n",
      "\n",
      "loss before training is 6.5230425901375935e-06 -- epoch number 7071\n",
      "\n",
      "\n",
      "loss before training is 6.514858853132973e-06 -- epoch number 7072\n",
      "\n",
      "\n",
      "loss before training is 6.506686290720689e-06 -- epoch number 7073\n",
      "\n",
      "\n",
      "loss before training is 6.4985248866883095e-06 -- epoch number 7074\n",
      "\n",
      "\n",
      "loss before training is 6.4903746248512825e-06 -- epoch number 7075\n",
      "\n",
      "\n",
      "loss before training is 6.4822354890472744e-06 -- epoch number 7076\n",
      "\n",
      "\n",
      "loss before training is 6.474107463137855e-06 -- epoch number 7077\n",
      "\n",
      "\n",
      "loss before training is 6.465990531010868e-06 -- epoch number 7078\n",
      "\n",
      "\n",
      "loss before training is 6.4578846765753585e-06 -- epoch number 7079\n",
      "\n",
      "\n",
      "loss before training is 6.449789883767118e-06 -- epoch number 7080\n",
      "\n",
      "\n",
      "loss before training is 6.441706136544846e-06 -- epoch number 7081\n",
      "\n",
      "\n",
      "loss before training is 6.433633418891698e-06 -- epoch number 7082\n",
      "\n",
      "\n",
      "loss before training is 6.425571714813442e-06 -- epoch number 7083\n",
      "\n",
      "\n",
      "loss before training is 6.417521008342128e-06 -- epoch number 7084\n",
      "\n",
      "\n",
      "loss before training is 6.409481283532258e-06 -- epoch number 7085\n",
      "\n",
      "\n",
      "loss before training is 6.401452524461905e-06 -- epoch number 7086\n",
      "\n",
      "\n",
      "loss before training is 6.393434715234089e-06 -- epoch number 7087\n",
      "\n",
      "\n",
      "loss before training is 6.385427839974961e-06 -- epoch number 7088\n",
      "\n",
      "\n",
      "loss before training is 6.3774318828350775e-06 -- epoch number 7089\n",
      "\n",
      "\n",
      "loss before training is 6.3694468279880835e-06 -- epoch number 7090\n",
      "\n",
      "\n",
      "loss before training is 6.3614726596312666e-06 -- epoch number 7091\n",
      "\n",
      "\n",
      "loss before training is 6.353509361986427e-06 -- epoch number 7092\n",
      "\n",
      "\n",
      "loss before training is 6.345556919298043e-06 -- epoch number 7093\n",
      "\n",
      "\n",
      "loss before training is 6.3376153158352624e-06 -- epoch number 7094\n",
      "\n",
      "\n",
      "loss before training is 6.329684535889656e-06 -- epoch number 7095\n",
      "\n",
      "\n",
      "loss before training is 6.3217645637774954e-06 -- epoch number 7096\n",
      "\n",
      "\n",
      "loss before training is 6.313855383837355e-06 -- epoch number 7097\n",
      "\n",
      "\n",
      "loss before training is 6.305956980432246e-06 -- epoch number 7098\n",
      "\n",
      "\n",
      "loss before training is 6.2980693379479e-06 -- epoch number 7099\n",
      "\n",
      "\n",
      "loss before training is 6.29019244079409e-06 -- epoch number 7100\n",
      "\n",
      "\n",
      "loss before training is 6.282326273403821e-06 -- epoch number 7101\n",
      "\n",
      "\n",
      "loss before training is 6.2744708202330495e-06 -- epoch number 7102\n",
      "\n",
      "\n",
      "loss before training is 6.266626065760826e-06 -- epoch number 7103\n",
      "\n",
      "\n",
      "loss before training is 6.2587919944903724e-06 -- epoch number 7104\n",
      "\n",
      "\n",
      "loss before training is 6.250968590947298e-06 -- epoch number 7105\n",
      "\n",
      "\n",
      "loss before training is 6.243155839681435e-06 -- epoch number 7106\n",
      "\n",
      "\n",
      "loss before training is 6.235353725264322e-06 -- epoch number 7107\n",
      "\n",
      "\n",
      "loss before training is 6.227562232291284e-06 -- epoch number 7108\n",
      "\n",
      "\n",
      "loss before training is 6.219781345381189e-06 -- epoch number 7109\n",
      "\n",
      "\n",
      "loss before training is 6.212011049175672e-06 -- epoch number 7110\n",
      "\n",
      "\n",
      "loss before training is 6.204251328338722e-06 -- epoch number 7111\n",
      "\n",
      "\n",
      "loss before training is 6.1965021675585545e-06 -- epoch number 7112\n",
      "\n",
      "\n",
      "loss before training is 6.1887635515450195e-06 -- epoch number 7113\n",
      "\n",
      "\n",
      "loss before training is 6.181035465031816e-06 -- epoch number 7114\n",
      "\n",
      "\n",
      "loss before training is 6.173317892774785e-06 -- epoch number 7115\n",
      "\n",
      "\n",
      "loss before training is 6.165610819553585e-06 -- epoch number 7116\n",
      "\n",
      "\n",
      "loss before training is 6.157914230169905e-06 -- epoch number 7117\n",
      "\n",
      "\n",
      "loss before training is 6.1502281094484965e-06 -- epoch number 7118\n",
      "\n",
      "\n",
      "loss before training is 6.1425524422364166e-06 -- epoch number 7119\n",
      "\n",
      "\n",
      "loss before training is 6.134887213403906e-06 -- epoch number 7120\n",
      "\n",
      "\n",
      "loss before training is 6.127232407843744e-06 -- epoch number 7121\n",
      "\n",
      "\n",
      "loss before training is 6.119588010471442e-06 -- epoch number 7122\n",
      "\n",
      "\n",
      "loss before training is 6.1119540062248605e-06 -- epoch number 7123\n",
      "\n",
      "\n",
      "loss before training is 6.10433038006457e-06 -- epoch number 7124\n",
      "\n",
      "\n",
      "loss before training is 6.096717116974022e-06 -- epoch number 7125\n",
      "\n",
      "\n",
      "loss before training is 6.08911420195829e-06 -- epoch number 7126\n",
      "\n",
      "\n",
      "loss before training is 6.081521620045638e-06 -- epoch number 7127\n",
      "\n",
      "\n",
      "loss before training is 6.07393935628686e-06 -- epoch number 7128\n",
      "\n",
      "\n",
      "loss before training is 6.066367395754538e-06 -- epoch number 7129\n",
      "\n",
      "\n",
      "loss before training is 6.058805723543606e-06 -- epoch number 7130\n",
      "\n",
      "\n",
      "loss before training is 6.051254324772408e-06 -- epoch number 7131\n",
      "\n",
      "\n",
      "loss before training is 6.0437131845801445e-06 -- epoch number 7132\n",
      "\n",
      "\n",
      "loss before training is 6.036182288129434e-06 -- epoch number 7133\n",
      "\n",
      "\n",
      "loss before training is 6.028661620604477e-06 -- epoch number 7134\n",
      "\n",
      "\n",
      "loss before training is 6.021151167211749e-06 -- epoch number 7135\n",
      "\n",
      "\n",
      "loss before training is 6.013650913180216e-06 -- epoch number 7136\n",
      "\n",
      "\n",
      "loss before training is 6.006160843760461e-06 -- epoch number 7137\n",
      "\n",
      "\n",
      "loss before training is 5.998680944225423e-06 -- epoch number 7138\n",
      "\n",
      "\n",
      "loss before training is 5.9912111998701815e-06 -- epoch number 7139\n",
      "\n",
      "\n",
      "loss before training is 5.983751596012148e-06 -- epoch number 7140\n",
      "\n",
      "\n",
      "loss before training is 5.976302117989892e-06 -- epoch number 7141\n",
      "\n",
      "\n",
      "loss before training is 5.968862751164235e-06 -- epoch number 7142\n",
      "\n",
      "\n",
      "loss before training is 5.961433480918621e-06 -- epoch number 7143\n",
      "\n",
      "\n",
      "loss before training is 5.954014292657873e-06 -- epoch number 7144\n",
      "\n",
      "\n",
      "loss before training is 5.946605171808301e-06 -- epoch number 7145\n",
      "\n",
      "\n",
      "loss before training is 5.939206103818123e-06 -- epoch number 7146\n",
      "\n",
      "\n",
      "loss before training is 5.931817074158902e-06 -- epoch number 7147\n",
      "\n",
      "\n",
      "loss before training is 5.924438068321211e-06 -- epoch number 7148\n",
      "\n",
      "\n",
      "loss before training is 5.9170690718198e-06 -- epoch number 7149\n",
      "\n",
      "\n",
      "loss before training is 5.909710070190125e-06 -- epoch number 7150\n",
      "\n",
      "\n",
      "loss before training is 5.90236104898866e-06 -- epoch number 7151\n",
      "\n",
      "\n",
      "loss before training is 5.895021993794888e-06 -- epoch number 7152\n",
      "\n",
      "\n",
      "loss before training is 5.887692890208988e-06 -- epoch number 7153\n",
      "\n",
      "\n",
      "loss before training is 5.880373723852898e-06 -- epoch number 7154\n",
      "\n",
      "\n",
      "loss before training is 5.8730644803702055e-06 -- epoch number 7155\n",
      "\n",
      "\n",
      "loss before training is 5.8657651454254485e-06 -- epoch number 7156\n",
      "\n",
      "\n",
      "loss before training is 5.858475704705905e-06 -- epoch number 7157\n",
      "\n",
      "\n",
      "loss before training is 5.851196143918876e-06 -- epoch number 7158\n",
      "\n",
      "\n",
      "loss before training is 5.8439264487934525e-06 -- epoch number 7159\n",
      "\n",
      "\n",
      "loss before training is 5.83666660508153e-06 -- epoch number 7160\n",
      "\n",
      "\n",
      "loss before training is 5.829416598553781e-06 -- epoch number 7161\n",
      "\n",
      "\n",
      "loss before training is 5.822176415004439e-06 -- epoch number 7162\n",
      "\n",
      "\n",
      "loss before training is 5.814946040247411e-06 -- epoch number 7163\n",
      "\n",
      "\n",
      "loss before training is 5.807725460119055e-06 -- epoch number 7164\n",
      "\n",
      "\n",
      "loss before training is 5.800514660475695e-06 -- epoch number 7165\n",
      "\n",
      "\n",
      "loss before training is 5.793313627196913e-06 -- epoch number 7166\n",
      "\n",
      "\n",
      "loss before training is 5.786122346181041e-06 -- epoch number 7167\n",
      "\n",
      "\n",
      "loss before training is 5.7789408033487994e-06 -- epoch number 7168\n",
      "\n",
      "\n",
      "loss before training is 5.771768984642249e-06 -- epoch number 7169\n",
      "\n",
      "\n",
      "loss before training is 5.764606876023292e-06 -- epoch number 7170\n",
      "\n",
      "\n",
      "loss before training is 5.757454463475649e-06 -- epoch number 7171\n",
      "\n",
      "\n",
      "loss before training is 5.750311733004792e-06 -- epoch number 7172\n",
      "\n",
      "\n",
      "loss before training is 5.743178670635771e-06 -- epoch number 7173\n",
      "\n",
      "\n",
      "loss before training is 5.736055262414673e-06 -- epoch number 7174\n",
      "\n",
      "\n",
      "loss before training is 5.728941494409742e-06 -- epoch number 7175\n",
      "\n",
      "\n",
      "loss before training is 5.72183735270925e-06 -- epoch number 7176\n",
      "\n",
      "\n",
      "loss before training is 5.714742823421071e-06 -- epoch number 7177\n",
      "\n",
      "\n",
      "loss before training is 5.707657892677073e-06 -- epoch number 7178\n",
      "\n",
      "\n",
      "loss before training is 5.700582546626138e-06 -- epoch number 7179\n",
      "\n",
      "\n",
      "loss before training is 5.693516771441053e-06 -- epoch number 7180\n",
      "\n",
      "\n",
      "loss before training is 5.686460553313164e-06 -- epoch number 7181\n",
      "\n",
      "\n",
      "loss before training is 5.679413878455352e-06 -- epoch number 7182\n",
      "\n",
      "\n",
      "loss before training is 5.672376733101485e-06 -- epoch number 7183\n",
      "\n",
      "\n",
      "loss before training is 5.6653491035051295e-06 -- epoch number 7184\n",
      "\n",
      "\n",
      "loss before training is 5.658330975941196e-06 -- epoch number 7185\n",
      "\n",
      "\n",
      "loss before training is 5.651322336704765e-06 -- epoch number 7186\n",
      "\n",
      "\n",
      "loss before training is 5.644323172111371e-06 -- epoch number 7187\n",
      "\n",
      "\n",
      "loss before training is 5.637333468497678e-06 -- epoch number 7188\n",
      "\n",
      "\n",
      "loss before training is 5.630353212220138e-06 -- epoch number 7189\n",
      "\n",
      "\n",
      "loss before training is 5.623382389655771e-06 -- epoch number 7190\n",
      "\n",
      "\n",
      "loss before training is 5.616420987201604e-06 -- epoch number 7191\n",
      "\n",
      "\n",
      "loss before training is 5.6094689912763565e-06 -- epoch number 7192\n",
      "\n",
      "\n",
      "loss before training is 5.602526388317686e-06 -- epoch number 7193\n",
      "\n",
      "\n",
      "loss before training is 5.59559316478369e-06 -- epoch number 7194\n",
      "\n",
      "\n",
      "loss before training is 5.588669307153907e-06 -- epoch number 7195\n",
      "\n",
      "\n",
      "loss before training is 5.5817548019268475e-06 -- epoch number 7196\n",
      "\n",
      "\n",
      "loss before training is 5.57484963562173e-06 -- epoch number 7197\n",
      "\n",
      "\n",
      "loss before training is 5.567953794777951e-06 -- epoch number 7198\n",
      "\n",
      "\n",
      "loss before training is 5.561067265955199e-06 -- epoch number 7199\n",
      "\n",
      "\n",
      "loss before training is 5.554190035732271e-06 -- epoch number 7200\n",
      "\n",
      "\n",
      "loss before training is 5.547322090710505e-06 -- epoch number 7201\n",
      "\n",
      "\n",
      "loss before training is 5.54046341750835e-06 -- epoch number 7202\n",
      "\n",
      "\n",
      "loss before training is 5.533614002765965e-06 -- epoch number 7203\n",
      "\n",
      "\n",
      "loss before training is 5.526773833143215e-06 -- epoch number 7204\n",
      "\n",
      "\n",
      "loss before training is 5.519942895319737e-06 -- epoch number 7205\n",
      "\n",
      "\n",
      "loss before training is 5.51312117599553e-06 -- epoch number 7206\n",
      "\n",
      "\n",
      "loss before training is 5.506308661890556e-06 -- epoch number 7207\n",
      "\n",
      "\n",
      "loss before training is 5.4995053397429305e-06 -- epoch number 7208\n",
      "\n",
      "\n",
      "loss before training is 5.492711196313543e-06 -- epoch number 7209\n",
      "\n",
      "\n",
      "loss before training is 5.485926218380419e-06 -- epoch number 7210\n",
      "\n",
      "\n",
      "loss before training is 5.479150392743122e-06 -- epoch number 7211\n",
      "\n",
      "\n",
      "loss before training is 5.472383706220134e-06 -- epoch number 7212\n",
      "\n",
      "\n",
      "loss before training is 5.465626145650072e-06 -- epoch number 7213\n",
      "\n",
      "\n",
      "loss before training is 5.4588776978910476e-06 -- epoch number 7214\n",
      "\n",
      "\n",
      "loss before training is 5.4521383498204505e-06 -- epoch number 7215\n",
      "\n",
      "\n",
      "loss before training is 5.4454080883363205e-06 -- epoch number 7216\n",
      "\n",
      "\n",
      "loss before training is 5.43868690035498e-06 -- epoch number 7217\n",
      "\n",
      "\n",
      "loss before training is 5.431974772813737e-06 -- epoch number 7218\n",
      "\n",
      "\n",
      "loss before training is 5.425271692668336e-06 -- epoch number 7219\n",
      "\n",
      "\n",
      "loss before training is 5.418577646894748e-06 -- epoch number 7220\n",
      "\n",
      "\n",
      "loss before training is 5.411892622487616e-06 -- epoch number 7221\n",
      "\n",
      "\n",
      "loss before training is 5.4052166064623485e-06 -- epoch number 7222\n",
      "\n",
      "\n",
      "loss before training is 5.39854958585216e-06 -- epoch number 7223\n",
      "\n",
      "\n",
      "loss before training is 5.391891547711289e-06 -- epoch number 7224\n",
      "\n",
      "\n",
      "loss before training is 5.385242479111949e-06 -- epoch number 7225\n",
      "\n",
      "\n",
      "loss before training is 5.378602367147031e-06 -- epoch number 7226\n",
      "\n",
      "\n",
      "loss before training is 5.371971198927003e-06 -- epoch number 7227\n",
      "\n",
      "\n",
      "loss before training is 5.365348961583495e-06 -- epoch number 7228\n",
      "\n",
      "\n",
      "loss before training is 5.358735642266345e-06 -- epoch number 7229\n",
      "\n",
      "\n",
      "loss before training is 5.35213122814445e-06 -- epoch number 7230\n",
      "\n",
      "\n",
      "loss before training is 5.3455357064068185e-06 -- epoch number 7231\n",
      "\n",
      "\n",
      "loss before training is 5.33894906426112e-06 -- epoch number 7232\n",
      "\n",
      "\n",
      "loss before training is 5.332371288933182e-06 -- epoch number 7233\n",
      "\n",
      "\n",
      "loss before training is 5.325802367669751e-06 -- epoch number 7234\n",
      "\n",
      "\n",
      "loss before training is 5.3192422877357985e-06 -- epoch number 7235\n",
      "\n",
      "\n",
      "loss before training is 5.312691036414522e-06 -- epoch number 7236\n",
      "\n",
      "\n",
      "loss before training is 5.306148601009634e-06 -- epoch number 7237\n",
      "\n",
      "\n",
      "loss before training is 5.299614968842859e-06 -- epoch number 7238\n",
      "\n",
      "\n",
      "loss before training is 5.293090127255482e-06 -- epoch number 7239\n",
      "\n",
      "\n",
      "loss before training is 5.286574063607305e-06 -- epoch number 7240\n",
      "\n",
      "\n",
      "loss before training is 5.280066765277019e-06 -- epoch number 7241\n",
      "\n",
      "\n",
      "loss before training is 5.273568219662444e-06 -- epoch number 7242\n",
      "\n",
      "\n",
      "loss before training is 5.26707841417999e-06 -- epoch number 7243\n",
      "\n",
      "\n",
      "loss before training is 5.260597336264972e-06 -- epoch number 7244\n",
      "\n",
      "\n",
      "loss before training is 5.2541249733723126e-06 -- epoch number 7245\n",
      "\n",
      "\n",
      "loss before training is 5.247661312973697e-06 -- epoch number 7246\n",
      "\n",
      "\n",
      "loss before training is 5.241206342561778e-06 -- epoch number 7247\n",
      "\n",
      "\n",
      "loss before training is 5.234760049646632e-06 -- epoch number 7248\n",
      "\n",
      "\n",
      "loss before training is 5.228322421757289e-06 -- epoch number 7249\n",
      "\n",
      "\n",
      "loss before training is 5.221893446441762e-06 -- epoch number 7250\n",
      "\n",
      "\n",
      "loss before training is 5.215473111265909e-06 -- epoch number 7251\n",
      "\n",
      "\n",
      "loss before training is 5.209061403815299e-06 -- epoch number 7252\n",
      "\n",
      "\n",
      "loss before training is 5.202658311692615e-06 -- epoch number 7253\n",
      "\n",
      "\n",
      "loss before training is 5.196263822520603e-06 -- epoch number 7254\n",
      "\n",
      "\n",
      "loss before training is 5.189877923939594e-06 -- epoch number 7255\n",
      "\n",
      "\n",
      "loss before training is 5.183500603608227e-06 -- epoch number 7256\n",
      "\n",
      "\n",
      "loss before training is 5.1771318492047175e-06 -- epoch number 7257\n",
      "\n",
      "\n",
      "loss before training is 5.170771648424464e-06 -- epoch number 7258\n",
      "\n",
      "\n",
      "loss before training is 5.1644199889824084e-06 -- epoch number 7259\n",
      "\n",
      "\n",
      "loss before training is 5.1580768586103985e-06 -- epoch number 7260\n",
      "\n",
      "\n",
      "loss before training is 5.1517422450597285e-06 -- epoch number 7261\n",
      "\n",
      "\n",
      "loss before training is 5.1454161361004e-06 -- epoch number 7262\n",
      "\n",
      "\n",
      "loss before training is 5.139098519519038e-06 -- epoch number 7263\n",
      "\n",
      "\n",
      "loss before training is 5.1327893831220815e-06 -- epoch number 7264\n",
      "\n",
      "\n",
      "loss before training is 5.126488714734011e-06 -- epoch number 7265\n",
      "\n",
      "\n",
      "loss before training is 5.120196502196788e-06 -- epoch number 7266\n",
      "\n",
      "\n",
      "loss before training is 5.113912733371151e-06 -- epoch number 7267\n",
      "\n",
      "\n",
      "loss before training is 5.107637396135209e-06 -- epoch number 7268\n",
      "\n",
      "\n",
      "loss before training is 5.10137047838633e-06 -- epoch number 7269\n",
      "\n",
      "\n",
      "loss before training is 5.095111968038657e-06 -- epoch number 7270\n",
      "\n",
      "\n",
      "loss before training is 5.088861853026194e-06 -- epoch number 7271\n",
      "\n",
      "\n",
      "loss before training is 5.082620121299252e-06 -- epoch number 7272\n",
      "\n",
      "\n",
      "loss before training is 5.076386760827207e-06 -- epoch number 7273\n",
      "\n",
      "\n",
      "loss before training is 5.0701617595967746e-06 -- epoch number 7274\n",
      "\n",
      "\n",
      "loss before training is 5.063945105612866e-06 -- epoch number 7275\n",
      "\n",
      "\n",
      "loss before training is 5.057736786898763e-06 -- epoch number 7276\n",
      "\n",
      "\n",
      "loss before training is 5.051536791494743e-06 -- epoch number 7277\n",
      "\n",
      "\n",
      "loss before training is 5.045345107460047e-06 -- epoch number 7278\n",
      "\n",
      "\n",
      "loss before training is 5.039161722870462e-06 -- epoch number 7279\n",
      "\n",
      "\n",
      "loss before training is 5.032986625821104e-06 -- epoch number 7280\n",
      "\n",
      "\n",
      "loss before training is 5.026819804423783e-06 -- epoch number 7281\n",
      "\n",
      "\n",
      "loss before training is 5.020661246808319e-06 -- epoch number 7282\n",
      "\n",
      "\n",
      "loss before training is 5.0145109411220394e-06 -- epoch number 7283\n",
      "\n",
      "\n",
      "loss before training is 5.008368875530924e-06 -- epoch number 7284\n",
      "\n",
      "\n",
      "loss before training is 5.002235038218288e-06 -- epoch number 7285\n",
      "\n",
      "\n",
      "loss before training is 4.996109417383523e-06 -- epoch number 7286\n",
      "\n",
      "\n",
      "loss before training is 4.989992001246253e-06 -- epoch number 7287\n",
      "\n",
      "\n",
      "loss before training is 4.9838827780421965e-06 -- epoch number 7288\n",
      "\n",
      "\n",
      "loss before training is 4.9777817360244655e-06 -- epoch number 7289\n",
      "\n",
      "\n",
      "loss before training is 4.97168886346411e-06 -- epoch number 7290\n",
      "\n",
      "\n",
      "loss before training is 4.965604148650374e-06 -- epoch number 7291\n",
      "\n",
      "\n",
      "loss before training is 4.959527579889111e-06 -- epoch number 7292\n",
      "\n",
      "\n",
      "loss before training is 4.953459145503561e-06 -- epoch number 7293\n",
      "\n",
      "\n",
      "loss before training is 4.94739883383509e-06 -- epoch number 7294\n",
      "\n",
      "\n",
      "loss before training is 4.941346633241925e-06 -- epoch number 7295\n",
      "\n",
      "\n",
      "loss before training is 4.935302532100423e-06 -- epoch number 7296\n",
      "\n",
      "\n",
      "loss before training is 4.929266518803625e-06 -- epoch number 7297\n",
      "\n",
      "\n",
      "loss before training is 4.9232385817618145e-06 -- epoch number 7298\n",
      "\n",
      "\n",
      "loss before training is 4.917218709403299e-06 -- epoch number 7299\n",
      "\n",
      "\n",
      "loss before training is 4.911206890172892e-06 -- epoch number 7300\n",
      "\n",
      "\n",
      "loss before training is 4.905203112533397e-06 -- epoch number 7301\n",
      "\n",
      "\n",
      "loss before training is 4.89920736496395e-06 -- epoch number 7302\n",
      "\n",
      "\n",
      "loss before training is 4.893219635962297e-06 -- epoch number 7303\n",
      "\n",
      "\n",
      "loss before training is 4.887239914041787e-06 -- epoch number 7304\n",
      "\n",
      "\n",
      "loss before training is 4.881268187734211e-06 -- epoch number 7305\n",
      "\n",
      "\n",
      "loss before training is 4.875304445587526e-06 -- epoch number 7306\n",
      "\n",
      "\n",
      "loss before training is 4.869348676167463e-06 -- epoch number 7307\n",
      "\n",
      "\n",
      "loss before training is 4.863400868056321e-06 -- epoch number 7308\n",
      "\n",
      "\n",
      "loss before training is 4.857461009854166e-06 -- epoch number 7309\n",
      "\n",
      "\n",
      "loss before training is 4.851529090177239e-06 -- epoch number 7310\n",
      "\n",
      "\n",
      "loss before training is 4.845605097659367e-06 -- epoch number 7311\n",
      "\n",
      "\n",
      "loss before training is 4.83968902095162e-06 -- epoch number 7312\n",
      "\n",
      "\n",
      "loss before training is 4.83378084872073e-06 -- epoch number 7313\n",
      "\n",
      "\n",
      "loss before training is 4.82788056965198e-06 -- epoch number 7314\n",
      "\n",
      "\n",
      "loss before training is 4.821988172446275e-06 -- epoch number 7315\n",
      "\n",
      "\n",
      "loss before training is 4.816103645822452e-06 -- epoch number 7316\n",
      "\n",
      "\n",
      "loss before training is 4.810226978514865e-06 -- epoch number 7317\n",
      "\n",
      "\n",
      "loss before training is 4.804358159276463e-06 -- epoch number 7318\n",
      "\n",
      "\n",
      "loss before training is 4.798497176875548e-06 -- epoch number 7319\n",
      "\n",
      "\n",
      "loss before training is 4.792644020097326e-06 -- epoch number 7320\n",
      "\n",
      "\n",
      "loss before training is 4.786798677744556e-06 -- epoch number 7321\n",
      "\n",
      "\n",
      "loss before training is 4.780961138636077e-06 -- epoch number 7322\n",
      "\n",
      "\n",
      "loss before training is 4.775131391607727e-06 -- epoch number 7323\n",
      "\n",
      "\n",
      "loss before training is 4.76930942551201e-06 -- epoch number 7324\n",
      "\n",
      "\n",
      "loss before training is 4.763495229217848e-06 -- epoch number 7325\n",
      "\n",
      "\n",
      "loss before training is 4.757688791610499e-06 -- epoch number 7326\n",
      "\n",
      "\n",
      "loss before training is 4.751890101592925e-06 -- epoch number 7327\n",
      "\n",
      "\n",
      "loss before training is 4.746099148083275e-06 -- epoch number 7328\n",
      "\n",
      "\n",
      "loss before training is 4.740315920017583e-06 -- epoch number 7329\n",
      "\n",
      "\n",
      "loss before training is 4.734540406347441e-06 -- epoch number 7330\n",
      "\n",
      "\n",
      "loss before training is 4.728772596041089e-06 -- epoch number 7331\n",
      "\n",
      "\n",
      "loss before training is 4.723012478083606e-06 -- epoch number 7332\n",
      "\n",
      "\n",
      "loss before training is 4.717260041476324e-06 -- epoch number 7333\n",
      "\n",
      "\n",
      "loss before training is 4.7115152752369195e-06 -- epoch number 7334\n",
      "\n",
      "\n",
      "loss before training is 4.705778168399177e-06 -- epoch number 7335\n",
      "\n",
      "\n",
      "loss before training is 4.700048710014132e-06 -- epoch number 7336\n",
      "\n",
      "\n",
      "loss before training is 4.694326889148458e-06 -- epoch number 7337\n",
      "\n",
      "\n",
      "loss before training is 4.688612694885009e-06 -- epoch number 7338\n",
      "\n",
      "\n",
      "loss before training is 4.682906116323711e-06 -- epoch number 7339\n",
      "\n",
      "\n",
      "loss before training is 4.6772071425804265e-06 -- epoch number 7340\n",
      "\n",
      "\n",
      "loss before training is 4.671515762786451e-06 -- epoch number 7341\n",
      "\n",
      "\n",
      "loss before training is 4.665831966090341e-06 -- epoch number 7342\n",
      "\n",
      "\n",
      "loss before training is 4.660155741656882e-06 -- epoch number 7343\n",
      "\n",
      "\n",
      "loss before training is 4.654487078665938e-06 -- epoch number 7344\n",
      "\n",
      "\n",
      "loss before training is 4.648825966315102e-06 -- epoch number 7345\n",
      "\n",
      "\n",
      "loss before training is 4.6431723938164e-06 -- epoch number 7346\n",
      "\n",
      "\n",
      "loss before training is 4.637526350399216e-06 -- epoch number 7347\n",
      "\n",
      "\n",
      "loss before training is 4.631887825308596e-06 -- epoch number 7348\n",
      "\n",
      "\n",
      "loss before training is 4.62625680780596e-06 -- epoch number 7349\n",
      "\n",
      "\n",
      "loss before training is 4.6206332871673386e-06 -- epoch number 7350\n",
      "\n",
      "\n",
      "loss before training is 4.615017252686551e-06 -- epoch number 7351\n",
      "\n",
      "\n",
      "loss before training is 4.609408693673011e-06 -- epoch number 7352\n",
      "\n",
      "\n",
      "loss before training is 4.603807599451262e-06 -- epoch number 7353\n",
      "\n",
      "\n",
      "loss before training is 4.598213959362555e-06 -- epoch number 7354\n",
      "\n",
      "\n",
      "loss before training is 4.5926277627637395e-06 -- epoch number 7355\n",
      "\n",
      "\n",
      "loss before training is 4.587048999027222e-06 -- epoch number 7356\n",
      "\n",
      "\n",
      "loss before training is 4.581477657542145e-06 -- epoch number 7357\n",
      "\n",
      "\n",
      "loss before training is 4.575913727712722e-06 -- epoch number 7358\n",
      "\n",
      "\n",
      "loss before training is 4.57035719895903e-06 -- epoch number 7359\n",
      "\n",
      "\n",
      "loss before training is 4.564808060717453e-06 -- epoch number 7360\n",
      "\n",
      "\n",
      "loss before training is 4.5592663024397105e-06 -- epoch number 7361\n",
      "\n",
      "\n",
      "loss before training is 4.553731913593142e-06 -- epoch number 7362\n",
      "\n",
      "\n",
      "loss before training is 4.548204883661723e-06 -- epoch number 7363\n",
      "\n",
      "\n",
      "loss before training is 4.542685202143676e-06 -- epoch number 7364\n",
      "\n",
      "\n",
      "loss before training is 4.537172858553442e-06 -- epoch number 7365\n",
      "\n",
      "\n",
      "loss before training is 4.531667842422129e-06 -- epoch number 7366\n",
      "\n",
      "\n",
      "loss before training is 4.526170143295241e-06 -- epoch number 7367\n",
      "\n",
      "\n",
      "loss before training is 4.520679750733895e-06 -- epoch number 7368\n",
      "\n",
      "\n",
      "loss before training is 4.515196654315602e-06 -- epoch number 7369\n",
      "\n",
      "\n",
      "loss before training is 4.509720843632869e-06 -- epoch number 7370\n",
      "\n",
      "\n",
      "loss before training is 4.504252308293703e-06 -- epoch number 7371\n",
      "\n",
      "\n",
      "loss before training is 4.498791037921925e-06 -- epoch number 7372\n",
      "\n",
      "\n",
      "loss before training is 4.493337022156352e-06 -- epoch number 7373\n",
      "\n",
      "\n",
      "loss before training is 4.487890250651851e-06 -- epoch number 7374\n",
      "\n",
      "\n",
      "loss before training is 4.482450713078224e-06 -- epoch number 7375\n",
      "\n",
      "\n",
      "loss before training is 4.477018399121013e-06 -- epoch number 7376\n",
      "\n",
      "\n",
      "loss before training is 4.4715932984807655e-06 -- epoch number 7377\n",
      "\n",
      "\n",
      "loss before training is 4.466175400873809e-06 -- epoch number 7378\n",
      "\n",
      "\n",
      "loss before training is 4.460764696031219e-06 -- epoch number 7379\n",
      "\n",
      "\n",
      "loss before training is 4.4553611737004524e-06 -- epoch number 7380\n",
      "\n",
      "\n",
      "loss before training is 4.449964823643023e-06 -- epoch number 7381\n",
      "\n",
      "\n",
      "loss before training is 4.444575635636616e-06 -- epoch number 7382\n",
      "\n",
      "\n",
      "loss before training is 4.439193599473775e-06 -- epoch number 7383\n",
      "\n",
      "\n",
      "loss before training is 4.433818704961972e-06 -- epoch number 7384\n",
      "\n",
      "\n",
      "loss before training is 4.428450941925098e-06 -- epoch number 7385\n",
      "\n",
      "\n",
      "loss before training is 4.423090300200072e-06 -- epoch number 7386\n",
      "\n",
      "\n",
      "loss before training is 4.4177367696412115e-06 -- epoch number 7387\n",
      "\n",
      "\n",
      "loss before training is 4.4123903401165115e-06 -- epoch number 7388\n",
      "\n",
      "\n",
      "loss before training is 4.407051001509921e-06 -- epoch number 7389\n",
      "\n",
      "\n",
      "loss before training is 4.401718743719414e-06 -- epoch number 7390\n",
      "\n",
      "\n",
      "loss before training is 4.396393556659392e-06 -- epoch number 7391\n",
      "\n",
      "\n",
      "loss before training is 4.391075430258116e-06 -- epoch number 7392\n",
      "\n",
      "\n",
      "loss before training is 4.385764354459691e-06 -- epoch number 7393\n",
      "\n",
      "\n",
      "loss before training is 4.38046031922305e-06 -- epoch number 7394\n",
      "\n",
      "\n",
      "loss before training is 4.375163314520898e-06 -- epoch number 7395\n",
      "\n",
      "\n",
      "loss before training is 4.369873330342907e-06 -- epoch number 7396\n",
      "\n",
      "\n",
      "loss before training is 4.364590356692635e-06 -- epoch number 7397\n",
      "\n",
      "\n",
      "loss before training is 4.3593143835881595e-06 -- epoch number 7398\n",
      "\n",
      "\n",
      "loss before training is 4.354045401062756e-06 -- epoch number 7399\n",
      "\n",
      "\n",
      "loss before training is 4.348783399164983e-06 -- epoch number 7400\n",
      "\n",
      "\n",
      "loss before training is 4.343528367957912e-06 -- epoch number 7401\n",
      "\n",
      "\n",
      "loss before training is 4.338280297519142e-06 -- epoch number 7402\n",
      "\n",
      "\n",
      "loss before training is 4.333039177941227e-06 -- epoch number 7403\n",
      "\n",
      "\n",
      "loss before training is 4.327804999332201e-06 -- epoch number 7404\n",
      "\n",
      "\n",
      "loss before training is 4.3225777518138184e-06 -- epoch number 7405\n",
      "\n",
      "\n",
      "loss before training is 4.3173574255227705e-06 -- epoch number 7406\n",
      "\n",
      "\n",
      "loss before training is 4.3121440106108115e-06 -- epoch number 7407\n",
      "\n",
      "\n",
      "loss before training is 4.306937497244443e-06 -- epoch number 7408\n",
      "\n",
      "\n",
      "loss before training is 4.301737875604122e-06 -- epoch number 7409\n",
      "\n",
      "\n",
      "loss before training is 4.296545135885838e-06 -- epoch number 7410\n",
      "\n",
      "\n",
      "loss before training is 4.291359268299357e-06 -- epoch number 7411\n",
      "\n",
      "\n",
      "loss before training is 4.286180263069484e-06 -- epoch number 7412\n",
      "\n",
      "\n",
      "loss before training is 4.281008110435602e-06 -- epoch number 7413\n",
      "\n",
      "\n",
      "loss before training is 4.27584280065187e-06 -- epoch number 7414\n",
      "\n",
      "\n",
      "loss before training is 4.27068432398594e-06 -- epoch number 7415\n",
      "\n",
      "\n",
      "loss before training is 4.2655326707210955e-06 -- epoch number 7416\n",
      "\n",
      "\n",
      "loss before training is 4.260387831154984e-06 -- epoch number 7417\n",
      "\n",
      "\n",
      "loss before training is 4.2552497955986116e-06 -- epoch number 7418\n",
      "\n",
      "\n",
      "loss before training is 4.2501185543788765e-06 -- epoch number 7419\n",
      "\n",
      "\n",
      "loss before training is 4.244994097836071e-06 -- epoch number 7420\n",
      "\n",
      "\n",
      "loss before training is 4.239876416325377e-06 -- epoch number 7421\n",
      "\n",
      "\n",
      "loss before training is 4.234765500215969e-06 -- epoch number 7422\n",
      "\n",
      "\n",
      "loss before training is 4.229661339891702e-06 -- epoch number 7423\n",
      "\n",
      "\n",
      "loss before training is 4.224563925750838e-06 -- epoch number 7424\n",
      "\n",
      "\n",
      "loss before training is 4.219473248205326e-06 -- epoch number 7425\n",
      "\n",
      "\n",
      "loss before training is 4.214389297682084e-06 -- epoch number 7426\n",
      "\n",
      "\n",
      "loss before training is 4.20931206462188e-06 -- epoch number 7427\n",
      "\n",
      "\n",
      "loss before training is 4.204241539480191e-06 -- epoch number 7428\n",
      "\n",
      "\n",
      "loss before training is 4.199177712725721e-06 -- epoch number 7429\n",
      "\n",
      "\n",
      "loss before training is 4.194120574842673e-06 -- epoch number 7430\n",
      "\n",
      "\n",
      "loss before training is 4.189070116328173e-06 -- epoch number 7431\n",
      "\n",
      "\n",
      "loss before training is 4.184026327694115e-06 -- epoch number 7432\n",
      "\n",
      "\n",
      "loss before training is 4.178989199467045e-06 -- epoch number 7433\n",
      "\n",
      "\n",
      "loss before training is 4.173958722186424e-06 -- epoch number 7434\n",
      "\n",
      "\n",
      "loss before training is 4.1689348864071126e-06 -- epoch number 7435\n",
      "\n",
      "\n",
      "loss before training is 4.163917682696557e-06 -- epoch number 7436\n",
      "\n",
      "\n",
      "loss before training is 4.158907101637772e-06 -- epoch number 7437\n",
      "\n",
      "\n",
      "loss before training is 4.153903133826595e-06 -- epoch number 7438\n",
      "\n",
      "\n",
      "loss before training is 4.148905769873697e-06 -- epoch number 7439\n",
      "\n",
      "\n",
      "loss before training is 4.143915000402603e-06 -- epoch number 7440\n",
      "\n",
      "\n",
      "loss before training is 4.138930816052515e-06 -- epoch number 7441\n",
      "\n",
      "\n",
      "loss before training is 4.133953207475168e-06 -- epoch number 7442\n",
      "\n",
      "\n",
      "loss before training is 4.128982165336525e-06 -- epoch number 7443\n",
      "\n",
      "\n",
      "loss before training is 4.124017680316993e-06 -- epoch number 7444\n",
      "\n",
      "\n",
      "loss before training is 4.119059743109818e-06 -- epoch number 7445\n",
      "\n",
      "\n",
      "loss before training is 4.114108344423548e-06 -- epoch number 7446\n",
      "\n",
      "\n",
      "loss before training is 4.109163474978809e-06 -- epoch number 7447\n",
      "\n",
      "\n",
      "loss before training is 4.1042251255113995e-06 -- epoch number 7448\n",
      "\n",
      "\n",
      "loss before training is 4.099293286770395e-06 -- epoch number 7449\n",
      "\n",
      "\n",
      "loss before training is 4.094367949519205e-06 -- epoch number 7450\n",
      "\n",
      "\n",
      "loss before training is 4.089449104533608e-06 -- epoch number 7451\n",
      "\n",
      "\n",
      "loss before training is 4.084536742604844e-06 -- epoch number 7452\n",
      "\n",
      "\n",
      "loss before training is 4.079630854536136e-06 -- epoch number 7453\n",
      "\n",
      "\n",
      "loss before training is 4.0747314311457705e-06 -- epoch number 7454\n",
      "\n",
      "\n",
      "loss before training is 4.069838463265455e-06 -- epoch number 7455\n",
      "\n",
      "\n",
      "loss before training is 4.064951941739551e-06 -- epoch number 7456\n",
      "\n",
      "\n",
      "loss before training is 4.060071857427157e-06 -- epoch number 7457\n",
      "\n",
      "\n",
      "loss before training is 4.0551982012008394e-06 -- epoch number 7458\n",
      "\n",
      "\n",
      "loss before training is 4.050330963945992e-06 -- epoch number 7459\n",
      "\n",
      "\n",
      "loss before training is 4.045470136562291e-06 -- epoch number 7460\n",
      "\n",
      "\n",
      "loss before training is 4.04061570996271e-06 -- epoch number 7461\n",
      "\n",
      "\n",
      "loss before training is 4.035767675073578e-06 -- epoch number 7462\n",
      "\n",
      "\n",
      "loss before training is 4.0309260228352604e-06 -- epoch number 7463\n",
      "\n",
      "\n",
      "loss before training is 4.0260907442009736e-06 -- epoch number 7464\n",
      "\n",
      "\n",
      "loss before training is 4.021261830137728e-06 -- epoch number 7465\n",
      "\n",
      "\n",
      "loss before training is 4.0164392716261454e-06 -- epoch number 7466\n",
      "\n",
      "\n",
      "loss before training is 4.011623059659199e-06 -- epoch number 7467\n",
      "\n",
      "\n",
      "loss before training is 4.006813185244961e-06 -- epoch number 7468\n",
      "\n",
      "\n",
      "loss before training is 4.002009639403357e-06 -- epoch number 7469\n",
      "\n",
      "\n",
      "loss before training is 3.997212413168986e-06 -- epoch number 7470\n",
      "\n",
      "\n",
      "loss before training is 3.992421497588234e-06 -- epoch number 7471\n",
      "\n",
      "\n",
      "loss before training is 3.987636883722327e-06 -- epoch number 7472\n",
      "\n",
      "\n",
      "loss before training is 3.982858562645249e-06 -- epoch number 7473\n",
      "\n",
      "\n",
      "loss before training is 3.97808652544354e-06 -- epoch number 7474\n",
      "\n",
      "\n",
      "loss before training is 3.973320763217929e-06 -- epoch number 7475\n",
      "\n",
      "\n",
      "loss before training is 3.968561267081888e-06 -- epoch number 7476\n",
      "\n",
      "\n",
      "loss before training is 3.963808028162628e-06 -- epoch number 7477\n",
      "\n",
      "\n",
      "loss before training is 3.959061037599684e-06 -- epoch number 7478\n",
      "\n",
      "\n",
      "loss before training is 3.954320286546605e-06 -- epoch number 7479\n",
      "\n",
      "\n",
      "loss before training is 3.9495857661694e-06 -- epoch number 7480\n",
      "\n",
      "\n",
      "loss before training is 3.9448574676479956e-06 -- epoch number 7481\n",
      "\n",
      "\n",
      "loss before training is 3.940135382174821e-06 -- epoch number 7482\n",
      "\n",
      "\n",
      "loss before training is 3.935419500955303e-06 -- epoch number 7483\n",
      "\n",
      "\n",
      "loss before training is 3.930709815208482e-06 -- epoch number 7484\n",
      "\n",
      "\n",
      "loss before training is 3.926006316166713e-06 -- epoch number 7485\n",
      "\n",
      "\n",
      "loss before training is 3.92130899507383e-06 -- epoch number 7486\n",
      "\n",
      "\n",
      "loss before training is 3.916617843188311e-06 -- epoch number 7487\n",
      "\n",
      "\n",
      "loss before training is 3.911932851780812e-06 -- epoch number 7488\n",
      "\n",
      "\n",
      "loss before training is 3.907254012135187e-06 -- epoch number 7489\n",
      "\n",
      "\n",
      "loss before training is 3.902581315548673e-06 -- epoch number 7490\n",
      "\n",
      "\n",
      "loss before training is 3.89791475333037e-06 -- epoch number 7491\n",
      "\n",
      "\n",
      "loss before training is 3.893254316803236e-06 -- epoch number 7492\n",
      "\n",
      "\n",
      "loss before training is 3.888599997303178e-06 -- epoch number 7493\n",
      "\n",
      "\n",
      "loss before training is 3.88395178617788e-06 -- epoch number 7494\n",
      "\n",
      "\n",
      "loss before training is 3.879309674789224e-06 -- epoch number 7495\n",
      "\n",
      "\n",
      "loss before training is 3.874673654510761e-06 -- epoch number 7496\n",
      "\n",
      "\n",
      "loss before training is 3.870043716730121e-06 -- epoch number 7497\n",
      "\n",
      "\n",
      "loss before training is 3.8654198528464806e-06 -- epoch number 7498\n",
      "\n",
      "\n",
      "loss before training is 3.860802054272851e-06 -- epoch number 7499\n",
      "\n",
      "\n",
      "loss before training is 3.856190312434152e-06 -- epoch number 7500\n",
      "\n",
      "\n",
      "loss before training is 3.851584618768385e-06 -- epoch number 7501\n",
      "\n",
      "\n",
      "loss before training is 3.846984964726359e-06 -- epoch number 7502\n",
      "\n",
      "\n",
      "loss before training is 3.8423913417716145e-06 -- epoch number 7503\n",
      "\n",
      "\n",
      "loss before training is 3.837803741380174e-06 -- epoch number 7504\n",
      "\n",
      "\n",
      "loss before training is 3.833222155040925e-06 -- epoch number 7505\n",
      "\n",
      "\n",
      "loss before training is 3.828646574255325e-06 -- epoch number 7506\n",
      "\n",
      "\n",
      "loss before training is 3.824076990537075e-06 -- epoch number 7507\n",
      "\n",
      "\n",
      "loss before training is 3.819513395413198e-06 -- epoch number 7508\n",
      "\n",
      "\n",
      "loss before training is 3.8149557804227355e-06 -- epoch number 7509\n",
      "\n",
      "\n",
      "loss before training is 3.810404137117618e-06 -- epoch number 7510\n",
      "\n",
      "\n",
      "loss before training is 3.8058584570624562e-06 -- epoch number 7511\n",
      "\n",
      "\n",
      "loss before training is 3.801318731833368e-06 -- epoch number 7512\n",
      "\n",
      "\n",
      "loss before training is 3.7967849530205123e-06 -- epoch number 7513\n",
      "\n",
      "\n",
      "loss before training is 3.792257112225245e-06 -- epoch number 7514\n",
      "\n",
      "\n",
      "loss before training is 3.787735201062616e-06 -- epoch number 7515\n",
      "\n",
      "\n",
      "loss before training is 3.7832192111589673e-06 -- epoch number 7516\n",
      "\n",
      "\n",
      "loss before training is 3.778709134153182e-06 -- epoch number 7517\n",
      "\n",
      "\n",
      "loss before training is 3.7742049616979606e-06 -- epoch number 7518\n",
      "\n",
      "\n",
      "loss before training is 3.7697066854562214e-06 -- epoch number 7519\n",
      "\n",
      "\n",
      "loss before training is 3.7652142971049343e-06 -- epoch number 7520\n",
      "\n",
      "\n",
      "loss before training is 3.7607277883328304e-06 -- epoch number 7521\n",
      "\n",
      "\n",
      "loss before training is 3.7562471508412857e-06 -- epoch number 7522\n",
      "\n",
      "\n",
      "loss before training is 3.7517723763434803e-06 -- epoch number 7523\n",
      "\n",
      "\n",
      "loss before training is 3.747303456565265e-06 -- epoch number 7524\n",
      "\n",
      "\n",
      "loss before training is 3.7428403832445533e-06 -- epoch number 7525\n",
      "\n",
      "\n",
      "loss before training is 3.7383831481318965e-06 -- epoch number 7526\n",
      "\n",
      "\n",
      "loss before training is 3.733931742989665e-06 -- epoch number 7527\n",
      "\n",
      "\n",
      "loss before training is 3.7294861595924914e-06 -- epoch number 7528\n",
      "\n",
      "\n",
      "loss before training is 3.7250463897277194e-06 -- epoch number 7529\n",
      "\n",
      "\n",
      "loss before training is 3.7206124251944695e-06 -- epoch number 7530\n",
      "\n",
      "\n",
      "loss before training is 3.716184257803761e-06 -- epoch number 7531\n",
      "\n",
      "\n",
      "loss before training is 3.7117618793793438e-06 -- epoch number 7532\n",
      "\n",
      "\n",
      "loss before training is 3.707345281756798e-06 -- epoch number 7533\n",
      "\n",
      "\n",
      "loss before training is 3.7029344567838293e-06 -- epoch number 7534\n",
      "\n",
      "\n",
      "loss before training is 3.6985293963206254e-06 -- epoch number 7535\n",
      "\n",
      "\n",
      "loss before training is 3.694130092238944e-06 -- epoch number 7536\n",
      "\n",
      "\n",
      "loss before training is 3.6897365364221104e-06 -- epoch number 7537\n",
      "\n",
      "\n",
      "loss before training is 3.685348720767271e-06 -- epoch number 7538\n",
      "\n",
      "\n",
      "loss before training is 3.680966637181626e-06 -- epoch number 7539\n",
      "\n",
      "\n",
      "loss before training is 3.676590277585892e-06 -- epoch number 7540\n",
      "\n",
      "\n",
      "loss before training is 3.6722196339117794e-06 -- epoch number 7541\n",
      "\n",
      "\n",
      "loss before training is 3.6678546981029537e-06 -- epoch number 7542\n",
      "\n",
      "\n",
      "loss before training is 3.663495462116172e-06 -- epoch number 7543\n",
      "\n",
      "\n",
      "loss before training is 3.6591419179186442e-06 -- epoch number 7544\n",
      "\n",
      "\n",
      "loss before training is 3.6547940574905914e-06 -- epoch number 7545\n",
      "\n",
      "\n",
      "loss before training is 3.6504518728237446e-06 -- epoch number 7546\n",
      "\n",
      "\n",
      "loss before training is 3.6461153559213965e-06 -- epoch number 7547\n",
      "\n",
      "\n",
      "loss before training is 3.641784498799579e-06 -- epoch number 7548\n",
      "\n",
      "\n",
      "loss before training is 3.6374592934848594e-06 -- epoch number 7549\n",
      "\n",
      "\n",
      "loss before training is 3.633139732016669e-06 -- epoch number 7550\n",
      "\n",
      "\n",
      "loss before training is 3.6288258064464657e-06 -- epoch number 7551\n",
      "\n",
      "\n",
      "loss before training is 3.6245175088362538e-06 -- epoch number 7552\n",
      "\n",
      "\n",
      "loss before training is 3.620214831260664e-06 -- epoch number 7553\n",
      "\n",
      "\n",
      "loss before training is 3.6159177658063605e-06 -- epoch number 7554\n",
      "\n",
      "\n",
      "loss before training is 3.6116263045710086e-06 -- epoch number 7555\n",
      "\n",
      "\n",
      "loss before training is 3.6073404396641022e-06 -- epoch number 7556\n",
      "\n",
      "\n",
      "loss before training is 3.603060163207676e-06 -- epoch number 7557\n",
      "\n",
      "\n",
      "loss before training is 3.5987854673339674e-06 -- epoch number 7558\n",
      "\n",
      "\n",
      "loss before training is 3.594516344188543e-06 -- epoch number 7559\n",
      "\n",
      "\n",
      "loss before training is 3.5902527859272752e-06 -- epoch number 7560\n",
      "\n",
      "\n",
      "loss before training is 3.5859947847183646e-06 -- epoch number 7561\n",
      "\n",
      "\n",
      "loss before training is 3.581742332741453e-06 -- epoch number 7562\n",
      "\n",
      "\n",
      "loss before training is 3.57749542218812e-06 -- epoch number 7563\n",
      "\n",
      "\n",
      "loss before training is 3.573254045260403e-06 -- epoch number 7564\n",
      "\n",
      "\n",
      "loss before training is 3.5690181941732324e-06 -- epoch number 7565\n",
      "\n",
      "\n",
      "loss before training is 3.564787861152306e-06 -- epoch number 7566\n",
      "\n",
      "\n",
      "loss before training is 3.5605630384348796e-06 -- epoch number 7567\n",
      "\n",
      "\n",
      "loss before training is 3.5563437182700973e-06 -- epoch number 7568\n",
      "\n",
      "\n",
      "loss before training is 3.5521298929184597e-06 -- epoch number 7569\n",
      "\n",
      "\n",
      "loss before training is 3.5479215546520074e-06 -- epoch number 7570\n",
      "\n",
      "\n",
      "loss before training is 3.5437186957536334e-06 -- epoch number 7571\n",
      "\n",
      "\n",
      "loss before training is 3.539521308518541e-06 -- epoch number 7572\n",
      "\n",
      "\n",
      "loss before training is 3.535329385252461e-06 -- epoch number 7573\n",
      "\n",
      "\n",
      "loss before training is 3.5311429182736027e-06 -- epoch number 7574\n",
      "\n",
      "\n",
      "loss before training is 3.5269618999101456e-06 -- epoch number 7575\n",
      "\n",
      "\n",
      "loss before training is 3.52278632250292e-06 -- epoch number 7576\n",
      "\n",
      "\n",
      "loss before training is 3.51861617840385e-06 -- epoch number 7577\n",
      "\n",
      "\n",
      "loss before training is 3.5144514599754797e-06 -- epoch number 7578\n",
      "\n",
      "\n",
      "loss before training is 3.5102921595923057e-06 -- epoch number 7579\n",
      "\n",
      "\n",
      "loss before training is 3.5061382696400715e-06 -- epoch number 7580\n",
      "\n",
      "\n",
      "loss before training is 3.5019897825156975e-06 -- epoch number 7581\n",
      "\n",
      "\n",
      "loss before training is 3.497846690627557e-06 -- epoch number 7582\n",
      "\n",
      "\n",
      "loss before training is 3.493708986394483e-06 -- epoch number 7583\n",
      "\n",
      "\n",
      "loss before training is 3.4895766622476164e-06 -- epoch number 7584\n",
      "\n",
      "\n",
      "loss before training is 3.4854497106283924e-06 -- epoch number 7585\n",
      "\n",
      "\n",
      "loss before training is 3.4813281239906394e-06 -- epoch number 7586\n",
      "\n",
      "\n",
      "loss before training is 3.4772118947979153e-06 -- epoch number 7587\n",
      "\n",
      "\n",
      "loss before training is 3.473101015525848e-06 -- epoch number 7588\n",
      "\n",
      "\n",
      "loss before training is 3.468995478660912e-06 -- epoch number 7589\n",
      "\n",
      "\n",
      "loss before training is 3.4648952767008586e-06 -- epoch number 7590\n",
      "\n",
      "\n",
      "loss before training is 3.4608004021543823e-06 -- epoch number 7591\n",
      "\n",
      "\n",
      "loss before training is 3.456710847541789e-06 -- epoch number 7592\n",
      "\n",
      "\n",
      "loss before training is 3.4526266053933655e-06 -- epoch number 7593\n",
      "\n",
      "\n",
      "loss before training is 3.4485476682514983e-06 -- epoch number 7594\n",
      "\n",
      "\n",
      "loss before training is 3.4444740286690764e-06 -- epoch number 7595\n",
      "\n",
      "\n",
      "loss before training is 3.440405679210292e-06 -- epoch number 7596\n",
      "\n",
      "\n",
      "loss before training is 3.436342612450184e-06 -- epoch number 7597\n",
      "\n",
      "\n",
      "loss before training is 3.4322848209746805e-06 -- epoch number 7598\n",
      "\n",
      "\n",
      "loss before training is 3.4282322973811295e-06 -- epoch number 7599\n",
      "\n",
      "\n",
      "loss before training is 3.4241850342776564e-06 -- epoch number 7600\n",
      "\n",
      "\n",
      "loss before training is 3.4201430242826937e-06 -- epoch number 7601\n",
      "\n",
      "\n",
      "loss before training is 3.4161062600263686e-06 -- epoch number 7602\n",
      "\n",
      "\n",
      "loss before training is 3.4120747341497206e-06 -- epoch number 7603\n",
      "\n",
      "\n",
      "loss before training is 3.4080484393037124e-06 -- epoch number 7604\n",
      "\n",
      "\n",
      "loss before training is 3.4040273681519163e-06 -- epoch number 7605\n",
      "\n",
      "\n",
      "loss before training is 3.4000115133670543e-06 -- epoch number 7606\n",
      "\n",
      "\n",
      "loss before training is 3.3960008676332753e-06 -- epoch number 7607\n",
      "\n",
      "\n",
      "loss before training is 3.391995423646257e-06 -- epoch number 7608\n",
      "\n",
      "\n",
      "loss before training is 3.387995174111324e-06 -- epoch number 7609\n",
      "\n",
      "\n",
      "loss before training is 3.384000111745678e-06 -- epoch number 7610\n",
      "\n",
      "\n",
      "loss before training is 3.3800102292762695e-06 -- epoch number 7611\n",
      "\n",
      "\n",
      "loss before training is 3.3760255194416623e-06 -- epoch number 7612\n",
      "\n",
      "\n",
      "loss before training is 3.372045974990582e-06 -- epoch number 7613\n",
      "\n",
      "\n",
      "loss before training is 3.3680715886829303e-06 -- epoch number 7614\n",
      "\n",
      "\n",
      "loss before training is 3.3641023532888608e-06 -- epoch number 7615\n",
      "\n",
      "\n",
      "loss before training is 3.360138261589621e-06 -- epoch number 7616\n",
      "\n",
      "\n",
      "loss before training is 3.3561793063771756e-06 -- epoch number 7617\n",
      "\n",
      "\n",
      "loss before training is 3.3522254804537436e-06 -- epoch number 7618\n",
      "\n",
      "\n",
      "loss before training is 3.3482767766326026e-06 -- epoch number 7619\n",
      "\n",
      "\n",
      "loss before training is 3.3443331877371665e-06 -- epoch number 7620\n",
      "\n",
      "\n",
      "loss before training is 3.340394706601927e-06 -- epoch number 7621\n",
      "\n",
      "\n",
      "loss before training is 3.336461326071831e-06 -- epoch number 7622\n",
      "\n",
      "\n",
      "loss before training is 3.3325330390025804e-06 -- epoch number 7623\n",
      "\n",
      "\n",
      "loss before training is 3.328609838259724e-06 -- epoch number 7624\n",
      "\n",
      "\n",
      "loss before training is 3.3246917167202534e-06 -- epoch number 7625\n",
      "\n",
      "\n",
      "loss before training is 3.3207786672714743e-06 -- epoch number 7626\n",
      "\n",
      "\n",
      "loss before training is 3.3168706828106356e-06 -- epoch number 7627\n",
      "\n",
      "\n",
      "loss before training is 3.312967756246227e-06 -- epoch number 7628\n",
      "\n",
      "\n",
      "loss before training is 3.30906988049697e-06 -- epoch number 7629\n",
      "\n",
      "\n",
      "loss before training is 3.3051770484912375e-06 -- epoch number 7630\n",
      "\n",
      "\n",
      "loss before training is 3.3012892531700757e-06 -- epoch number 7631\n",
      "\n",
      "\n",
      "loss before training is 3.297406487482161e-06 -- epoch number 7632\n",
      "\n",
      "\n",
      "loss before training is 3.2935287443883095e-06 -- epoch number 7633\n",
      "\n",
      "\n",
      "loss before training is 3.289656016859805e-06 -- epoch number 7634\n",
      "\n",
      "\n",
      "loss before training is 3.2857882978774183e-06 -- epoch number 7635\n",
      "\n",
      "\n",
      "loss before training is 3.281925580433181e-06 -- epoch number 7636\n",
      "\n",
      "\n",
      "loss before training is 3.2780678575288363e-06 -- epoch number 7637\n",
      "\n",
      "\n",
      "loss before training is 3.274215122176137e-06 -- epoch number 7638\n",
      "\n",
      "\n",
      "loss before training is 3.2703673673987945e-06 -- epoch number 7639\n",
      "\n",
      "\n",
      "loss before training is 3.2665245862290534e-06 -- epoch number 7640\n",
      "\n",
      "\n",
      "loss before training is 3.2626867717102563e-06 -- epoch number 7641\n",
      "\n",
      "\n",
      "loss before training is 3.2588539168961214e-06 -- epoch number 7642\n",
      "\n",
      "\n",
      "loss before training is 3.2550260148506234e-06 -- epoch number 7643\n",
      "\n",
      "\n",
      "loss before training is 3.2512030586471876e-06 -- epoch number 7644\n",
      "\n",
      "\n",
      "loss before training is 3.2473850413705006e-06 -- epoch number 7645\n",
      "\n",
      "\n",
      "loss before training is 3.243571956115234e-06 -- epoch number 7646\n",
      "\n",
      "\n",
      "loss before training is 3.239763795985284e-06 -- epoch number 7647\n",
      "\n",
      "\n",
      "loss before training is 3.2359605540965515e-06 -- epoch number 7648\n",
      "\n",
      "\n",
      "loss before training is 3.232162223573546e-06 -- epoch number 7649\n",
      "\n",
      "\n",
      "loss before training is 3.228368797551511e-06 -- epoch number 7650\n",
      "\n",
      "\n",
      "loss before training is 3.224580269175964e-06 -- epoch number 7651\n",
      "\n",
      "\n",
      "loss before training is 3.220796631602292e-06 -- epoch number 7652\n",
      "\n",
      "\n",
      "loss before training is 3.2170178779958213e-06 -- epoch number 7653\n",
      "\n",
      "\n",
      "loss before training is 3.213244001532681e-06 -- epoch number 7654\n",
      "\n",
      "\n",
      "loss before training is 3.20947499539846e-06 -- epoch number 7655\n",
      "\n",
      "\n",
      "loss before training is 3.20571085278896e-06 -- epoch number 7656\n",
      "\n",
      "\n",
      "loss before training is 3.201951566909784e-06 -- epoch number 7657\n",
      "\n",
      "\n",
      "loss before training is 3.198197130977212e-06 -- epoch number 7658\n",
      "\n",
      "\n",
      "loss before training is 3.1944475382169943e-06 -- epoch number 7659\n",
      "\n",
      "\n",
      "loss before training is 3.1907027818652573e-06 -- epoch number 7660\n",
      "\n",
      "\n",
      "loss before training is 3.18696285516776e-06 -- epoch number 7661\n",
      "\n",
      "\n",
      "loss before training is 3.183227751380256e-06 -- epoch number 7662\n",
      "\n",
      "\n",
      "loss before training is 3.179497463768504e-06 -- epoch number 7663\n",
      "\n",
      "\n",
      "loss before training is 3.1757719856088537e-06 -- epoch number 7664\n",
      "\n",
      "\n",
      "loss before training is 3.1720513101863763e-06 -- epoch number 7665\n",
      "\n",
      "\n",
      "loss before training is 3.168335430796813e-06 -- epoch number 7666\n",
      "\n",
      "\n",
      "loss before training is 3.1646243407462106e-06 -- epoch number 7667\n",
      "\n",
      "\n",
      "loss before training is 3.160918033349302e-06 -- epoch number 7668\n",
      "\n",
      "\n",
      "loss before training is 3.1572165019316283e-06 -- epoch number 7669\n",
      "\n",
      "\n",
      "loss before training is 3.153519739828371e-06 -- epoch number 7670\n",
      "\n",
      "\n",
      "loss before training is 3.1498277403844604e-06 -- epoch number 7671\n",
      "\n",
      "\n",
      "loss before training is 3.146140496954365e-06 -- epoch number 7672\n",
      "\n",
      "\n",
      "loss before training is 3.1424580029031064e-06 -- epoch number 7673\n",
      "\n",
      "\n",
      "loss before training is 3.1387802516047667e-06 -- epoch number 7674\n",
      "\n",
      "\n",
      "loss before training is 3.1351072364436236e-06 -- epoch number 7675\n",
      "\n",
      "\n",
      "loss before training is 3.131438950813313e-06 -- epoch number 7676\n",
      "\n",
      "\n",
      "loss before training is 3.127775388117853e-06 -- epoch number 7677\n",
      "\n",
      "\n",
      "loss before training is 3.1241165417704638e-06 -- epoch number 7678\n",
      "\n",
      "\n",
      "loss before training is 3.1204624051943165e-06 -- epoch number 7679\n",
      "\n",
      "\n",
      "loss before training is 3.116812971822183e-06 -- epoch number 7680\n",
      "\n",
      "\n",
      "loss before training is 3.1131682350964124e-06 -- epoch number 7681\n",
      "\n",
      "\n",
      "loss before training is 3.1095281884694564e-06 -- epoch number 7682\n",
      "\n",
      "\n",
      "loss before training is 3.105892825402648e-06 -- epoch number 7683\n",
      "\n",
      "\n",
      "loss before training is 3.1022621393680815e-06 -- epoch number 7684\n",
      "\n",
      "\n",
      "loss before training is 3.098636123846453e-06 -- epoch number 7685\n",
      "\n",
      "\n",
      "loss before training is 3.09501477232856e-06 -- epoch number 7686\n",
      "\n",
      "\n",
      "loss before training is 3.091398078314863e-06 -- epoch number 7687\n",
      "\n",
      "\n",
      "loss before training is 3.087786035314932e-06 -- epoch number 7688\n",
      "\n",
      "\n",
      "loss before training is 3.0841786368486597e-06 -- epoch number 7689\n",
      "\n",
      "\n",
      "loss before training is 3.080575876444227e-06 -- epoch number 7690\n",
      "\n",
      "\n",
      "loss before training is 3.076977747641606e-06 -- epoch number 7691\n",
      "\n",
      "\n",
      "loss before training is 3.073384243987657e-06 -- epoch number 7692\n",
      "\n",
      "\n",
      "loss before training is 3.069795359040613e-06 -- epoch number 7693\n",
      "\n",
      "\n",
      "loss before training is 3.066211086367188e-06 -- epoch number 7694\n",
      "\n",
      "\n",
      "loss before training is 3.0626314195441893e-06 -- epoch number 7695\n",
      "\n",
      "\n",
      "loss before training is 3.059056352157738e-06 -- epoch number 7696\n",
      "\n",
      "\n",
      "loss before training is 3.055485877803197e-06 -- epoch number 7697\n",
      "\n",
      "\n",
      "loss before training is 3.0519199900854184e-06 -- epoch number 7698\n",
      "\n",
      "\n",
      "loss before training is 3.048358682619071e-06 -- epoch number 7699\n",
      "\n",
      "\n",
      "loss before training is 3.0448019490279633e-06 -- epoch number 7700\n",
      "\n",
      "\n",
      "loss before training is 3.0412497829448214e-06 -- epoch number 7701\n",
      "\n",
      "\n",
      "loss before training is 3.037702178012507e-06 -- epoch number 7702\n",
      "\n",
      "\n",
      "loss before training is 3.0341591278830058e-06 -- epoch number 7703\n",
      "\n",
      "\n",
      "loss before training is 3.030620626217604e-06 -- epoch number 7704\n",
      "\n",
      "\n",
      "loss before training is 3.027086666686947e-06 -- epoch number 7705\n",
      "\n",
      "\n",
      "loss before training is 3.0235572429706043e-06 -- epoch number 7706\n",
      "\n",
      "\n",
      "loss before training is 3.0200323487583506e-06 -- epoch number 7707\n",
      "\n",
      "\n",
      "loss before training is 3.0165119777486437e-06 -- epoch number 7708\n",
      "\n",
      "\n",
      "loss before training is 3.012996123649306e-06 -- epoch number 7709\n",
      "\n",
      "\n",
      "loss before training is 3.0094847801774183e-06 -- epoch number 7710\n",
      "\n",
      "\n",
      "loss before training is 3.0059779410593194e-06 -- epoch number 7711\n",
      "\n",
      "\n",
      "loss before training is 3.0024756000305936e-06 -- epoch number 7712\n",
      "\n",
      "\n",
      "loss before training is 2.998977750836115e-06 -- epoch number 7713\n",
      "\n",
      "\n",
      "loss before training is 2.995484387230057e-06 -- epoch number 7714\n",
      "\n",
      "\n",
      "loss before training is 2.991995502975756e-06 -- epoch number 7715\n",
      "\n",
      "\n",
      "loss before training is 2.988511091845206e-06 -- epoch number 7716\n",
      "\n",
      "\n",
      "loss before training is 2.985031147620567e-06 -- epoch number 7717\n",
      "\n",
      "\n",
      "loss before training is 2.981555664092283e-06 -- epoch number 7718\n",
      "\n",
      "\n",
      "loss before training is 2.97808463506031e-06 -- epoch number 7719\n",
      "\n",
      "\n",
      "loss before training is 2.9746180543337847e-06 -- epoch number 7720\n",
      "\n",
      "\n",
      "loss before training is 2.9711559157308182e-06 -- epoch number 7721\n",
      "\n",
      "\n",
      "loss before training is 2.967698213078556e-06 -- epoch number 7722\n",
      "\n",
      "\n",
      "loss before training is 2.9642449402136885e-06 -- epoch number 7723\n",
      "\n",
      "\n",
      "loss before training is 2.9607960909813475e-06 -- epoch number 7724\n",
      "\n",
      "\n",
      "loss before training is 2.9573516592361248e-06 -- epoch number 7725\n",
      "\n",
      "\n",
      "loss before training is 2.9539116388413916e-06 -- epoch number 7726\n",
      "\n",
      "\n",
      "loss before training is 2.9504760236699805e-06 -- epoch number 7727\n",
      "\n",
      "\n",
      "loss before training is 2.9470448076033415e-06 -- epoch number 7728\n",
      "\n",
      "\n",
      "loss before training is 2.943617984532132e-06 -- epoch number 7729\n",
      "\n",
      "\n",
      "loss before training is 2.9401955483554423e-06 -- epoch number 7730\n",
      "\n",
      "\n",
      "loss before training is 2.9367774929826993e-06 -- epoch number 7731\n",
      "\n",
      "\n",
      "loss before training is 2.9333638123309427e-06 -- epoch number 7732\n",
      "\n",
      "\n",
      "loss before training is 2.9299545003266502e-06 -- epoch number 7733\n",
      "\n",
      "\n",
      "loss before training is 2.926549550905222e-06 -- epoch number 7734\n",
      "\n",
      "\n",
      "loss before training is 2.923148958011126e-06 -- epoch number 7735\n",
      "\n",
      "\n",
      "loss before training is 2.919752715597614e-06 -- epoch number 7736\n",
      "\n",
      "\n",
      "loss before training is 2.916360817626661e-06 -- epoch number 7737\n",
      "\n",
      "\n",
      "loss before training is 2.9129732580693966e-06 -- epoch number 7738\n",
      "\n",
      "\n",
      "loss before training is 2.9095900309059772e-06 -- epoch number 7739\n",
      "\n",
      "\n",
      "loss before training is 2.906211130124538e-06 -- epoch number 7740\n",
      "\n",
      "\n",
      "loss before training is 2.902836549723353e-06 -- epoch number 7741\n",
      "\n",
      "\n",
      "loss before training is 2.899466283708172e-06 -- epoch number 7742\n",
      "\n",
      "\n",
      "loss before training is 2.8961003260948764e-06 -- epoch number 7743\n",
      "\n",
      "\n",
      "loss before training is 2.8927386709072313e-06 -- epoch number 7744\n",
      "\n",
      "\n",
      "loss before training is 2.889381312177837e-06 -- epoch number 7745\n",
      "\n",
      "\n",
      "loss before training is 2.886028243948657e-06 -- epoch number 7746\n",
      "\n",
      "\n",
      "loss before training is 2.8826794602699862e-06 -- epoch number 7747\n",
      "\n",
      "\n",
      "loss before training is 2.8793349552008556e-06 -- epoch number 7748\n",
      "\n",
      "\n",
      "loss before training is 2.8759947228093842e-06 -- epoch number 7749\n",
      "\n",
      "\n",
      "loss before training is 2.8726587571715066e-06 -- epoch number 7750\n",
      "\n",
      "\n",
      "loss before training is 2.869327052373284e-06 -- epoch number 7751\n",
      "\n",
      "\n",
      "loss before training is 2.8659996025082767e-06 -- epoch number 7752\n",
      "\n",
      "\n",
      "loss before training is 2.862676401679184e-06 -- epoch number 7753\n",
      "\n",
      "\n",
      "loss before training is 2.859357443997369e-06 -- epoch number 7754\n",
      "\n",
      "\n",
      "loss before training is 2.8560427235828873e-06 -- epoch number 7755\n",
      "\n",
      "\n",
      "loss before training is 2.852732234564068e-06 -- epoch number 7756\n",
      "\n",
      "\n",
      "loss before training is 2.84942597107861e-06 -- epoch number 7757\n",
      "\n",
      "\n",
      "loss before training is 2.846123927272259e-06 -- epoch number 7758\n",
      "\n",
      "\n",
      "loss before training is 2.8428260972993773e-06 -- epoch number 7759\n",
      "\n",
      "\n",
      "loss before training is 2.8395324753236316e-06 -- epoch number 7760\n",
      "\n",
      "\n",
      "loss before training is 2.836243055515611e-06 -- epoch number 7761\n",
      "\n",
      "\n",
      "loss before training is 2.8329578320562592e-06 -- epoch number 7762\n",
      "\n",
      "\n",
      "loss before training is 2.8296767991342314e-06 -- epoch number 7763\n",
      "\n",
      "\n",
      "loss before training is 2.8263999509465837e-06 -- epoch number 7764\n",
      "\n",
      "\n",
      "loss before training is 2.82312728169994e-06 -- epoch number 7765\n",
      "\n",
      "\n",
      "loss before training is 2.8198587856075693e-06 -- epoch number 7766\n",
      "\n",
      "\n",
      "loss before training is 2.8165944568927677e-06 -- epoch number 7767\n",
      "\n",
      "\n",
      "loss before training is 2.81333428978728e-06 -- epoch number 7768\n",
      "\n",
      "\n",
      "loss before training is 2.810078278530348e-06 -- epoch number 7769\n",
      "\n",
      "\n",
      "loss before training is 2.8068264173707243e-06 -- epoch number 7770\n",
      "\n",
      "\n",
      "loss before training is 2.8035787005646275e-06 -- epoch number 7771\n",
      "\n",
      "\n",
      "loss before training is 2.8003351223774707e-06 -- epoch number 7772\n",
      "\n",
      "\n",
      "loss before training is 2.797095677083005e-06 -- epoch number 7773\n",
      "\n",
      "\n",
      "loss before training is 2.7938603589628486e-06 -- epoch number 7774\n",
      "\n",
      "\n",
      "loss before training is 2.7906291623075836e-06 -- epoch number 7775\n",
      "\n",
      "\n",
      "loss before training is 2.7874020814162765e-06 -- epoch number 7776\n",
      "\n",
      "\n",
      "loss before training is 2.7841791105953542e-06 -- epoch number 7777\n",
      "\n",
      "\n",
      "loss before training is 2.7809602441608743e-06 -- epoch number 7778\n",
      "\n",
      "\n",
      "loss before training is 2.7777454764365865e-06 -- epoch number 7779\n",
      "\n",
      "\n",
      "loss before training is 2.774534801754598e-06 -- epoch number 7780\n",
      "\n",
      "\n",
      "loss before training is 2.7713282144554315e-06 -- epoch number 7781\n",
      "\n",
      "\n",
      "loss before training is 2.768125708887895e-06 -- epoch number 7782\n",
      "\n",
      "\n",
      "loss before training is 2.764927279408942e-06 -- epoch number 7783\n",
      "\n",
      "\n",
      "loss before training is 2.7617329203843744e-06 -- epoch number 7784\n",
      "\n",
      "\n",
      "loss before training is 2.7585426261876332e-06 -- epoch number 7785\n",
      "\n",
      "\n",
      "loss before training is 2.755356391200286e-06 -- epoch number 7786\n",
      "\n",
      "\n",
      "loss before training is 2.752174209813086e-06 -- epoch number 7787\n",
      "\n",
      "\n",
      "loss before training is 2.748996076424127e-06 -- epoch number 7788\n",
      "\n",
      "\n",
      "loss before training is 2.745821985439814e-06 -- epoch number 7789\n",
      "\n",
      "\n",
      "loss before training is 2.7426519312754062e-06 -- epoch number 7790\n",
      "\n",
      "\n",
      "loss before training is 2.739485908353776e-06 -- epoch number 7791\n",
      "\n",
      "\n",
      "loss before training is 2.736323911105952e-06 -- epoch number 7792\n",
      "\n",
      "\n",
      "loss before training is 2.7331659339712786e-06 -- epoch number 7793\n",
      "\n",
      "\n",
      "loss before training is 2.7300119713976066e-06 -- epoch number 7794\n",
      "\n",
      "\n",
      "loss before training is 2.726862017840531e-06 -- epoch number 7795\n",
      "\n",
      "\n",
      "loss before training is 2.723716067763627e-06 -- epoch number 7796\n",
      "\n",
      "\n",
      "loss before training is 2.7205741156390792e-06 -- epoch number 7797\n",
      "\n",
      "\n",
      "loss before training is 2.717436155946779e-06 -- epoch number 7798\n",
      "\n",
      "\n",
      "loss before training is 2.7143021831747844e-06 -- epoch number 7799\n",
      "\n",
      "\n",
      "loss before training is 2.7111721918196297e-06 -- epoch number 7800\n",
      "\n",
      "\n",
      "loss before training is 2.7080461763852127e-06 -- epoch number 7801\n",
      "\n",
      "\n",
      "loss before training is 2.704924131384184e-06 -- epoch number 7802\n",
      "\n",
      "\n",
      "loss before training is 2.7018060513368008e-06 -- epoch number 7803\n",
      "\n",
      "\n",
      "loss before training is 2.6986919307714326e-06 -- epoch number 7804\n",
      "\n",
      "\n",
      "loss before training is 2.6955817642248644e-06 -- epoch number 7805\n",
      "\n",
      "\n",
      "loss before training is 2.6924755462410335e-06 -- epoch number 7806\n",
      "\n",
      "\n",
      "loss before training is 2.689373271372983e-06 -- epoch number 7807\n",
      "\n",
      "\n",
      "loss before training is 2.6862749341807233e-06 -- epoch number 7808\n",
      "\n",
      "\n",
      "loss before training is 2.6831805292328476e-06 -- epoch number 7809\n",
      "\n",
      "\n",
      "loss before training is 2.680090051105957e-06 -- epoch number 7810\n",
      "\n",
      "\n",
      "loss before training is 2.677003494383579e-06 -- epoch number 7811\n",
      "\n",
      "\n",
      "loss before training is 2.673920853659348e-06 -- epoch number 7812\n",
      "\n",
      "\n",
      "loss before training is 2.670842123532177e-06 -- epoch number 7813\n",
      "\n",
      "\n",
      "loss before training is 2.667767298611121e-06 -- epoch number 7814\n",
      "\n",
      "\n",
      "loss before training is 2.6646963735114507e-06 -- epoch number 7815\n",
      "\n",
      "\n",
      "loss before training is 2.6616293428573833e-06 -- epoch number 7816\n",
      "\n",
      "\n",
      "loss before training is 2.6585662012810124e-06 -- epoch number 7817\n",
      "\n",
      "\n",
      "loss before training is 2.6555069434215485e-06 -- epoch number 7818\n",
      "\n",
      "\n",
      "loss before training is 2.6524515639266402e-06 -- epoch number 7819\n",
      "\n",
      "\n",
      "loss before training is 2.649400057451604e-06 -- epoch number 7820\n",
      "\n",
      "\n",
      "loss before training is 2.646352418659812e-06 -- epoch number 7821\n",
      "\n",
      "\n",
      "loss before training is 2.643308642221996e-06 -- epoch number 7822\n",
      "\n",
      "\n",
      "loss before training is 2.6402687228171646e-06 -- epoch number 7823\n",
      "\n",
      "\n",
      "loss before training is 2.6372326551316415e-06 -- epoch number 7824\n",
      "\n",
      "\n",
      "loss before training is 2.6342004338601466e-06 -- epoch number 7825\n",
      "\n",
      "\n",
      "loss before training is 2.631172053704931e-06 -- epoch number 7826\n",
      "\n",
      "\n",
      "loss before training is 2.6281475093752895e-06 -- epoch number 7827\n",
      "\n",
      "\n",
      "loss before training is 2.6251267955892126e-06 -- epoch number 7828\n",
      "\n",
      "\n",
      "loss before training is 2.622109907072278e-06 -- epoch number 7829\n",
      "\n",
      "\n",
      "loss before training is 2.619096838557519e-06 -- epoch number 7830\n",
      "\n",
      "\n",
      "loss before training is 2.6160875847854694e-06 -- epoch number 7831\n",
      "\n",
      "\n",
      "loss before training is 2.6130821405050176e-06 -- epoch number 7832\n",
      "\n",
      "\n",
      "loss before training is 2.61008050047215e-06 -- epoch number 7833\n",
      "\n",
      "\n",
      "loss before training is 2.607082659450892e-06 -- epoch number 7834\n",
      "\n",
      "\n",
      "loss before training is 2.604088612212945e-06 -- epoch number 7835\n",
      "\n",
      "\n",
      "loss before training is 2.601098353537055e-06 -- epoch number 7836\n",
      "\n",
      "\n",
      "loss before training is 2.598111878210592e-06 -- epoch number 7837\n",
      "\n",
      "\n",
      "loss before training is 2.5951291810278985e-06 -- epoch number 7838\n",
      "\n",
      "\n",
      "loss before training is 2.5921502567908187e-06 -- epoch number 7839\n",
      "\n",
      "\n",
      "loss before training is 2.589175100309186e-06 -- epoch number 7840\n",
      "\n",
      "\n",
      "loss before training is 2.586203706400254e-06 -- epoch number 7841\n",
      "\n",
      "\n",
      "loss before training is 2.58323606988954e-06 -- epoch number 7842\n",
      "\n",
      "\n",
      "loss before training is 2.580272185608676e-06 -- epoch number 7843\n",
      "\n",
      "\n",
      "loss before training is 2.5773120483980775e-06 -- epoch number 7844\n",
      "\n",
      "\n",
      "loss before training is 2.5743556531052606e-06 -- epoch number 7845\n",
      "\n",
      "\n",
      "loss before training is 2.5714029945853977e-06 -- epoch number 7846\n",
      "\n",
      "\n",
      "loss before training is 2.56845406770084e-06 -- epoch number 7847\n",
      "\n",
      "\n",
      "loss before training is 2.5655088673221905e-06 -- epoch number 7848\n",
      "\n",
      "\n",
      "loss before training is 2.5625673883267503e-06 -- epoch number 7849\n",
      "\n",
      "\n",
      "loss before training is 2.5596296256000756e-06 -- epoch number 7850\n",
      "\n",
      "\n",
      "loss before training is 2.5566955740344347e-06 -- epoch number 7851\n",
      "\n",
      "\n",
      "loss before training is 2.5537652285299306e-06 -- epoch number 7852\n",
      "\n",
      "\n",
      "loss before training is 2.5508385839944337e-06 -- epoch number 7853\n",
      "\n",
      "\n",
      "loss before training is 2.547915635342768e-06 -- epoch number 7854\n",
      "\n",
      "\n",
      "loss before training is 2.54499637749735e-06 -- epoch number 7855\n",
      "\n",
      "\n",
      "loss before training is 2.5420808053882193e-06 -- epoch number 7856\n",
      "\n",
      "\n",
      "loss before training is 2.5391689139523555e-06 -- epoch number 7857\n",
      "\n",
      "\n",
      "loss before training is 2.5362606981346915e-06 -- epoch number 7858\n",
      "\n",
      "\n",
      "loss before training is 2.533356152887145e-06 -- epoch number 7859\n",
      "\n",
      "\n",
      "loss before training is 2.530455273169424e-06 -- epoch number 7860\n",
      "\n",
      "\n",
      "loss before training is 2.527558053948149e-06 -- epoch number 7861\n",
      "\n",
      "\n",
      "loss before training is 2.5246644901976097e-06 -- epoch number 7862\n",
      "\n",
      "\n",
      "loss before training is 2.521774576899217e-06 -- epoch number 7863\n",
      "\n",
      "\n",
      "loss before training is 2.518888309042262e-06 -- epoch number 7864\n",
      "\n",
      "\n",
      "loss before training is 2.5160056816223197e-06 -- epoch number 7865\n",
      "\n",
      "\n",
      "loss before training is 2.5131266896431033e-06 -- epoch number 7866\n",
      "\n",
      "\n",
      "loss before training is 2.510251328115455e-06 -- epoch number 7867\n",
      "\n",
      "\n",
      "loss before training is 2.5073795920577228e-06 -- epoch number 7868\n",
      "\n",
      "\n",
      "loss before training is 2.504511476495019e-06 -- epoch number 7869\n",
      "\n",
      "\n",
      "loss before training is 2.5016469764598568e-06 -- epoch number 7870\n",
      "\n",
      "\n",
      "loss before training is 2.498786086992611e-06 -- epoch number 7871\n",
      "\n",
      "\n",
      "loss before training is 2.495928803139926e-06 -- epoch number 7872\n",
      "\n",
      "\n",
      "loss before training is 2.4930751199562866e-06 -- epoch number 7873\n",
      "\n",
      "\n",
      "loss before training is 2.4902250325037598e-06 -- epoch number 7874\n",
      "\n",
      "\n",
      "loss before training is 2.487378535850645e-06 -- epoch number 7875\n",
      "\n",
      "\n",
      "loss before training is 2.4845356250731075e-06 -- epoch number 7876\n",
      "\n",
      "\n",
      "loss before training is 2.4816962952545915e-06 -- epoch number 7877\n",
      "\n",
      "\n",
      "loss before training is 2.4788605414852296e-06 -- epoch number 7878\n",
      "\n",
      "\n",
      "loss before training is 2.476028358862556e-06 -- epoch number 7879\n",
      "\n",
      "\n",
      "loss before training is 2.473199742491579e-06 -- epoch number 7880\n",
      "\n",
      "\n",
      "loss before training is 2.4703746874837497e-06 -- epoch number 7881\n",
      "\n",
      "\n",
      "loss before training is 2.467553188958587e-06 -- epoch number 7882\n",
      "\n",
      "\n",
      "loss before training is 2.464735242041905e-06 -- epoch number 7883\n",
      "\n",
      "\n",
      "loss before training is 2.461920841867065e-06 -- epoch number 7884\n",
      "\n",
      "\n",
      "loss before training is 2.4591099835743423e-06 -- epoch number 7885\n",
      "\n",
      "\n",
      "loss before training is 2.4563026623114475e-06 -- epoch number 7886\n",
      "\n",
      "\n",
      "loss before training is 2.4534988732327485e-06 -- epoch number 7887\n",
      "\n",
      "\n",
      "loss before training is 2.4506986114995794e-06 -- epoch number 7888\n",
      "\n",
      "\n",
      "loss before training is 2.4479018722807574e-06 -- epoch number 7889\n",
      "\n",
      "\n",
      "loss before training is 2.445108650752528e-06 -- epoch number 7890\n",
      "\n",
      "\n",
      "loss before training is 2.4423189420971655e-06 -- epoch number 7891\n",
      "\n",
      "\n",
      "loss before training is 2.4395327415044278e-06 -- epoch number 7892\n",
      "\n",
      "\n",
      "loss before training is 2.436750044171344e-06 -- epoch number 7893\n",
      "\n",
      "\n",
      "loss before training is 2.4339708453016965e-06 -- epoch number 7894\n",
      "\n",
      "\n",
      "loss before training is 2.43119514010604e-06 -- epoch number 7895\n",
      "\n",
      "\n",
      "loss before training is 2.428422923802687e-06 -- epoch number 7896\n",
      "\n",
      "\n",
      "loss before training is 2.4256541916158746e-06 -- epoch number 7897\n",
      "\n",
      "\n",
      "loss before training is 2.4228889387778274e-06 -- epoch number 7898\n",
      "\n",
      "\n",
      "loss before training is 2.4201271605270012e-06 -- epoch number 7899\n",
      "\n",
      "\n",
      "loss before training is 2.417368852108882e-06 -- epoch number 7900\n",
      "\n",
      "\n",
      "loss before training is 2.4146140087764456e-06 -- epoch number 7901\n",
      "\n",
      "\n",
      "loss before training is 2.411862625789182e-06 -- epoch number 7902\n",
      "\n",
      "\n",
      "loss before training is 2.409114698413034e-06 -- epoch number 7903\n",
      "\n",
      "\n",
      "loss before training is 2.4063702219221565e-06 -- epoch number 7904\n",
      "\n",
      "\n",
      "loss before training is 2.4036291915957444e-06 -- epoch number 7905\n",
      "\n",
      "\n",
      "loss before training is 2.4008916027215183e-06 -- epoch number 7906\n",
      "\n",
      "\n",
      "loss before training is 2.398157450593577e-06 -- epoch number 7907\n",
      "\n",
      "\n",
      "loss before training is 2.3954267305123763e-06 -- epoch number 7908\n",
      "\n",
      "\n",
      "loss before training is 2.3926994377859707e-06 -- epoch number 7909\n",
      "\n",
      "\n",
      "loss before training is 2.3899755677284424e-06 -- epoch number 7910\n",
      "\n",
      "\n",
      "loss before training is 2.387255115661451e-06 -- epoch number 7911\n",
      "\n",
      "\n",
      "loss before training is 2.384538076913381e-06 -- epoch number 7912\n",
      "\n",
      "\n",
      "loss before training is 2.3818244468186893e-06 -- epoch number 7913\n",
      "\n",
      "\n",
      "loss before training is 2.3791142207195254e-06 -- epoch number 7914\n",
      "\n",
      "\n",
      "loss before training is 2.376407393964378e-06 -- epoch number 7915\n",
      "\n",
      "\n",
      "loss before training is 2.373703961908373e-06 -- epoch number 7916\n",
      "\n",
      "\n",
      "loss before training is 2.371003919914273e-06 -- epoch number 7917\n",
      "\n",
      "\n",
      "loss before training is 2.3683072633502715e-06 -- epoch number 7918\n",
      "\n",
      "\n",
      "loss before training is 2.365613987592217e-06 -- epoch number 7919\n",
      "\n",
      "\n",
      "loss before training is 2.3629240880226336e-06 -- epoch number 7920\n",
      "\n",
      "\n",
      "loss before training is 2.3602375600303057e-06 -- epoch number 7921\n",
      "\n",
      "\n",
      "loss before training is 2.3575543990114573e-06 -- epoch number 7922\n",
      "\n",
      "\n",
      "loss before training is 2.3548746003681996e-06 -- epoch number 7923\n",
      "\n",
      "\n",
      "loss before training is 2.3521981595101255e-06 -- epoch number 7924\n",
      "\n",
      "\n",
      "loss before training is 2.3495250718529737e-06 -- epoch number 7925\n",
      "\n",
      "\n",
      "loss before training is 2.3468553328190195e-06 -- epoch number 7926\n",
      "\n",
      "\n",
      "loss before training is 2.3441889378380658e-06 -- epoch number 7927\n",
      "\n",
      "\n",
      "loss before training is 2.3415258823456496e-06 -- epoch number 7928\n",
      "\n",
      "\n",
      "loss before training is 2.3388661617842446e-06 -- epoch number 7929\n",
      "\n",
      "\n",
      "loss before training is 2.3362097716031655e-06 -- epoch number 7930\n",
      "\n",
      "\n",
      "loss before training is 2.333556707258565e-06 -- epoch number 7931\n",
      "\n",
      "\n",
      "loss before training is 2.3309069642121617e-06 -- epoch number 7932\n",
      "\n",
      "\n",
      "loss before training is 2.3282605379335033e-06 -- epoch number 7933\n",
      "\n",
      "\n",
      "loss before training is 2.3256174238981196e-06 -- epoch number 7934\n",
      "\n",
      "\n",
      "loss before training is 2.322977617588214e-06 -- epoch number 7935\n",
      "\n",
      "\n",
      "loss before training is 2.320341114492472e-06 -- epoch number 7936\n",
      "\n",
      "\n",
      "loss before training is 2.3177079101063356e-06 -- epoch number 7937\n",
      "\n",
      "\n",
      "loss before training is 2.315077999931659e-06 -- epoch number 7938\n",
      "\n",
      "\n",
      "loss before training is 2.31245137947678e-06 -- epoch number 7939\n",
      "\n",
      "\n",
      "loss before training is 2.309828044257124e-06 -- epoch number 7940\n",
      "\n",
      "\n",
      "loss before training is 2.30720798979389e-06 -- epoch number 7941\n",
      "\n",
      "\n",
      "loss before training is 2.3045912116149064e-06 -- epoch number 7942\n",
      "\n",
      "\n",
      "loss before training is 2.3019777052554893e-06 -- epoch number 7943\n",
      "\n",
      "\n",
      "loss before training is 2.2993674662556895e-06 -- epoch number 7944\n",
      "\n",
      "\n",
      "loss before training is 2.296760490163712e-06 -- epoch number 7945\n",
      "\n",
      "\n",
      "loss before training is 2.2941567725333647e-06 -- epoch number 7946\n",
      "\n",
      "\n",
      "loss before training is 2.2915563089250342e-06 -- epoch number 7947\n",
      "\n",
      "\n",
      "loss before training is 2.288959094905894e-06 -- epoch number 7948\n",
      "\n",
      "\n",
      "loss before training is 2.28636512604902e-06 -- epoch number 7949\n",
      "\n",
      "\n",
      "loss before training is 2.2837743979341836e-06 -- epoch number 7950\n",
      "\n",
      "\n",
      "loss before training is 2.2811869061481363e-06 -- epoch number 7951\n",
      "\n",
      "\n",
      "loss before training is 2.2786026462830375e-06 -- epoch number 7952\n",
      "\n",
      "\n",
      "loss before training is 2.2760216139381617e-06 -- epoch number 7953\n",
      "\n",
      "\n",
      "loss before training is 2.2734438047190075e-06 -- epoch number 7954\n",
      "\n",
      "\n",
      "loss before training is 2.2708692142373035e-06 -- epoch number 7955\n",
      "\n",
      "\n",
      "loss before training is 2.2682978381112247e-06 -- epoch number 7956\n",
      "\n",
      "\n",
      "loss before training is 2.2657296719657776e-06 -- epoch number 7957\n",
      "\n",
      "\n",
      "loss before training is 2.263164711431438e-06 -- epoch number 7958\n",
      "\n",
      "\n",
      "loss before training is 2.2606029521460773e-06 -- epoch number 7959\n",
      "\n",
      "\n",
      "loss before training is 2.258044389752782e-06 -- epoch number 7960\n",
      "\n",
      "\n",
      "loss before training is 2.2554890199015932e-06 -- epoch number 7961\n",
      "\n",
      "\n",
      "loss before training is 2.252936838249392e-06 -- epoch number 7962\n",
      "\n",
      "\n",
      "loss before training is 2.2503878404583825e-06 -- epoch number 7963\n",
      "\n",
      "\n",
      "loss before training is 2.247842022197613e-06 -- epoch number 7964\n",
      "\n",
      "\n",
      "loss before training is 2.245299379142127e-06 -- epoch number 7965\n",
      "\n",
      "\n",
      "loss before training is 2.2427599069732904e-06 -- epoch number 7966\n",
      "\n",
      "\n",
      "loss before training is 2.240223601379582e-06 -- epoch number 7967\n",
      "\n",
      "\n",
      "loss before training is 2.237690458054612e-06 -- epoch number 7968\n",
      "\n",
      "\n",
      "loss before training is 2.235160472698418e-06 -- epoch number 7969\n",
      "\n",
      "\n",
      "loss before training is 2.2326336410180918e-06 -- epoch number 7970\n",
      "\n",
      "\n",
      "loss before training is 2.2301099587258335e-06 -- epoch number 7971\n",
      "\n",
      "\n",
      "loss before training is 2.227589421541397e-06 -- epoch number 7972\n",
      "\n",
      "\n",
      "loss before training is 2.225072025189105e-06 -- epoch number 7973\n",
      "\n",
      "\n",
      "loss before training is 2.2225577654010973e-06 -- epoch number 7974\n",
      "\n",
      "\n",
      "loss before training is 2.220046637914693e-06 -- epoch number 7975\n",
      "\n",
      "\n",
      "loss before training is 2.217538638473866e-06 -- epoch number 7976\n",
      "\n",
      "\n",
      "loss before training is 2.215033762828524e-06 -- epoch number 7977\n",
      "\n",
      "\n",
      "loss before training is 2.212532006734946e-06 -- epoch number 7978\n",
      "\n",
      "\n",
      "loss before training is 2.2100333659555267e-06 -- epoch number 7979\n",
      "\n",
      "\n",
      "loss before training is 2.2075378362583527e-06 -- epoch number 7980\n",
      "\n",
      "\n",
      "loss before training is 2.2050454134182445e-06 -- epoch number 7981\n",
      "\n",
      "\n",
      "loss before training is 2.202556093216151e-06 -- epoch number 7982\n",
      "\n",
      "\n",
      "loss before training is 2.2000698714390294e-06 -- epoch number 7983\n",
      "\n",
      "\n",
      "loss before training is 2.1975867438795334e-06 -- epoch number 7984\n",
      "\n",
      "\n",
      "loss before training is 2.1951067063371216e-06 -- epoch number 7985\n",
      "\n",
      "\n",
      "loss before training is 2.192629754616698e-06 -- epoch number 7986\n",
      "\n",
      "\n",
      "loss before training is 2.190155884529659e-06 -- epoch number 7987\n",
      "\n",
      "\n",
      "loss before training is 2.187685091893533e-06 -- epoch number 7988\n",
      "\n",
      "\n",
      "loss before training is 2.1852173725316336e-06 -- epoch number 7989\n",
      "\n",
      "\n",
      "loss before training is 2.182752722273151e-06 -- epoch number 7990\n",
      "\n",
      "\n",
      "loss before training is 2.18029113695426e-06 -- epoch number 7991\n",
      "\n",
      "\n",
      "loss before training is 2.177832612416151e-06 -- epoch number 7992\n",
      "\n",
      "\n",
      "loss before training is 2.1753771445063703e-06 -- epoch number 7993\n",
      "\n",
      "\n",
      "loss before training is 2.172924729078902e-06 -- epoch number 7994\n",
      "\n",
      "\n",
      "loss before training is 2.1704753619931085e-06 -- epoch number 7995\n",
      "\n",
      "\n",
      "loss before training is 2.168029039114765e-06 -- epoch number 7996\n",
      "\n",
      "\n",
      "loss before training is 2.1655857563155728e-06 -- epoch number 7997\n",
      "\n",
      "\n",
      "loss before training is 2.1631455094730212e-06 -- epoch number 7998\n",
      "\n",
      "\n",
      "loss before training is 2.160708294470885e-06 -- epoch number 7999\n",
      "\n",
      "\n",
      "loss before training is 2.158274107198604e-06 -- epoch number 8000\n",
      "\n",
      "\n",
      "loss before training is 2.1558429435519883e-06 -- epoch number 8001\n",
      "\n",
      "\n",
      "loss before training is 2.153414799432275e-06 -- epoch number 8002\n",
      "\n",
      "\n",
      "loss before training is 2.1509896707468974e-06 -- epoch number 8003\n",
      "\n",
      "\n",
      "loss before training is 2.1485675534095133e-06 -- epoch number 8004\n",
      "\n",
      "\n",
      "loss before training is 2.146148443339359e-06 -- epoch number 8005\n",
      "\n",
      "\n",
      "loss before training is 2.1437323364614135e-06 -- epoch number 8006\n",
      "\n",
      "\n",
      "loss before training is 2.1413192287069418e-06 -- epoch number 8007\n",
      "\n",
      "\n",
      "loss before training is 2.1389091160128364e-06 -- epoch number 8008\n",
      "\n",
      "\n",
      "loss before training is 2.1365019943221483e-06 -- epoch number 8009\n",
      "\n",
      "\n",
      "loss before training is 2.1340978595837425e-06 -- epoch number 8010\n",
      "\n",
      "\n",
      "loss before training is 2.131696707751953e-06 -- epoch number 8011\n",
      "\n",
      "\n",
      "loss before training is 2.129298534787423e-06 -- epoch number 8012\n",
      "\n",
      "\n",
      "loss before training is 2.126903336657002e-06 -- epoch number 8013\n",
      "\n",
      "\n",
      "loss before training is 2.124511109331996e-06 -- epoch number 8014\n",
      "\n",
      "\n",
      "loss before training is 2.122121848791278e-06 -- epoch number 8015\n",
      "\n",
      "\n",
      "loss before training is 2.1197355510178505e-06 -- epoch number 8016\n",
      "\n",
      "\n",
      "loss before training is 2.117352212002422e-06 -- epoch number 8017\n",
      "\n",
      "\n",
      "loss before training is 2.1149718277397444e-06 -- epoch number 8018\n",
      "\n",
      "\n",
      "loss before training is 2.1125943942312075e-06 -- epoch number 8019\n",
      "\n",
      "\n",
      "loss before training is 2.110219907484347e-06 -- epoch number 8020\n",
      "\n",
      "\n",
      "loss before training is 2.107848363511484e-06 -- epoch number 8021\n",
      "\n",
      "\n",
      "loss before training is 2.1054797583314487e-06 -- epoch number 8022\n",
      "\n",
      "\n",
      "loss before training is 2.103114087968803e-06 -- epoch number 8023\n",
      "\n",
      "\n",
      "loss before training is 2.1007513484534887e-06 -- epoch number 8024\n",
      "\n",
      "\n",
      "loss before training is 2.0983915358214377e-06 -- epoch number 8025\n",
      "\n",
      "\n",
      "loss before training is 2.0960346461143685e-06 -- epoch number 8026\n",
      "\n",
      "\n",
      "loss before training is 2.093680675379525e-06 -- epoch number 8027\n",
      "\n",
      "\n",
      "loss before training is 2.0913296196704386e-06 -- epoch number 8028\n",
      "\n",
      "\n",
      "loss before training is 2.0889814750453456e-06 -- epoch number 8029\n",
      "\n",
      "\n",
      "loss before training is 2.086636237568663e-06 -- epoch number 8030\n",
      "\n",
      "\n",
      "loss before training is 2.084293903311292e-06 -- epoch number 8031\n",
      "\n",
      "\n",
      "loss before training is 2.0819544683487503e-06 -- epoch number 8032\n",
      "\n",
      "\n",
      "loss before training is 2.079617928762422e-06 -- epoch number 8033\n",
      "\n",
      "\n",
      "loss before training is 2.07728428063987e-06 -- epoch number 8034\n",
      "\n",
      "\n",
      "loss before training is 2.074953520073863e-06 -- epoch number 8035\n",
      "\n",
      "\n",
      "loss before training is 2.0726256431627953e-06 -- epoch number 8036\n",
      "\n",
      "\n",
      "loss before training is 2.0703006460110867e-06 -- epoch number 8037\n",
      "\n",
      "\n",
      "loss before training is 2.0679785247283217e-06 -- epoch number 8038\n",
      "\n",
      "\n",
      "loss before training is 2.0656592754301946e-06 -- epoch number 8039\n",
      "\n",
      "\n",
      "loss before training is 2.063342894237679e-06 -- epoch number 8040\n",
      "\n",
      "\n",
      "loss before training is 2.061029377277407e-06 -- epoch number 8041\n",
      "\n",
      "\n",
      "loss before training is 2.0587187206816934e-06 -- epoch number 8042\n",
      "\n",
      "\n",
      "loss before training is 2.056410920588806e-06 -- epoch number 8043\n",
      "\n",
      "\n",
      "loss before training is 2.054105973141448e-06 -- epoch number 8044\n",
      "\n",
      "\n",
      "loss before training is 2.0518038744890237e-06 -- epoch number 8045\n",
      "\n",
      "\n",
      "loss before training is 2.0495046207863526e-06 -- epoch number 8046\n",
      "\n",
      "\n",
      "loss before training is 2.047208208193147e-06 -- epoch number 8047\n",
      "\n",
      "\n",
      "loss before training is 2.0449146328755414e-06 -- epoch number 8048\n",
      "\n",
      "\n",
      "loss before training is 2.0426238910046156e-06 -- epoch number 8049\n",
      "\n",
      "\n",
      "loss before training is 2.040335978757028e-06 -- epoch number 8050\n",
      "\n",
      "\n",
      "loss before training is 2.0380508923153484e-06 -- epoch number 8051\n",
      "\n",
      "\n",
      "loss before training is 2.0357686278672295e-06 -- epoch number 8052\n",
      "\n",
      "\n",
      "loss before training is 2.0334891816061454e-06 -- epoch number 8053\n",
      "\n",
      "\n",
      "loss before training is 2.0312125497306737e-06 -- epoch number 8054\n",
      "\n",
      "\n",
      "loss before training is 2.0289387284454924e-06 -- epoch number 8055\n",
      "\n",
      "\n",
      "loss before training is 2.0266677139599802e-06 -- epoch number 8056\n",
      "\n",
      "\n",
      "loss before training is 2.0243995024900405e-06 -- epoch number 8057\n",
      "\n",
      "\n",
      "loss before training is 2.0221340902557784e-06 -- epoch number 8058\n",
      "\n",
      "\n",
      "loss before training is 2.0198714734838473e-06 -- epoch number 8059\n",
      "\n",
      "\n",
      "loss before training is 2.017611648405537e-06 -- epoch number 8060\n",
      "\n",
      "\n",
      "loss before training is 2.0153546112582747e-06 -- epoch number 8061\n",
      "\n",
      "\n",
      "loss before training is 2.0131003582847785e-06 -- epoch number 8062\n",
      "\n",
      "\n",
      "loss before training is 2.0108488857324117e-06 -- epoch number 8063\n",
      "\n",
      "\n",
      "loss before training is 2.0086001898550292e-06 -- epoch number 8064\n",
      "\n",
      "\n",
      "loss before training is 2.0063542669114865e-06 -- epoch number 8065\n",
      "\n",
      "\n",
      "loss before training is 2.004111113165411e-06 -- epoch number 8066\n",
      "\n",
      "\n",
      "loss before training is 2.0018707248871263e-06 -- epoch number 8067\n",
      "\n",
      "\n",
      "loss before training is 1.9996330983511865e-06 -- epoch number 8068\n",
      "\n",
      "\n",
      "loss before training is 1.997398229837874e-06 -- epoch number 8069\n",
      "\n",
      "\n",
      "loss before training is 1.995166115633183e-06 -- epoch number 8070\n",
      "\n",
      "\n",
      "loss before training is 1.9929367520279605e-06 -- epoch number 8071\n",
      "\n",
      "\n",
      "loss before training is 1.9907101353189116e-06 -- epoch number 8072\n",
      "\n",
      "\n",
      "loss before training is 1.9884862618075232e-06 -- epoch number 8073\n",
      "\n",
      "\n",
      "loss before training is 1.986265127800871e-06 -- epoch number 8074\n",
      "\n",
      "\n",
      "loss before training is 1.984046729611868e-06 -- epoch number 8075\n",
      "\n",
      "\n",
      "loss before training is 1.981831063557991e-06 -- epoch number 8076\n",
      "\n",
      "\n",
      "loss before training is 1.9796181259619805e-06 -- epoch number 8077\n",
      "\n",
      "\n",
      "loss before training is 1.9774079131526956e-06 -- epoch number 8078\n",
      "\n",
      "\n",
      "loss before training is 1.975200421463895e-06 -- epoch number 8079\n",
      "\n",
      "\n",
      "loss before training is 1.972995647234211e-06 -- epoch number 8080\n",
      "\n",
      "\n",
      "loss before training is 1.9707935868079526e-06 -- epoch number 8081\n",
      "\n",
      "\n",
      "loss before training is 1.9685942365346467e-06 -- epoch number 8082\n",
      "\n",
      "\n",
      "loss before training is 1.966397592769091e-06 -- epoch number 8083\n",
      "\n",
      "\n",
      "loss before training is 1.9642036518715355e-06 -- epoch number 8084\n",
      "\n",
      "\n",
      "loss before training is 1.9620124102068166e-06 -- epoch number 8085\n",
      "\n",
      "\n",
      "loss before training is 1.9598238641459654e-06 -- epoch number 8086\n",
      "\n",
      "\n",
      "loss before training is 1.9576380100643878e-06 -- epoch number 8087\n",
      "\n",
      "\n",
      "loss before training is 1.955454844343413e-06 -- epoch number 8088\n",
      "\n",
      "\n",
      "loss before training is 1.9532743633688564e-06 -- epoch number 8089\n",
      "\n",
      "\n",
      "loss before training is 1.951096563532302e-06 -- epoch number 8090\n",
      "\n",
      "\n",
      "loss before training is 1.9489214412305084e-06 -- epoch number 8091\n",
      "\n",
      "\n",
      "loss before training is 1.946748992865054e-06 -- epoch number 8092\n",
      "\n",
      "\n",
      "loss before training is 1.94457921484304e-06 -- epoch number 8093\n",
      "\n",
      "\n",
      "loss before training is 1.9424121035765035e-06 -- epoch number 8094\n",
      "\n",
      "\n",
      "loss before training is 1.9402476554832076e-06 -- epoch number 8095\n",
      "\n",
      "\n",
      "loss before training is 1.9380858669851204e-06 -- epoch number 8096\n",
      "\n",
      "\n",
      "loss before training is 1.935926734510328e-06 -- epoch number 8097\n",
      "\n",
      "\n",
      "loss before training is 1.933770254491378e-06 -- epoch number 8098\n",
      "\n",
      "\n",
      "loss before training is 1.9316164233663848e-06 -- epoch number 8099\n",
      "\n",
      "\n",
      "loss before training is 1.929465237578283e-06 -- epoch number 8100\n",
      "\n",
      "\n",
      "loss before training is 1.9273166935752472e-06 -- epoch number 8101\n",
      "\n",
      "\n",
      "loss before training is 1.9251707878109466e-06 -- epoch number 8102\n",
      "\n",
      "\n",
      "loss before training is 1.9230275167432396e-06 -- epoch number 8103\n",
      "\n",
      "\n",
      "loss before training is 1.9208868768359452e-06 -- epoch number 8104\n",
      "\n",
      "\n",
      "loss before training is 1.9187488645577248e-06 -- epoch number 8105\n",
      "\n",
      "\n",
      "loss before training is 1.916613476382297e-06 -- epoch number 8106\n",
      "\n",
      "\n",
      "loss before training is 1.9144807087884127e-06 -- epoch number 8107\n",
      "\n",
      "\n",
      "loss before training is 1.9123505582597275e-06 -- epoch number 8108\n",
      "\n",
      "\n",
      "loss before training is 1.9102230212853437e-06 -- epoch number 8109\n",
      "\n",
      "\n",
      "loss before training is 1.9080980943594737e-06 -- epoch number 8110\n",
      "\n",
      "\n",
      "loss before training is 1.9059757739804817e-06 -- epoch number 8111\n",
      "\n",
      "\n",
      "loss before training is 1.903856056652733e-06 -- epoch number 8112\n",
      "\n",
      "\n",
      "loss before training is 1.9017389388855225e-06 -- epoch number 8113\n",
      "\n",
      "\n",
      "loss before training is 1.8996244171928223e-06 -- epoch number 8114\n",
      "\n",
      "\n",
      "loss before training is 1.8975124880936518e-06 -- epoch number 8115\n",
      "\n",
      "\n",
      "loss before training is 1.8954031481121434e-06 -- epoch number 8116\n",
      "\n",
      "\n",
      "loss before training is 1.893296393777478e-06 -- epoch number 8117\n",
      "\n",
      "\n",
      "loss before training is 1.8911922216240253e-06 -- epoch number 8118\n",
      "\n",
      "\n",
      "loss before training is 1.8890906281904034e-06 -- epoch number 8119\n",
      "\n",
      "\n",
      "loss before training is 1.886991610021131e-06 -- epoch number 8120\n",
      "\n",
      "\n",
      "loss before training is 1.8848951636651835e-06 -- epoch number 8121\n",
      "\n",
      "\n",
      "loss before training is 1.882801285676095e-06 -- epoch number 8122\n",
      "\n",
      "\n",
      "loss before training is 1.8807099726136337e-06 -- epoch number 8123\n",
      "\n",
      "\n",
      "loss before training is 1.8786212210412405e-06 -- epoch number 8124\n",
      "\n",
      "\n",
      "loss before training is 1.8765350275276963e-06 -- epoch number 8125\n",
      "\n",
      "\n",
      "loss before training is 1.8744513886473096e-06 -- epoch number 8126\n",
      "\n",
      "\n",
      "loss before training is 1.8723703009783964e-06 -- epoch number 8127\n",
      "\n",
      "\n",
      "loss before training is 1.8702917611047504e-06 -- epoch number 8128\n",
      "\n",
      "\n",
      "loss before training is 1.86821576561504e-06 -- epoch number 8129\n",
      "\n",
      "\n",
      "loss before training is 1.8661423111023128e-06 -- epoch number 8130\n",
      "\n",
      "\n",
      "loss before training is 1.864071394165142e-06 -- epoch number 8131\n",
      "\n",
      "\n",
      "loss before training is 1.8620030114071013e-06 -- epoch number 8132\n",
      "\n",
      "\n",
      "loss before training is 1.8599371594359e-06 -- epoch number 8133\n",
      "\n",
      "\n",
      "loss before training is 1.8578738348648331e-06 -- epoch number 8134\n",
      "\n",
      "\n",
      "loss before training is 1.8558130343115545e-06 -- epoch number 8135\n",
      "\n",
      "\n",
      "loss before training is 1.8537547543988048e-06 -- epoch number 8136\n",
      "\n",
      "\n",
      "loss before training is 1.851698991754427e-06 -- epoch number 8137\n",
      "\n",
      "\n",
      "loss before training is 1.8496457430108192e-06 -- epoch number 8138\n",
      "\n",
      "\n",
      "loss before training is 1.8475950048048289e-06 -- epoch number 8139\n",
      "\n",
      "\n",
      "loss before training is 1.8455467737790273e-06 -- epoch number 8140\n",
      "\n",
      "\n",
      "loss before training is 1.843501046580212e-06 -- epoch number 8141\n",
      "\n",
      "\n",
      "loss before training is 1.8414578198598308e-06 -- epoch number 8142\n",
      "\n",
      "\n",
      "loss before training is 1.8394170902747399e-06 -- epoch number 8143\n",
      "\n",
      "\n",
      "loss before training is 1.8373788544865325e-06 -- epoch number 8144\n",
      "\n",
      "\n",
      "loss before training is 1.8353431091607398e-06 -- epoch number 8145\n",
      "\n",
      "\n",
      "loss before training is 1.8333098509686136e-06 -- epoch number 8146\n",
      "\n",
      "\n",
      "loss before training is 1.8312790765858436e-06 -- epoch number 8147\n",
      "\n",
      "\n",
      "loss before training is 1.8292507826932132e-06 -- epoch number 8148\n",
      "\n",
      "\n",
      "loss before training is 1.827224965975507e-06 -- epoch number 8149\n",
      "\n",
      "\n",
      "loss before training is 1.8252016231228754e-06 -- epoch number 8150\n",
      "\n",
      "\n",
      "loss before training is 1.8231807508300339e-06 -- epoch number 8151\n",
      "\n",
      "\n",
      "loss before training is 1.8211623457969251e-06 -- epoch number 8152\n",
      "\n",
      "\n",
      "loss before training is 1.8191464047271014e-06 -- epoch number 8153\n",
      "\n",
      "\n",
      "loss before training is 1.817132924330037e-06 -- epoch number 8154\n",
      "\n",
      "\n",
      "loss before training is 1.815121901319386e-06 -- epoch number 8155\n",
      "\n",
      "\n",
      "loss before training is 1.8131133324132074e-06 -- epoch number 8156\n",
      "\n",
      "\n",
      "loss before training is 1.8111072143349389e-06 -- epoch number 8157\n",
      "\n",
      "\n",
      "loss before training is 1.8091035438121583e-06 -- epoch number 8158\n",
      "\n",
      "\n",
      "loss before training is 1.8071023175777322e-06 -- epoch number 8159\n",
      "\n",
      "\n",
      "loss before training is 1.8051035323686342e-06 -- epoch number 8160\n",
      "\n",
      "\n",
      "loss before training is 1.8031071849268342e-06 -- epoch number 8161\n",
      "\n",
      "\n",
      "loss before training is 1.8011132719987761e-06 -- epoch number 8162\n",
      "\n",
      "\n",
      "loss before training is 1.7991217903356422e-06 -- epoch number 8163\n",
      "\n",
      "\n",
      "loss before training is 1.7971327366936519e-06 -- epoch number 8164\n",
      "\n",
      "\n",
      "loss before training is 1.7951461078329667e-06 -- epoch number 8165\n",
      "\n",
      "\n",
      "loss before training is 1.7931619005187853e-06 -- epoch number 8166\n",
      "\n",
      "\n",
      "loss before training is 1.7911801115212178e-06 -- epoch number 8167\n",
      "\n",
      "\n",
      "loss before training is 1.7892007376145105e-06 -- epoch number 8168\n",
      "\n",
      "\n",
      "loss before training is 1.7872237755777512e-06 -- epoch number 8169\n",
      "\n",
      "\n",
      "loss before training is 1.7852492221944946e-06 -- epoch number 8170\n",
      "\n",
      "\n",
      "loss before training is 1.7832770742532715e-06 -- epoch number 8171\n",
      "\n",
      "\n",
      "loss before training is 1.7813073285468888e-06 -- epoch number 8172\n",
      "\n",
      "\n",
      "loss before training is 1.7793399818728375e-06 -- epoch number 8173\n",
      "\n",
      "\n",
      "loss before training is 1.7773750310332902e-06 -- epoch number 8174\n",
      "\n",
      "\n",
      "loss before training is 1.775412472834676e-06 -- epoch number 8175\n",
      "\n",
      "\n",
      "loss before training is 1.7734523040884616e-06 -- epoch number 8176\n",
      "\n",
      "\n",
      "loss before training is 1.7714945216104188e-06 -- epoch number 8177\n",
      "\n",
      "\n",
      "loss before training is 1.769539122221194e-06 -- epoch number 8178\n",
      "\n",
      "\n",
      "loss before training is 1.7675861027452607e-06 -- epoch number 8179\n",
      "\n",
      "\n",
      "loss before training is 1.7656354600121536e-06 -- epoch number 8180\n",
      "\n",
      "\n",
      "loss before training is 1.7636871908560872e-06 -- epoch number 8181\n",
      "\n",
      "\n",
      "loss before training is 1.7617412921155297e-06 -- epoch number 8182\n",
      "\n",
      "\n",
      "loss before training is 1.7597977606336298e-06 -- epoch number 8183\n",
      "\n",
      "\n",
      "loss before training is 1.7578565932579121e-06 -- epoch number 8184\n",
      "\n",
      "\n",
      "loss before training is 1.7559177868407206e-06 -- epoch number 8185\n",
      "\n",
      "\n",
      "loss before training is 1.7539813382383436e-06 -- epoch number 8186\n",
      "\n",
      "\n",
      "loss before training is 1.7520472443122115e-06 -- epoch number 8187\n",
      "\n",
      "\n",
      "loss before training is 1.7501155019275326e-06 -- epoch number 8188\n",
      "\n",
      "\n",
      "loss before training is 1.7481861079550802e-06 -- epoch number 8189\n",
      "\n",
      "\n",
      "loss before training is 1.7462590592686866e-06 -- epoch number 8190\n",
      "\n",
      "\n",
      "loss before training is 1.7443343527478664e-06 -- epoch number 8191\n",
      "\n",
      "\n",
      "loss before training is 1.7424119852761639e-06 -- epoch number 8192\n",
      "\n",
      "\n",
      "loss before training is 1.7404919537414522e-06 -- epoch number 8193\n",
      "\n",
      "\n",
      "loss before training is 1.7385742550361677e-06 -- epoch number 8194\n",
      "\n",
      "\n",
      "loss before training is 1.7366588860571664e-06 -- epoch number 8195\n",
      "\n",
      "\n",
      "loss before training is 1.734745843705806e-06 -- epoch number 8196\n",
      "\n",
      "\n",
      "loss before training is 1.7328351248878679e-06 -- epoch number 8197\n",
      "\n",
      "\n",
      "loss before training is 1.7309267265136e-06 -- epoch number 8198\n",
      "\n",
      "\n",
      "loss before training is 1.7290206454976743e-06 -- epoch number 8199\n",
      "\n",
      "\n",
      "loss before training is 1.7271168787588932e-06 -- epoch number 8200\n",
      "\n",
      "\n",
      "loss before training is 1.7252154232209894e-06 -- epoch number 8201\n",
      "\n",
      "\n",
      "loss before training is 1.7233162758113059e-06 -- epoch number 8202\n",
      "\n",
      "\n",
      "loss before training is 1.7214194334622456e-06 -- epoch number 8203\n",
      "\n",
      "\n",
      "loss before training is 1.7195248931108317e-06 -- epoch number 8204\n",
      "\n",
      "\n",
      "loss before training is 1.7176326516975285e-06 -- epoch number 8205\n",
      "\n",
      "\n",
      "loss before training is 1.7157427061683214e-06 -- epoch number 8206\n",
      "\n",
      "\n",
      "loss before training is 1.7138550534722936e-06 -- epoch number 8207\n",
      "\n",
      "\n",
      "loss before training is 1.7119696905637034e-06 -- epoch number 8208\n",
      "\n",
      "\n",
      "loss before training is 1.7100866144011617e-06 -- epoch number 8209\n",
      "\n",
      "\n",
      "loss before training is 1.7082058219474653e-06 -- epoch number 8210\n",
      "\n",
      "\n",
      "loss before training is 1.706327310169677e-06 -- epoch number 8211\n",
      "\n",
      "\n",
      "loss before training is 1.7044510760393459e-06 -- epoch number 8212\n",
      "\n",
      "\n",
      "loss before training is 1.702577116531814e-06 -- epoch number 8213\n",
      "\n",
      "\n",
      "loss before training is 1.700705428627685e-06 -- epoch number 8214\n",
      "\n",
      "\n",
      "loss before training is 1.6988360093115766e-06 -- epoch number 8215\n",
      "\n",
      "\n",
      "loss before training is 1.6969688555718275e-06 -- epoch number 8216\n",
      "\n",
      "\n",
      "loss before training is 1.6951039644012663e-06 -- epoch number 8217\n",
      "\n",
      "\n",
      "loss before training is 1.6932413327980685e-06 -- epoch number 8218\n",
      "\n",
      "\n",
      "loss before training is 1.6913809577631154e-06 -- epoch number 8219\n",
      "\n",
      "\n",
      "loss before training is 1.6895228363025482e-06 -- epoch number 8220\n",
      "\n",
      "\n",
      "loss before training is 1.6876669654265549e-06 -- epoch number 8221\n",
      "\n",
      "\n",
      "loss before training is 1.6858133421494983e-06 -- epoch number 8222\n",
      "\n",
      "\n",
      "loss before training is 1.6839619634905169e-06 -- epoch number 8223\n",
      "\n",
      "\n",
      "loss before training is 1.6821128264721325e-06 -- epoch number 8224\n",
      "\n",
      "\n",
      "loss before training is 1.6802659281216158e-06 -- epoch number 8225\n",
      "\n",
      "\n",
      "loss before training is 1.678421265470721e-06 -- epoch number 8226\n",
      "\n",
      "\n",
      "loss before training is 1.6765788355548669e-06 -- epoch number 8227\n",
      "\n",
      "\n",
      "loss before training is 1.6747386354140726e-06 -- epoch number 8228\n",
      "\n",
      "\n",
      "loss before training is 1.6729006620927723e-06 -- epoch number 8229\n",
      "\n",
      "\n",
      "loss before training is 1.671064912638849e-06 -- epoch number 8230\n",
      "\n",
      "\n",
      "loss before training is 1.669231384105265e-06 -- epoch number 8231\n",
      "\n",
      "\n",
      "loss before training is 1.6674000735487097e-06 -- epoch number 8232\n",
      "\n",
      "\n",
      "loss before training is 1.6655709780303477e-06 -- epoch number 8233\n",
      "\n",
      "\n",
      "loss before training is 1.6637440946153486e-06 -- epoch number 8234\n",
      "\n",
      "\n",
      "loss before training is 1.6619194203727608e-06 -- epoch number 8235\n",
      "\n",
      "\n",
      "loss before training is 1.660096952376535e-06 -- epoch number 8236\n",
      "\n",
      "\n",
      "loss before training is 1.6582766877041481e-06 -- epoch number 8237\n",
      "\n",
      "\n",
      "loss before training is 1.6564586234377236e-06 -- epoch number 8238\n",
      "\n",
      "\n",
      "loss before training is 1.6546427566633455e-06 -- epoch number 8239\n",
      "\n",
      "\n",
      "loss before training is 1.652829084470833e-06 -- epoch number 8240\n",
      "\n",
      "\n",
      "loss before training is 1.65101760395524e-06 -- epoch number 8241\n",
      "\n",
      "\n",
      "loss before training is 1.6492083122145178e-06 -- epoch number 8242\n",
      "\n",
      "\n",
      "loss before training is 1.6474012063515265e-06 -- epoch number 8243\n",
      "\n",
      "\n",
      "loss before training is 1.6455962834729916e-06 -- epoch number 8244\n",
      "\n",
      "\n",
      "loss before training is 1.643793540690015e-06 -- epoch number 8245\n",
      "\n",
      "\n",
      "loss before training is 1.6419929751174394e-06 -- epoch number 8246\n",
      "\n",
      "\n",
      "loss before training is 1.640194583874747e-06 -- epoch number 8247\n",
      "\n",
      "\n",
      "loss before training is 1.6383983640845253e-06 -- epoch number 8248\n",
      "\n",
      "\n",
      "loss before training is 1.63660431287479e-06 -- epoch number 8249\n",
      "\n",
      "\n",
      "loss before training is 1.6348124273766163e-06 -- epoch number 8250\n",
      "\n",
      "\n",
      "loss before training is 1.633022704725427e-06 -- epoch number 8251\n",
      "\n",
      "\n",
      "loss before training is 1.6312351420613959e-06 -- epoch number 8252\n",
      "\n",
      "\n",
      "loss before training is 1.6294497365276257e-06 -- epoch number 8253\n",
      "\n",
      "\n",
      "loss before training is 1.6276664852724075e-06 -- epoch number 8254\n",
      "\n",
      "\n",
      "loss before training is 1.6258853854469388e-06 -- epoch number 8255\n",
      "\n",
      "\n",
      "loss before training is 1.6241064342076032e-06 -- epoch number 8256\n",
      "\n",
      "\n",
      "loss before training is 1.622329628714238e-06 -- epoch number 8257\n",
      "\n",
      "\n",
      "loss before training is 1.6205549661306264e-06 -- epoch number 8258\n",
      "\n",
      "\n",
      "loss before training is 1.6187824436250358e-06 -- epoch number 8259\n",
      "\n",
      "\n",
      "loss before training is 1.6170120583691796e-06 -- epoch number 8260\n",
      "\n",
      "\n",
      "loss before training is 1.615243807539588e-06 -- epoch number 8261\n",
      "\n",
      "\n",
      "loss before training is 1.6134776883160723e-06 -- epoch number 8262\n",
      "\n",
      "\n",
      "loss before training is 1.6117136978826939e-06 -- epoch number 8263\n",
      "\n",
      "\n",
      "loss before training is 1.609951833427632e-06 -- epoch number 8264\n",
      "\n",
      "\n",
      "loss before training is 1.6081920921430815e-06 -- epoch number 8265\n",
      "\n",
      "\n",
      "loss before training is 1.6064344712252097e-06 -- epoch number 8266\n",
      "\n",
      "\n",
      "loss before training is 1.604678967874053e-06 -- epoch number 8267\n",
      "\n",
      "\n",
      "loss before training is 1.6029255792936872e-06 -- epoch number 8268\n",
      "\n",
      "\n",
      "loss before training is 1.6011743026922391e-06 -- epoch number 8269\n",
      "\n",
      "\n",
      "loss before training is 1.5994251352816902e-06 -- epoch number 8270\n",
      "\n",
      "\n",
      "loss before training is 1.5976780742780011e-06 -- epoch number 8271\n",
      "\n",
      "\n",
      "loss before training is 1.5959331169011843e-06 -- epoch number 8272\n",
      "\n",
      "\n",
      "loss before training is 1.59419026037552e-06 -- epoch number 8273\n",
      "\n",
      "\n",
      "loss before training is 1.5924495019282703e-06 -- epoch number 8274\n",
      "\n",
      "\n",
      "loss before training is 1.5907108387917249e-06 -- epoch number 8275\n",
      "\n",
      "\n",
      "loss before training is 1.588974268201541e-06 -- epoch number 8276\n",
      "\n",
      "\n",
      "loss before training is 1.5872397873972528e-06 -- epoch number 8277\n",
      "\n",
      "\n",
      "loss before training is 1.585507393622716e-06 -- epoch number 8278\n",
      "\n",
      "\n",
      "loss before training is 1.5837770841252434e-06 -- epoch number 8279\n",
      "\n",
      "\n",
      "loss before training is 1.5820488561565552e-06 -- epoch number 8280\n",
      "\n",
      "\n",
      "loss before training is 1.5803227069716558e-06 -- epoch number 8281\n",
      "\n",
      "\n",
      "loss before training is 1.5785986338301777e-06 -- epoch number 8282\n",
      "\n",
      "\n",
      "loss before training is 1.5768766339948994e-06 -- epoch number 8283\n",
      "\n",
      "\n",
      "loss before training is 1.5751567047332652e-06 -- epoch number 8284\n",
      "\n",
      "\n",
      "loss before training is 1.5734388433160176e-06 -- epoch number 8285\n",
      "\n",
      "\n",
      "loss before training is 1.5717230470178906e-06 -- epoch number 8286\n",
      "\n",
      "\n",
      "loss before training is 1.5700093131175963e-06 -- epoch number 8287\n",
      "\n",
      "\n",
      "loss before training is 1.5682976388977535e-06 -- epoch number 8288\n",
      "\n",
      "\n",
      "loss before training is 1.5665880216447865e-06 -- epoch number 8289\n",
      "\n",
      "\n",
      "loss before training is 1.5648804586489756e-06 -- epoch number 8290\n",
      "\n",
      "\n",
      "loss before training is 1.5631749472044108e-06 -- epoch number 8291\n",
      "\n",
      "\n",
      "loss before training is 1.5614714846090536e-06 -- epoch number 8292\n",
      "\n",
      "\n",
      "loss before training is 1.5597700681645198e-06 -- epoch number 8293\n",
      "\n",
      "\n",
      "loss before training is 1.5580706951767132e-06 -- epoch number 8294\n",
      "\n",
      "\n",
      "loss before training is 1.5563733629550699e-06 -- epoch number 8295\n",
      "\n",
      "\n",
      "loss before training is 1.554678068812799e-06 -- epoch number 8296\n",
      "\n",
      "\n",
      "loss before training is 1.5529848100669511e-06 -- epoch number 8297\n",
      "\n",
      "\n",
      "loss before training is 1.5512935840385816e-06 -- epoch number 8298\n",
      "\n",
      "\n",
      "loss before training is 1.5496043880520982e-06 -- epoch number 8299\n",
      "\n",
      "\n",
      "loss before training is 1.5479172194362848e-06 -- epoch number 8300\n",
      "\n",
      "\n",
      "loss before training is 1.5462320755234595e-06 -- epoch number 8301\n",
      "\n",
      "\n",
      "loss before training is 1.5445489536496313e-06 -- epoch number 8302\n",
      "\n",
      "\n",
      "loss before training is 1.5428678511544605e-06 -- epoch number 8303\n",
      "\n",
      "\n",
      "loss before training is 1.5411887653821317e-06 -- epoch number 8304\n",
      "\n",
      "\n",
      "loss before training is 1.5395116936794246e-06 -- epoch number 8305\n",
      "\n",
      "\n",
      "loss before training is 1.537836633397716e-06 -- epoch number 8306\n",
      "\n",
      "\n",
      "loss before training is 1.5361635818922911e-06 -- epoch number 8307\n",
      "\n",
      "\n",
      "loss before training is 1.5344925365215719e-06 -- epoch number 8308\n",
      "\n",
      "\n",
      "loss before training is 1.532823494647781e-06 -- epoch number 8309\n",
      "\n",
      "\n",
      "loss before training is 1.5311564536376186e-06 -- epoch number 8310\n",
      "\n",
      "\n",
      "loss before training is 1.5294914108605273e-06 -- epoch number 8311\n",
      "\n",
      "\n",
      "loss before training is 1.5278283636905625e-06 -- epoch number 8312\n",
      "\n",
      "\n",
      "loss before training is 1.5261673095046593e-06 -- epoch number 8313\n",
      "\n",
      "\n",
      "loss before training is 1.5245082456842206e-06 -- epoch number 8314\n",
      "\n",
      "\n",
      "loss before training is 1.5228511696138296e-06 -- epoch number 8315\n",
      "\n",
      "\n",
      "loss before training is 1.5211960786823876e-06 -- epoch number 8316\n",
      "\n",
      "\n",
      "loss before training is 1.519542970281608e-06 -- epoch number 8317\n",
      "\n",
      "\n",
      "loss before training is 1.5178918418078728e-06 -- epoch number 8318\n",
      "\n",
      "\n",
      "loss before training is 1.5162426906601748e-06 -- epoch number 8319\n",
      "\n",
      "\n",
      "loss before training is 1.514595514242475e-06 -- epoch number 8320\n",
      "\n",
      "\n",
      "loss before training is 1.5129503099614597e-06 -- epoch number 8321\n",
      "\n",
      "\n",
      "loss before training is 1.5113070752275679e-06 -- epoch number 8322\n",
      "\n",
      "\n",
      "loss before training is 1.5096658074555278e-06 -- epoch number 8323\n",
      "\n",
      "\n",
      "loss before training is 1.5080265040628679e-06 -- epoch number 8324\n",
      "\n",
      "\n",
      "loss before training is 1.5063891624718272e-06 -- epoch number 8325\n",
      "\n",
      "\n",
      "loss before training is 1.5047537801071613e-06 -- epoch number 8326\n",
      "\n",
      "\n",
      "loss before training is 1.5031203543979115e-06 -- epoch number 8327\n",
      "\n",
      "\n",
      "loss before training is 1.5014888827769461e-06 -- epoch number 8328\n",
      "\n",
      "\n",
      "loss before training is 1.4998593626801342e-06 -- epoch number 8329\n",
      "\n",
      "\n",
      "loss before training is 1.498231791547416e-06 -- epoch number 8330\n",
      "\n",
      "\n",
      "loss before training is 1.4966061668225168e-06 -- epoch number 8331\n",
      "\n",
      "\n",
      "loss before training is 1.4949824859520646e-06 -- epoch number 8332\n",
      "\n",
      "\n",
      "loss before training is 1.4933607463873794e-06 -- epoch number 8333\n",
      "\n",
      "\n",
      "loss before training is 1.49174094558228e-06 -- epoch number 8334\n",
      "\n",
      "\n",
      "loss before training is 1.490123080994982e-06 -- epoch number 8335\n",
      "\n",
      "\n",
      "loss before training is 1.4885071500867503e-06 -- epoch number 8336\n",
      "\n",
      "\n",
      "loss before training is 1.4868931503228697e-06 -- epoch number 8337\n",
      "\n",
      "\n",
      "loss before training is 1.4852810791722055e-06 -- epoch number 8338\n",
      "\n",
      "\n",
      "loss before training is 1.4836709341065424e-06 -- epoch number 8339\n",
      "\n",
      "\n",
      "loss before training is 1.4820627126022894e-06 -- epoch number 8340\n",
      "\n",
      "\n",
      "loss before training is 1.4804564121388328e-06 -- epoch number 8341\n",
      "\n",
      "\n",
      "loss before training is 1.4788520301989161e-06 -- epoch number 8342\n",
      "\n",
      "\n",
      "loss before training is 1.477249564269167e-06 -- epoch number 8343\n",
      "\n",
      "\n",
      "loss before training is 1.4756490118396643e-06 -- epoch number 8344\n",
      "\n",
      "\n",
      "loss before training is 1.4740503704042928e-06 -- epoch number 8345\n",
      "\n",
      "\n",
      "loss before training is 1.4724536374601766e-06 -- epoch number 8346\n",
      "\n",
      "\n",
      "loss before training is 1.4708588105080017e-06 -- epoch number 8347\n",
      "\n",
      "\n",
      "loss before training is 1.4692658870521132e-06 -- epoch number 8348\n",
      "\n",
      "\n",
      "loss before training is 1.4676748646005098e-06 -- epoch number 8349\n",
      "\n",
      "\n",
      "loss before training is 1.4660857406642364e-06 -- epoch number 8350\n",
      "\n",
      "\n",
      "loss before training is 1.464498512758234e-06 -- epoch number 8351\n",
      "\n",
      "\n",
      "loss before training is 1.4629131784012316e-06 -- epoch number 8352\n",
      "\n",
      "\n",
      "loss before training is 1.4613297351146875e-06 -- epoch number 8353\n",
      "\n",
      "\n",
      "loss before training is 1.4597481804243002e-06 -- epoch number 8354\n",
      "\n",
      "\n",
      "loss before training is 1.4581685118586548e-06 -- epoch number 8355\n",
      "\n",
      "\n",
      "loss before training is 1.4565907269502958e-06 -- epoch number 8356\n",
      "\n",
      "\n",
      "loss before training is 1.4550148232353036e-06 -- epoch number 8357\n",
      "\n",
      "\n",
      "loss before training is 1.4534407982525038e-06 -- epoch number 8358\n",
      "\n",
      "\n",
      "loss before training is 1.4518686495453852e-06 -- epoch number 8359\n",
      "\n",
      "\n",
      "loss before training is 1.4502983746597499e-06 -- epoch number 8360\n",
      "\n",
      "\n",
      "loss before training is 1.4487299711456856e-06 -- epoch number 8361\n",
      "\n",
      "\n",
      "loss before training is 1.4471634365561439e-06 -- epoch number 8362\n",
      "\n",
      "\n",
      "loss before training is 1.4455987684482436e-06 -- epoch number 8363\n",
      "\n",
      "\n",
      "loss before training is 1.4440359643816026e-06 -- epoch number 8364\n",
      "\n",
      "\n",
      "loss before training is 1.4424750219202713e-06 -- epoch number 8365\n",
      "\n",
      "\n",
      "loss before training is 1.4409159386310383e-06 -- epoch number 8366\n",
      "\n",
      "\n",
      "loss before training is 1.4393587120843214e-06 -- epoch number 8367\n",
      "\n",
      "\n",
      "loss before training is 1.43780333985412e-06 -- epoch number 8368\n",
      "\n",
      "\n",
      "loss before training is 1.436249819517969e-06 -- epoch number 8369\n",
      "\n",
      "\n",
      "loss before training is 1.434698148656139e-06 -- epoch number 8370\n",
      "\n",
      "\n",
      "loss before training is 1.4331483248531344e-06 -- epoch number 8371\n",
      "\n",
      "\n",
      "loss before training is 1.431600345696393e-06 -- epoch number 8372\n",
      "\n",
      "\n",
      "loss before training is 1.4300542087768992e-06 -- epoch number 8373\n",
      "\n",
      "\n",
      "loss before training is 1.4285099116891384e-06 -- epoch number 8374\n",
      "\n",
      "\n",
      "loss before training is 1.4269674520309389e-06 -- epoch number 8375\n",
      "\n",
      "\n",
      "loss before training is 1.4254268274032287e-06 -- epoch number 8376\n",
      "\n",
      "\n",
      "loss before training is 1.423888035410681e-06 -- epoch number 8377\n",
      "\n",
      "\n",
      "loss before training is 1.4223510736610669e-06 -- epoch number 8378\n",
      "\n",
      "\n",
      "loss before training is 1.4208159397658448e-06 -- epoch number 8379\n",
      "\n",
      "\n",
      "loss before training is 1.4192826313397766e-06 -- epoch number 8380\n",
      "\n",
      "\n",
      "loss before training is 1.41775114600069e-06 -- epoch number 8381\n",
      "\n",
      "\n",
      "loss before training is 1.4162214813700928e-06 -- epoch number 8382\n",
      "\n",
      "\n",
      "loss before training is 1.4146936350728845e-06 -- epoch number 8383\n",
      "\n",
      "\n",
      "loss before training is 1.413167604736725e-06 -- epoch number 8384\n",
      "\n",
      "\n",
      "loss before training is 1.4116433879935545e-06 -- epoch number 8385\n",
      "\n",
      "\n",
      "loss before training is 1.410120982477976e-06 -- epoch number 8386\n",
      "\n",
      "\n",
      "loss before training is 1.4086003858279937e-06 -- epoch number 8387\n",
      "\n",
      "\n",
      "loss before training is 1.4070815956850842e-06 -- epoch number 8388\n",
      "\n",
      "\n",
      "loss before training is 1.4055646096941325e-06 -- epoch number 8389\n",
      "\n",
      "\n",
      "loss before training is 1.404049425503381e-06 -- epoch number 8390\n",
      "\n",
      "\n",
      "loss before training is 1.4025360407637853e-06 -- epoch number 8391\n",
      "\n",
      "\n",
      "loss before training is 1.4010244531305274e-06 -- epoch number 8392\n",
      "\n",
      "\n",
      "loss before training is 1.3995146602612446e-06 -- epoch number 8393\n",
      "\n",
      "\n",
      "loss before training is 1.3980066598175944e-06 -- epoch number 8394\n",
      "\n",
      "\n",
      "loss before training is 1.3965004494641789e-06 -- epoch number 8395\n",
      "\n",
      "\n",
      "loss before training is 1.3949960268686594e-06 -- epoch number 8396\n",
      "\n",
      "\n",
      "loss before training is 1.3934933897023618e-06 -- epoch number 8397\n",
      "\n",
      "\n",
      "loss before training is 1.391992535639888e-06 -- epoch number 8398\n",
      "\n",
      "\n",
      "loss before training is 1.3904934623587585e-06 -- epoch number 8399\n",
      "\n",
      "\n",
      "loss before training is 1.3889961675402164e-06 -- epoch number 8400\n",
      "\n",
      "\n",
      "loss before training is 1.38750064886851e-06 -- epoch number 8401\n",
      "\n",
      "\n",
      "loss before training is 1.3860069040310793e-06 -- epoch number 8402\n",
      "\n",
      "\n",
      "loss before training is 1.384514930718728e-06 -- epoch number 8403\n",
      "\n",
      "\n",
      "loss before training is 1.3830247266256955e-06 -- epoch number 8404\n",
      "\n",
      "\n",
      "loss before training is 1.381536289449238e-06 -- epoch number 8405\n",
      "\n",
      "\n",
      "loss before training is 1.380049616889678e-06 -- epoch number 8406\n",
      "\n",
      "\n",
      "loss before training is 1.378564706651023e-06 -- epoch number 8407\n",
      "\n",
      "\n",
      "loss before training is 1.377081556440364e-06 -- epoch number 8408\n",
      "\n",
      "\n",
      "loss before training is 1.3756001639678006e-06 -- epoch number 8409\n",
      "\n",
      "\n",
      "loss before training is 1.374120526946862e-06 -- epoch number 8410\n",
      "\n",
      "\n",
      "loss before training is 1.3726426430942466e-06 -- epoch number 8411\n",
      "\n",
      "\n",
      "loss before training is 1.3711665101297254e-06 -- epoch number 8412\n",
      "\n",
      "\n",
      "loss before training is 1.369692125776467e-06 -- epoch number 8413\n",
      "\n",
      "\n",
      "loss before training is 1.3682194877608388e-06 -- epoch number 8414\n",
      "\n",
      "\n",
      "loss before training is 1.3667485938124469e-06 -- epoch number 8415\n",
      "\n",
      "\n",
      "loss before training is 1.3652794416639173e-06 -- epoch number 8416\n",
      "\n",
      "\n",
      "loss before training is 1.363812029050839e-06 -- epoch number 8417\n",
      "\n",
      "\n",
      "loss before training is 1.3623463537127615e-06 -- epoch number 8418\n",
      "\n",
      "\n",
      "loss before training is 1.3608824133916869e-06 -- epoch number 8419\n",
      "\n",
      "\n",
      "loss before training is 1.3594202058329607e-06 -- epoch number 8420\n",
      "\n",
      "\n",
      "loss before training is 1.3579597287855032e-06 -- epoch number 8421\n",
      "\n",
      "\n",
      "loss before training is 1.356500980000766e-06 -- epoch number 8422\n",
      "\n",
      "\n",
      "loss before training is 1.3550439572339357e-06 -- epoch number 8423\n",
      "\n",
      "\n",
      "loss before training is 1.3535886582428708e-06 -- epoch number 8424\n",
      "\n",
      "\n",
      "loss before training is 1.3521350807888049e-06 -- epoch number 8425\n",
      "\n",
      "\n",
      "loss before training is 1.3506832226362956e-06 -- epoch number 8426\n",
      "\n",
      "\n",
      "loss before training is 1.3492330815530703e-06 -- epoch number 8427\n",
      "\n",
      "\n",
      "loss before training is 1.3477846553092112e-06 -- epoch number 8428\n",
      "\n",
      "\n",
      "loss before training is 1.346337941678661e-06 -- epoch number 8429\n",
      "\n",
      "\n",
      "loss before training is 1.3448929384388681e-06 -- epoch number 8430\n",
      "\n",
      "\n",
      "loss before training is 1.3434496433691915e-06 -- epoch number 8431\n",
      "\n",
      "\n",
      "loss before training is 1.3420080542532682e-06 -- epoch number 8432\n",
      "\n",
      "\n",
      "loss before training is 1.3405681688772496e-06 -- epoch number 8433\n",
      "\n",
      "\n",
      "loss before training is 1.3391299850302478e-06 -- epoch number 8434\n",
      "\n",
      "\n",
      "loss before training is 1.3376935005053602e-06 -- epoch number 8435\n",
      "\n",
      "\n",
      "loss before training is 1.336258713097497e-06 -- epoch number 8436\n",
      "\n",
      "\n",
      "loss before training is 1.3348256206057985e-06 -- epoch number 8437\n",
      "\n",
      "\n",
      "loss before training is 1.3333942208317813e-06 -- epoch number 8438\n",
      "\n",
      "\n",
      "loss before training is 1.3319645115803796e-06 -- epoch number 8439\n",
      "\n",
      "\n",
      "loss before training is 1.3305364906597597e-06 -- epoch number 8440\n",
      "\n",
      "\n",
      "loss before training is 1.32911015588064e-06 -- epoch number 8441\n",
      "\n",
      "\n",
      "loss before training is 1.3276855050572504e-06 -- epoch number 8442\n",
      "\n",
      "\n",
      "loss before training is 1.3262625360068825e-06 -- epoch number 8443\n",
      "\n",
      "\n",
      "loss before training is 1.3248412465497362e-06 -- epoch number 8444\n",
      "\n",
      "\n",
      "loss before training is 1.3234216345087462e-06 -- epoch number 8445\n",
      "\n",
      "\n",
      "loss before training is 1.3220036977105882e-06 -- epoch number 8446\n",
      "\n",
      "\n",
      "loss before training is 1.3205874339846012e-06 -- epoch number 8447\n",
      "\n",
      "\n",
      "loss before training is 1.3191728411629963e-06 -- epoch number 8448\n",
      "\n",
      "\n",
      "loss before training is 1.3177599170817102e-06 -- epoch number 8449\n",
      "\n",
      "\n",
      "loss before training is 1.3163486595789663e-06 -- epoch number 8450\n",
      "\n",
      "\n",
      "loss before training is 1.3149390664961721e-06 -- epoch number 8451\n",
      "\n",
      "\n",
      "loss before training is 1.3135311356780719e-06 -- epoch number 8452\n",
      "\n",
      "\n",
      "loss before training is 1.3121248649723098e-06 -- epoch number 8453\n",
      "\n",
      "\n",
      "loss before training is 1.3107202522293697e-06 -- epoch number 8454\n",
      "\n",
      "\n",
      "loss before training is 1.3093172953030606e-06 -- epoch number 8455\n",
      "\n",
      "\n",
      "loss before training is 1.3079159920497805e-06 -- epoch number 8456\n",
      "\n",
      "\n",
      "loss before training is 1.3065163403292996e-06 -- epoch number 8457\n",
      "\n",
      "\n",
      "loss before training is 1.3051183380042308e-06 -- epoch number 8458\n",
      "\n",
      "\n",
      "loss before training is 1.303721982940452e-06 -- epoch number 8459\n",
      "\n",
      "\n",
      "loss before training is 1.3023272730059815e-06 -- epoch number 8460\n",
      "\n",
      "\n",
      "loss before training is 1.3009342060730662e-06 -- epoch number 8461\n",
      "\n",
      "\n",
      "loss before training is 1.2995427800159625e-06 -- epoch number 8462\n",
      "\n",
      "\n",
      "loss before training is 1.298152992712335e-06 -- epoch number 8463\n",
      "\n",
      "\n",
      "loss before training is 1.2967648420427527e-06 -- epoch number 8464\n",
      "\n",
      "\n",
      "loss before training is 1.295378325890777e-06 -- epoch number 8465\n",
      "\n",
      "\n",
      "loss before training is 1.2939934421426505e-06 -- epoch number 8466\n",
      "\n",
      "\n",
      "loss before training is 1.292610188688276e-06 -- epoch number 8467\n",
      "\n",
      "\n",
      "loss before training is 1.2912285634194166e-06 -- epoch number 8468\n",
      "\n",
      "\n",
      "loss before training is 1.2898485642320787e-06 -- epoch number 8469\n",
      "\n",
      "\n",
      "loss before training is 1.2884701890241995e-06 -- epoch number 8470\n",
      "\n",
      "\n",
      "loss before training is 1.2870934356968296e-06 -- epoch number 8471\n",
      "\n",
      "\n",
      "loss before training is 1.2857183021545138e-06 -- epoch number 8472\n",
      "\n",
      "\n",
      "loss before training is 1.2843447863044552e-06 -- epoch number 8473\n",
      "\n",
      "\n",
      "loss before training is 1.282972886056326e-06 -- epoch number 8474\n",
      "\n",
      "\n",
      "loss before training is 1.281602599323158e-06 -- epoch number 8475\n",
      "\n",
      "\n",
      "loss before training is 1.2802339240209715e-06 -- epoch number 8476\n",
      "\n",
      "\n",
      "loss before training is 1.2788668580686923e-06 -- epoch number 8477\n",
      "\n",
      "\n",
      "loss before training is 1.2775013993878362e-06 -- epoch number 8478\n",
      "\n",
      "\n",
      "loss before training is 1.2761375459030408e-06 -- epoch number 8479\n",
      "\n",
      "\n",
      "loss before training is 1.2747752955419083e-06 -- epoch number 8480\n",
      "\n",
      "\n",
      "loss before training is 1.2734146462348851e-06 -- epoch number 8481\n",
      "\n",
      "\n",
      "loss before training is 1.2720555959151052e-06 -- epoch number 8482\n",
      "\n",
      "\n",
      "loss before training is 1.2706981425191863e-06 -- epoch number 8483\n",
      "\n",
      "\n",
      "loss before training is 1.2693422839856597e-06 -- epoch number 8484\n",
      "\n",
      "\n",
      "loss before training is 1.2679880182570117e-06 -- epoch number 8485\n",
      "\n",
      "\n",
      "loss before training is 1.2666353432778745e-06 -- epoch number 8486\n",
      "\n",
      "\n",
      "loss before training is 1.2652842569960593e-06 -- epoch number 8487\n",
      "\n",
      "\n",
      "loss before training is 1.263934757362163e-06 -- epoch number 8488\n",
      "\n",
      "\n",
      "loss before training is 1.2625868423295156e-06 -- epoch number 8489\n",
      "\n",
      "\n",
      "loss before training is 1.2612405098547426e-06 -- epoch number 8490\n",
      "\n",
      "\n",
      "loss before training is 1.259895757896651e-06 -- epoch number 8491\n",
      "\n",
      "\n",
      "loss before training is 1.2585525844177648e-06 -- epoch number 8492\n",
      "\n",
      "\n",
      "loss before training is 1.2572109873826407e-06 -- epoch number 8493\n",
      "\n",
      "\n",
      "loss before training is 1.2558709647589477e-06 -- epoch number 8494\n",
      "\n",
      "\n",
      "loss before training is 1.254532514517484e-06 -- epoch number 8495\n",
      "\n",
      "\n",
      "loss before training is 1.2531956346315448e-06 -- epoch number 8496\n",
      "\n",
      "\n",
      "loss before training is 1.2518603230773523e-06 -- epoch number 8497\n",
      "\n",
      "\n",
      "loss before training is 1.2505265778341175e-06 -- epoch number 8498\n",
      "\n",
      "\n",
      "loss before training is 1.2491943968836765e-06 -- epoch number 8499\n",
      "\n",
      "\n",
      "loss before training is 1.2478637782106163e-06 -- epoch number 8500\n",
      "\n",
      "\n",
      "loss before training is 1.2465347198025238e-06 -- epoch number 8501\n",
      "\n",
      "\n",
      "loss before training is 1.2452072196497731e-06 -- epoch number 8502\n",
      "\n",
      "\n",
      "loss before training is 1.2438812757454138e-06 -- epoch number 8503\n",
      "\n",
      "\n",
      "loss before training is 1.242556886085626e-06 -- epoch number 8504\n",
      "\n",
      "\n",
      "loss before training is 1.2412340486688601e-06 -- epoch number 8505\n",
      "\n",
      "\n",
      "loss before training is 1.2399127614968545e-06 -- epoch number 8506\n",
      "\n",
      "\n",
      "loss before training is 1.2385930225738898e-06 -- epoch number 8507\n",
      "\n",
      "\n",
      "loss before training is 1.2372748299069832e-06 -- epoch number 8508\n",
      "\n",
      "\n",
      "loss before training is 1.2359581815061345e-06 -- epoch number 8509\n",
      "\n",
      "\n",
      "loss before training is 1.2346430753839957e-06 -- epoch number 8510\n",
      "\n",
      "\n",
      "loss before training is 1.2333295095558816e-06 -- epoch number 8511\n",
      "\n",
      "\n",
      "loss before training is 1.2320174820402276e-06 -- epoch number 8512\n",
      "\n",
      "\n",
      "loss before training is 1.2307069908578384e-06 -- epoch number 8513\n",
      "\n",
      "\n",
      "loss before training is 1.229398034032586e-06 -- epoch number 8514\n",
      "\n",
      "\n",
      "loss before training is 1.2280906095907897e-06 -- epoch number 8515\n",
      "\n",
      "\n",
      "loss before training is 1.226784715561974e-06 -- epoch number 8516\n",
      "\n",
      "\n",
      "loss before training is 1.2254803499777874e-06 -- epoch number 8517\n",
      "\n",
      "\n",
      "loss before training is 1.2241775108731358e-06 -- epoch number 8518\n",
      "\n",
      "\n",
      "loss before training is 1.2228761962858084e-06 -- epoch number 8519\n",
      "\n",
      "\n",
      "loss before training is 1.2215764042553049e-06 -- epoch number 8520\n",
      "\n",
      "\n",
      "loss before training is 1.2202781328253636e-06 -- epoch number 8521\n",
      "\n",
      "\n",
      "loss before training is 1.2189813800410655e-06 -- epoch number 8522\n",
      "\n",
      "\n",
      "loss before training is 1.2176861439512655e-06 -- epoch number 8523\n",
      "\n",
      "\n",
      "loss before training is 1.2163924226066725e-06 -- epoch number 8524\n",
      "\n",
      "\n",
      "loss before training is 1.2151002140615153e-06 -- epoch number 8525\n",
      "\n",
      "\n",
      "loss before training is 1.2138095163720634e-06 -- epoch number 8526\n",
      "\n",
      "\n",
      "loss before training is 1.2125203275975893e-06 -- epoch number 8527\n",
      "\n",
      "\n",
      "loss before training is 1.211232645800179e-06 -- epoch number 8528\n",
      "\n",
      "\n",
      "loss before training is 1.209946469044581e-06 -- epoch number 8529\n",
      "\n",
      "\n",
      "loss before training is 1.208661795397828e-06 -- epoch number 8530\n",
      "\n",
      "\n",
      "loss before training is 1.2073786229304312e-06 -- epoch number 8531\n",
      "\n",
      "\n",
      "loss before training is 1.206096949714676e-06 -- epoch number 8532\n",
      "\n",
      "\n",
      "loss before training is 1.2048167738263652e-06 -- epoch number 8533\n",
      "\n",
      "\n",
      "loss before training is 1.2035380933433823e-06 -- epoch number 8534\n",
      "\n",
      "\n",
      "loss before training is 1.2022609063466323e-06 -- epoch number 8535\n",
      "\n",
      "\n",
      "loss before training is 1.20098521091939e-06 -- epoch number 8536\n",
      "\n",
      "\n",
      "loss before training is 1.1997110051479723e-06 -- epoch number 8537\n",
      "\n",
      "\n",
      "loss before training is 1.1984382871211601e-06 -- epoch number 8538\n",
      "\n",
      "\n",
      "loss before training is 1.1971670549302909e-06 -- epoch number 8539\n",
      "\n",
      "\n",
      "loss before training is 1.195897306669572e-06 -- epoch number 8540\n",
      "\n",
      "\n",
      "loss before training is 1.1946290404354423e-06 -- epoch number 8541\n",
      "\n",
      "\n",
      "loss before training is 1.193362254327792e-06 -- epoch number 8542\n",
      "\n",
      "\n",
      "loss before training is 1.1920969464484065e-06 -- epoch number 8543\n",
      "\n",
      "\n",
      "loss before training is 1.1908331149021375e-06 -- epoch number 8544\n",
      "\n",
      "\n",
      "loss before training is 1.1895707577960286e-06 -- epoch number 8545\n",
      "\n",
      "\n",
      "loss before training is 1.188309873240322e-06 -- epoch number 8546\n",
      "\n",
      "\n",
      "loss before training is 1.187050459347536e-06 -- epoch number 8547\n",
      "\n",
      "\n",
      "loss before training is 1.1857925142328605e-06 -- epoch number 8548\n",
      "\n",
      "\n",
      "loss before training is 1.1845360360140867e-06 -- epoch number 8549\n",
      "\n",
      "\n",
      "loss before training is 1.1832810228117518e-06 -- epoch number 8550\n",
      "\n",
      "\n",
      "loss before training is 1.182027472748853e-06 -- epoch number 8551\n",
      "\n",
      "\n",
      "loss before training is 1.1807753839511879e-06 -- epoch number 8552\n",
      "\n",
      "\n",
      "loss before training is 1.1795247545468662e-06 -- epoch number 8553\n",
      "\n",
      "\n",
      "loss before training is 1.1782755826668965e-06 -- epoch number 8554\n",
      "\n",
      "\n",
      "loss before training is 1.1770278664448704e-06 -- epoch number 8555\n",
      "\n",
      "\n",
      "loss before training is 1.175781604016695e-06 -- epoch number 8556\n",
      "\n",
      "\n",
      "loss before training is 1.1745367935210713e-06 -- epoch number 8557\n",
      "\n",
      "\n",
      "loss before training is 1.173293433099165e-06 -- epoch number 8558\n",
      "\n",
      "\n",
      "loss before training is 1.1720515208950575e-06 -- epoch number 8559\n",
      "\n",
      "\n",
      "loss before training is 1.1708110550549795e-06 -- epoch number 8560\n",
      "\n",
      "\n",
      "loss before training is 1.1695720337281814e-06 -- epoch number 8561\n",
      "\n",
      "\n",
      "loss before training is 1.1683344550659073e-06 -- epoch number 8562\n",
      "\n",
      "\n",
      "loss before training is 1.1670983172226362e-06 -- epoch number 8563\n",
      "\n",
      "\n",
      "loss before training is 1.1658636183547032e-06 -- epoch number 8564\n",
      "\n",
      "\n",
      "loss before training is 1.1646303566214836e-06 -- epoch number 8565\n",
      "\n",
      "\n",
      "loss before training is 1.1633985301848536e-06 -- epoch number 8566\n",
      "\n",
      "\n",
      "loss before training is 1.1621681372090905e-06 -- epoch number 8567\n",
      "\n",
      "\n",
      "loss before training is 1.1609391758612842e-06 -- epoch number 8568\n",
      "\n",
      "\n",
      "loss before training is 1.1597116443109608e-06 -- epoch number 8569\n",
      "\n",
      "\n",
      "loss before training is 1.1584855407298087e-06 -- epoch number 8570\n",
      "\n",
      "\n",
      "loss before training is 1.1572608632925e-06 -- epoch number 8571\n",
      "\n",
      "\n",
      "loss before training is 1.1560376101762035e-06 -- epoch number 8572\n",
      "\n",
      "\n",
      "loss before training is 1.1548157795604545e-06 -- epoch number 8573\n",
      "\n",
      "\n",
      "loss before training is 1.1535953696273362e-06 -- epoch number 8574\n",
      "\n",
      "\n",
      "loss before training is 1.152376378561468e-06 -- epoch number 8575\n",
      "\n",
      "\n",
      "loss before training is 1.151158804550402e-06 -- epoch number 8576\n",
      "\n",
      "\n",
      "loss before training is 1.1499426457832776e-06 -- epoch number 8577\n",
      "\n",
      "\n",
      "loss before training is 1.1487279004527532e-06 -- epoch number 8578\n",
      "\n",
      "\n",
      "loss before training is 1.1475145667533548e-06 -- epoch number 8579\n",
      "\n",
      "\n",
      "loss before training is 1.1463026428820552e-06 -- epoch number 8580\n",
      "\n",
      "\n",
      "loss before training is 1.1450921270388807e-06 -- epoch number 8581\n",
      "\n",
      "\n",
      "loss before training is 1.1438830174261557e-06 -- epoch number 8582\n",
      "\n",
      "\n",
      "loss before training is 1.1426753122481748e-06 -- epoch number 8583\n",
      "\n",
      "\n",
      "loss before training is 1.1414690097122248e-06 -- epoch number 8584\n",
      "\n",
      "\n",
      "loss before training is 1.1402641080283057e-06 -- epoch number 8585\n",
      "\n",
      "\n",
      "loss before training is 1.1390606054081608e-06 -- epoch number 8586\n",
      "\n",
      "\n",
      "loss before training is 1.1378585000669012e-06 -- epoch number 8587\n",
      "\n",
      "\n",
      "loss before training is 1.1366577902211235e-06 -- epoch number 8588\n",
      "\n",
      "\n",
      "loss before training is 1.135458474090824e-06 -- epoch number 8589\n",
      "\n",
      "\n",
      "loss before training is 1.1342605498977353e-06 -- epoch number 8590\n",
      "\n",
      "\n",
      "loss before training is 1.1330640158664514e-06 -- epoch number 8591\n",
      "\n",
      "\n",
      "loss before training is 1.131868870224222e-06 -- epoch number 8592\n",
      "\n",
      "\n",
      "loss before training is 1.1306751112001374e-06 -- epoch number 8593\n",
      "\n",
      "\n",
      "loss before training is 1.1294827370262954e-06 -- epoch number 8594\n",
      "\n",
      "\n",
      "loss before training is 1.128291745937067e-06 -- epoch number 8595\n",
      "\n",
      "\n",
      "loss before training is 1.1271021361689332e-06 -- epoch number 8596\n",
      "\n",
      "\n",
      "loss before training is 1.1259139059612473e-06 -- epoch number 8597\n",
      "\n",
      "\n",
      "loss before training is 1.1247270535557504e-06 -- epoch number 8598\n",
      "\n",
      "\n",
      "loss before training is 1.1235415771964874e-06 -- epoch number 8599\n",
      "\n",
      "\n",
      "loss before training is 1.1223574751299768e-06 -- epoch number 8600\n",
      "\n",
      "\n",
      "loss before training is 1.1211747456054159e-06 -- epoch number 8601\n",
      "\n",
      "\n",
      "loss before training is 1.1199933868735982e-06 -- epoch number 8602\n",
      "\n",
      "\n",
      "loss before training is 1.1188133971888127e-06 -- epoch number 8603\n",
      "\n",
      "\n",
      "loss before training is 1.1176347748071557e-06 -- epoch number 8604\n",
      "\n",
      "\n",
      "loss before training is 1.1164575179872397e-06 -- epoch number 8605\n",
      "\n",
      "\n",
      "loss before training is 1.1152816249899719e-06 -- epoch number 8606\n",
      "\n",
      "\n",
      "loss before training is 1.1141070940790989e-06 -- epoch number 8607\n",
      "\n",
      "\n",
      "loss before training is 1.1129339235200963e-06 -- epoch number 8608\n",
      "\n",
      "\n",
      "loss before training is 1.1117621115815137e-06 -- epoch number 8609\n",
      "\n",
      "\n",
      "loss before training is 1.1105916565338555e-06 -- epoch number 8610\n",
      "\n",
      "\n",
      "loss before training is 1.109422556650134e-06 -- epoch number 8611\n",
      "\n",
      "\n",
      "loss before training is 1.1082548102058066e-06 -- epoch number 8612\n",
      "\n",
      "\n",
      "loss before training is 1.1070884154787728e-06 -- epoch number 8613\n",
      "\n",
      "\n",
      "loss before training is 1.105923370748903e-06 -- epoch number 8614\n",
      "\n",
      "\n",
      "loss before training is 1.1047596742991528e-06 -- epoch number 8615\n",
      "\n",
      "\n",
      "loss before training is 1.1035973244144119e-06 -- epoch number 8616\n",
      "\n",
      "\n",
      "loss before training is 1.1024363193815896e-06 -- epoch number 8617\n",
      "\n",
      "\n",
      "loss before training is 1.1012766574907413e-06 -- epoch number 8618\n",
      "\n",
      "\n",
      "loss before training is 1.1001183370340742e-06 -- epoch number 8619\n",
      "\n",
      "\n",
      "loss before training is 1.0989613563054962e-06 -- epoch number 8620\n",
      "\n",
      "\n",
      "loss before training is 1.0978057136020773e-06 -- epoch number 8621\n",
      "\n",
      "\n",
      "loss before training is 1.0966514072228517e-06 -- epoch number 8622\n",
      "\n",
      "\n",
      "loss before training is 1.0954984354691733e-06 -- epoch number 8623\n",
      "\n",
      "\n",
      "loss before training is 1.0943467966450433e-06 -- epoch number 8624\n",
      "\n",
      "\n",
      "loss before training is 1.0931964890565458e-06 -- epoch number 8625\n",
      "\n",
      "\n",
      "loss before training is 1.092047511012343e-06 -- epoch number 8626\n",
      "\n",
      "\n",
      "loss before training is 1.0908998608228795e-06 -- epoch number 8627\n",
      "\n",
      "\n",
      "loss before training is 1.089753536801599e-06 -- epoch number 8628\n",
      "\n",
      "\n",
      "loss before training is 1.0886085372640689e-06 -- epoch number 8629\n",
      "\n",
      "\n",
      "loss before training is 1.0874648605277477e-06 -- epoch number 8630\n",
      "\n",
      "\n",
      "loss before training is 1.086322504913028e-06 -- epoch number 8631\n",
      "\n",
      "\n",
      "loss before training is 1.0851814687424868e-06 -- epoch number 8632\n",
      "\n",
      "\n",
      "loss before training is 1.084041750340602e-06 -- epoch number 8633\n",
      "\n",
      "\n",
      "loss before training is 1.0829033480348496e-06 -- epoch number 8634\n",
      "\n",
      "\n",
      "loss before training is 1.0817662601541155e-06 -- epoch number 8635\n",
      "\n",
      "\n",
      "loss before training is 1.0806304850304708e-06 -- epoch number 8636\n",
      "\n",
      "\n",
      "loss before training is 1.0794960209979208e-06 -- epoch number 8637\n",
      "\n",
      "\n",
      "loss before training is 1.0783628663925666e-06 -- epoch number 8638\n",
      "\n",
      "\n",
      "loss before training is 1.0772310195531852e-06 -- epoch number 8639\n",
      "\n",
      "\n",
      "loss before training is 1.0761004788204713e-06 -- epoch number 8640\n",
      "\n",
      "\n",
      "loss before training is 1.0749712425379461e-06 -- epoch number 8641\n",
      "\n",
      "\n",
      "loss before training is 1.0738433090507515e-06 -- epoch number 8642\n",
      "\n",
      "\n",
      "loss before training is 1.0727166767067127e-06 -- epoch number 8643\n",
      "\n",
      "\n",
      "loss before training is 1.0715913438560114e-06 -- epoch number 8644\n",
      "\n",
      "\n",
      "loss before training is 1.070467308850905e-06 -- epoch number 8645\n",
      "\n",
      "\n",
      "loss before training is 1.0693445700456076e-06 -- epoch number 8646\n",
      "\n",
      "\n",
      "loss before training is 1.0682231257975225e-06 -- epoch number 8647\n",
      "\n",
      "\n",
      "loss before training is 1.0671029744653515e-06 -- epoch number 8648\n",
      "\n",
      "\n",
      "loss before training is 1.0659841144106452e-06 -- epoch number 8649\n",
      "\n",
      "\n",
      "loss before training is 1.06486654399685e-06 -- epoch number 8650\n",
      "\n",
      "\n",
      "loss before training is 1.063750261590168e-06 -- epoch number 8651\n",
      "\n",
      "\n",
      "loss before training is 1.0626352655584316e-06 -- epoch number 8652\n",
      "\n",
      "\n",
      "loss before training is 1.0615215542721046e-06 -- epoch number 8653\n",
      "\n",
      "\n",
      "loss before training is 1.0604091261038692e-06 -- epoch number 8654\n",
      "\n",
      "\n",
      "loss before training is 1.0592979794286202e-06 -- epoch number 8655\n",
      "\n",
      "\n",
      "loss before training is 1.0581881126235394e-06 -- epoch number 8656\n",
      "\n",
      "\n",
      "loss before training is 1.0570795240675435e-06 -- epoch number 8657\n",
      "\n",
      "\n",
      "loss before training is 1.0559722121428283e-06 -- epoch number 8658\n",
      "\n",
      "\n",
      "loss before training is 1.054866175232747e-06 -- epoch number 8659\n",
      "\n",
      "\n",
      "loss before training is 1.0537614117235068e-06 -- epoch number 8660\n",
      "\n",
      "\n",
      "loss before training is 1.0526579200033247e-06 -- epoch number 8661\n",
      "\n",
      "\n",
      "loss before training is 1.0515556984627316e-06 -- epoch number 8662\n",
      "\n",
      "\n",
      "loss before training is 1.0504547454942757e-06 -- epoch number 8663\n",
      "\n",
      "\n",
      "loss before training is 1.049355059492968e-06 -- epoch number 8664\n",
      "\n",
      "\n",
      "loss before training is 1.0482566388560249e-06 -- epoch number 8665\n",
      "\n",
      "\n",
      "loss before training is 1.047159481982572e-06 -- epoch number 8666\n",
      "\n",
      "\n",
      "loss before training is 1.0460635872742745e-06 -- epoch number 8667\n",
      "\n",
      "\n",
      "loss before training is 1.0449689531345758e-06 -- epoch number 8668\n",
      "\n",
      "\n",
      "loss before training is 1.0438755779697584e-06 -- epoch number 8669\n",
      "\n",
      "\n",
      "loss before training is 1.0427834601876965e-06 -- epoch number 8670\n",
      "\n",
      "\n",
      "loss before training is 1.041692598198779e-06 -- epoch number 8671\n",
      "\n",
      "\n",
      "loss before training is 1.0406029904153795e-06 -- epoch number 8672\n",
      "\n",
      "\n",
      "loss before training is 1.0395146352523843e-06 -- epoch number 8673\n",
      "\n",
      "\n",
      "loss before training is 1.0384275311266527e-06 -- epoch number 8674\n",
      "\n",
      "\n",
      "loss before training is 1.0373416764568517e-06 -- epoch number 8675\n",
      "\n",
      "\n",
      "loss before training is 1.0362570696644077e-06 -- epoch number 8676\n",
      "\n",
      "\n",
      "loss before training is 1.0351737091728297e-06 -- epoch number 8677\n",
      "\n",
      "\n",
      "loss before training is 1.0340915934075532e-06 -- epoch number 8678\n",
      "\n",
      "\n",
      "loss before training is 1.0330107207959762e-06 -- epoch number 8679\n",
      "\n",
      "\n",
      "loss before training is 1.0319310897684457e-06 -- epoch number 8680\n",
      "\n",
      "\n",
      "loss before training is 1.0308526987565316e-06 -- epoch number 8681\n",
      "\n",
      "\n",
      "loss before training is 1.0297755461949017e-06 -- epoch number 8682\n",
      "\n",
      "\n",
      "loss before training is 1.0286996305196322e-06 -- epoch number 8683\n",
      "\n",
      "\n",
      "loss before training is 1.0276249501691648e-06 -- epoch number 8684\n",
      "\n",
      "\n",
      "loss before training is 1.026551503584156e-06 -- epoch number 8685\n",
      "\n",
      "\n",
      "loss before training is 1.0254792892071405e-06 -- epoch number 8686\n",
      "\n",
      "\n",
      "loss before training is 1.0244083054835917e-06 -- epoch number 8687\n",
      "\n",
      "\n",
      "loss before training is 1.0233385508601479e-06 -- epoch number 8688\n",
      "\n",
      "\n",
      "loss before training is 1.0222700237858729e-06 -- epoch number 8689\n",
      "\n",
      "\n",
      "loss before training is 1.021202722712359e-06 -- epoch number 8690\n",
      "\n",
      "\n",
      "loss before training is 1.0201366460928299e-06 -- epoch number 8691\n",
      "\n",
      "\n",
      "loss before training is 1.0190717923830131e-06 -- epoch number 8692\n",
      "\n",
      "\n",
      "loss before training is 1.0180081600404854e-06 -- epoch number 8693\n",
      "\n",
      "\n",
      "loss before training is 1.0169457475251109e-06 -- epoch number 8694\n",
      "\n",
      "\n",
      "loss before training is 1.0158845532986787e-06 -- epoch number 8695\n",
      "\n",
      "\n",
      "loss before training is 1.0148245758252065e-06 -- epoch number 8696\n",
      "\n",
      "\n",
      "loss before training is 1.013765813570981e-06 -- epoch number 8697\n",
      "\n",
      "\n",
      "loss before training is 1.0127082650039744e-06 -- epoch number 8698\n",
      "\n",
      "\n",
      "loss before training is 1.0116519285947847e-06 -- epoch number 8699\n",
      "\n",
      "\n",
      "loss before training is 1.0105968028157242e-06 -- epoch number 8700\n",
      "\n",
      "\n",
      "loss before training is 1.0095428861411682e-06 -- epoch number 8701\n",
      "\n",
      "\n",
      "loss before training is 1.0084901770480109e-06 -- epoch number 8702\n",
      "\n",
      "\n",
      "loss before training is 1.00743867401481e-06 -- epoch number 8703\n",
      "\n",
      "\n",
      "loss before training is 1.006388375522372e-06 -- epoch number 8704\n",
      "\n",
      "\n",
      "loss before training is 1.0053392800534642e-06 -- epoch number 8705\n",
      "\n",
      "\n",
      "loss before training is 1.0042913860931028e-06 -- epoch number 8706\n",
      "\n",
      "\n",
      "loss before training is 1.0032446921286386e-06 -- epoch number 8707\n",
      "\n",
      "\n",
      "loss before training is 1.0021991966487308e-06 -- epoch number 8708\n",
      "\n",
      "\n",
      "loss before training is 1.0011548981447712e-06 -- epoch number 8709\n",
      "\n",
      "\n",
      "loss before training is 1.000111795109992e-06 -- epoch number 8710\n",
      "\n",
      "\n",
      "loss before training is 9.990698860396027e-07 -- epoch number 8711\n",
      "\n",
      "\n",
      "loss before training is 9.980291694311413e-07 -- epoch number 8712\n",
      "\n",
      "\n",
      "loss before training is 9.969896437838733e-07 -- epoch number 8713\n",
      "\n",
      "\n",
      "loss before training is 9.959513075992986e-07 -- epoch number 8714\n",
      "\n",
      "\n",
      "loss before training is 9.949141593812087e-07 -- epoch number 8715\n",
      "\n",
      "\n",
      "loss before training is 9.938781976349585e-07 -- epoch number 8716\n",
      "\n",
      "\n",
      "loss before training is 9.928434208683595e-07 -- epoch number 8717\n",
      "\n",
      "\n",
      "loss before training is 9.918098275908535e-07 -- epoch number 8718\n",
      "\n",
      "\n",
      "loss before training is 9.907774163143874e-07 -- epoch number 8719\n",
      "\n",
      "\n",
      "loss before training is 9.897461855524465e-07 -- epoch number 8720\n",
      "\n",
      "\n",
      "loss before training is 9.887161338212462e-07 -- epoch number 8721\n",
      "\n",
      "\n",
      "loss before training is 9.876872596382691e-07 -- epoch number 8722\n",
      "\n",
      "\n",
      "loss before training is 9.866595615235383e-07 -- epoch number 8723\n",
      "\n",
      "\n",
      "loss before training is 9.856330379988331e-07 -- epoch number 8724\n",
      "\n",
      "\n",
      "loss before training is 9.846076875882007e-07 -- epoch number 8725\n",
      "\n",
      "\n",
      "loss before training is 9.8358350881735e-07 -- epoch number 8726\n",
      "\n",
      "\n",
      "loss before training is 9.825605002145924e-07 -- epoch number 8727\n",
      "\n",
      "\n",
      "loss before training is 9.81538660309385e-07 -- epoch number 8728\n",
      "\n",
      "\n",
      "loss before training is 9.805179876342393e-07 -- epoch number 8729\n",
      "\n",
      "\n",
      "loss before training is 9.79498480722651e-07 -- epoch number 8730\n",
      "\n",
      "\n",
      "loss before training is 9.784801381109507e-07 -- epoch number 8731\n",
      "\n",
      "\n",
      "loss before training is 9.774629583370046e-07 -- epoch number 8732\n",
      "\n",
      "\n",
      "loss before training is 9.764469399408416e-07 -- epoch number 8733\n",
      "\n",
      "\n",
      "loss before training is 9.754320814643505e-07 -- epoch number 8734\n",
      "\n",
      "\n",
      "loss before training is 9.744183814515145e-07 -- epoch number 8735\n",
      "\n",
      "\n",
      "loss before training is 9.734058384482889e-07 -- epoch number 8736\n",
      "\n",
      "\n",
      "loss before training is 9.723944510028897e-07 -- epoch number 8737\n",
      "\n",
      "\n",
      "loss before training is 9.713842176650652e-07 -- epoch number 8738\n",
      "\n",
      "\n",
      "loss before training is 9.703751369864851e-07 -- epoch number 8739\n",
      "\n",
      "\n",
      "loss before training is 9.69367207521684e-07 -- epoch number 8740\n",
      "\n",
      "\n",
      "loss before training is 9.683604278258917e-07 -- epoch number 8741\n",
      "\n",
      "\n",
      "loss before training is 9.67354796457358e-07 -- epoch number 8742\n",
      "\n",
      "\n",
      "loss before training is 9.66350311975739e-07 -- epoch number 8743\n",
      "\n",
      "\n",
      "loss before training is 9.653469729428826e-07 -- epoch number 8744\n",
      "\n",
      "\n",
      "loss before training is 9.643447779225467e-07 -- epoch number 8745\n",
      "\n",
      "\n",
      "loss before training is 9.633437254804221e-07 -- epoch number 8746\n",
      "\n",
      "\n",
      "loss before training is 9.623438141841712e-07 -- epoch number 8747\n",
      "\n",
      "\n",
      "loss before training is 9.613450426035344e-07 -- epoch number 8748\n",
      "\n",
      "\n",
      "loss before training is 9.603474093100222e-07 -- epoch number 8749\n",
      "\n",
      "\n",
      "loss before training is 9.593509128771313e-07 -- epoch number 8750\n",
      "\n",
      "\n",
      "loss before training is 9.583555518804103e-07 -- epoch number 8751\n",
      "\n",
      "\n",
      "loss before training is 9.57361324897279e-07 -- epoch number 8752\n",
      "\n",
      "\n",
      "loss before training is 9.563682305071925e-07 -- epoch number 8753\n",
      "\n",
      "\n",
      "loss before training is 9.55376267291207e-07 -- epoch number 8754\n",
      "\n",
      "\n",
      "loss before training is 9.543854338328626e-07 -- epoch number 8755\n",
      "\n",
      "\n",
      "loss before training is 9.533957287171412e-07 -- epoch number 8756\n",
      "\n",
      "\n",
      "loss before training is 9.524071505313739e-07 -- epoch number 8757\n",
      "\n",
      "\n",
      "loss before training is 9.514196978644628e-07 -- epoch number 8758\n",
      "\n",
      "\n",
      "loss before training is 9.504333693071854e-07 -- epoch number 8759\n",
      "\n",
      "\n",
      "loss before training is 9.494481634526905e-07 -- epoch number 8760\n",
      "\n",
      "\n",
      "loss before training is 9.484640788957113e-07 -- epoch number 8761\n",
      "\n",
      "\n",
      "loss before training is 9.474811142330524e-07 -- epoch number 8762\n",
      "\n",
      "\n",
      "loss before training is 9.464992680632476e-07 -- epoch number 8763\n",
      "\n",
      "\n",
      "loss before training is 9.455185389867551e-07 -- epoch number 8764\n",
      "\n",
      "\n",
      "loss before training is 9.445389256064157e-07 -- epoch number 8765\n",
      "\n",
      "\n",
      "loss before training is 9.435604265260498e-07 -- epoch number 8766\n",
      "\n",
      "\n",
      "loss before training is 9.425830403523294e-07 -- epoch number 8767\n",
      "\n",
      "\n",
      "loss before training is 9.416067656932993e-07 -- epoch number 8768\n",
      "\n",
      "\n",
      "loss before training is 9.40631601158907e-07 -- epoch number 8769\n",
      "\n",
      "\n",
      "loss before training is 9.396575453613612e-07 -- epoch number 8770\n",
      "\n",
      "\n",
      "loss before training is 9.386845969142368e-07 -- epoch number 8771\n",
      "\n",
      "\n",
      "loss before training is 9.37712754433473e-07 -- epoch number 8772\n",
      "\n",
      "\n",
      "loss before training is 9.367420165365719e-07 -- epoch number 8773\n",
      "\n",
      "\n",
      "loss before training is 9.357723818432998e-07 -- epoch number 8774\n",
      "\n",
      "\n",
      "loss before training is 9.348038489746174e-07 -- epoch number 8775\n",
      "\n",
      "\n",
      "loss before training is 9.338364165539831e-07 -- epoch number 8776\n",
      "\n",
      "\n",
      "loss before training is 9.328700832065188e-07 -- epoch number 8777\n",
      "\n",
      "\n",
      "loss before training is 9.319048475594304e-07 -- epoch number 8778\n",
      "\n",
      "\n",
      "loss before training is 9.309407082414162e-07 -- epoch number 8779\n",
      "\n",
      "\n",
      "loss before training is 9.299776638834291e-07 -- epoch number 8780\n",
      "\n",
      "\n",
      "loss before training is 9.29015713117699e-07 -- epoch number 8781\n",
      "\n",
      "\n",
      "loss before training is 9.280548545789559e-07 -- epoch number 8782\n",
      "\n",
      "\n",
      "loss before training is 9.270950869034547e-07 -- epoch number 8783\n",
      "\n",
      "\n",
      "loss before training is 9.261364087294087e-07 -- epoch number 8784\n",
      "\n",
      "\n",
      "loss before training is 9.251788186971335e-07 -- epoch number 8785\n",
      "\n",
      "\n",
      "loss before training is 9.242223154479527e-07 -- epoch number 8786\n",
      "\n",
      "\n",
      "loss before training is 9.232668976261835e-07 -- epoch number 8787\n",
      "\n",
      "\n",
      "loss before training is 9.223125638770921e-07 -- epoch number 8788\n",
      "\n",
      "\n",
      "loss before training is 9.213593128479754e-07 -- epoch number 8789\n",
      "\n",
      "\n",
      "loss before training is 9.204071431885447e-07 -- epoch number 8790\n",
      "\n",
      "\n",
      "loss before training is 9.194560535496494e-07 -- epoch number 8791\n",
      "\n",
      "\n",
      "loss before training is 9.185060425841157e-07 -- epoch number 8792\n",
      "\n",
      "\n",
      "loss before training is 9.175571089469854e-07 -- epoch number 8793\n",
      "\n",
      "\n",
      "loss before training is 9.166092512945962e-07 -- epoch number 8794\n",
      "\n",
      "\n",
      "loss before training is 9.156624682857751e-07 -- epoch number 8795\n",
      "\n",
      "\n",
      "loss before training is 9.147167585802774e-07 -- epoch number 8796\n",
      "\n",
      "\n",
      "loss before training is 9.137721208404338e-07 -- epoch number 8797\n",
      "\n",
      "\n",
      "loss before training is 9.128285537301048e-07 -- epoch number 8798\n",
      "\n",
      "\n",
      "loss before training is 9.118860559151969e-07 -- epoch number 8799\n",
      "\n",
      "\n",
      "loss before training is 9.10944626062931e-07 -- epoch number 8800\n",
      "\n",
      "\n",
      "loss before training is 9.10004262842698e-07 -- epoch number 8801\n",
      "\n",
      "\n",
      "loss before training is 9.0906496492568e-07 -- epoch number 8802\n",
      "\n",
      "\n",
      "loss before training is 9.081267309851326e-07 -- epoch number 8803\n",
      "\n",
      "\n",
      "loss before training is 9.071895596951584e-07 -- epoch number 8804\n",
      "\n",
      "\n",
      "loss before training is 9.062534497330286e-07 -- epoch number 8805\n",
      "\n",
      "\n",
      "loss before training is 9.053183997764543e-07 -- epoch number 8806\n",
      "\n",
      "\n",
      "loss before training is 9.043844085059703e-07 -- epoch number 8807\n",
      "\n",
      "\n",
      "loss before training is 9.034514746033399e-07 -- epoch number 8808\n",
      "\n",
      "\n",
      "loss before training is 9.025195967523782e-07 -- epoch number 8809\n",
      "\n",
      "\n",
      "loss before training is 9.015887736386839e-07 -- epoch number 8810\n",
      "\n",
      "\n",
      "loss before training is 9.006590039493883e-07 -- epoch number 8811\n",
      "\n",
      "\n",
      "loss before training is 8.997302863735862e-07 -- epoch number 8812\n",
      "\n",
      "\n",
      "loss before training is 8.988026196021806e-07 -- epoch number 8813\n",
      "\n",
      "\n",
      "loss before training is 8.978760023276881e-07 -- epoch number 8814\n",
      "\n",
      "\n",
      "loss before training is 8.969504332447743e-07 -- epoch number 8815\n",
      "\n",
      "\n",
      "loss before training is 8.96025911049381e-07 -- epoch number 8816\n",
      "\n",
      "\n",
      "loss before training is 8.951024344397016e-07 -- epoch number 8817\n",
      "\n",
      "\n",
      "loss before training is 8.941800021151419e-07 -- epoch number 8818\n",
      "\n",
      "\n",
      "loss before training is 8.932586127773733e-07 -- epoch number 8819\n",
      "\n",
      "\n",
      "loss before training is 8.923382651296021e-07 -- epoch number 8820\n",
      "\n",
      "\n",
      "loss before training is 8.914189578768103e-07 -- epoch number 8821\n",
      "\n",
      "\n",
      "loss before training is 8.905006897258716e-07 -- epoch number 8822\n",
      "\n",
      "\n",
      "loss before training is 8.895834593851474e-07 -- epoch number 8823\n",
      "\n",
      "\n",
      "loss before training is 8.886672655649367e-07 -- epoch number 8824\n",
      "\n",
      "\n",
      "loss before training is 8.877521069773531e-07 -- epoch number 8825\n",
      "\n",
      "\n",
      "loss before training is 8.868379823359103e-07 -- epoch number 8826\n",
      "\n",
      "\n",
      "loss before training is 8.859248903562974e-07 -- epoch number 8827\n",
      "\n",
      "\n",
      "loss before training is 8.850128297558254e-07 -- epoch number 8828\n",
      "\n",
      "\n",
      "loss before training is 8.841017992531799e-07 -- epoch number 8829\n",
      "\n",
      "\n",
      "loss before training is 8.831917975693606e-07 -- epoch number 8830\n",
      "\n",
      "\n",
      "loss before training is 8.822828234266447e-07 -- epoch number 8831\n",
      "\n",
      "\n",
      "loss before training is 8.813748755493523e-07 -- epoch number 8832\n",
      "\n",
      "\n",
      "loss before training is 8.804679526633818e-07 -- epoch number 8833\n",
      "\n",
      "\n",
      "loss before training is 8.795620534960657e-07 -- epoch number 8834\n",
      "\n",
      "\n",
      "loss before training is 8.786571767770437e-07 -- epoch number 8835\n",
      "\n",
      "\n",
      "loss before training is 8.777533212375502e-07 -- epoch number 8836\n",
      "\n",
      "\n",
      "loss before training is 8.76850485609983e-07 -- epoch number 8837\n",
      "\n",
      "\n",
      "loss before training is 8.759486686289922e-07 -- epoch number 8838\n",
      "\n",
      "\n",
      "loss before training is 8.750478690309258e-07 -- epoch number 8839\n",
      "\n",
      "\n",
      "loss before training is 8.741480855537707e-07 -- epoch number 8840\n",
      "\n",
      "\n",
      "loss before training is 8.73249316936879e-07 -- epoch number 8841\n",
      "\n",
      "\n",
      "loss before training is 8.72351561921911e-07 -- epoch number 8842\n",
      "\n",
      "\n",
      "loss before training is 8.714548192514636e-07 -- epoch number 8843\n",
      "\n",
      "\n",
      "loss before training is 8.705590876708502e-07 -- epoch number 8844\n",
      "\n",
      "\n",
      "loss before training is 8.696643659263131e-07 -- epoch number 8845\n",
      "\n",
      "\n",
      "loss before training is 8.687706527657825e-07 -- epoch number 8846\n",
      "\n",
      "\n",
      "loss before training is 8.678779469392382e-07 -- epoch number 8847\n",
      "\n",
      "\n",
      "loss before training is 8.669862471984739e-07 -- epoch number 8848\n",
      "\n",
      "\n",
      "loss before training is 8.66095552296231e-07 -- epoch number 8849\n",
      "\n",
      "\n",
      "loss before training is 8.65205860987792e-07 -- epoch number 8850\n",
      "\n",
      "\n",
      "loss before training is 8.643171720296438e-07 -- epoch number 8851\n",
      "\n",
      "\n",
      "loss before training is 8.634294841800252e-07 -- epoch number 8852\n",
      "\n",
      "\n",
      "loss before training is 8.625427961988741e-07 -- epoch number 8853\n",
      "\n",
      "\n",
      "loss before training is 8.616571068477348e-07 -- epoch number 8854\n",
      "\n",
      "\n",
      "loss before training is 8.60772414890249e-07 -- epoch number 8855\n",
      "\n",
      "\n",
      "loss before training is 8.598887190911269e-07 -- epoch number 8856\n",
      "\n",
      "\n",
      "loss before training is 8.590060182168993e-07 -- epoch number 8857\n",
      "\n",
      "\n",
      "loss before training is 8.581243110360782e-07 -- epoch number 8858\n",
      "\n",
      "\n",
      "loss before training is 8.572435963185284e-07 -- epoch number 8859\n",
      "\n",
      "\n",
      "loss before training is 8.563638728360079e-07 -- epoch number 8860\n",
      "\n",
      "\n",
      "loss before training is 8.554851393616024e-07 -- epoch number 8861\n",
      "\n",
      "\n",
      "loss before training is 8.546073946706457e-07 -- epoch number 8862\n",
      "\n",
      "\n",
      "loss before training is 8.537306375392111e-07 -- epoch number 8863\n",
      "\n",
      "\n",
      "loss before training is 8.52854866746089e-07 -- epoch number 8864\n",
      "\n",
      "\n",
      "loss before training is 8.519800810708326e-07 -- epoch number 8865\n",
      "\n",
      "\n",
      "loss before training is 8.511062792951037e-07 -- epoch number 8866\n",
      "\n",
      "\n",
      "loss before training is 8.502334602020462e-07 -- epoch number 8867\n",
      "\n",
      "\n",
      "loss before training is 8.493616225767047e-07 -- epoch number 8868\n",
      "\n",
      "\n",
      "loss before training is 8.484907652052254e-07 -- epoch number 8869\n",
      "\n",
      "\n",
      "loss before training is 8.476208868759095e-07 -- epoch number 8870\n",
      "\n",
      "\n",
      "loss before training is 8.467519863788204e-07 -- epoch number 8871\n",
      "\n",
      "\n",
      "loss before training is 8.45884062504906e-07 -- epoch number 8872\n",
      "\n",
      "\n",
      "loss before training is 8.450171140473151e-07 -- epoch number 8873\n",
      "\n",
      "\n",
      "loss before training is 8.441511398006835e-07 -- epoch number 8874\n",
      "\n",
      "\n",
      "loss before training is 8.432861385613311e-07 -- epoch number 8875\n",
      "\n",
      "\n",
      "loss before training is 8.424221091272334e-07 -- epoch number 8876\n",
      "\n",
      "\n",
      "loss before training is 8.415590502977453e-07 -- epoch number 8877\n",
      "\n",
      "\n",
      "loss before training is 8.406969608741373e-07 -- epoch number 8878\n",
      "\n",
      "\n",
      "loss before training is 8.398358396590831e-07 -- epoch number 8879\n",
      "\n",
      "\n",
      "loss before training is 8.389756854570055e-07 -- epoch number 8880\n",
      "\n",
      "\n",
      "loss before training is 8.381164970740389e-07 -- epoch number 8881\n",
      "\n",
      "\n",
      "loss before training is 8.372582733174469e-07 -- epoch number 8882\n",
      "\n",
      "\n",
      "loss before training is 8.364010129965718e-07 -- epoch number 8883\n",
      "\n",
      "\n",
      "loss before training is 8.355447149224024e-07 -- epoch number 8884\n",
      "\n",
      "\n",
      "loss before training is 8.34689377906984e-07 -- epoch number 8885\n",
      "\n",
      "\n",
      "loss before training is 8.338350007647412e-07 -- epoch number 8886\n",
      "\n",
      "\n",
      "loss before training is 8.329815823108079e-07 -- epoch number 8887\n",
      "\n",
      "\n",
      "loss before training is 8.321291213629148e-07 -- epoch number 8888\n",
      "\n",
      "\n",
      "loss before training is 8.31277616739487e-07 -- epoch number 8889\n",
      "\n",
      "\n",
      "loss before training is 8.304270672609907e-07 -- epoch number 8890\n",
      "\n",
      "\n",
      "loss before training is 8.295774717494868e-07 -- epoch number 8891\n",
      "\n",
      "\n",
      "loss before training is 8.287288290285004e-07 -- epoch number 8892\n",
      "\n",
      "\n",
      "loss before training is 8.278811379230331e-07 -- epoch number 8893\n",
      "\n",
      "\n",
      "loss before training is 8.270343972600262e-07 -- epoch number 8894\n",
      "\n",
      "\n",
      "loss before training is 8.261886058676996e-07 -- epoch number 8895\n",
      "\n",
      "\n",
      "loss before training is 8.253437625759861e-07 -- epoch number 8896\n",
      "\n",
      "\n",
      "loss before training is 8.244998662162701e-07 -- epoch number 8897\n",
      "\n",
      "\n",
      "loss before training is 8.236569156216155e-07 -- epoch number 8898\n",
      "\n",
      "\n",
      "loss before training is 8.228149096266425e-07 -- epoch number 8899\n",
      "\n",
      "\n",
      "loss before training is 8.219738470674535e-07 -- epoch number 8900\n",
      "\n",
      "\n",
      "loss before training is 8.211337267819995e-07 -- epoch number 8901\n",
      "\n",
      "\n",
      "loss before training is 8.202945476092621e-07 -- epoch number 8902\n",
      "\n",
      "\n",
      "loss before training is 8.194563083904565e-07 -- epoch number 8903\n",
      "\n",
      "\n",
      "loss before training is 8.186190079676736e-07 -- epoch number 8904\n",
      "\n",
      "\n",
      "loss before training is 8.177826451851633e-07 -- epoch number 8905\n",
      "\n",
      "\n",
      "loss before training is 8.169472188882498e-07 -- epoch number 8906\n",
      "\n",
      "\n",
      "loss before training is 8.161127279242015e-07 -- epoch number 8907\n",
      "\n",
      "\n",
      "loss before training is 8.152791711415899e-07 -- epoch number 8908\n",
      "\n",
      "\n",
      "loss before training is 8.144465473906143e-07 -- epoch number 8909\n",
      "\n",
      "\n",
      "loss before training is 8.136148555228217e-07 -- epoch number 8910\n",
      "\n",
      "\n",
      "loss before training is 8.127840943917369e-07 -- epoch number 8911\n",
      "\n",
      "\n",
      "loss before training is 8.119542628520571e-07 -- epoch number 8912\n",
      "\n",
      "\n",
      "loss before training is 8.111253597602189e-07 -- epoch number 8913\n",
      "\n",
      "\n",
      "loss before training is 8.102973839741333e-07 -- epoch number 8914\n",
      "\n",
      "\n",
      "loss before training is 8.094703343529693e-07 -- epoch number 8915\n",
      "\n",
      "\n",
      "loss before training is 8.086442097581116e-07 -- epoch number 8916\n",
      "\n",
      "\n",
      "loss before training is 8.078190090516817e-07 -- epoch number 8917\n",
      "\n",
      "\n",
      "loss before training is 8.06994731097828e-07 -- epoch number 8918\n",
      "\n",
      "\n",
      "loss before training is 8.061713747620898e-07 -- epoch number 8919\n",
      "\n",
      "\n",
      "loss before training is 8.053489389115983e-07 -- epoch number 8920\n",
      "\n",
      "\n",
      "loss before training is 8.045274224149875e-07 -- epoch number 8921\n",
      "\n",
      "\n",
      "loss before training is 8.037068241420919e-07 -- epoch number 8922\n",
      "\n",
      "\n",
      "loss before training is 8.028871429648106e-07 -- epoch number 8923\n",
      "\n",
      "\n",
      "loss before training is 8.020683777562239e-07 -- epoch number 8924\n",
      "\n",
      "\n",
      "loss before training is 8.012505273911027e-07 -- epoch number 8925\n",
      "\n",
      "\n",
      "loss before training is 8.004335907452088e-07 -- epoch number 8926\n",
      "\n",
      "\n",
      "loss before training is 7.996175666965606e-07 -- epoch number 8927\n",
      "\n",
      "\n",
      "loss before training is 7.988024541241912e-07 -- epoch number 8928\n",
      "\n",
      "\n",
      "loss before training is 7.97988251908954e-07 -- epoch number 8929\n",
      "\n",
      "\n",
      "loss before training is 7.971749589329043e-07 -- epoch number 8930\n",
      "\n",
      "\n",
      "loss before training is 7.963625740796356e-07 -- epoch number 8931\n",
      "\n",
      "\n",
      "loss before training is 7.95551096234643e-07 -- epoch number 8932\n",
      "\n",
      "\n",
      "loss before training is 7.94740524284174e-07 -- epoch number 8933\n",
      "\n",
      "\n",
      "loss before training is 7.939308571167328e-07 -- epoch number 8934\n",
      "\n",
      "\n",
      "loss before training is 7.931220936218804e-07 -- epoch number 8935\n",
      "\n",
      "\n",
      "loss before training is 7.923142326908237e-07 -- epoch number 8936\n",
      "\n",
      "\n",
      "loss before training is 7.915072732160432e-07 -- epoch number 8937\n",
      "\n",
      "\n",
      "loss before training is 7.907012140917447e-07 -- epoch number 8938\n",
      "\n",
      "\n",
      "loss before training is 7.898960542136279e-07 -- epoch number 8939\n",
      "\n",
      "\n",
      "loss before training is 7.890917924786135e-07 -- epoch number 8940\n",
      "\n",
      "\n",
      "loss before training is 7.882884277852786e-07 -- epoch number 8941\n",
      "\n",
      "\n",
      "loss before training is 7.874859590339072e-07 -- epoch number 8942\n",
      "\n",
      "\n",
      "loss before training is 7.866843851257537e-07 -- epoch number 8943\n",
      "\n",
      "\n",
      "loss before training is 7.858837049637883e-07 -- epoch number 8944\n",
      "\n",
      "\n",
      "loss before training is 7.850839174526524e-07 -- epoch number 8945\n",
      "\n",
      "\n",
      "loss before training is 7.842850214980966e-07 -- epoch number 8946\n",
      "\n",
      "\n",
      "loss before training is 7.83487016007692e-07 -- epoch number 8947\n",
      "\n",
      "\n",
      "loss before training is 7.826898998900944e-07 -- epoch number 8948\n",
      "\n",
      "\n",
      "loss before training is 7.818936720557463e-07 -- epoch number 8949\n",
      "\n",
      "\n",
      "loss before training is 7.81098331416205e-07 -- epoch number 8950\n",
      "\n",
      "\n",
      "loss before training is 7.803038768849509e-07 -- epoch number 8951\n",
      "\n",
      "\n",
      "loss before training is 7.795103073766241e-07 -- epoch number 8952\n",
      "\n",
      "\n",
      "loss before training is 7.787176218072626e-07 -- epoch number 8953\n",
      "\n",
      "\n",
      "loss before training is 7.77925819094539e-07 -- epoch number 8954\n",
      "\n",
      "\n",
      "loss before training is 7.771348981574671e-07 -- epoch number 8955\n",
      "\n",
      "\n",
      "loss before training is 7.763448579164731e-07 -- epoch number 8956\n",
      "\n",
      "\n",
      "loss before training is 7.755556972936718e-07 -- epoch number 8957\n",
      "\n",
      "\n",
      "loss before training is 7.74767415212074e-07 -- epoch number 8958\n",
      "\n",
      "\n",
      "loss before training is 7.739800105966712e-07 -- epoch number 8959\n",
      "\n",
      "\n",
      "loss before training is 7.731934823738768e-07 -- epoch number 8960\n",
      "\n",
      "\n",
      "loss before training is 7.724078294710898e-07 -- epoch number 8961\n",
      "\n",
      "\n",
      "loss before training is 7.716230508176904e-07 -- epoch number 8962\n",
      "\n",
      "\n",
      "loss before training is 7.708391453442079e-07 -- epoch number 8963\n",
      "\n",
      "\n",
      "loss before training is 7.700561119821583e-07 -- epoch number 8964\n",
      "\n",
      "\n",
      "loss before training is 7.692739496656277e-07 -- epoch number 8965\n",
      "\n",
      "\n",
      "loss before training is 7.684926573290696e-07 -- epoch number 8966\n",
      "\n",
      "\n",
      "loss before training is 7.677122339087542e-07 -- epoch number 8967\n",
      "\n",
      "\n",
      "loss before training is 7.669326783424177e-07 -- epoch number 8968\n",
      "\n",
      "\n",
      "loss before training is 7.661539895692593e-07 -- epoch number 8969\n",
      "\n",
      "\n",
      "loss before training is 7.653761665293989e-07 -- epoch number 8970\n",
      "\n",
      "\n",
      "loss before training is 7.645992081652744e-07 -- epoch number 8971\n",
      "\n",
      "\n",
      "loss before training is 7.638231134198654e-07 -- epoch number 8972\n",
      "\n",
      "\n",
      "loss before training is 7.63047881238266e-07 -- epoch number 8973\n",
      "\n",
      "\n",
      "loss before training is 7.62273510566291e-07 -- epoch number 8974\n",
      "\n",
      "\n",
      "loss before training is 7.61500000351725e-07 -- epoch number 8975\n",
      "\n",
      "\n",
      "loss before training is 7.607273495436266e-07 -- epoch number 8976\n",
      "\n",
      "\n",
      "loss before training is 7.599555570919551e-07 -- epoch number 8977\n",
      "\n",
      "\n",
      "loss before training is 7.591846219489431e-07 -- epoch number 8978\n",
      "\n",
      "\n",
      "loss before training is 7.584145430675444e-07 -- epoch number 8979\n",
      "\n",
      "\n",
      "loss before training is 7.576453194024884e-07 -- epoch number 8980\n",
      "\n",
      "\n",
      "loss before training is 7.568769499096424e-07 -- epoch number 8981\n",
      "\n",
      "\n",
      "loss before training is 7.561094335463745e-07 -- epoch number 8982\n",
      "\n",
      "\n",
      "loss before training is 7.553427692715351e-07 -- epoch number 8983\n",
      "\n",
      "\n",
      "loss before training is 7.545769560451902e-07 -- epoch number 8984\n",
      "\n",
      "\n",
      "loss before training is 7.538119928289662e-07 -- epoch number 8985\n",
      "\n",
      "\n",
      "loss before training is 7.530478785856813e-07 -- epoch number 8986\n",
      "\n",
      "\n",
      "loss before training is 7.522846122796381e-07 -- epoch number 8987\n",
      "\n",
      "\n",
      "loss before training is 7.515221928765586e-07 -- epoch number 8988\n",
      "\n",
      "\n",
      "loss before training is 7.507606193436467e-07 -- epoch number 8989\n",
      "\n",
      "\n",
      "loss before training is 7.499998906491843e-07 -- epoch number 8990\n",
      "\n",
      "\n",
      "loss before training is 7.492400057630617e-07 -- epoch number 8991\n",
      "\n",
      "\n",
      "loss before training is 7.484809636562987e-07 -- epoch number 8992\n",
      "\n",
      "\n",
      "loss before training is 7.47722763301838e-07 -- epoch number 8993\n",
      "\n",
      "\n",
      "loss before training is 7.469654036732521e-07 -- epoch number 8994\n",
      "\n",
      "\n",
      "loss before training is 7.462088837459015e-07 -- epoch number 8995\n",
      "\n",
      "\n",
      "loss before training is 7.454532024966914e-07 -- epoch number 8996\n",
      "\n",
      "\n",
      "loss before training is 7.446983589034215e-07 -- epoch number 8997\n",
      "\n",
      "\n",
      "loss before training is 7.439443519455979e-07 -- epoch number 8998\n",
      "\n",
      "\n",
      "loss before training is 7.431911806038643e-07 -- epoch number 8999\n",
      "\n",
      "\n",
      "loss before training is 7.424388438604558e-07 -- epoch number 9000\n",
      "\n",
      "\n",
      "loss before training is 7.416873406988128e-07 -- epoch number 9001\n",
      "\n",
      "\n",
      "loss before training is 7.409366701037355e-07 -- epoch number 9002\n",
      "\n",
      "\n",
      "loss before training is 7.401868310614162e-07 -- epoch number 9003\n",
      "\n",
      "\n",
      "loss before training is 7.394378225594352e-07 -- epoch number 9004\n",
      "\n",
      "\n",
      "loss before training is 7.386896435863167e-07 -- epoch number 9005\n",
      "\n",
      "\n",
      "loss before training is 7.379422931328126e-07 -- epoch number 9006\n",
      "\n",
      "\n",
      "loss before training is 7.37195770190148e-07 -- epoch number 9007\n",
      "\n",
      "\n",
      "loss before training is 7.364500737512705e-07 -- epoch number 9008\n",
      "\n",
      "\n",
      "loss before training is 7.357052028105903e-07 -- epoch number 9009\n",
      "\n",
      "\n",
      "loss before training is 7.349611563634588e-07 -- epoch number 9010\n",
      "\n",
      "\n",
      "loss before training is 7.342179334069521e-07 -- epoch number 9011\n",
      "\n",
      "\n",
      "loss before training is 7.334755329391984e-07 -- epoch number 9012\n",
      "\n",
      "\n",
      "loss before training is 7.327339539599519e-07 -- epoch number 9013\n",
      "\n",
      "\n",
      "loss before training is 7.319931954700638e-07 -- epoch number 9014\n",
      "\n",
      "\n",
      "loss before training is 7.312532564717876e-07 -- epoch number 9015\n",
      "\n",
      "\n",
      "loss before training is 7.305141359684822e-07 -- epoch number 9016\n",
      "\n",
      "\n",
      "loss before training is 7.29775832965411e-07 -- epoch number 9017\n",
      "\n",
      "\n",
      "loss before training is 7.2903834646874e-07 -- epoch number 9018\n",
      "\n",
      "\n",
      "loss before training is 7.283016754856613e-07 -- epoch number 9019\n",
      "\n",
      "\n",
      "loss before training is 7.27565819025386e-07 -- epoch number 9020\n",
      "\n",
      "\n",
      "loss before training is 7.268307760980254e-07 -- epoch number 9021\n",
      "\n",
      "\n",
      "loss before training is 7.260965457149924e-07 -- epoch number 9022\n",
      "\n",
      "\n",
      "loss before training is 7.253631268891578e-07 -- epoch number 9023\n",
      "\n",
      "\n",
      "loss before training is 7.246305186346007e-07 -- epoch number 9024\n",
      "\n",
      "\n",
      "loss before training is 7.238987199669857e-07 -- epoch number 9025\n",
      "\n",
      "\n",
      "loss before training is 7.231677299025282e-07 -- epoch number 9026\n",
      "\n",
      "\n",
      "loss before training is 7.224375474597705e-07 -- epoch number 9027\n",
      "\n",
      "\n",
      "loss before training is 7.217081716580112e-07 -- epoch number 9028\n",
      "\n",
      "\n",
      "loss before training is 7.209796015176394e-07 -- epoch number 9029\n",
      "\n",
      "\n",
      "loss before training is 7.202518360608547e-07 -- epoch number 9030\n",
      "\n",
      "\n",
      "loss before training is 7.195248743107627e-07 -- epoch number 9031\n",
      "\n",
      "\n",
      "loss before training is 7.187987152921119e-07 -- epoch number 9032\n",
      "\n",
      "\n",
      "loss before training is 7.180733580305075e-07 -- epoch number 9033\n",
      "\n",
      "\n",
      "loss before training is 7.173488015532216e-07 -- epoch number 9034\n",
      "\n",
      "\n",
      "loss before training is 7.166250448885086e-07 -- epoch number 9035\n",
      "\n",
      "\n",
      "loss before training is 7.159020870663532e-07 -- epoch number 9036\n",
      "\n",
      "\n",
      "loss before training is 7.151799271177152e-07 -- epoch number 9037\n",
      "\n",
      "\n",
      "loss before training is 7.144585640748059e-07 -- epoch number 9038\n",
      "\n",
      "\n",
      "loss before training is 7.13737996971085e-07 -- epoch number 9039\n",
      "\n",
      "\n",
      "loss before training is 7.130182248417581e-07 -- epoch number 9040\n",
      "\n",
      "\n",
      "loss before training is 7.122992467225916e-07 -- epoch number 9041\n",
      "\n",
      "\n",
      "loss before training is 7.115810616512142e-07 -- epoch number 9042\n",
      "\n",
      "\n",
      "loss before training is 7.108636686662866e-07 -- epoch number 9043\n",
      "\n",
      "\n",
      "loss before training is 7.101470668077443e-07 -- epoch number 9044\n",
      "\n",
      "\n",
      "loss before training is 7.094312551169529e-07 -- epoch number 9045\n",
      "\n",
      "\n",
      "loss before training is 7.087162326362315e-07 -- epoch number 9046\n",
      "\n",
      "\n",
      "loss before training is 7.080019984095932e-07 -- epoch number 9047\n",
      "\n",
      "\n",
      "loss before training is 7.07288551481951e-07 -- epoch number 9048\n",
      "\n",
      "\n",
      "loss before training is 7.065758908995341e-07 -- epoch number 9049\n",
      "\n",
      "\n",
      "loss before training is 7.058640157101048e-07 -- epoch number 9050\n",
      "\n",
      "\n",
      "loss before training is 7.051529249622669e-07 -- epoch number 9051\n",
      "\n",
      "\n",
      "loss before training is 7.044426177063298e-07 -- epoch number 9052\n",
      "\n",
      "\n",
      "loss before training is 7.037330929938088e-07 -- epoch number 9053\n",
      "\n",
      "\n",
      "loss before training is 7.030243498769475e-07 -- epoch number 9054\n",
      "\n",
      "\n",
      "loss before training is 7.023163874099923e-07 -- epoch number 9055\n",
      "\n",
      "\n",
      "loss before training is 7.016092046477311e-07 -- epoch number 9056\n",
      "\n",
      "\n",
      "loss before training is 7.009028006467752e-07 -- epoch number 9057\n",
      "\n",
      "\n",
      "loss before training is 7.001971744646248e-07 -- epoch number 9058\n",
      "\n",
      "\n",
      "loss before training is 6.994923251602335e-07 -- epoch number 9059\n",
      "\n",
      "\n",
      "loss before training is 6.987882517936625e-07 -- epoch number 9060\n",
      "\n",
      "\n",
      "loss before training is 6.980849534264202e-07 -- epoch number 9061\n",
      "\n",
      "\n",
      "loss before training is 6.973824291208821e-07 -- epoch number 9062\n",
      "\n",
      "\n",
      "loss before training is 6.966806779411626e-07 -- epoch number 9063\n",
      "\n",
      "\n",
      "loss before training is 6.959796989521214e-07 -- epoch number 9064\n",
      "\n",
      "\n",
      "loss before training is 6.952794912202053e-07 -- epoch number 9065\n",
      "\n",
      "\n",
      "loss before training is 6.945800538129595e-07 -- epoch number 9066\n",
      "\n",
      "\n",
      "loss before training is 6.938813857991536e-07 -- epoch number 9067\n",
      "\n",
      "\n",
      "loss before training is 6.931834862488118e-07 -- epoch number 9068\n",
      "\n",
      "\n",
      "loss before training is 6.92486354233338e-07 -- epoch number 9069\n",
      "\n",
      "\n",
      "loss before training is 6.917899888250704e-07 -- epoch number 9070\n",
      "\n",
      "\n",
      "loss before training is 6.9109438909755e-07 -- epoch number 9071\n",
      "\n",
      "\n",
      "loss before training is 6.903995541260133e-07 -- epoch number 9072\n",
      "\n",
      "\n",
      "loss before training is 6.8970548298661e-07 -- epoch number 9073\n",
      "\n",
      "\n",
      "loss before training is 6.890121747566659e-07 -- epoch number 9074\n",
      "\n",
      "\n",
      "loss before training is 6.883196285146285e-07 -- epoch number 9075\n",
      "\n",
      "\n",
      "loss before training is 6.876278433406464e-07 -- epoch number 9076\n",
      "\n",
      "\n",
      "loss before training is 6.869368183153491e-07 -- epoch number 9077\n",
      "\n",
      "\n",
      "loss before training is 6.86246552521281e-07 -- epoch number 9078\n",
      "\n",
      "\n",
      "loss before training is 6.855570450417273e-07 -- epoch number 9079\n",
      "\n",
      "\n",
      "loss before training is 6.848682949614538e-07 -- epoch number 9080\n",
      "\n",
      "\n",
      "loss before training is 6.841803013664563e-07 -- epoch number 9081\n",
      "\n",
      "\n",
      "loss before training is 6.834930633434721e-07 -- epoch number 9082\n",
      "\n",
      "\n",
      "loss before training is 6.828065799813087e-07 -- epoch number 9083\n",
      "\n",
      "\n",
      "loss before training is 6.82120850369054e-07 -- epoch number 9084\n",
      "\n",
      "\n",
      "loss before training is 6.814358735976761e-07 -- epoch number 9085\n",
      "\n",
      "\n",
      "loss before training is 6.807516487587355e-07 -- epoch number 9086\n",
      "\n",
      "\n",
      "loss before training is 6.800681749457014e-07 -- epoch number 9087\n",
      "\n",
      "\n",
      "loss before training is 6.793854512526295e-07 -- epoch number 9088\n",
      "\n",
      "\n",
      "loss before training is 6.787034767751633e-07 -- epoch number 9089\n",
      "\n",
      "\n",
      "loss before training is 6.780222506100769e-07 -- epoch number 9090\n",
      "\n",
      "\n",
      "loss before training is 6.773417718549697e-07 -- epoch number 9091\n",
      "\n",
      "\n",
      "loss before training is 6.766620396089799e-07 -- epoch number 9092\n",
      "\n",
      "\n",
      "loss before training is 6.759830529726969e-07 -- epoch number 9093\n",
      "\n",
      "\n",
      "loss before training is 6.75304811047101e-07 -- epoch number 9094\n",
      "\n",
      "\n",
      "loss before training is 6.746273129351575e-07 -- epoch number 9095\n",
      "\n",
      "\n",
      "loss before training is 6.739505577405041e-07 -- epoch number 9096\n",
      "\n",
      "\n",
      "loss before training is 6.732745445683181e-07 -- epoch number 9097\n",
      "\n",
      "\n",
      "loss before training is 6.725992725244781e-07 -- epoch number 9098\n",
      "\n",
      "\n",
      "loss before training is 6.719247407166496e-07 -- epoch number 9099\n",
      "\n",
      "\n",
      "loss before training is 6.712509482532135e-07 -- epoch number 9100\n",
      "\n",
      "\n",
      "loss before training is 6.705778942438853e-07 -- epoch number 9101\n",
      "\n",
      "\n",
      "loss before training is 6.699055777997359e-07 -- epoch number 9102\n",
      "\n",
      "\n",
      "loss before training is 6.692339980324871e-07 -- epoch number 9103\n",
      "\n",
      "\n",
      "loss before training is 6.685631540555558e-07 -- epoch number 9104\n",
      "\n",
      "\n",
      "loss before training is 6.678930449834427e-07 -- epoch number 9105\n",
      "\n",
      "\n",
      "loss before training is 6.672236699314654e-07 -- epoch number 9106\n",
      "\n",
      "\n",
      "loss before training is 6.665550280165252e-07 -- epoch number 9107\n",
      "\n",
      "\n",
      "loss before training is 6.658871183565132e-07 -- epoch number 9108\n",
      "\n",
      "\n",
      "loss before training is 6.652199400703542e-07 -- epoch number 9109\n",
      "\n",
      "\n",
      "loss before training is 6.645534922784344e-07 -- epoch number 9110\n",
      "\n",
      "\n",
      "loss before training is 6.638877741017761e-07 -- epoch number 9111\n",
      "\n",
      "\n",
      "loss before training is 6.632227846634635e-07 -- epoch number 9112\n",
      "\n",
      "\n",
      "loss before training is 6.625585230866724e-07 -- epoch number 9113\n",
      "\n",
      "\n",
      "loss before training is 6.618949884966123e-07 -- epoch number 9114\n",
      "\n",
      "\n",
      "loss before training is 6.612321800188439e-07 -- epoch number 9115\n",
      "\n",
      "\n",
      "loss before training is 6.60570096781096e-07 -- epoch number 9116\n",
      "\n",
      "\n",
      "loss before training is 6.599087379110195e-07 -- epoch number 9117\n",
      "\n",
      "\n",
      "loss before training is 6.592481025384457e-07 -- epoch number 9118\n",
      "\n",
      "\n",
      "loss before training is 6.58588189793961e-07 -- epoch number 9119\n",
      "\n",
      "\n",
      "loss before training is 6.579289988090987e-07 -- epoch number 9120\n",
      "\n",
      "\n",
      "loss before training is 6.572705287168029e-07 -- epoch number 9121\n",
      "\n",
      "\n",
      "loss before training is 6.566127786510939e-07 -- epoch number 9122\n",
      "\n",
      "\n",
      "loss before training is 6.559557477473493e-07 -- epoch number 9123\n",
      "\n",
      "\n",
      "loss before training is 6.552994351414721e-07 -- epoch number 9124\n",
      "\n",
      "\n",
      "loss before training is 6.546438399708888e-07 -- epoch number 9125\n",
      "\n",
      "\n",
      "loss before training is 6.539889613746096e-07 -- epoch number 9126\n",
      "\n",
      "\n",
      "loss before training is 6.533347984918026e-07 -- epoch number 9127\n",
      "\n",
      "\n",
      "loss before training is 6.526813504636993e-07 -- epoch number 9128\n",
      "\n",
      "\n",
      "loss before training is 6.520286164318251e-07 -- epoch number 9129\n",
      "\n",
      "\n",
      "loss before training is 6.513765955396364e-07 -- epoch number 9130\n",
      "\n",
      "\n",
      "loss before training is 6.507252869311342e-07 -- epoch number 9131\n",
      "\n",
      "\n",
      "loss before training is 6.500746897516725e-07 -- epoch number 9132\n",
      "\n",
      "\n",
      "loss before training is 6.494248031477397e-07 -- epoch number 9133\n",
      "\n",
      "\n",
      "loss before training is 6.487756262668871e-07 -- epoch number 9134\n",
      "\n",
      "\n",
      "loss before training is 6.481271582578131e-07 -- epoch number 9135\n",
      "\n",
      "\n",
      "loss before training is 6.474793982702122e-07 -- epoch number 9136\n",
      "\n",
      "\n",
      "loss before training is 6.468323454552293e-07 -- epoch number 9137\n",
      "\n",
      "\n",
      "loss before training is 6.461859989647136e-07 -- epoch number 9138\n",
      "\n",
      "\n",
      "loss before training is 6.455403579519582e-07 -- epoch number 9139\n",
      "\n",
      "\n",
      "loss before training is 6.448954215711316e-07 -- epoch number 9140\n",
      "\n",
      "\n",
      "loss before training is 6.442511889777065e-07 -- epoch number 9141\n",
      "\n",
      "\n",
      "loss before training is 6.436076593280957e-07 -- epoch number 9142\n",
      "\n",
      "\n",
      "loss before training is 6.429648317797091e-07 -- epoch number 9143\n",
      "\n",
      "\n",
      "loss before training is 6.423227054916741e-07 -- epoch number 9144\n",
      "\n",
      "\n",
      "loss before training is 6.416812796233549e-07 -- epoch number 9145\n",
      "\n",
      "\n",
      "loss before training is 6.410405533360196e-07 -- epoch number 9146\n",
      "\n",
      "\n",
      "loss before training is 6.404005257913758e-07 -- epoch number 9147\n",
      "\n",
      "\n",
      "loss before training is 6.397611961526475e-07 -- epoch number 9148\n",
      "\n",
      "\n",
      "loss before training is 6.391225635841863e-07 -- epoch number 9149\n",
      "\n",
      "\n",
      "loss before training is 6.384846272510133e-07 -- epoch number 9150\n",
      "\n",
      "\n",
      "loss before training is 6.378473863196977e-07 -- epoch number 9151\n",
      "\n",
      "\n",
      "loss before training is 6.372108399577946e-07 -- epoch number 9152\n",
      "\n",
      "\n",
      "loss before training is 6.365749873337059e-07 -- epoch number 9153\n",
      "\n",
      "\n",
      "loss before training is 6.359398276171308e-07 -- epoch number 9154\n",
      "\n",
      "\n",
      "loss before training is 6.353053599787427e-07 -- epoch number 9155\n",
      "\n",
      "\n",
      "loss before training is 6.346715835906106e-07 -- epoch number 9156\n",
      "\n",
      "\n",
      "loss before training is 6.34038497625491e-07 -- epoch number 9157\n",
      "\n",
      "\n",
      "loss before training is 6.334061012576708e-07 -- epoch number 9158\n",
      "\n",
      "\n",
      "loss before training is 6.327743936618349e-07 -- epoch number 9159\n",
      "\n",
      "\n",
      "loss before training is 6.321433740143759e-07 -- epoch number 9160\n",
      "\n",
      "\n",
      "loss before training is 6.31513041492538e-07 -- epoch number 9161\n",
      "\n",
      "\n",
      "loss before training is 6.308833952745926e-07 -- epoch number 9162\n",
      "\n",
      "\n",
      "loss before training is 6.302544345401132e-07 -- epoch number 9163\n",
      "\n",
      "\n",
      "loss before training is 6.296261584692746e-07 -- epoch number 9164\n",
      "\n",
      "\n",
      "loss before training is 6.289985662438173e-07 -- epoch number 9165\n",
      "\n",
      "\n",
      "loss before training is 6.283716570466097e-07 -- epoch number 9166\n",
      "\n",
      "\n",
      "loss before training is 6.277454300609565e-07 -- epoch number 9167\n",
      "\n",
      "\n",
      "loss before training is 6.271198844717622e-07 -- epoch number 9168\n",
      "\n",
      "\n",
      "loss before training is 6.264950194648929e-07 -- epoch number 9169\n",
      "\n",
      "\n",
      "loss before training is 6.258708342272889e-07 -- epoch number 9170\n",
      "\n",
      "\n",
      "loss before training is 6.252473279467988e-07 -- epoch number 9171\n",
      "\n",
      "\n",
      "loss before training is 6.246244998125556e-07 -- epoch number 9172\n",
      "\n",
      "\n",
      "loss before training is 6.240023490145283e-07 -- epoch number 9173\n",
      "\n",
      "\n",
      "loss before training is 6.233808747438658e-07 -- epoch number 9174\n",
      "\n",
      "\n",
      "loss before training is 6.227600761929287e-07 -- epoch number 9175\n",
      "\n",
      "\n",
      "loss before training is 6.221399525548212e-07 -- epoch number 9176\n",
      "\n",
      "\n",
      "loss before training is 6.215205030240703e-07 -- epoch number 9177\n",
      "\n",
      "\n",
      "loss before training is 6.209017267957472e-07 -- epoch number 9178\n",
      "\n",
      "\n",
      "loss before training is 6.202836230664467e-07 -- epoch number 9179\n",
      "\n",
      "\n",
      "loss before training is 6.19666191033677e-07 -- epoch number 9180\n",
      "\n",
      "\n",
      "loss before training is 6.190494298958255e-07 -- epoch number 9181\n",
      "\n",
      "\n",
      "loss before training is 6.184333388526169e-07 -- epoch number 9182\n",
      "\n",
      "\n",
      "loss before training is 6.178179171044269e-07 -- epoch number 9183\n",
      "\n",
      "\n",
      "loss before training is 6.172031638532644e-07 -- epoch number 9184\n",
      "\n",
      "\n",
      "loss before training is 6.165890783015379e-07 -- epoch number 9185\n",
      "\n",
      "\n",
      "loss before training is 6.159756596530597e-07 -- epoch number 9186\n",
      "\n",
      "\n",
      "loss before training is 6.153629071126239e-07 -- epoch number 9187\n",
      "\n",
      "\n",
      "loss before training is 6.147508198861739e-07 -- epoch number 9188\n",
      "\n",
      "\n",
      "loss before training is 6.14139397180458e-07 -- epoch number 9189\n",
      "\n",
      "\n",
      "loss before training is 6.135286382033103e-07 -- epoch number 9190\n",
      "\n",
      "\n",
      "loss before training is 6.129185421637643e-07 -- epoch number 9191\n",
      "\n",
      "\n",
      "loss before training is 6.123091082718419e-07 -- epoch number 9192\n",
      "\n",
      "\n",
      "loss before training is 6.117003357383436e-07 -- epoch number 9193\n",
      "\n",
      "\n",
      "loss before training is 6.11092223775504e-07 -- epoch number 9194\n",
      "\n",
      "\n",
      "loss before training is 6.104847715962136e-07 -- epoch number 9195\n",
      "\n",
      "\n",
      "loss before training is 6.098779784146367e-07 -- epoch number 9196\n",
      "\n",
      "\n",
      "loss before training is 6.092718434458417e-07 -- epoch number 9197\n",
      "\n",
      "\n",
      "loss before training is 6.08666365905963e-07 -- epoch number 9198\n",
      "\n",
      "\n",
      "loss before training is 6.08061545012155e-07 -- epoch number 9199\n",
      "\n",
      "\n",
      "loss before training is 6.074573799826535e-07 -- epoch number 9200\n",
      "\n",
      "\n",
      "loss before training is 6.068538700366418e-07 -- epoch number 9201\n",
      "\n",
      "\n",
      "loss before training is 6.062510143942424e-07 -- epoch number 9202\n",
      "\n",
      "\n",
      "loss before training is 6.05648812276629e-07 -- epoch number 9203\n",
      "\n",
      "\n",
      "loss before training is 6.050472629064285e-07 -- epoch number 9204\n",
      "\n",
      "\n",
      "loss before training is 6.044463655063749e-07 -- epoch number 9205\n",
      "\n",
      "\n",
      "loss before training is 6.038461193011931e-07 -- epoch number 9206\n",
      "\n",
      "\n",
      "loss before training is 6.032465235157917e-07 -- epoch number 9207\n",
      "\n",
      "\n",
      "loss before training is 6.026475773766972e-07 -- epoch number 9208\n",
      "\n",
      "\n",
      "loss before training is 6.020492801111028e-07 -- epoch number 9209\n",
      "\n",
      "\n",
      "loss before training is 6.014516309475946e-07 -- epoch number 9210\n",
      "\n",
      "\n",
      "loss before training is 6.008546291150122e-07 -- epoch number 9211\n",
      "\n",
      "\n",
      "loss before training is 6.002582738440006e-07 -- epoch number 9212\n",
      "\n",
      "\n",
      "loss before training is 5.996625643658852e-07 -- epoch number 9213\n",
      "\n",
      "\n",
      "loss before training is 5.990674999128605e-07 -- epoch number 9214\n",
      "\n",
      "\n",
      "loss before training is 5.984730797182341e-07 -- epoch number 9215\n",
      "\n",
      "\n",
      "loss before training is 5.978793030163917e-07 -- epoch number 9216\n",
      "\n",
      "\n",
      "loss before training is 5.972861690427764e-07 -- epoch number 9217\n",
      "\n",
      "\n",
      "loss before training is 5.966936770334635e-07 -- epoch number 9218\n",
      "\n",
      "\n",
      "loss before training is 5.961018262259027e-07 -- epoch number 9219\n",
      "\n",
      "\n",
      "loss before training is 5.955106158583521e-07 -- epoch number 9220\n",
      "\n",
      "\n",
      "loss before training is 5.949200451701399e-07 -- epoch number 9221\n",
      "\n",
      "\n",
      "loss before training is 5.943301134015643e-07 -- epoch number 9222\n",
      "\n",
      "\n",
      "loss before training is 5.937408197938053e-07 -- epoch number 9223\n",
      "\n",
      "\n",
      "loss before training is 5.931521635892247e-07 -- epoch number 9224\n",
      "\n",
      "\n",
      "loss before training is 5.925641440308217e-07 -- epoch number 9225\n",
      "\n",
      "\n",
      "loss before training is 5.919767603632329e-07 -- epoch number 9226\n",
      "\n",
      "\n",
      "loss before training is 5.913900118313354e-07 -- epoch number 9227\n",
      "\n",
      "\n",
      "loss before training is 5.908038976815417e-07 -- epoch number 9228\n",
      "\n",
      "\n",
      "loss before training is 5.902184171609438e-07 -- epoch number 9229\n",
      "\n",
      "\n",
      "loss before training is 5.896335695175454e-07 -- epoch number 9230\n",
      "\n",
      "\n",
      "loss before training is 5.890493540007412e-07 -- epoch number 9231\n",
      "\n",
      "\n",
      "loss before training is 5.884657698604302e-07 -- epoch number 9232\n",
      "\n",
      "\n",
      "loss before training is 5.878828163478714e-07 -- epoch number 9233\n",
      "\n",
      "\n",
      "loss before training is 5.873004927148777e-07 -- epoch number 9234\n",
      "\n",
      "\n",
      "loss before training is 5.867187982148166e-07 -- epoch number 9235\n",
      "\n",
      "\n",
      "loss before training is 5.861377321012685e-07 -- epoch number 9236\n",
      "\n",
      "\n",
      "loss before training is 5.855572936295803e-07 -- epoch number 9237\n",
      "\n",
      "\n",
      "loss before training is 5.849774820554625e-07 -- epoch number 9238\n",
      "\n",
      "\n",
      "loss before training is 5.843982966358545e-07 -- epoch number 9239\n",
      "\n",
      "\n",
      "loss before training is 5.838197366287037e-07 -- epoch number 9240\n",
      "\n",
      "\n",
      "loss before training is 5.832418012928257e-07 -- epoch number 9241\n",
      "\n",
      "\n",
      "loss before training is 5.826644898879546e-07 -- epoch number 9242\n",
      "\n",
      "\n",
      "loss before training is 5.820878016749492e-07 -- epoch number 9243\n",
      "\n",
      "\n",
      "loss before training is 5.815117359152562e-07 -- epoch number 9244\n",
      "\n",
      "\n",
      "loss before training is 5.809362918718861e-07 -- epoch number 9245\n",
      "\n",
      "\n",
      "loss before training is 5.803614688082889e-07 -- epoch number 9246\n",
      "\n",
      "\n",
      "loss before training is 5.797872659890621e-07 -- epoch number 9247\n",
      "\n",
      "\n",
      "loss before training is 5.792136826797506e-07 -- epoch number 9248\n",
      "\n",
      "\n",
      "loss before training is 5.786407181470508e-07 -- epoch number 9249\n",
      "\n",
      "\n",
      "loss before training is 5.780683716579834e-07 -- epoch number 9250\n",
      "\n",
      "\n",
      "loss before training is 5.774966424814367e-07 -- epoch number 9251\n",
      "\n",
      "\n",
      "loss before training is 5.769255298863392e-07 -- epoch number 9252\n",
      "\n",
      "\n",
      "loss before training is 5.763550331431448e-07 -- epoch number 9253\n",
      "\n",
      "\n",
      "loss before training is 5.757851515231759e-07 -- epoch number 9254\n",
      "\n",
      "\n",
      "loss before training is 5.752158842985097e-07 -- epoch number 9255\n",
      "\n",
      "\n",
      "loss before training is 5.746472307424254e-07 -- epoch number 9256\n",
      "\n",
      "\n",
      "loss before training is 5.740791901286835e-07 -- epoch number 9257\n",
      "\n",
      "\n",
      "loss before training is 5.735117617326983e-07 -- epoch number 9258\n",
      "\n",
      "\n",
      "loss before training is 5.729449448300573e-07 -- epoch number 9259\n",
      "\n",
      "\n",
      "loss before training is 5.723787386978576e-07 -- epoch number 9260\n",
      "\n",
      "\n",
      "loss before training is 5.718131426139139e-07 -- epoch number 9261\n",
      "\n",
      "\n",
      "loss before training is 5.712481558569765e-07 -- epoch number 9262\n",
      "\n",
      "\n",
      "loss before training is 5.706837777066331e-07 -- epoch number 9263\n",
      "\n",
      "\n",
      "loss before training is 5.701200074437986e-07 -- epoch number 9264\n",
      "\n",
      "\n",
      "loss before training is 5.695568443496811e-07 -- epoch number 9265\n",
      "\n",
      "\n",
      "loss before training is 5.689942877070648e-07 -- epoch number 9266\n",
      "\n",
      "\n",
      "loss before training is 5.684323367991922e-07 -- epoch number 9267\n",
      "\n",
      "\n",
      "loss before training is 5.678709909104571e-07 -- epoch number 9268\n",
      "\n",
      "\n",
      "loss before training is 5.673102493261182e-07 -- epoch number 9269\n",
      "\n",
      "\n",
      "loss before training is 5.667501113325231e-07 -- epoch number 9270\n",
      "\n",
      "\n",
      "loss before training is 5.661905762165785e-07 -- epoch number 9271\n",
      "\n",
      "\n",
      "loss before training is 5.656316432665146e-07 -- epoch number 9272\n",
      "\n",
      "\n",
      "loss before training is 5.650733117711587e-07 -- epoch number 9273\n",
      "\n",
      "\n",
      "loss before training is 5.645155810206559e-07 -- epoch number 9274\n",
      "\n",
      "\n",
      "loss before training is 5.639584503055738e-07 -- epoch number 9275\n",
      "\n",
      "\n",
      "loss before training is 5.63401918917686e-07 -- epoch number 9276\n",
      "\n",
      "\n",
      "loss before training is 5.628459861496904e-07 -- epoch number 9277\n",
      "\n",
      "\n",
      "loss before training is 5.622906512951199e-07 -- epoch number 9278\n",
      "\n",
      "\n",
      "loss before training is 5.617359136483999e-07 -- epoch number 9279\n",
      "\n",
      "\n",
      "loss before training is 5.611817725050603e-07 -- epoch number 9280\n",
      "\n",
      "\n",
      "loss before training is 5.606282271612261e-07 -- epoch number 9281\n",
      "\n",
      "\n",
      "loss before training is 5.600752769143835e-07 -- epoch number 9282\n",
      "\n",
      "\n",
      "loss before training is 5.595229210622342e-07 -- epoch number 9283\n",
      "\n",
      "\n",
      "loss before training is 5.589711589041811e-07 -- epoch number 9284\n",
      "\n",
      "\n",
      "loss before training is 5.584199897400394e-07 -- epoch number 9285\n",
      "\n",
      "\n",
      "loss before training is 5.578694128704067e-07 -- epoch number 9286\n",
      "\n",
      "\n",
      "loss before training is 5.573194275973644e-07 -- epoch number 9287\n",
      "\n",
      "\n",
      "loss before training is 5.567700332233537e-07 -- epoch number 9288\n",
      "\n",
      "\n",
      "loss before training is 5.562212290521129e-07 -- epoch number 9289\n",
      "\n",
      "\n",
      "loss before training is 5.556730143877707e-07 -- epoch number 9290\n",
      "\n",
      "\n",
      "loss before training is 5.551253885359567e-07 -- epoch number 9291\n",
      "\n",
      "\n",
      "loss before training is 5.545783508028136e-07 -- epoch number 9292\n",
      "\n",
      "\n",
      "loss before training is 5.540319004952978e-07 -- epoch number 9293\n",
      "\n",
      "\n",
      "loss before training is 5.534860369217683e-07 -- epoch number 9294\n",
      "\n",
      "\n",
      "loss before training is 5.529407593909219e-07 -- epoch number 9295\n",
      "\n",
      "\n",
      "loss before training is 5.523960672126609e-07 -- epoch number 9296\n",
      "\n",
      "\n",
      "loss before training is 5.51851959697653e-07 -- epoch number 9297\n",
      "\n",
      "\n",
      "loss before training is 5.513084361575245e-07 -- epoch number 9298\n",
      "\n",
      "\n",
      "loss before training is 5.507654959047447e-07 -- epoch number 9299\n",
      "\n",
      "\n",
      "loss before training is 5.50223138252726e-07 -- epoch number 9300\n",
      "\n",
      "\n",
      "loss before training is 5.496813625155749e-07 -- epoch number 9301\n",
      "\n",
      "\n",
      "loss before training is 5.491401680085687e-07 -- epoch number 9302\n",
      "\n",
      "\n",
      "loss before training is 5.485995540478773e-07 -- epoch number 9303\n",
      "\n",
      "\n",
      "loss before training is 5.480595199500719e-07 -- epoch number 9304\n",
      "\n",
      "\n",
      "loss before training is 5.475200650331787e-07 -- epoch number 9305\n",
      "\n",
      "\n",
      "loss before training is 5.469811886157516e-07 -- epoch number 9306\n",
      "\n",
      "\n",
      "loss before training is 5.464428900174986e-07 -- epoch number 9307\n",
      "\n",
      "\n",
      "loss before training is 5.459051685586963e-07 -- epoch number 9308\n",
      "\n",
      "\n",
      "loss before training is 5.453680235606181e-07 -- epoch number 9309\n",
      "\n",
      "\n",
      "loss before training is 5.448314543455921e-07 -- epoch number 9310\n",
      "\n",
      "\n",
      "loss before training is 5.442954602365707e-07 -- epoch number 9311\n",
      "\n",
      "\n",
      "loss before training is 5.437600405574651e-07 -- epoch number 9312\n",
      "\n",
      "\n",
      "loss before training is 5.432251946330919e-07 -- epoch number 9313\n",
      "\n",
      "\n",
      "loss before training is 5.426909217891676e-07 -- epoch number 9314\n",
      "\n",
      "\n",
      "loss before training is 5.421572213521459e-07 -- epoch number 9315\n",
      "\n",
      "\n",
      "loss before training is 5.416240926494718e-07 -- epoch number 9316\n",
      "\n",
      "\n",
      "loss before training is 5.410915350094152e-07 -- epoch number 9317\n",
      "\n",
      "\n",
      "loss before training is 5.405595477611425e-07 -- epoch number 9318\n",
      "\n",
      "\n",
      "loss before training is 5.400281302347214e-07 -- epoch number 9319\n",
      "\n",
      "\n",
      "loss before training is 5.394972817606791e-07 -- epoch number 9320\n",
      "\n",
      "\n",
      "loss before training is 5.389670016711042e-07 -- epoch number 9321\n",
      "\n",
      "\n",
      "loss before training is 5.384372892982319e-07 -- epoch number 9322\n",
      "\n",
      "\n",
      "loss before training is 5.37908143975991e-07 -- epoch number 9323\n",
      "\n",
      "\n",
      "loss before training is 5.373795650383021e-07 -- epoch number 9324\n",
      "\n",
      "\n",
      "loss before training is 5.36851551820363e-07 -- epoch number 9325\n",
      "\n",
      "\n",
      "loss before training is 5.363241036581508e-07 -- epoch number 9326\n",
      "\n",
      "\n",
      "loss before training is 5.357972198888337e-07 -- epoch number 9327\n",
      "\n",
      "\n",
      "loss before training is 5.352708998497465e-07 -- epoch number 9328\n",
      "\n",
      "\n",
      "loss before training is 5.347451428797466e-07 -- epoch number 9329\n",
      "\n",
      "\n",
      "loss before training is 5.342199483181059e-07 -- epoch number 9330\n",
      "\n",
      "\n",
      "loss before training is 5.336953155050598e-07 -- epoch number 9331\n",
      "\n",
      "\n",
      "loss before training is 5.331712437818323e-07 -- epoch number 9332\n",
      "\n",
      "\n",
      "loss before training is 5.326477324904781e-07 -- epoch number 9333\n",
      "\n",
      "\n",
      "loss before training is 5.321247809735977e-07 -- epoch number 9334\n",
      "\n",
      "\n",
      "loss before training is 5.316023885749362e-07 -- epoch number 9335\n",
      "\n",
      "\n",
      "loss before training is 5.310805546390228e-07 -- epoch number 9336\n",
      "\n",
      "\n",
      "loss before training is 5.305592785112746e-07 -- epoch number 9337\n",
      "\n",
      "\n",
      "loss before training is 5.300385595376562e-07 -- epoch number 9338\n",
      "\n",
      "\n",
      "loss before training is 5.295183970654554e-07 -- epoch number 9339\n",
      "\n",
      "\n",
      "loss before training is 5.289987904423376e-07 -- epoch number 9340\n",
      "\n",
      "\n",
      "loss before training is 5.284797390169777e-07 -- epoch number 9341\n",
      "\n",
      "\n",
      "loss before training is 5.279612421391954e-07 -- epoch number 9342\n",
      "\n",
      "\n",
      "loss before training is 5.274432991590847e-07 -- epoch number 9343\n",
      "\n",
      "\n",
      "loss before training is 5.269259094280531e-07 -- epoch number 9344\n",
      "\n",
      "\n",
      "loss before training is 5.264090722980566e-07 -- epoch number 9345\n",
      "\n",
      "\n",
      "loss before training is 5.258927871218384e-07 -- epoch number 9346\n",
      "\n",
      "\n",
      "loss before training is 5.253770532534656e-07 -- epoch number 9347\n",
      "\n",
      "\n",
      "loss before training is 5.248618700470243e-07 -- epoch number 9348\n",
      "\n",
      "\n",
      "loss before training is 5.243472368581939e-07 -- epoch number 9349\n",
      "\n",
      "\n",
      "loss before training is 5.238331530430471e-07 -- epoch number 9350\n",
      "\n",
      "\n",
      "loss before training is 5.23319617958708e-07 -- epoch number 9351\n",
      "\n",
      "\n",
      "loss before training is 5.228066309628333e-07 -- epoch number 9352\n",
      "\n",
      "\n",
      "loss before training is 5.222941914142977e-07 -- epoch number 9353\n",
      "\n",
      "\n",
      "loss before training is 5.217822986724376e-07 -- epoch number 9354\n",
      "\n",
      "\n",
      "loss before training is 5.212709520976263e-07 -- epoch number 9355\n",
      "\n",
      "\n",
      "loss before training is 5.207601510510288e-07 -- epoch number 9356\n",
      "\n",
      "\n",
      "loss before training is 5.202498948945542e-07 -- epoch number 9357\n",
      "\n",
      "\n",
      "loss before training is 5.197401829910105e-07 -- epoch number 9358\n",
      "\n",
      "\n",
      "loss before training is 5.192310147039114e-07 -- epoch number 9359\n",
      "\n",
      "\n",
      "loss before training is 5.18722389397709e-07 -- epoch number 9360\n",
      "\n",
      "\n",
      "loss before training is 5.182143064377207e-07 -- epoch number 9361\n",
      "\n",
      "\n",
      "loss before training is 5.177067651897137e-07 -- epoch number 9362\n",
      "\n",
      "\n",
      "loss before training is 5.171997650208327e-07 -- epoch number 9363\n",
      "\n",
      "\n",
      "loss before training is 5.166933052986113e-07 -- epoch number 9364\n",
      "\n",
      "\n",
      "loss before training is 5.161873853914276e-07 -- epoch number 9365\n",
      "\n",
      "\n",
      "loss before training is 5.156820046686783e-07 -- epoch number 9366\n",
      "\n",
      "\n",
      "loss before training is 5.151771625003515e-07 -- epoch number 9367\n",
      "\n",
      "\n",
      "loss before training is 5.146728582574704e-07 -- epoch number 9368\n",
      "\n",
      "\n",
      "loss before training is 5.141690913116174e-07 -- epoch number 9369\n",
      "\n",
      "\n",
      "loss before training is 5.136658610353273e-07 -- epoch number 9370\n",
      "\n",
      "\n",
      "loss before training is 5.13163166801884e-07 -- epoch number 9371\n",
      "\n",
      "\n",
      "loss before training is 5.126610079854692e-07 -- epoch number 9372\n",
      "\n",
      "\n",
      "loss before training is 5.121593839610338e-07 -- epoch number 9373\n",
      "\n",
      "\n",
      "loss before training is 5.116582941040939e-07 -- epoch number 9374\n",
      "\n",
      "\n",
      "loss before training is 5.111577377912895e-07 -- epoch number 9375\n",
      "\n",
      "\n",
      "loss before training is 5.106577143998838e-07 -- epoch number 9376\n",
      "\n",
      "\n",
      "loss before training is 5.10158223308137e-07 -- epoch number 9377\n",
      "\n",
      "\n",
      "loss before training is 5.096592638946846e-07 -- epoch number 9378\n",
      "\n",
      "\n",
      "loss before training is 5.091608355393537e-07 -- epoch number 9379\n",
      "\n",
      "\n",
      "loss before training is 5.086629376225712e-07 -- epoch number 9380\n",
      "\n",
      "\n",
      "loss before training is 5.081655695256765e-07 -- epoch number 9381\n",
      "\n",
      "\n",
      "loss before training is 5.076687306309219e-07 -- epoch number 9382\n",
      "\n",
      "\n",
      "loss before training is 5.071724203208872e-07 -- epoch number 9383\n",
      "\n",
      "\n",
      "loss before training is 5.066766379792237e-07 -- epoch number 9384\n",
      "\n",
      "\n",
      "loss before training is 5.061813829904978e-07 -- epoch number 9385\n",
      "\n",
      "\n",
      "loss before training is 5.056866547400817e-07 -- epoch number 9386\n",
      "\n",
      "\n",
      "loss before training is 5.051924526136998e-07 -- epoch number 9387\n",
      "\n",
      "\n",
      "loss before training is 5.04698775998244e-07 -- epoch number 9388\n",
      "\n",
      "\n",
      "loss before training is 5.042056242813023e-07 -- epoch number 9389\n",
      "\n",
      "\n",
      "loss before training is 5.037129968512474e-07 -- epoch number 9390\n",
      "\n",
      "\n",
      "loss before training is 5.032208930972388e-07 -- epoch number 9391\n",
      "\n",
      "\n",
      "loss before training is 5.027293124091971e-07 -- epoch number 9392\n",
      "\n",
      "\n",
      "loss before training is 5.022382541778955e-07 -- epoch number 9393\n",
      "\n",
      "\n",
      "loss before training is 5.01747717794626e-07 -- epoch number 9394\n",
      "\n",
      "\n",
      "loss before training is 5.0125770265179e-07 -- epoch number 9395\n",
      "\n",
      "\n",
      "loss before training is 5.007682081425091e-07 -- epoch number 9396\n",
      "\n",
      "\n",
      "loss before training is 5.002792336603956e-07 -- epoch number 9397\n",
      "\n",
      "\n",
      "loss before training is 4.997907786000949e-07 -- epoch number 9398\n",
      "\n",
      "\n",
      "loss before training is 4.993028423571027e-07 -- epoch number 9399\n",
      "\n",
      "\n",
      "loss before training is 4.988154243273264e-07 -- epoch number 9400\n",
      "\n",
      "\n",
      "loss before training is 4.983285239079305e-07 -- epoch number 9401\n",
      "\n",
      "\n",
      "loss before training is 4.978421404962513e-07 -- epoch number 9402\n",
      "\n",
      "\n",
      "loss before training is 4.973562734909923e-07 -- epoch number 9403\n",
      "\n",
      "\n",
      "loss before training is 4.968709222913223e-07 -- epoch number 9404\n",
      "\n",
      "\n",
      "loss before training is 4.963860862971391e-07 -- epoch number 9405\n",
      "\n",
      "\n",
      "loss before training is 4.959017649092373e-07 -- epoch number 9406\n",
      "\n",
      "\n",
      "loss before training is 4.954179575291919e-07 -- epoch number 9407\n",
      "\n",
      "\n",
      "loss before training is 4.949346635590487e-07 -- epoch number 9408\n",
      "\n",
      "\n",
      "loss before training is 4.944518824020505e-07 -- epoch number 9409\n",
      "\n",
      "\n",
      "loss before training is 4.939696134619018e-07 -- epoch number 9410\n",
      "\n",
      "\n",
      "loss before training is 4.934878561431964e-07 -- epoch number 9411\n",
      "\n",
      "\n",
      "loss before training is 4.930066098511259e-07 -- epoch number 9412\n",
      "\n",
      "\n",
      "loss before training is 4.92525873991905e-07 -- epoch number 9413\n",
      "\n",
      "\n",
      "loss before training is 4.920456479722748e-07 -- epoch number 9414\n",
      "\n",
      "\n",
      "loss before training is 4.915659311998691e-07 -- epoch number 9415\n",
      "\n",
      "\n",
      "loss before training is 4.910867230829843e-07 -- epoch number 9416\n",
      "\n",
      "\n",
      "loss before training is 4.906080230306806e-07 -- epoch number 9417\n",
      "\n",
      "\n",
      "loss before training is 4.901298304528191e-07 -- epoch number 9418\n",
      "\n",
      "\n",
      "loss before training is 4.896521447600831e-07 -- epoch number 9419\n",
      "\n",
      "\n",
      "loss before training is 4.891749653637717e-07 -- epoch number 9420\n",
      "\n",
      "\n",
      "loss before training is 4.886982916758793e-07 -- epoch number 9421\n",
      "\n",
      "\n",
      "loss before training is 4.882221231093547e-07 -- epoch number 9422\n",
      "\n",
      "\n",
      "loss before training is 4.87746459077765e-07 -- epoch number 9423\n",
      "\n",
      "\n",
      "loss before training is 4.87271298995417e-07 -- epoch number 9424\n",
      "\n",
      "\n",
      "loss before training is 4.867966422774474e-07 -- epoch number 9425\n",
      "\n",
      "\n",
      "loss before training is 4.863224883397041e-07 -- epoch number 9426\n",
      "\n",
      "\n",
      "loss before training is 4.858488365985235e-07 -- epoch number 9427\n",
      "\n",
      "\n",
      "loss before training is 4.853756864716962e-07 -- epoch number 9428\n",
      "\n",
      "\n",
      "loss before training is 4.849030373767893e-07 -- epoch number 9429\n",
      "\n",
      "\n",
      "loss before training is 4.844308887328662e-07 -- epoch number 9430\n",
      "\n",
      "\n",
      "loss before training is 4.839592399593915e-07 -- epoch number 9431\n",
      "\n",
      "\n",
      "loss before training is 4.834880904766286e-07 -- epoch number 9432\n",
      "\n",
      "\n",
      "loss before training is 4.830174397056997e-07 -- epoch number 9433\n",
      "\n",
      "\n",
      "loss before training is 4.825472870681183e-07 -- epoch number 9434\n",
      "\n",
      "\n",
      "loss before training is 4.820776319865203e-07 -- epoch number 9435\n",
      "\n",
      "\n",
      "loss before training is 4.816084738842558e-07 -- epoch number 9436\n",
      "\n",
      "\n",
      "loss before training is 4.811398121849639e-07 -- epoch number 9437\n",
      "\n",
      "\n",
      "loss before training is 4.806716463135825e-07 -- epoch number 9438\n",
      "\n",
      "\n",
      "loss before training is 4.802039756953901e-07 -- epoch number 9439\n",
      "\n",
      "\n",
      "loss before training is 4.797367997565786e-07 -- epoch number 9440\n",
      "\n",
      "\n",
      "loss before training is 4.792701179240432e-07 -- epoch number 9441\n",
      "\n",
      "\n",
      "loss before training is 4.788039296253332e-07 -- epoch number 9442\n",
      "\n",
      "\n",
      "loss before training is 4.783382342888197e-07 -- epoch number 9443\n",
      "\n",
      "\n",
      "loss before training is 4.778730313435032e-07 -- epoch number 9444\n",
      "\n",
      "\n",
      "loss before training is 4.77408320219261e-07 -- epoch number 9445\n",
      "\n",
      "\n",
      "loss before training is 4.769441003464772e-07 -- epoch number 9446\n",
      "\n",
      "\n",
      "loss before training is 4.764803711564654e-07 -- epoch number 9447\n",
      "\n",
      "\n",
      "loss before training is 4.760171320812392e-07 -- epoch number 9448\n",
      "\n",
      "\n",
      "loss before training is 4.7555438255330385e-07 -- epoch number 9449\n",
      "\n",
      "\n",
      "loss before training is 4.7509212200610046e-07 -- epoch number 9450\n",
      "\n",
      "\n",
      "loss before training is 4.7463034987381264e-07 -- epoch number 9451\n",
      "\n",
      "\n",
      "loss before training is 4.7416906559123235e-07 -- epoch number 9452\n",
      "\n",
      "\n",
      "loss before training is 4.737082685938282e-07 -- epoch number 9453\n",
      "\n",
      "\n",
      "loss before training is 4.73247958318055e-07 -- epoch number 9454\n",
      "\n",
      "\n",
      "loss before training is 4.7278813420070233e-07 -- epoch number 9455\n",
      "\n",
      "\n",
      "loss before training is 4.7232879567963114e-07 -- epoch number 9456\n",
      "\n",
      "\n",
      "loss before training is 4.718699421930077e-07 -- epoch number 9457\n",
      "\n",
      "\n",
      "loss before training is 4.7141157318014744e-07 -- epoch number 9458\n",
      "\n",
      "\n",
      "loss before training is 4.709536880807888e-07 -- epoch number 9459\n",
      "\n",
      "\n",
      "loss before training is 4.7049628633557895e-07 -- epoch number 9460\n",
      "\n",
      "\n",
      "loss before training is 4.7003936738569987e-07 -- epoch number 9461\n",
      "\n",
      "\n",
      "loss before training is 4.695829306730322e-07 -- epoch number 9462\n",
      "\n",
      "\n",
      "loss before training is 4.691269756403224e-07 -- epoch number 9463\n",
      "\n",
      "\n",
      "loss before training is 4.68671501730923e-07 -- epoch number 9464\n",
      "\n",
      "\n",
      "loss before training is 4.6821650838899795e-07 -- epoch number 9465\n",
      "\n",
      "\n",
      "loss before training is 4.67761995059119e-07 -- epoch number 9466\n",
      "\n",
      "\n",
      "loss before training is 4.673079611870165e-07 -- epoch number 9467\n",
      "\n",
      "\n",
      "loss before training is 4.6685440621868556e-07 -- epoch number 9468\n",
      "\n",
      "\n",
      "loss before training is 4.664013296011439e-07 -- epoch number 9469\n",
      "\n",
      "\n",
      "loss before training is 4.659487307818151e-07 -- epoch number 9470\n",
      "\n",
      "\n",
      "loss before training is 4.6549660920930556e-07 -- epoch number 9471\n",
      "\n",
      "\n",
      "loss before training is 4.6504496433225063e-07 -- epoch number 9472\n",
      "\n",
      "\n",
      "loss before training is 4.645937956005044e-07 -- epoch number 9473\n",
      "\n",
      "\n",
      "loss before training is 4.6414310246441647e-07 -- epoch number 9474\n",
      "\n",
      "\n",
      "loss before training is 4.6369288437503424e-07 -- epoch number 9475\n",
      "\n",
      "\n",
      "loss before training is 4.6324314078438376e-07 -- epoch number 9476\n",
      "\n",
      "\n",
      "loss before training is 4.62793871144586e-07 -- epoch number 9477\n",
      "\n",
      "\n",
      "loss before training is 4.6234507490887745e-07 -- epoch number 9478\n",
      "\n",
      "\n",
      "loss before training is 4.618967515312984e-07 -- epoch number 9479\n",
      "\n",
      "\n",
      "loss before training is 4.614489004662447e-07 -- epoch number 9480\n",
      "\n",
      "\n",
      "loss before training is 4.610015211688878e-07 -- epoch number 9481\n",
      "\n",
      "\n",
      "loss before training is 4.605546130953496e-07 -- epoch number 9482\n",
      "\n",
      "\n",
      "loss before training is 4.6010817570199217e-07 -- epoch number 9483\n",
      "\n",
      "\n",
      "loss before training is 4.596622084463789e-07 -- epoch number 9484\n",
      "\n",
      "\n",
      "loss before training is 4.592167107862471e-07 -- epoch number 9485\n",
      "\n",
      "\n",
      "loss before training is 4.587716821804617e-07 -- epoch number 9486\n",
      "\n",
      "\n",
      "loss before training is 4.583271220882207e-07 -- epoch number 9487\n",
      "\n",
      "\n",
      "loss before training is 4.5788302996961735e-07 -- epoch number 9488\n",
      "\n",
      "\n",
      "loss before training is 4.5743940528545006e-07 -- epoch number 9489\n",
      "\n",
      "\n",
      "loss before training is 4.5699624749708517e-07 -- epoch number 9490\n",
      "\n",
      "\n",
      "loss before training is 4.565535560665627e-07 -- epoch number 9491\n",
      "\n",
      "\n",
      "loss before training is 4.561113304565842e-07 -- epoch number 9492\n",
      "\n",
      "\n",
      "loss before training is 4.5566957013078324e-07 -- epoch number 9493\n",
      "\n",
      "\n",
      "loss before training is 4.5522827455315123e-07 -- epoch number 9494\n",
      "\n",
      "\n",
      "loss before training is 4.547874431883711e-07 -- epoch number 9495\n",
      "\n",
      "\n",
      "loss before training is 4.543470755022699e-07 -- epoch number 9496\n",
      "\n",
      "\n",
      "loss before training is 4.539071709605995e-07 -- epoch number 9497\n",
      "\n",
      "\n",
      "loss before training is 4.534677290303838e-07 -- epoch number 9498\n",
      "\n",
      "\n",
      "loss before training is 4.5302874917910156e-07 -- epoch number 9499\n",
      "\n",
      "\n",
      "loss before training is 4.525902308747891e-07 -- epoch number 9500\n",
      "\n",
      "\n",
      "loss before training is 4.521521735864906e-07 -- epoch number 9501\n",
      "\n",
      "\n",
      "loss before training is 4.517145767835595e-07 -- epoch number 9502\n",
      "\n",
      "\n",
      "loss before training is 4.512774399362575e-07 -- epoch number 9503\n",
      "\n",
      "\n",
      "loss before training is 4.5084076251543145e-07 -- epoch number 9504\n",
      "\n",
      "\n",
      "loss before training is 4.504045439925297e-07 -- epoch number 9505\n",
      "\n",
      "\n",
      "loss before training is 4.4996878383982007e-07 -- epoch number 9506\n",
      "\n",
      "\n",
      "loss before training is 4.495334815300232e-07 -- epoch number 9507\n",
      "\n",
      "\n",
      "loss before training is 4.4909863653682645e-07 -- epoch number 9508\n",
      "\n",
      "\n",
      "loss before training is 4.486642483342815e-07 -- epoch number 9509\n",
      "\n",
      "\n",
      "loss before training is 4.4823031639720495e-07 -- epoch number 9510\n",
      "\n",
      "\n",
      "loss before training is 4.477968402011519e-07 -- epoch number 9511\n",
      "\n",
      "\n",
      "loss before training is 4.473638192222364e-07 -- epoch number 9512\n",
      "\n",
      "\n",
      "loss before training is 4.469312529374506e-07 -- epoch number 9513\n",
      "\n",
      "\n",
      "loss before training is 4.4649914082406357e-07 -- epoch number 9514\n",
      "\n",
      "\n",
      "loss before training is 4.460674823602794e-07 -- epoch number 9515\n",
      "\n",
      "\n",
      "loss before training is 4.4563627702498097e-07 -- epoch number 9516\n",
      "\n",
      "\n",
      "loss before training is 4.452055242975262e-07 -- epoch number 9517\n",
      "\n",
      "\n",
      "loss before training is 4.447752236580626e-07 -- epoch number 9518\n",
      "\n",
      "\n",
      "loss before training is 4.4434537458721224e-07 -- epoch number 9519\n",
      "\n",
      "\n",
      "loss before training is 4.439159765667272e-07 -- epoch number 9520\n",
      "\n",
      "\n",
      "loss before training is 4.434870290784716e-07 -- epoch number 9521\n",
      "\n",
      "\n",
      "loss before training is 4.43058531605177e-07 -- epoch number 9522\n",
      "\n",
      "\n",
      "loss before training is 4.426304836301309e-07 -- epoch number 9523\n",
      "\n",
      "\n",
      "loss before training is 4.4220288463758987e-07 -- epoch number 9524\n",
      "\n",
      "\n",
      "loss before training is 4.41775734112012e-07 -- epoch number 9525\n",
      "\n",
      "\n",
      "loss before training is 4.4134903153888474e-07 -- epoch number 9526\n",
      "\n",
      "\n",
      "loss before training is 4.409227764040095e-07 -- epoch number 9527\n",
      "\n",
      "\n",
      "loss before training is 4.404969681942045e-07 -- epoch number 9528\n",
      "\n",
      "\n",
      "loss before training is 4.400716063966343e-07 -- epoch number 9529\n",
      "\n",
      "\n",
      "loss before training is 4.3964669049916187e-07 -- epoch number 9530\n",
      "\n",
      "\n",
      "loss before training is 4.392222199904706e-07 -- epoch number 9531\n",
      "\n",
      "\n",
      "loss before training is 4.387981943596147e-07 -- epoch number 9532\n",
      "\n",
      "\n",
      "loss before training is 4.3837461309653976e-07 -- epoch number 9533\n",
      "\n",
      "\n",
      "loss before training is 4.379514756916989e-07 -- epoch number 9534\n",
      "\n",
      "\n",
      "loss before training is 4.3752878163618437e-07 -- epoch number 9535\n",
      "\n",
      "\n",
      "loss before training is 4.3710653042177067e-07 -- epoch number 9536\n",
      "\n",
      "\n",
      "loss before training is 4.366847215409936e-07 -- epoch number 9537\n",
      "\n",
      "\n",
      "loss before training is 4.36263354486646e-07 -- epoch number 9538\n",
      "\n",
      "\n",
      "loss before training is 4.3584242875266615e-07 -- epoch number 9539\n",
      "\n",
      "\n",
      "loss before training is 4.3542194383327287e-07 -- epoch number 9540\n",
      "\n",
      "\n",
      "loss before training is 4.350018992232914e-07 -- epoch number 9541\n",
      "\n",
      "\n",
      "loss before training is 4.3458229441843097e-07 -- epoch number 9542\n",
      "\n",
      "\n",
      "loss before training is 4.3416312891493554e-07 -- epoch number 9543\n",
      "\n",
      "\n",
      "loss before training is 4.3374440220951254e-07 -- epoch number 9544\n",
      "\n",
      "\n",
      "loss before training is 4.333261137997539e-07 -- epoch number 9545\n",
      "\n",
      "\n",
      "loss before training is 4.3290826318384546e-07 -- epoch number 9546\n",
      "\n",
      "\n",
      "loss before training is 4.324908498603821e-07 -- epoch number 9547\n",
      "\n",
      "\n",
      "loss before training is 4.3207387332885837e-07 -- epoch number 9548\n",
      "\n",
      "\n",
      "loss before training is 4.3165733308917325e-07 -- epoch number 9549\n",
      "\n",
      "\n",
      "loss before training is 4.3124122864199406e-07 -- epoch number 9550\n",
      "\n",
      "\n",
      "loss before training is 4.308255594886086e-07 -- epoch number 9551\n",
      "\n",
      "\n",
      "loss before training is 4.304103251308495e-07 -- epoch number 9552\n",
      "\n",
      "\n",
      "loss before training is 4.299955250713771e-07 -- epoch number 9553\n",
      "\n",
      "\n",
      "loss before training is 4.2958115881319946e-07 -- epoch number 9554\n",
      "\n",
      "\n",
      "loss before training is 4.291672258600699e-07 -- epoch number 9555\n",
      "\n",
      "\n",
      "loss before training is 4.2875372571635316e-07 -- epoch number 9556\n",
      "\n",
      "\n",
      "loss before training is 4.2834065788701437e-07 -- epoch number 9557\n",
      "\n",
      "\n",
      "loss before training is 4.279280218777964e-07 -- epoch number 9558\n",
      "\n",
      "\n",
      "loss before training is 4.275158171950161e-07 -- epoch number 9559\n",
      "\n",
      "\n",
      "loss before training is 4.271040433451803e-07 -- epoch number 9560\n",
      "\n",
      "\n",
      "loss before training is 4.2669269983614933e-07 -- epoch number 9561\n",
      "\n",
      "\n",
      "loss before training is 4.2628178617586124e-07 -- epoch number 9562\n",
      "\n",
      "\n",
      "loss before training is 4.258713018730524e-07 -- epoch number 9563\n",
      "\n",
      "\n",
      "loss before training is 4.254612464369686e-07 -- epoch number 9564\n",
      "\n",
      "\n",
      "loss before training is 4.2505161937767156e-07 -- epoch number 9565\n",
      "\n",
      "\n",
      "loss before training is 4.246424202056485e-07 -- epoch number 9566\n",
      "\n",
      "\n",
      "loss before training is 4.242336484320577e-07 -- epoch number 9567\n",
      "\n",
      "\n",
      "loss before training is 4.2382530356889397e-07 -- epoch number 9568\n",
      "\n",
      "\n",
      "loss before training is 4.23417385128248e-07 -- epoch number 9569\n",
      "\n",
      "\n",
      "loss before training is 4.2300989262317935e-07 -- epoch number 9570\n",
      "\n",
      "\n",
      "loss before training is 4.2260282556750203e-07 -- epoch number 9571\n",
      "\n",
      "\n",
      "loss before training is 4.221961834753708e-07 -- epoch number 9572\n",
      "\n",
      "\n",
      "loss before training is 4.21789965861452e-07 -- epoch number 9573\n",
      "\n",
      "\n",
      "loss before training is 4.2138417224132104e-07 -- epoch number 9574\n",
      "\n",
      "\n",
      "loss before training is 4.2097880213115e-07 -- epoch number 9575\n",
      "\n",
      "\n",
      "loss before training is 4.205738550474136e-07 -- epoch number 9576\n",
      "\n",
      "\n",
      "loss before training is 4.201693305073717e-07 -- epoch number 9577\n",
      "\n",
      "\n",
      "loss before training is 4.1976522802900803e-07 -- epoch number 9578\n",
      "\n",
      "\n",
      "loss before training is 4.193615471306743e-07 -- epoch number 9579\n",
      "\n",
      "\n",
      "loss before training is 4.189582873314704e-07 -- epoch number 9580\n",
      "\n",
      "\n",
      "loss before training is 4.185554481512885e-07 -- epoch number 9581\n",
      "\n",
      "\n",
      "loss before training is 4.1815302910999294e-07 -- epoch number 9582\n",
      "\n",
      "\n",
      "loss before training is 4.1775102972866826e-07 -- epoch number 9583\n",
      "\n",
      "\n",
      "loss before training is 4.173494495287535e-07 -- epoch number 9584\n",
      "\n",
      "\n",
      "loss before training is 4.169482880325171e-07 -- epoch number 9585\n",
      "\n",
      "\n",
      "loss before training is 4.1654754476237194e-07 -- epoch number 9586\n",
      "\n",
      "\n",
      "loss before training is 4.161472192415861e-07 -- epoch number 9587\n",
      "\n",
      "\n",
      "loss before training is 4.157473109941732e-07 -- epoch number 9588\n",
      "\n",
      "\n",
      "loss before training is 4.1534781954452535e-07 -- epoch number 9589\n",
      "\n",
      "\n",
      "loss before training is 4.1494874441759343e-07 -- epoch number 9590\n",
      "\n",
      "\n",
      "loss before training is 4.145500851393147e-07 -- epoch number 9591\n",
      "\n",
      "\n",
      "loss before training is 4.141518412355522e-07 -- epoch number 9592\n",
      "\n",
      "\n",
      "loss before training is 4.137540122334399e-07 -- epoch number 9593\n",
      "\n",
      "\n",
      "loss before training is 4.133565976600841e-07 -- epoch number 9594\n",
      "\n",
      "\n",
      "loss before training is 4.129595970438736e-07 -- epoch number 9595\n",
      "\n",
      "\n",
      "loss before training is 4.1256300991310273e-07 -- epoch number 9596\n",
      "\n",
      "\n",
      "loss before training is 4.121668357970418e-07 -- epoch number 9597\n",
      "\n",
      "\n",
      "loss before training is 4.1177107422553016e-07 -- epoch number 9598\n",
      "\n",
      "\n",
      "loss before training is 4.113757247289114e-07 -- epoch number 9599\n",
      "\n",
      "\n",
      "loss before training is 4.10980786838033e-07 -- epoch number 9600\n",
      "\n",
      "\n",
      "loss before training is 4.105862600845758e-07 -- epoch number 9601\n",
      "\n",
      "\n",
      "loss before training is 4.101921440006494e-07 -- epoch number 9602\n",
      "\n",
      "\n",
      "loss before training is 4.0979843811882896e-07 -- epoch number 9603\n",
      "\n",
      "\n",
      "loss before training is 4.09405141972514e-07 -- epoch number 9604\n",
      "\n",
      "\n",
      "loss before training is 4.090122550955737e-07 -- epoch number 9605\n",
      "\n",
      "\n",
      "loss before training is 4.0861977702242054e-07 -- epoch number 9606\n",
      "\n",
      "\n",
      "loss before training is 4.0822770728800083e-07 -- epoch number 9607\n",
      "\n",
      "\n",
      "loss before training is 4.078360454281634e-07 -- epoch number 9608\n",
      "\n",
      "\n",
      "loss before training is 4.0744479097887475e-07 -- epoch number 9609\n",
      "\n",
      "\n",
      "loss before training is 4.0705394347699045e-07 -- epoch number 9610\n",
      "\n",
      "\n",
      "loss before training is 4.066635024598023e-07 -- epoch number 9611\n",
      "\n",
      "\n",
      "loss before training is 4.0627346746539275e-07 -- epoch number 9612\n",
      "\n",
      "\n",
      "loss before training is 4.0588383803209046e-07 -- epoch number 9613\n",
      "\n",
      "\n",
      "loss before training is 4.054946136989326e-07 -- epoch number 9614\n",
      "\n",
      "\n",
      "loss before training is 4.0510579400587147e-07 -- epoch number 9615\n",
      "\n",
      "\n",
      "loss before training is 4.0471737849279133e-07 -- epoch number 9616\n",
      "\n",
      "\n",
      "loss before training is 4.043293667006982e-07 -- epoch number 9617\n",
      "\n",
      "\n",
      "loss before training is 4.039417581707787e-07 -- epoch number 9618\n",
      "\n",
      "\n",
      "loss before training is 4.0355455244514565e-07 -- epoch number 9619\n",
      "\n",
      "\n",
      "loss before training is 4.031677490663575e-07 -- epoch number 9620\n",
      "\n",
      "\n",
      "loss before training is 4.0278134757722635e-07 -- epoch number 9621\n",
      "\n",
      "\n",
      "loss before training is 4.0239534752167e-07 -- epoch number 9622\n",
      "\n",
      "\n",
      "loss before training is 4.0200974844368626e-07 -- epoch number 9623\n",
      "\n",
      "\n",
      "loss before training is 4.016245498881796e-07 -- epoch number 9624\n",
      "\n",
      "\n",
      "loss before training is 4.012397514005433e-07 -- epoch number 9625\n",
      "\n",
      "\n",
      "loss before training is 4.008553525267285e-07 -- epoch number 9626\n",
      "\n",
      "\n",
      "loss before training is 4.004713528129839e-07 -- epoch number 9627\n",
      "\n",
      "\n",
      "loss before training is 4.0008775180654575e-07 -- epoch number 9628\n",
      "\n",
      "\n",
      "loss before training is 3.9970454905502e-07 -- epoch number 9629\n",
      "\n",
      "\n",
      "loss before training is 3.993217441065632e-07 -- epoch number 9630\n",
      "\n",
      "\n",
      "loss before training is 3.9893933650976044e-07 -- epoch number 9631\n",
      "\n",
      "\n",
      "loss before training is 3.9855732581413914e-07 -- epoch number 9632\n",
      "\n",
      "\n",
      "loss before training is 3.981757115695292e-07 -- epoch number 9633\n",
      "\n",
      "\n",
      "loss before training is 3.9779449332616513e-07 -- epoch number 9634\n",
      "\n",
      "\n",
      "loss before training is 3.974136706352501e-07 -- epoch number 9635\n",
      "\n",
      "\n",
      "loss before training is 3.9703324304815527e-07 -- epoch number 9636\n",
      "\n",
      "\n",
      "loss before training is 3.966532101170476e-07 -- epoch number 9637\n",
      "\n",
      "\n",
      "loss before training is 3.962735713945416e-07 -- epoch number 9638\n",
      "\n",
      "\n",
      "loss before training is 3.9589432643385626e-07 -- epoch number 9639\n",
      "\n",
      "\n",
      "loss before training is 3.955154747888738e-07 -- epoch number 9640\n",
      "\n",
      "\n",
      "loss before training is 3.9513701601358313e-07 -- epoch number 9641\n",
      "\n",
      "\n",
      "loss before training is 3.947589496631822e-07 -- epoch number 9642\n",
      "\n",
      "\n",
      "loss before training is 3.9438127529290826e-07 -- epoch number 9643\n",
      "\n",
      "\n",
      "loss before training is 3.9400399245886097e-07 -- epoch number 9644\n",
      "\n",
      "\n",
      "loss before training is 3.936271007175837e-07 -- epoch number 9645\n",
      "\n",
      "\n",
      "loss before training is 3.932505996259952e-07 -- epoch number 9646\n",
      "\n",
      "\n",
      "loss before training is 3.9287448874172343e-07 -- epoch number 9647\n",
      "\n",
      "\n",
      "loss before training is 3.9249876762322935e-07 -- epoch number 9648\n",
      "\n",
      "\n",
      "loss before training is 3.921234358288973e-07 -- epoch number 9649\n",
      "\n",
      "\n",
      "loss before training is 3.9174849291821424e-07 -- epoch number 9650\n",
      "\n",
      "\n",
      "loss before training is 3.913739384509069e-07 -- epoch number 9651\n",
      "\n",
      "\n",
      "loss before training is 3.9099977198735217e-07 -- epoch number 9652\n",
      "\n",
      "\n",
      "loss before training is 3.906259930884707e-07 -- epoch number 9653\n",
      "\n",
      "\n",
      "loss before training is 3.90252601315749e-07 -- epoch number 9654\n",
      "\n",
      "\n",
      "loss before training is 3.898795962311924e-07 -- epoch number 9655\n",
      "\n",
      "\n",
      "loss before training is 3.8950697739728714e-07 -- epoch number 9656\n",
      "\n",
      "\n",
      "loss before training is 3.891347443771277e-07 -- epoch number 9657\n",
      "\n",
      "\n",
      "loss before training is 3.887628967343328e-07 -- epoch number 9658\n",
      "\n",
      "\n",
      "loss before training is 3.883914340332764e-07 -- epoch number 9659\n",
      "\n",
      "\n",
      "loss before training is 3.880203558383684e-07 -- epoch number 9660\n",
      "\n",
      "\n",
      "loss before training is 3.876496617149925e-07 -- epoch number 9661\n",
      "\n",
      "\n",
      "loss before training is 3.8727935122888295e-07 -- epoch number 9662\n",
      "\n",
      "\n",
      "loss before training is 3.869094239465623e-07 -- epoch number 9663\n",
      "\n",
      "\n",
      "loss before training is 3.865398794347046e-07 -- epoch number 9664\n",
      "\n",
      "\n",
      "loss before training is 3.8617071726067373e-07 -- epoch number 9665\n",
      "\n",
      "\n",
      "loss before training is 3.8580193699258053e-07 -- epoch number 9666\n",
      "\n",
      "\n",
      "loss before training is 3.854335381988301e-07 -- epoch number 9667\n",
      "\n",
      "\n",
      "loss before training is 3.8506552044849626e-07 -- epoch number 9668\n",
      "\n",
      "\n",
      "loss before training is 3.846978833108867e-07 -- epoch number 9669\n",
      "\n",
      "\n",
      "loss before training is 3.843306263563777e-07 -- epoch number 9670\n",
      "\n",
      "\n",
      "loss before training is 3.839637491553765e-07 -- epoch number 9671\n",
      "\n",
      "\n",
      "loss before training is 3.835972512790383e-07 -- epoch number 9672\n",
      "\n",
      "\n",
      "loss before training is 3.832311322991128e-07 -- epoch number 9673\n",
      "\n",
      "\n",
      "loss before training is 3.8286539178779877e-07 -- epoch number 9674\n",
      "\n",
      "\n",
      "loss before training is 3.8250002931773486e-07 -- epoch number 9675\n",
      "\n",
      "\n",
      "loss before training is 3.821350444623114e-07 -- epoch number 9676\n",
      "\n",
      "\n",
      "loss before training is 3.817704367952351e-07 -- epoch number 9677\n",
      "\n",
      "\n",
      "loss before training is 3.814062058907708e-07 -- epoch number 9678\n",
      "\n",
      "\n",
      "loss before training is 3.810423513238677e-07 -- epoch number 9679\n",
      "\n",
      "\n",
      "loss before training is 3.806788726698187e-07 -- epoch number 9680\n",
      "\n",
      "\n",
      "loss before training is 3.8031576950461507e-07 -- epoch number 9681\n",
      "\n",
      "\n",
      "loss before training is 3.799530414046266e-07 -- epoch number 9682\n",
      "\n",
      "\n",
      "loss before training is 3.79590687946752e-07 -- epoch number 9683\n",
      "\n",
      "\n",
      "loss before training is 3.7922870870846843e-07 -- epoch number 9684\n",
      "\n",
      "\n",
      "loss before training is 3.7886710326780273e-07 -- epoch number 9685\n",
      "\n",
      "\n",
      "loss before training is 3.785058712032461e-07 -- epoch number 9686\n",
      "\n",
      "\n",
      "loss before training is 3.781450120938214e-07 -- epoch number 9687\n",
      "\n",
      "\n",
      "loss before training is 3.7778452551907475e-07 -- epoch number 9688\n",
      "\n",
      "\n",
      "loss before training is 3.774244110591216e-07 -- epoch number 9689\n",
      "\n",
      "\n",
      "loss before training is 3.770646682945085e-07 -- epoch number 9690\n",
      "\n",
      "\n",
      "loss before training is 3.7670529680633267e-07 -- epoch number 9691\n",
      "\n",
      "\n",
      "loss before training is 3.7634629617630595e-07 -- epoch number 9692\n",
      "\n",
      "\n",
      "loss before training is 3.7598766598638895e-07 -- epoch number 9693\n",
      "\n",
      "\n",
      "loss before training is 3.7562940581947033e-07 -- epoch number 9694\n",
      "\n",
      "\n",
      "loss before training is 3.7527151525857877e-07 -- epoch number 9695\n",
      "\n",
      "\n",
      "loss before training is 3.749139938874337e-07 -- epoch number 9696\n",
      "\n",
      "\n",
      "loss before training is 3.745568412902075e-07 -- epoch number 9697\n",
      "\n",
      "\n",
      "loss before training is 3.7420005705176276e-07 -- epoch number 9698\n",
      "\n",
      "\n",
      "loss before training is 3.7384364075718047e-07 -- epoch number 9699\n",
      "\n",
      "\n",
      "loss before training is 3.7348759199217235e-07 -- epoch number 9700\n",
      "\n",
      "\n",
      "loss before training is 3.7313191034318795e-07 -- epoch number 9701\n",
      "\n",
      "\n",
      "loss before training is 3.7277659539679006e-07 -- epoch number 9702\n",
      "\n",
      "\n",
      "loss before training is 3.724216467403089e-07 -- epoch number 9703\n",
      "\n",
      "\n",
      "loss before training is 3.72067063961605e-07 -- epoch number 9704\n",
      "\n",
      "\n",
      "loss before training is 3.7171284664884194e-07 -- epoch number 9705\n",
      "\n",
      "\n",
      "loss before training is 3.7135899439103765e-07 -- epoch number 9706\n",
      "\n",
      "\n",
      "loss before training is 3.7100550677719105e-07 -- epoch number 9707\n",
      "\n",
      "\n",
      "loss before training is 3.7065238339742306e-07 -- epoch number 9708\n",
      "\n",
      "\n",
      "loss before training is 3.702996238418291e-07 -- epoch number 9709\n",
      "\n",
      "\n",
      "loss before training is 3.6994722770124254e-07 -- epoch number 9710\n",
      "\n",
      "\n",
      "loss before training is 3.695951945672634e-07 -- epoch number 9711\n",
      "\n",
      "\n",
      "loss before training is 3.6924352403141276e-07 -- epoch number 9712\n",
      "\n",
      "\n",
      "loss before training is 3.6889221568610484e-07 -- epoch number 9713\n",
      "\n",
      "\n",
      "loss before training is 3.685412691242288e-07 -- epoch number 9714\n",
      "\n",
      "\n",
      "loss before training is 3.6819068393913413e-07 -- epoch number 9715\n",
      "\n",
      "\n",
      "loss before training is 3.6784045972469975e-07 -- epoch number 9716\n",
      "\n",
      "\n",
      "loss before training is 3.674905960750557e-07 -- epoch number 9717\n",
      "\n",
      "\n",
      "loss before training is 3.6714109258532865e-07 -- epoch number 9718\n",
      "\n",
      "\n",
      "loss before training is 3.6679194885070414e-07 -- epoch number 9719\n",
      "\n",
      "\n",
      "loss before training is 3.6644316446707057e-07 -- epoch number 9720\n",
      "\n",
      "\n",
      "loss before training is 3.6609473903066805e-07 -- epoch number 9721\n",
      "\n",
      "\n",
      "loss before training is 3.6574667213841233e-07 -- epoch number 9722\n",
      "\n",
      "\n",
      "loss before training is 3.653989633876567e-07 -- epoch number 9723\n",
      "\n",
      "\n",
      "loss before training is 3.650516123762064e-07 -- epoch number 9724\n",
      "\n",
      "\n",
      "loss before training is 3.647046187023479e-07 -- epoch number 9725\n",
      "\n",
      "\n",
      "loss before training is 3.6435798196485565e-07 -- epoch number 9726\n",
      "\n",
      "\n",
      "loss before training is 3.640117017632018e-07 -- epoch number 9727\n",
      "\n",
      "\n",
      "loss before training is 3.6366577769702633e-07 -- epoch number 9728\n",
      "\n",
      "\n",
      "loss before training is 3.633202093668341e-07 -- epoch number 9729\n",
      "\n",
      "\n",
      "loss before training is 3.629749963731163e-07 -- epoch number 9730\n",
      "\n",
      "\n",
      "loss before training is 3.62630138317443e-07 -- epoch number 9731\n",
      "\n",
      "\n",
      "loss before training is 3.622856348012365e-07 -- epoch number 9732\n",
      "\n",
      "\n",
      "loss before training is 3.619414854271993e-07 -- epoch number 9733\n",
      "\n",
      "\n",
      "loss before training is 3.615976897976723e-07 -- epoch number 9734\n",
      "\n",
      "\n",
      "loss before training is 3.6125424751611076e-07 -- epoch number 9735\n",
      "\n",
      "\n",
      "loss before training is 3.6091115818624014e-07 -- epoch number 9736\n",
      "\n",
      "\n",
      "loss before training is 3.605684214122015e-07 -- epoch number 9737\n",
      "\n",
      "\n",
      "loss before training is 3.6022603679872143e-07 -- epoch number 9738\n",
      "\n",
      "\n",
      "loss before training is 3.5988400395095085e-07 -- epoch number 9739\n",
      "\n",
      "\n",
      "loss before training is 3.59542322474621e-07 -- epoch number 9740\n",
      "\n",
      "\n",
      "loss before training is 3.592009919757355e-07 -- epoch number 9741\n",
      "\n",
      "\n",
      "loss before training is 3.588600120612255e-07 -- epoch number 9742\n",
      "\n",
      "\n",
      "loss before training is 3.585193823379102e-07 -- epoch number 9743\n",
      "\n",
      "\n",
      "loss before training is 3.5817910241356174e-07 -- epoch number 9744\n",
      "\n",
      "\n",
      "loss before training is 3.5783917189624185e-07 -- epoch number 9745\n",
      "\n",
      "\n",
      "loss before training is 3.5749959039444203e-07 -- epoch number 9746\n",
      "\n",
      "\n",
      "loss before training is 3.5716035751730047e-07 -- epoch number 9747\n",
      "\n",
      "\n",
      "loss before training is 3.568214728743508e-07 -- epoch number 9748\n",
      "\n",
      "\n",
      "loss before training is 3.5648293607552065e-07 -- epoch number 9749\n",
      "\n",
      "\n",
      "loss before training is 3.5614474673135813e-07 -- epoch number 9750\n",
      "\n",
      "\n",
      "loss before training is 3.5580690445272164e-07 -- epoch number 9751\n",
      "\n",
      "\n",
      "loss before training is 3.554694088511639e-07 -- epoch number 9752\n",
      "\n",
      "\n",
      "loss before training is 3.5513225953865696e-07 -- epoch number 9753\n",
      "\n",
      "\n",
      "loss before training is 3.547954561273505e-07 -- epoch number 9754\n",
      "\n",
      "\n",
      "loss before training is 3.5445899823043376e-07 -- epoch number 9755\n",
      "\n",
      "\n",
      "loss before training is 3.5412288546105764e-07 -- epoch number 9756\n",
      "\n",
      "\n",
      "loss before training is 3.537871174329597e-07 -- epoch number 9757\n",
      "\n",
      "\n",
      "loss before training is 3.5345169376072286e-07 -- epoch number 9758\n",
      "\n",
      "\n",
      "loss before training is 3.5311661405875516e-07 -- epoch number 9759\n",
      "\n",
      "\n",
      "loss before training is 3.527818779426597e-07 -- epoch number 9760\n",
      "\n",
      "\n",
      "loss before training is 3.5244748502785584e-07 -- epoch number 9761\n",
      "\n",
      "\n",
      "loss before training is 3.521134349306201e-07 -- epoch number 9762\n",
      "\n",
      "\n",
      "loss before training is 3.5177972726766856e-07 -- epoch number 9763\n",
      "\n",
      "\n",
      "loss before training is 3.5144636165610375e-07 -- epoch number 9764\n",
      "\n",
      "\n",
      "loss before training is 3.511133377134e-07 -- epoch number 9765\n",
      "\n",
      "\n",
      "loss before training is 3.5078065505780557e-07 -- epoch number 9766\n",
      "\n",
      "\n",
      "loss before training is 3.5044831330759206e-07 -- epoch number 9767\n",
      "\n",
      "\n",
      "loss before training is 3.501163120820267e-07 -- epoch number 9768\n",
      "\n",
      "\n",
      "loss before training is 3.49784651000449e-07 -- epoch number 9769\n",
      "\n",
      "\n",
      "loss before training is 3.494533296827891e-07 -- epoch number 9770\n",
      "\n",
      "\n",
      "loss before training is 3.4912234774943144e-07 -- epoch number 9771\n",
      "\n",
      "\n",
      "loss before training is 3.4879170482124273e-07 -- epoch number 9772\n",
      "\n",
      "\n",
      "loss before training is 3.4846140051945697e-07 -- epoch number 9773\n",
      "\n",
      "\n",
      "loss before training is 3.481314344659524e-07 -- epoch number 9774\n",
      "\n",
      "\n",
      "loss before training is 3.478018062830299e-07 -- epoch number 9775\n",
      "\n",
      "\n",
      "loss before training is 3.4747251559338066e-07 -- epoch number 9776\n",
      "\n",
      "\n",
      "loss before training is 3.471435620200865e-07 -- epoch number 9777\n",
      "\n",
      "\n",
      "loss before training is 3.468149451868421e-07 -- epoch number 9778\n",
      "\n",
      "\n",
      "loss before training is 3.464866647177272e-07 -- epoch number 9779\n",
      "\n",
      "\n",
      "loss before training is 3.4615872023730426e-07 -- epoch number 9780\n",
      "\n",
      "\n",
      "loss before training is 3.4583111137061924e-07 -- epoch number 9781\n",
      "\n",
      "\n",
      "loss before training is 3.45503837743053e-07 -- epoch number 9782\n",
      "\n",
      "\n",
      "loss before training is 3.451768989806173e-07 -- epoch number 9783\n",
      "\n",
      "\n",
      "loss before training is 3.448502947097009e-07 -- epoch number 9784\n",
      "\n",
      "\n",
      "loss before training is 3.4452402455718315e-07 -- epoch number 9785\n",
      "\n",
      "\n",
      "loss before training is 3.4419808815019495e-07 -- epoch number 9786\n",
      "\n",
      "\n",
      "loss before training is 3.4387248511662244e-07 -- epoch number 9787\n",
      "\n",
      "\n",
      "loss before training is 3.4354721508471127e-07 -- epoch number 9788\n",
      "\n",
      "\n",
      "loss before training is 3.4322227768299456e-07 -- epoch number 9789\n",
      "\n",
      "\n",
      "loss before training is 3.4289767254076993e-07 -- epoch number 9790\n",
      "\n",
      "\n",
      "loss before training is 3.4257339928740704e-07 -- epoch number 9791\n",
      "\n",
      "\n",
      "loss before training is 3.422494575531062e-07 -- epoch number 9792\n",
      "\n",
      "\n",
      "loss before training is 3.4192584696820324e-07 -- epoch number 9793\n",
      "\n",
      "\n",
      "loss before training is 3.4160256716380197e-07 -- epoch number 9794\n",
      "\n",
      "\n",
      "loss before training is 3.4127961777120405e-07 -- epoch number 9795\n",
      "\n",
      "\n",
      "loss before training is 3.4095699842215346e-07 -- epoch number 9796\n",
      "\n",
      "\n",
      "loss before training is 3.406347087489922e-07 -- epoch number 9797\n",
      "\n",
      "\n",
      "loss before training is 3.4031274838435763e-07 -- epoch number 9798\n",
      "\n",
      "\n",
      "loss before training is 3.3999111696167313e-07 -- epoch number 9799\n",
      "\n",
      "\n",
      "loss before training is 3.396698141142508e-07 -- epoch number 9800\n",
      "\n",
      "\n",
      "loss before training is 3.3934883947645397e-07 -- epoch number 9801\n",
      "\n",
      "\n",
      "loss before training is 3.39028192682609e-07 -- epoch number 9802\n",
      "\n",
      "\n",
      "loss before training is 3.387078733677653e-07 -- epoch number 9803\n",
      "\n",
      "\n",
      "loss before training is 3.3838788116728513e-07 -- epoch number 9804\n",
      "\n",
      "\n",
      "loss before training is 3.3806821571712297e-07 -- epoch number 9805\n",
      "\n",
      "\n",
      "loss before training is 3.377488766534609e-07 -- epoch number 9806\n",
      "\n",
      "\n",
      "loss before training is 3.374298636130141e-07 -- epoch number 9807\n",
      "\n",
      "\n",
      "loss before training is 3.371111762330391e-07 -- epoch number 9808\n",
      "\n",
      "\n",
      "loss before training is 3.3679281415123686e-07 -- epoch number 9809\n",
      "\n",
      "\n",
      "loss before training is 3.3647477700550366e-07 -- epoch number 9810\n",
      "\n",
      "\n",
      "loss before training is 3.361570644345377e-07 -- epoch number 9811\n",
      "\n",
      "\n",
      "loss before training is 3.3583967607713877e-07 -- epoch number 9812\n",
      "\n",
      "\n",
      "loss before training is 3.3552261157276354e-07 -- epoch number 9813\n",
      "\n",
      "\n",
      "loss before training is 3.3520587056131295e-07 -- epoch number 9814\n",
      "\n",
      "\n",
      "loss before training is 3.3488945268294893e-07 -- epoch number 9815\n",
      "\n",
      "\n",
      "loss before training is 3.3457335757829635e-07 -- epoch number 9816\n",
      "\n",
      "\n",
      "loss before training is 3.342575848887399e-07 -- epoch number 9817\n",
      "\n",
      "\n",
      "loss before training is 3.339421342557512e-07 -- epoch number 9818\n",
      "\n",
      "\n",
      "loss before training is 3.3362700532128536e-07 -- epoch number 9819\n",
      "\n",
      "\n",
      "loss before training is 3.333121977279291e-07 -- epoch number 9820\n",
      "\n",
      "\n",
      "loss before training is 3.3299771111852144e-07 -- epoch number 9821\n",
      "\n",
      "\n",
      "loss before training is 3.326835451363243e-07 -- epoch number 9822\n",
      "\n",
      "\n",
      "loss before training is 3.323696994251045e-07 -- epoch number 9823\n",
      "\n",
      "\n",
      "loss before training is 3.3205617362912807e-07 -- epoch number 9824\n",
      "\n",
      "\n",
      "loss before training is 3.317429673929773e-07 -- epoch number 9825\n",
      "\n",
      "\n",
      "loss before training is 3.3143008036177653e-07 -- epoch number 9826\n",
      "\n",
      "\n",
      "loss before training is 3.3111751218082575e-07 -- epoch number 9827\n",
      "\n",
      "\n",
      "loss before training is 3.30805262496388e-07 -- epoch number 9828\n",
      "\n",
      "\n",
      "loss before training is 3.3049333095455626e-07 -- epoch number 9829\n",
      "\n",
      "\n",
      "loss before training is 3.3018171720214467e-07 -- epoch number 9830\n",
      "\n",
      "\n",
      "loss before training is 3.29870420886395e-07 -- epoch number 9831\n",
      "\n",
      "\n",
      "loss before training is 3.295594416548934e-07 -- epoch number 9832\n",
      "\n",
      "\n",
      "loss before training is 3.2924877915589533e-07 -- epoch number 9833\n",
      "\n",
      "\n",
      "loss before training is 3.289384330377428e-07 -- epoch number 9834\n",
      "\n",
      "\n",
      "loss before training is 3.2862840294944407e-07 -- epoch number 9835\n",
      "\n",
      "\n",
      "loss before training is 3.283186885402897e-07 -- epoch number 9836\n",
      "\n",
      "\n",
      "loss before training is 3.2800928946002407e-07 -- epoch number 9837\n",
      "\n",
      "\n",
      "loss before training is 3.2770020535891015e-07 -- epoch number 9838\n",
      "\n",
      "\n",
      "loss before training is 3.2739143588758146e-07 -- epoch number 9839\n",
      "\n",
      "\n",
      "loss before training is 3.2708298069715015e-07 -- epoch number 9840\n",
      "\n",
      "\n",
      "loss before training is 3.267748394389878e-07 -- epoch number 9841\n",
      "\n",
      "\n",
      "loss before training is 3.264670117650511e-07 -- epoch number 9842\n",
      "\n",
      "\n",
      "loss before training is 3.261594973276658e-07 -- epoch number 9843\n",
      "\n",
      "\n",
      "loss before training is 3.258522957796872e-07 -- epoch number 9844\n",
      "\n",
      "\n",
      "loss before training is 3.255454067739926e-07 -- epoch number 9845\n",
      "\n",
      "\n",
      "loss before training is 3.252388299645086e-07 -- epoch number 9846\n",
      "\n",
      "\n",
      "loss before training is 3.249325650050053e-07 -- epoch number 9847\n",
      "\n",
      "\n",
      "loss before training is 3.246266115500553e-07 -- epoch number 9848\n",
      "\n",
      "\n",
      "loss before training is 3.24320969254453e-07 -- epoch number 9849\n",
      "\n",
      "\n",
      "loss before training is 3.2401563777344586e-07 -- epoch number 9850\n",
      "\n",
      "\n",
      "loss before training is 3.2371061676272706e-07 -- epoch number 9851\n",
      "\n",
      "\n",
      "loss before training is 3.234059058784207e-07 -- epoch number 9852\n",
      "\n",
      "\n",
      "loss before training is 3.2310150477712714e-07 -- epoch number 9853\n",
      "\n",
      "\n",
      "loss before training is 3.227974131156674e-07 -- epoch number 9854\n",
      "\n",
      "\n",
      "loss before training is 3.224936305515387e-07 -- epoch number 9855\n",
      "\n",
      "\n",
      "loss before training is 3.221901567424032e-07 -- epoch number 9856\n",
      "\n",
      "\n",
      "loss before training is 3.2188699134636027e-07 -- epoch number 9857\n",
      "\n",
      "\n",
      "loss before training is 3.2158413402219355e-07 -- epoch number 9858\n",
      "\n",
      "\n",
      "loss before training is 3.2128158442886046e-07 -- epoch number 9859\n",
      "\n",
      "\n",
      "loss before training is 3.2097934222579474e-07 -- epoch number 9860\n",
      "\n",
      "\n",
      "loss before training is 3.206774070728103e-07 -- epoch number 9861\n",
      "\n",
      "\n",
      "loss before training is 3.20375778630181e-07 -- epoch number 9862\n",
      "\n",
      "\n",
      "loss before training is 3.20074456558557e-07 -- epoch number 9863\n",
      "\n",
      "\n",
      "loss before training is 3.1977344051900477e-07 -- epoch number 9864\n",
      "\n",
      "\n",
      "loss before training is 3.1947273017302045e-07 -- epoch number 9865\n",
      "\n",
      "\n",
      "loss before training is 3.191723251825492e-07 -- epoch number 9866\n",
      "\n",
      "\n",
      "loss before training is 3.188722252098746e-07 -- epoch number 9867\n",
      "\n",
      "\n",
      "loss before training is 3.1857242991776935e-07 -- epoch number 9868\n",
      "\n",
      "\n",
      "loss before training is 3.182729389691604e-07 -- epoch number 9869\n",
      "\n",
      "\n",
      "loss before training is 3.179737520278474e-07 -- epoch number 9870\n",
      "\n",
      "\n",
      "loss before training is 3.1767486875759626e-07 -- epoch number 9871\n",
      "\n",
      "\n",
      "loss before training is 3.173762888228013e-07 -- epoch number 9872\n",
      "\n",
      "\n",
      "loss before training is 3.170780118882443e-07 -- epoch number 9873\n",
      "\n",
      "\n",
      "loss before training is 3.1678003761899165e-07 -- epoch number 9874\n",
      "\n",
      "\n",
      "loss before training is 3.1648236568069753e-07 -- epoch number 9875\n",
      "\n",
      "\n",
      "loss before training is 3.161849957393393e-07 -- epoch number 9876\n",
      "\n",
      "\n",
      "loss before training is 3.158879274613097e-07 -- epoch number 9877\n",
      "\n",
      "\n",
      "loss before training is 3.1559116051337545e-07 -- epoch number 9878\n",
      "\n",
      "\n",
      "loss before training is 3.1529469456255126e-07 -- epoch number 9879\n",
      "\n",
      "\n",
      "loss before training is 3.1499852927671403e-07 -- epoch number 9880\n",
      "\n",
      "\n",
      "loss before training is 3.147026643236022e-07 -- epoch number 9881\n",
      "\n",
      "\n",
      "loss before training is 3.1440709937170827e-07 -- epoch number 9882\n",
      "\n",
      "\n",
      "loss before training is 3.1411183408984477e-07 -- epoch number 9883\n",
      "\n",
      "\n",
      "loss before training is 3.138168681470962e-07 -- epoch number 9884\n",
      "\n",
      "\n",
      "loss before training is 3.135222012132328e-07 -- epoch number 9885\n",
      "\n",
      "\n",
      "loss before training is 3.132278329580284e-07 -- epoch number 9886\n",
      "\n",
      "\n",
      "loss before training is 3.12933763052088e-07 -- epoch number 9887\n",
      "\n",
      "\n",
      "loss before training is 3.1263999116606064e-07 -- epoch number 9888\n",
      "\n",
      "\n",
      "loss before training is 3.1234651697110774e-07 -- epoch number 9889\n",
      "\n",
      "\n",
      "loss before training is 3.1205334013883975e-07 -- epoch number 9890\n",
      "\n",
      "\n",
      "loss before training is 3.1176046034131575e-07 -- epoch number 9891\n",
      "\n",
      "\n",
      "loss before training is 3.1146787725091217e-07 -- epoch number 9892\n",
      "\n",
      "\n",
      "loss before training is 3.1117559054024413e-07 -- epoch number 9893\n",
      "\n",
      "\n",
      "loss before training is 3.1088359988267236e-07 -- epoch number 9894\n",
      "\n",
      "\n",
      "loss before training is 3.105919049515094e-07 -- epoch number 9895\n",
      "\n",
      "\n",
      "loss before training is 3.103005054209736e-07 -- epoch number 9896\n",
      "\n",
      "\n",
      "loss before training is 3.1000940096523317e-07 -- epoch number 9897\n",
      "\n",
      "\n",
      "loss before training is 3.097185912591388e-07 -- epoch number 9898\n",
      "\n",
      "\n",
      "loss before training is 3.094280759778223e-07 -- epoch number 9899\n",
      "\n",
      "\n",
      "loss before training is 3.091378547966786e-07 -- epoch number 9900\n",
      "\n",
      "\n",
      "loss before training is 3.0884792739176424e-07 -- epoch number 9901\n",
      "\n",
      "\n",
      "loss before training is 3.0855829343940835e-07 -- epoch number 9902\n",
      "\n",
      "\n",
      "loss before training is 3.0826895261612224e-07 -- epoch number 9903\n",
      "\n",
      "\n",
      "loss before training is 3.079799045992132e-07 -- epoch number 9904\n",
      "\n",
      "\n",
      "loss before training is 3.0769114906610394e-07 -- epoch number 9905\n",
      "\n",
      "\n",
      "loss before training is 3.074026856945328e-07 -- epoch number 9906\n",
      "\n",
      "\n",
      "loss before training is 3.0711451416290944e-07 -- epoch number 9907\n",
      "\n",
      "\n",
      "loss before training is 3.0682663414977196e-07 -- epoch number 9908\n",
      "\n",
      "\n",
      "loss before training is 3.0653904533425013e-07 -- epoch number 9909\n",
      "\n",
      "\n",
      "loss before training is 3.0625174739565313e-07 -- epoch number 9910\n",
      "\n",
      "\n",
      "loss before training is 3.059647400138229e-07 -- epoch number 9911\n",
      "\n",
      "\n",
      "loss before training is 3.056780228691133e-07 -- epoch number 9912\n",
      "\n",
      "\n",
      "loss before training is 3.053915956418398e-07 -- epoch number 9913\n",
      "\n",
      "\n",
      "loss before training is 3.051054580132196e-07 -- epoch number 9914\n",
      "\n",
      "\n",
      "loss before training is 3.04819609664302e-07 -- epoch number 9915\n",
      "\n",
      "\n",
      "loss before training is 3.0453405027715793e-07 -- epoch number 9916\n",
      "\n",
      "\n",
      "loss before training is 3.042487795336336e-07 -- epoch number 9917\n",
      "\n",
      "\n",
      "loss before training is 3.039637971163278e-07 -- epoch number 9918\n",
      "\n",
      "\n",
      "loss before training is 3.0367910270813347e-07 -- epoch number 9919\n",
      "\n",
      "\n",
      "loss before training is 3.033946959922739e-07 -- epoch number 9920\n",
      "\n",
      "\n",
      "loss before training is 3.03110576652495e-07 -- epoch number 9921\n",
      "\n",
      "\n",
      "loss before training is 3.0282674437259144e-07 -- epoch number 9922\n",
      "\n",
      "\n",
      "loss before training is 3.0254319883722496e-07 -- epoch number 9923\n",
      "\n",
      "\n",
      "loss before training is 3.022599397310094e-07 -- epoch number 9924\n",
      "\n",
      "\n",
      "loss before training is 3.0197696673920974e-07 -- epoch number 9925\n",
      "\n",
      "\n",
      "loss before training is 3.0169427954736583e-07 -- epoch number 9926\n",
      "\n",
      "\n",
      "loss before training is 3.0141187784125817e-07 -- epoch number 9927\n",
      "\n",
      "\n",
      "loss before training is 3.011297613073732e-07 -- epoch number 9928\n",
      "\n",
      "\n",
      "loss before training is 3.0084792963219924e-07 -- epoch number 9929\n",
      "\n",
      "\n",
      "loss before training is 3.0056638250301777e-07 -- epoch number 9930\n",
      "\n",
      "\n",
      "loss before training is 3.0028511960698717e-07 -- epoch number 9931\n",
      "\n",
      "\n",
      "loss before training is 3.000041406321722e-07 -- epoch number 9932\n",
      "\n",
      "\n",
      "loss before training is 2.99723445266576e-07 -- epoch number 9933\n",
      "\n",
      "\n",
      "loss before training is 2.994430331988767e-07 -- epoch number 9934\n",
      "\n",
      "\n",
      "loss before training is 2.991629041179173e-07 -- epoch number 9935\n",
      "\n",
      "\n",
      "loss before training is 2.988830577130564e-07 -- epoch number 9936\n",
      "\n",
      "\n",
      "loss before training is 2.9860349367384124e-07 -- epoch number 9937\n",
      "\n",
      "\n",
      "loss before training is 2.983242116905654e-07 -- epoch number 9938\n",
      "\n",
      "\n",
      "loss before training is 2.980452114534301e-07 -- epoch number 9939\n",
      "\n",
      "\n",
      "loss before training is 2.977664926533853e-07 -- epoch number 9940\n",
      "\n",
      "\n",
      "loss before training is 2.974880549815505e-07 -- epoch number 9941\n",
      "\n",
      "\n",
      "loss before training is 2.9720989812931896e-07 -- epoch number 9942\n",
      "\n",
      "\n",
      "loss before training is 2.969320217887296e-07 -- epoch number 9943\n",
      "\n",
      "\n",
      "loss before training is 2.966544256521961e-07 -- epoch number 9944\n",
      "\n",
      "\n",
      "loss before training is 2.9637710941209953e-07 -- epoch number 9945\n",
      "\n",
      "\n",
      "loss before training is 2.96100072761547e-07 -- epoch number 9946\n",
      "\n",
      "\n",
      "loss before training is 2.958233153940236e-07 -- epoch number 9947\n",
      "\n",
      "\n",
      "loss before training is 2.9554683700328626e-07 -- epoch number 9948\n",
      "\n",
      "\n",
      "loss before training is 2.9527063728326164e-07 -- epoch number 9949\n",
      "\n",
      "\n",
      "loss before training is 2.9499471592860934e-07 -- epoch number 9950\n",
      "\n",
      "\n",
      "loss before training is 2.947190726342206e-07 -- epoch number 9951\n",
      "\n",
      "\n",
      "loss before training is 2.944437070951485e-07 -- epoch number 9952\n",
      "\n",
      "\n",
      "loss before training is 2.9416861900704823e-07 -- epoch number 9953\n",
      "\n",
      "\n",
      "loss before training is 2.9389380806600636e-07 -- epoch number 9954\n",
      "\n",
      "\n",
      "loss before training is 2.936192739681364e-07 -- epoch number 9955\n",
      "\n",
      "\n",
      "loss before training is 2.933450164102031e-07 -- epoch number 9956\n",
      "\n",
      "\n",
      "loss before training is 2.930710350892946e-07 -- epoch number 9957\n",
      "\n",
      "\n",
      "loss before training is 2.927973297027723e-07 -- epoch number 9958\n",
      "\n",
      "\n",
      "loss before training is 2.925238999484047e-07 -- epoch number 9959\n",
      "\n",
      "\n",
      "loss before training is 2.922507455242934e-07 -- epoch number 9960\n",
      "\n",
      "\n",
      "loss before training is 2.919778661290377e-07 -- epoch number 9961\n",
      "\n",
      "\n",
      "loss before training is 2.9170526146147273e-07 -- epoch number 9962\n",
      "\n",
      "\n",
      "loss before training is 2.9143293122069645e-07 -- epoch number 9963\n",
      "\n",
      "\n",
      "loss before training is 2.9116087510640324e-07 -- epoch number 9964\n",
      "\n",
      "\n",
      "loss before training is 2.90889092818484e-07 -- epoch number 9965\n",
      "\n",
      "\n",
      "loss before training is 2.9061758405730174e-07 -- epoch number 9966\n",
      "\n",
      "\n",
      "loss before training is 2.9034634852345566e-07 -- epoch number 9967\n",
      "\n",
      "\n",
      "loss before training is 2.9007538591797953e-07 -- epoch number 9968\n",
      "\n",
      "\n",
      "loss before training is 2.898046959421603e-07 -- epoch number 9969\n",
      "\n",
      "\n",
      "loss before training is 2.8953427829782227e-07 -- epoch number 9970\n",
      "\n",
      "\n",
      "loss before training is 2.892641326870964e-07 -- epoch number 9971\n",
      "\n",
      "\n",
      "loss before training is 2.8899425881235e-07 -- epoch number 9972\n",
      "\n",
      "\n",
      "loss before training is 2.887246563763354e-07 -- epoch number 9973\n",
      "\n",
      "\n",
      "loss before training is 2.8845532508239435e-07 -- epoch number 9974\n",
      "\n",
      "\n",
      "loss before training is 2.8818626463377243e-07 -- epoch number 9975\n",
      "\n",
      "\n",
      "loss before training is 2.879174747345747e-07 -- epoch number 9976\n",
      "\n",
      "\n",
      "loss before training is 2.8764895508887586e-07 -- epoch number 9977\n",
      "\n",
      "\n",
      "loss before training is 2.8738070540142933e-07 -- epoch number 9978\n",
      "\n",
      "\n",
      "loss before training is 2.871127253769949e-07 -- epoch number 9979\n",
      "\n",
      "\n",
      "loss before training is 2.8684501472089166e-07 -- epoch number 9980\n",
      "\n",
      "\n",
      "loss before training is 2.865775731386878e-07 -- epoch number 9981\n",
      "\n",
      "\n",
      "loss before training is 2.8631040033657754e-07 -- epoch number 9982\n",
      "\n",
      "\n",
      "loss before training is 2.860434960206677e-07 -- epoch number 9983\n",
      "\n",
      "\n",
      "loss before training is 2.857768598977875e-07 -- epoch number 9984\n",
      "\n",
      "\n",
      "loss before training is 2.8551049167493475e-07 -- epoch number 9985\n",
      "\n",
      "\n",
      "loss before training is 2.852443910595293e-07 -- epoch number 9986\n",
      "\n",
      "\n",
      "loss before training is 2.8497855775921846e-07 -- epoch number 9987\n",
      "\n",
      "\n",
      "loss before training is 2.847129914822796e-07 -- epoch number 9988\n",
      "\n",
      "\n",
      "loss before training is 2.8444769193690184e-07 -- epoch number 9989\n",
      "\n",
      "\n",
      "loss before training is 2.841826588320657e-07 -- epoch number 9990\n",
      "\n",
      "\n",
      "loss before training is 2.839178918768436e-07 -- epoch number 9991\n",
      "\n",
      "\n",
      "loss before training is 2.8365339078066346e-07 -- epoch number 9992\n",
      "\n",
      "\n",
      "loss before training is 2.8338915525348457e-07 -- epoch number 9993\n",
      "\n",
      "\n",
      "loss before training is 2.8312518500536174e-07 -- epoch number 9994\n",
      "\n",
      "\n",
      "loss before training is 2.8286147974684515e-07 -- epoch number 9995\n",
      "\n",
      "\n",
      "loss before training is 2.825980391888222e-07 -- epoch number 9996\n",
      "\n",
      "\n",
      "loss before training is 2.823348630424945e-07 -- epoch number 9997\n",
      "\n",
      "\n",
      "loss before training is 2.8207195101938204e-07 -- epoch number 9998\n",
      "\n",
      "\n",
      "loss before training is 2.8180930283149965e-07 -- epoch number 9999\n",
      "\n",
      "\n",
      "loss before training is 2.815469181909573e-07 -- epoch number 10000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np  # importing NumPy\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "input_nodes = 5  # nodes in each layer\n",
    "hidden_1_nodes = 3\n",
    "hidden_2_nodes = 5\n",
    "output_nodes = 4\n",
    "\n",
    "x = np.random.randint(1, 100, size=(input_nodes, 1)) / 100\n",
    "x\n",
    "\n",
    "y = np.random.randint(1, 100, size=(output_nodes, 1)) / 100\n",
    "y\n",
    "\n",
    "\n",
    "def relu(x, leak=0):  # ReLU\n",
    "    return np.where(x <= 0, leak * x, x)\n",
    "\n",
    "\n",
    "def relu_dash(x, leak=0):  # ReLU derivative\n",
    "    return np.where(x <= 0, leak, 1)\n",
    "\n",
    "\n",
    "def sig(x):  # Sigmoid\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "\n",
    "def sig_dash(x):  # Sigmoid derivative\n",
    "    return sig(x) * (1 - sig(x))\n",
    "\n",
    "\n",
    "def mse(y_true, y_pred):  # MSE\n",
    "    return np.mean((y_true - y_pred) ** 2)\n",
    "\n",
    "\n",
    "def mse_grad(y_true, y_pred):  # MSE derivative\n",
    "    N = y_true.shape[0]\n",
    "    return -2 * (y_true - y_pred) / N\n",
    "\n",
    "\n",
    "w1 = np.random.random(size=(hidden_1_nodes, input_nodes))  # w1\n",
    "b1 = np.zeros(shape=(hidden_1_nodes, 1))  # b1\n",
    "\n",
    "w2 = np.random.random(size=(hidden_2_nodes, hidden_1_nodes))  # w2\n",
    "b2 = np.zeros(shape=(hidden_2_nodes, 1))  # b2\n",
    "\n",
    "w3 = np.random.random(size=(output_nodes, hidden_2_nodes))  # w3\n",
    "b3 = np.zeros(shape=(output_nodes, 1))  # b3\n",
    "\n",
    "in_hidden_1 = w1.dot(x) + b1  # forward feed\n",
    "out_hidden_1 = relu(in_hidden_1, leak=0.1)\n",
    "in_hidden_2 = w2.dot(out_hidden_1) + b2\n",
    "out_hidden_2 = sig(in_hidden_2)\n",
    "in_output_layer = w3.dot(out_hidden_2) + b3\n",
    "y_hat = sig(in_output_layer)\n",
    "print(\"y_hat\")  # y_hat\n",
    "print(y_hat)  # y_hat\n",
    "print(\"y\")  # y\n",
    "print(y)  # y\n",
    "print(\"mse(y, y_hat)\")  # MSE loss\n",
    "print(mse(y, y_hat))  # MSE loss\n",
    "\n",
    "learning_rate = 0.01\n",
    "epochs = 10000\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # ----------------------Forward Propagation--------------------------\n",
    "\n",
    "    in_hidden_1 = w1.dot(x) + b1\n",
    "    out_hidden_1 = relu(in_hidden_1, leak=0.1)\n",
    "    in_hidden_2 = w2.dot(out_hidden_1) + b2\n",
    "    out_hidden_2 = sig(in_hidden_2)\n",
    "    in_output_layer = w3.dot(out_hidden_2) + b3\n",
    "    y_hat = sig(in_output_layer)\n",
    "\n",
    "    loss = mse(y, y_hat)\n",
    "    print(f\"loss before training is {loss} -- epoch number {epoch + 1}\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "    # -------------------------- Gradient Calculation via Backpropagation ------------------------------ #\n",
    "\n",
    "    grad_w3 = mse_grad(y, y_hat) * sig_dash(in_output_layer).dot(\n",
    "        out_hidden_2.T\n",
    "    )  # grad_w3\n",
    "\n",
    "    grad_b3 = mse_grad(y, y_hat) * sig_dash(in_output_layer)  # grad_b3\n",
    "\n",
    "    error_grad_upto_H2 = np.sum(\n",
    "        mse_grad(y, y_hat) * sig_dash(in_output_layer) * w3, axis=0\n",
    "    ).reshape((-1, 1))\n",
    "    # error grad upto H2\n",
    "\n",
    "    grad_w2 = error_grad_upto_H2 * sig_dash(in_hidden_2).dot(out_hidden_1.T)  # grad w2\n",
    "\n",
    "    grad_b2 = error_grad_upto_H2 * sig_dash(in_hidden_2)  # grad b2\n",
    "\n",
    "    error_grad_upto_H1 = np.sum(\n",
    "        error_grad_upto_H2 * sig_dash(in_hidden_2) * w2, axis=0\n",
    "    ).reshape((-1, 1))\n",
    "    # error grad upto H1\n",
    "\n",
    "    grad_w1 = error_grad_upto_H1 * relu_dash(in_hidden_1, leak=0.1).dot(x.T)\n",
    "    # grad w1\n",
    "\n",
    "    grad_b1 = error_grad_upto_H1 * relu_dash(in_hidden_1, leak=0.1)\n",
    "    # grad b1\n",
    "\n",
    "    update_w1 = -learning_rate * grad_w1\n",
    "    w1 += update_w1  # w1\n",
    "\n",
    "    update_b1 = -learning_rate * grad_b1\n",
    "    b1 += update_b1  # b1\n",
    "\n",
    "    update_w2 = -learning_rate * grad_w2\n",
    "    w2 += update_w2  # w2\n",
    "\n",
    "    update_b2 = -learning_rate * grad_b2\n",
    "    b2 += update_b2  # b2\n",
    "\n",
    "    update_w3 = -learning_rate * grad_w3\n",
    "    w3 += update_w3  # w3\n",
    "\n",
    "    update_b3 = -learning_rate * grad_b3\n",
    "    b3 += update_b3  # b3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N y_hat\n",
      "[[0.21021091]\n",
      " [0.83087915]\n",
      " [0.86950084]\n",
      " [0.75024423]]\n",
      "N y\n",
      "[[0.21]\n",
      " [0.83]\n",
      " [0.87]\n",
      " [0.75]]\n",
      "N mse(y, y_hat)\n",
      "2.815469181909573e-07\n"
     ]
    }
   ],
   "source": [
    "print(\"N y_hat\")  # y_hat\n",
    "print(y_hat)  # y_hat\n",
    "print(\"N y\")  # y\n",
    "print(y)  # y\n",
    "print(\"N mse(y, y_hat)\")  # MSE loss\n",
    "print(mse(y, y_hat))  # MSE loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
