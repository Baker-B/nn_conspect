{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# neuralthreads\n",
    "[medium](https://neuralthreads.medium.com/i-was-not-satisfied-by-any-deep-learning-tutorials-online-37c5e9f4bea1)\n",
    "\n",
    "## Chapter 4 — Losses and their derivatives\n",
    "\n",
    "Categorical cross-entropy loss — The most important loss function\n",
    "\n",
    "### 4.3 What is Categorical cross-entropy loss and how to compute the gradients?\n",
    "\n",
    "This post is the most important post in the fourth chapter. Here we will talk about Categorical cross-entropy loss and what it means.\n",
    "\n",
    "Suppose I ask you ‘Who is this actor?’"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt text](image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And I give you 3 options.\n",
    "\n",
    "1. Chris Evans\n",
    "2. RDJ\n",
    "3. Chris Hemsworth\n",
    "\n",
    "We all know he is RDJ. So, the correct answer ‘y_true’ is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{gather*}\n",
       "\\newcommand{\\arraystretch}{1.5}\n",
       "    y\\_true = \n",
       "    \\begin{bmatrix*}\n",
       "    0 \\\\\n",
       "    1 \\\\\n",
       "    0\n",
       "    \\end{bmatrix*}\n",
       "\\end{gather*}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "\\begin{gather*}\n",
    "\\newcommand{\\arraystretch}{1.5}\n",
    "    y\\_true = \n",
    "    \\begin{bmatrix*}\n",
    "    0 \\\\\n",
    "    1 \\\\\n",
    "    0\n",
    "    \\end{bmatrix*}\n",
    "\\end{gather*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But, you don’t know who he is and you guess the answer with probabilities ‘y_pred’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{gather*}\n",
       "\\newcommand{\\arraystretch}{1.5}\n",
       "    y\\_pred =  \n",
       "    \\begin{bmatrix*}\n",
       "    0.2 \\\\\n",
       "    0.45 \\\\\n",
       "    0.35 \n",
       "    \\end{bmatrix*}\n",
       "\\end{gather*}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "\\begin{gather*}\n",
    "\\newcommand{\\arraystretch}{1.5}\n",
    "    y\\_pred =  \n",
    "    \\begin{bmatrix*}\n",
    "    0.2 \\\\\n",
    "    0.45 \\\\\n",
    "    0.35 \n",
    "    \\end{bmatrix*}\n",
    "\\end{gather*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two things,\n",
    "\n",
    "**First**, in both answers, i.e. correct and predicted, the sum of entries is equal to 1. Because they are probabilities or answers to the same question.\n",
    "\n",
    "**Second**, we can be optimistic and say that we will take the entry with the highest magnitude. In that case, your predicted answer is correct because the highest probability of 0.45 is of the second entry, i.e., RDJ. But there is still an error because the predicted answer for RDJ is not 1 or close to 1.\n",
    "\n",
    "Here, we will use Categorical cross-entropy loss.\n",
    "\n",
    "Suppose we have true values,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{gather*}\n",
       "\\newcommand{\\arraystretch}{1.5}\n",
       "    y\\_true = y =\n",
       "    \\begin{bmatrix*}\n",
       "    y_1 \\\\\n",
       "    y_2 \\\\\n",
       "    y_3\n",
       "    \\end{bmatrix*}\n",
       "\\end{gather*}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "\\begin{gather*}\n",
    "\\newcommand{\\arraystretch}{1.5}\n",
    "    y\\_true = y =\n",
    "    \\begin{bmatrix*}\n",
    "    y_1 \\\\\n",
    "    y_2 \\\\\n",
    "    y_3\n",
    "    \\end{bmatrix*}\n",
    "\\end{gather*}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and predicted values,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{gather*}\n",
       "\\newcommand{\\arraystretch}{1.5}\n",
       "    y\\_pred = \\hat{y} =\n",
       "    \\begin{bmatrix*}\n",
       "    \\hat{y_1} \\\\\n",
       "    \\hat{y_2} \\\\\n",
       "    \\hat{y_3}\n",
       "    \\end{bmatrix*}\n",
       "\\end{gather*}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "\\begin{gather*}\n",
    "\\newcommand{\\arraystretch}{1.5}\n",
    "    y\\_pred = \\hat{y} =\n",
    "    \\begin{bmatrix*}\n",
    "    \\hat{y_1} \\\\\n",
    "    \\hat{y_2} \\\\\n",
    "    \\hat{y_3}\n",
    "    \\end{bmatrix*}\n",
    "\\end{gather*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then Categorical cross-entropy liss is calculated as follow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected character after line continuation character (3550618597.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[9], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\u001b[0m\n\u001b[0m     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected character after line continuation character\n"
     ]
    }
   ],
   "source": [
    "\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can easily calculate Mean Absolute Error in Python like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np                             # importing NumPy\n",
    "np.random.seed(42)\n",
    "\n",
    "def mae(y_true, y_pred):                     # MSE\n",
    "    return np.mean(abs(y_true - y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we know that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{gather*}\n",
       "    MAE = f(\\hat{y_1},\\hat{y_2},\\hat{y_3})\n",
       "\\end{gather*}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "\\begin{gather*}\n",
    "    MAE = f(\\hat{y_1},\\hat{y_2},\\hat{y_3})\n",
    "\\end{gather*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, like MSE activation function, we have a **Jacobian** for MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{gather*}\n",
       "    \\newcommand{\\arraystretch}{2.5}\n",
       "    J = \\dfrac{\\partial{(MAE)}}{(\\hat{y_1},\\hat{y_2},\\hat{y_3})} =     \n",
       "    \\begin{bmatrix*}\n",
       "    \\dfrac{\\partial{(MAE)}}{\\partial(\\hat{y_1})} \\\\\n",
       "    \\dfrac{\\partial{(MAE)}}{\\partial(\\hat{y_2})} \\\\\n",
       "    \\dfrac{\\partial{(MAE)}}{\\partial(\\hat{y_3})} \n",
       "    \\end{bmatrix*}\n",
       "    \n",
       "\\end{gather*}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "\\begin{gather*}\n",
    "    \\newcommand{\\arraystretch}{2.5}\n",
    "    J = \\dfrac{\\partial{(MAE)}}{(\\hat{y_1},\\hat{y_2},\\hat{y_3})} =     \n",
    "    \\begin{bmatrix*}\n",
    "    \\dfrac{\\partial{(MAE)}}{\\partial(\\hat{y_1})} \\\\\n",
    "    \\dfrac{\\partial{(MAE)}}{\\partial(\\hat{y_2})} \\\\\n",
    "    \\dfrac{\\partial{(MAE)}}{\\partial(\\hat{y_3})} \n",
    "    \\end{bmatrix*}\n",
    "    \n",
    "\\end{gather*}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can easily find each term in this Jacobian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{gather*}\n",
       "    \\newcommand{\\arraystretch}{3}\n",
       "    \\Rightarrow J =  \n",
       "    \\begin{bmatrix*}\n",
       "      \\frac{-(y_1 - \\hat{y_1})}{3|y_1 - \\hat{y_1}|} \\\\\n",
       "      \\frac{-(y_2 - \\hat{y_2})}{3|y_2 - \\hat{y_2}|} \\\\ \n",
       "      \\frac{-(y_3 - \\hat{y_3})}{3|y_3 - \\hat{y_3}|} \\\\\n",
       "    \\end{bmatrix*} \\Rightarrow  \\\\\n",
       "    \\newcommand{\\arraystretch}{1.5}\n",
       "    \\Rightarrow J =  - \\frac{1}{3} (\n",
       "    \\begin{bmatrix*}\n",
       "      y_{1} - \\hat{y_{1}} \\\\\n",
       "      y_{2} - \\hat{y_{2}} \\\\ \n",
       "      y_{3} - \\hat{y_{3}} \\\\\n",
       "    \\end{bmatrix*} / \n",
       "    \\begin{bmatrix*}\n",
       "      |y_1 - \\hat{y_1}| \\\\\n",
       "      |y_2 - \\hat{y_2}| \\\\ \n",
       "      |y_3 - \\hat{y_3}| \\\\\n",
       "    \\end{bmatrix*}\n",
       "    ) \\Rightarrow  \\\\\n",
       "\n",
       "    \\\\\n",
       "  \\Rightarrow J = - \\frac{1}{3} \\frac{y\\_true - y\\_pred}{|y\\_true - y\\_pred|}\n",
       "\\end{gather*}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "\\begin{gather*}\n",
    "    \\newcommand{\\arraystretch}{3}\n",
    "    \\Rightarrow J =  \n",
    "    \\begin{bmatrix*}\n",
    "      \\frac{-(y_1 - \\hat{y_1})}{3|y_1 - \\hat{y_1}|} \\\\\n",
    "      \\frac{-(y_2 - \\hat{y_2})}{3|y_2 - \\hat{y_2}|} \\\\ \n",
    "      \\frac{-(y_3 - \\hat{y_3})}{3|y_3 - \\hat{y_3}|} \\\\\n",
    "    \\end{bmatrix*} \\Rightarrow  \\\\\n",
    "    \\newcommand{\\arraystretch}{1.5}\n",
    "    \\Rightarrow J =  - \\frac{1}{3} (\n",
    "    \\begin{bmatrix*}\n",
    "      y_{1} - \\hat{y_{1}} \\\\\n",
    "      y_{2} - \\hat{y_{2}} \\\\ \n",
    "      y_{3} - \\hat{y_{3}} \\\\\n",
    "    \\end{bmatrix*} / \n",
    "    \\begin{bmatrix*}\n",
    "      |y_1 - \\hat{y_1}| \\\\\n",
    "      |y_2 - \\hat{y_2}| \\\\ \n",
    "      |y_3 - \\hat{y_3}| \\\\\n",
    "    \\end{bmatrix*}\n",
    "    ) \\Rightarrow  \\\\\n",
    "\n",
    "    \\\\\n",
    "  \\Rightarrow J = - \\frac{1}{3} \\frac{y\\_true - y\\_pred}{|y\\_true - y\\_pred|}\n",
    "\\end{gather*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note — Here, 3 represents ‘N’, i.e., the entries in y_true and y_pred\n",
    "\n",
    "We can reduce it to define the MAE Jacobian in Python like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae_grad(y_true, y_pred):\n",
    "    N = y_true.shape[0]\n",
    "    return -((y_true - y_pred) / (abs(y_true - y_pred)+ 10**-100))/N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note — 10**-100 is for stability.\n",
    "\n",
    "Let us have a look at an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.5]\n",
      " [0.2]\n",
      " [3.9]\n",
      " [6.2]\n",
      " [5.2]]\n",
      "[[1.2]\n",
      " [0.5]\n",
      " [3.2]\n",
      " [4.2]\n",
      " [3.2]]\n",
      "(5, 1)\n"
     ]
    }
   ],
   "source": [
    "y_true = np.array([[1.5], [0.2], [3.9], [6.2], [5.2]])\n",
    "print(y_true)\n",
    "y_pred = np.array([[1.2], [0.5], [3.2], [4.2], [3.2]])\n",
    "print(y_pred)\n",
    "print(y_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.06"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.2],\n",
       "       [ 0.2],\n",
       "       [-0.2],\n",
       "       [-0.2],\n",
       "       [-0.2]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae_grad(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I hope you now understand how to implement Mean Absolute Error."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
